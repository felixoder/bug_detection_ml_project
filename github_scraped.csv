code,label
"    maintainer='root',
    maintainer_email='root@todo.todo',
    description='TODO: Package description',
    license='Apache-2.0',",buggy
"from pathlib import Path

        (str(Path('share') / package_name / 'assets'), list(map(str, Path('./assets').glob('*.png')))),
        (str(Path('share') / package_name / 'config'), list(map(str, Path('./config').glob('*.yaml')))),
        (str(Path('share') / package_name / 'launch'), list(map(str, Path('./launch').glob('*.xml')))),
        (str(Path('share') / package_name / 'models'), list(map(str, Path('./models').glob('*.blob')))),
        (str(Path('share') / package_name / 'models'), list(map(str, Path('./models').glob('*.yaml')))),
    maintainer='Duke Robotics',
    maintainer_email='hello@duke-robotics.com',
    description='Computer Vision pipeline, including DepthAI and HSV filtering.',
    license='MIT',
            'bin_detector = cv.bin_detector:main',
            'blue_rectangle_detector = cv.blue_rectangle_detector:main',
            'buoy_detector_contour_matching = cv.buoy_detector_contour_matching:main',
            'depthai_camera_connect = cv.depthai_camera_connect:main',
            'depthai_mono_detection = cv.depthai_mono_detection:main',
            'depthai_publish_save_streams = cv.depthai_publish_save_streams:main',
            'depthai_spatial_detection = cv.depthai_spatial_detection:main',
            'path_marker_detector = cv.path_marker_detector:main',
            'pink_bins_detector = cv.pink_bins_detector:main',
            'usb_camera_connect = cv.usb_camera_connect:main',
            'usb_camera = cv.usb_camera:main',",bug-free
"import requests
import json 
from datetime import datetime, timedelta, timezone
    project=""slimeify"",  # Google Cloud project ID
    database=""mlb-sluggers""  # Must be declared if it's not ""(default)""

# Function to construct the team logo URL
def get_team_logoUrl(teamId):
    return f'https://www.mlbstatic.com/team-logos/{teamId}.svg'
    teams = [
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/109.svg"",
                    ""name"": ""Arizona Diamondbacks"",
                    ""shortName"": ""D-backs"",
                    ""teamId"": 109
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/133.svg"",
                    ""name"": ""Athletics"",
                    ""shortName"": ""Athletics"",
                    ""teamId"": 133
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/144.svg"",
                    ""name"": ""Atlanta Braves"",
                    ""shortName"": ""Braves"",
                    ""teamId"": 144
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/110.svg"",
                    ""name"": ""Baltimore Orioles"",
                    ""shortName"": ""Orioles"",
                    ""teamId"": 110
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/111.svg"",
                    ""name"": ""Boston Red Sox"",
                    ""shortName"": ""Red Sox"",
                    ""teamId"": 111
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/112.svg"",
                    ""name"": ""Chicago Cubs"",
                    ""shortName"": ""Cubs"",
                    ""teamId"": 112
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/145.svg"",
                    ""name"": ""Chicago White Sox"",
                    ""shortName"": ""White Sox"",
                    ""teamId"": 145
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/113.svg"",
                    ""name"": ""Cincinnati Reds"",
                    ""shortName"": ""Reds"",
                    ""teamId"": 113
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/114.svg"",
                    ""name"": ""Cleveland Guardians"",
                    ""shortName"": ""Guardians"",
                    ""teamId"": 114
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/115.svg"",
                    ""name"": ""Colorado Rockies"",
                    ""shortName"": ""Rockies"",
                    ""teamId"": 115
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/116.svg"",
                    ""name"": ""Detroit Tigers"",
                    ""shortName"": ""Tigers"",
                    ""teamId"": 116
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/117.svg"",
                    ""name"": ""Houston Astros"",
                    ""shortName"": ""Astros"",
                    ""teamId"": 117
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/118.svg"",
                    ""name"": ""Kansas City Royals"",
                    ""shortName"": ""Royals"",
                    ""teamId"": 118
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/108.svg"",
                    ""name"": ""Los Angeles Angels"",
                    ""shortName"": ""Angels"",
                    ""teamId"": 108
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/119.svg"",
                    ""name"": ""Los Angeles Dodgers"",
                    ""shortName"": ""Dodgers"",
                    ""teamId"": 119
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/146.svg"",
                    ""name"": ""Miami Marlins"",
                    ""shortName"": ""Marlins"",
                    ""teamId"": 146
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/158.svg"",
                    ""name"": ""Milwaukee Brewers"",
                    ""shortName"": ""Brewers"",
                    ""teamId"": 158
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/142.svg"",
                    ""name"": ""Minnesota Twins"",
                    ""shortName"": ""Twins"",
                    ""teamId"": 142
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/121.svg"",
                    ""name"": ""New York Mets"",
                    ""shortName"": ""Mets"",
                    ""teamId"": 121
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/147.svg"",
                    ""name"": ""New York Yankees"",
                    ""shortName"": ""Yankees"",
                    ""teamId"": 147
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/143.svg"",
                    ""name"": ""Philadelphia Phillies"",
                    ""shortName"": ""Phillies"",
                    ""teamId"": 143
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/134.svg"",
                    ""name"": ""Pittsburgh Pirates"",
                    ""shortName"": ""Pirates"",
                    ""teamId"": 134
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/135.svg"",
                    ""name"": ""San Diego Padres"",
                    ""shortName"": ""Padres"",
                    ""teamId"": 135
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/137.svg"",
                    ""name"": ""San Francisco Giants"",
                    ""shortName"": ""Giants"",
                    ""teamId"": 137
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/136.svg"",
                    ""name"": ""Seattle Mariners"",
                    ""shortName"": ""Mariners"",
                    ""teamId"": 136
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/138.svg"",
                    ""name"": ""St. Louis Cardinals"",
                    ""shortName"": ""Cardinals"",
                    ""teamId"": 138
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/139.svg"",
                    ""name"": ""Tampa Bay Rays"",
                    ""shortName"": ""Rays"",
                    ""teamId"": 139
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/140.svg"",
                    ""name"": ""Texas Rangers"",
                    ""shortName"": ""Rangers"",
                    ""teamId"": 140
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/141.svg"",
                    ""name"": ""Toronto Blue Jays"",
                    ""shortName"": ""Blue Jays"",
                    ""teamId"": 141
                },
                {
                    ""logoUrl"": ""https://www.mlbstatic.com/team-logos/120.svg"",
                    ""name"": ""Washington Nationals"",
                    ""shortName"": ""Nationals"",
                    ""teamId"": 120
                }
            ]
    return jsonify(teams), 200

    # URL for the MLB API
    # teams_endpoint_url = 'https://statsapi.mlb.com/api/v1/teams?sportId=1'

    # try:
        # Fetch data from the MLB API
        # response = requests.get(teams_endpoint_url)
        # response.raise_for_status()  # Raise exception for HTTP errors
        # data = response.json()

        # Parse and format team data
        # teams = []
        # for team in data['teams']:
          #  team_data = {
          #      'teamId': team['id'],
          #      'name': team['name'],
          #      'shortName': team['teamName'],
          #      'logoUrl': get_team_logoUrl(team['id'])
          #  }
          #  teams.append(team_data)

        # Sort teams alphabetically by name
        #teams_sorted = sorted(teams, key=lambda x: x['name'])
        #return jsonify(teams_sorted)

    #except requests.exceptions.RequestException as e:
        #return jsonify({""error"": str(e)}), 500
@app.route(""/highlights/<int:teamId>"", methods=[""GET""])
def get_highlights(teamId):
        query = highlights_ref.where(""homeTeam.team_id"", ""=="", teamId).stream()
        query_away = highlights_ref.where(""awayTeam.team_id"", ""=="", teamId).stream()
        # Combine results from both queries
        results = []
        for doc in query:
            highlight = doc.to_dict()
            if ""storyboard"" in highlight and isinstance(highlight[""storyboard""], list) and highlight[""storyboard""]:
                results.append(highlight)
        for doc in query_away:
            highlight = doc.to_dict()
            if ""storyboard"" in highlight and isinstance(highlight[""storyboard""], list) and highlight[""storyboard""]:
                results.append(highlight)
        # Remove duplicates (if any) based on gamePk
        results = {item[""gamePk""]: item for item in results}.values()
        # Sort by gameDate in descending order
        results = sorted(results, key=lambda h: h[""gameDate""], reverse=True)
        # Return results or 404 if none found
            return jsonify({""error"": ""No highlights found for the specified team""}), 404
        return jsonify(results), 200
        # Log and return the error
        print(f""Error fetching highlights for team {teamId}: {e}"")
#Endpoint to create a new highlight
        if not isinstance(data[""homeTeam""], dict) or not isinstance(data[""awayTeam""], dict):
        # Validate 'storyboard' array
        if not isinstance(data[""storyboard""], list) or not all(isinstance(item, dict) for item in data[""storyboard""]):
            return jsonify({""error"": ""'storyboard' must be an array of objects.""}), 400
        # Validate each storyboard item
        for item in data[""storyboard""]:
            if ""storyTitle"" not in item or ""teaserSummary"" not in item or ""scenes"" not in item:
                return jsonify({""error"": ""Each storyboard must include 'storyTitle', 'teaserSummary', and 'scenes'.""}), 400
            if not isinstance(item[""scenes""], list):
                return jsonify({""error"": ""Each storyboard's 'scenes' must be an array.""}), 400
        
        data[""gameDate""] = datetime.fromisoformat(data[""gameDate""].replace(""Z"", ""+00:00""))
        print(f""Error adding highlight: {e}"")
# PROCESSING HIGHLIGHTS
# API edndpoint: /highlights/process/{teamId}
# Variables and functions for processing MLB schedule for final and upcoming games

MLB_API_BASE_URL = ""https://statsapi.mlb.com/api/v1/schedule""

def fetch_schedule(team_id, season):
    """"""Fetches schedule data from MLB Stats API""""""
    url = f""{MLB_API_BASE_URL}?sportId=1&season={season}&teamId={team_id}""
    response = requests.get(url)
    if response.status_code != 200:
        print(f""Error fetching schedule: {response.text}"")
        return None
    return response.json()

# Function to publish message to Pub/Sub to kick off Gem/Imagen processing
def trigger_ai_processing(game_pk):
    """"""Publishes a message to Pub/Sub to start AI processing.""""""
    message = json.dumps({""gamePk"": game_pk}).encode(""utf-8"")
    future = publisher.publish(topic_path, message)
    print(f""AI Processing triggered for game {game_pk}, ID: {future.result()}"")

# Function to process past finalized games
def process_past_games(team_id, season):
    """"""Processes finalized past games, updates status in Firestore, and triggers AI processing.""""""
    try:
        data = fetch_schedule(team_id, season)
        if not data or ""dates"" not in data:
            print(f""No data fetched for team {team_id}, season {season}."")
            return []

        highlights = []
        current_date = datetime.utcnow().replace(tzinfo=timezone.utc)

        for date_entry in data[""dates""]:
            for game in date_entry[""games""]:
                game_pk_str = str(game[""gamePk""])  # Convert gamePk to string
                game_date = datetime.fromisoformat(game[""gameDate""].replace(""Z"", ""+00:00"")).astimezone(timezone.utc)
                game_status = game[""status""].get(""abstractGameState"", """")

                # Only process games that are Final
                if game_status == ""Final"":
                    doc_ref = db.collection(""highlights"").document(game_pk_str)
                    doc_snapshot = doc_ref.get()

                    if doc_snapshot.exists:
                        stored_data = doc_snapshot.to_dict()

                        # Update only if the status has changed
                        if stored_data.get(""status"") != ""Final"":
                            doc_ref.update({""status"": ""Final"", ""updatedAt"": datetime.utcnow().replace(tzinfo=timezone.utc)})
                            print(f""Updated game {game_pk_str} to Final in Firestore."")

                            # Trigger AI Processing
                            trigger_ai_processing(game_pk_str)
                        else:
                            print(f""Game {game_pk_str} already marked Final, skipping update."")

                    else:
                        # Insert new record
                        highlight = {
                            ""gamePk"": game_pk_str,
                            ""gameDate"": game[""gameDate""],
                            ""homeTeam"": {
                                ""team_id"": game[""teams""][""home""][""team""][""id""],
                                ""name"": game[""teams""][""home""][""team""][""name""],
                                ""shortName"": game[""teams""][""home""][""team""].get(""abbreviation"", """"),
                                ""logo_url"": f""https://www.mlbstatic.com/team-logos/{game['teams']['home']['team']['id']}.svg""
                            },
                            ""awayTeam"": {
                                ""team_id"": game[""teams""][""away""][""team""][""id""],
                                ""name"": game[""teams""][""away""][""team""][""name""],
                                ""shortName"": game[""teams""][""away""][""team""].get(""abbreviation"", """"),
                                ""logo_url"": f""https://www.mlbstatic.com/team-logos/{game['teams']['away']['team']['id']}.svg""
                            },
                            ""status"": game[""status""][""detailedState""],
                            ""updatedAt"": datetime.utcnow().replace(tzinfo=timezone.utc),
                            ""createdAt"": datetime.utcnow().replace(tzinfo=timezone.utc),
                        }
                        doc_ref.set(highlight)
                        print(f""Inserted new game {game_pk_str} in Firestore."")

                        # Trigger AI Processing
                        trigger_ai_processing(game_pk_str)

                    highlights.append(game_pk_str)

        print(f""Processed {len(highlights)} finalized highlights for team {team_id}."")
        return highlights
    except Exception as e:
        print(f""Error processing past games: {e}"")
        return []

# Publishes a message when an upcoming game is detected
def publish_game_status_event(game_pk, game_date, max_retries=3):
    """"""Publishes a message to Pub/Sub with retry logic.""""""
    message = json.dumps({""gamePk"": game_pk, ""gameDate"": game_date}).encode(""utf-8"")
    for attempt in range(1, max_retries + 1):
            future = publisher.publish(topic_path, message)
            message_id = future.result(timeout=10)  # Wait for a result
            print(f""Successfully published game {game_pk} to Pub/Sub (Message ID: {message_id})"")
            return
        except Exception as e:
            print(f""Attempt {attempt}: Failed to publish Pub/Sub message for game {game_pk}. Error: {e}"")
            if attempt < max_retries:
                wait_time = 2 ** attempt  # Exponential backoff (2s, 4s, 8s)
                print(f""Retrying in {wait_time} seconds..."")
                time.sleep(wait_time)
            else:
                print(f""Failed to publish Pub/Sub message after {max_retries} attempts. Giving up."")

# Checks for upcoming games & sends pubsub message
def check_next_game(team_id, season):
    """"""Finds the next upcoming game within the next 7 days and stores it in the 'highlights' collection.""""""
    try:
        data = fetch_schedule(team_id, season)
        if not data or ""dates"" not in data:
            print(f""No schedule data found for team {team_id}, season {season}."")
            return None

        current_date = datetime.utcnow().replace(tzinfo=timezone.utc)
        next_game = None

        for date_entry in data[""dates""]:
            for game in date_entry[""games""]:
                game_date = datetime.fromisoformat(game[""gameDate""].replace(""Z"", ""+00:00"")).astimezone(timezone.utc)

                if game_date > current_date and game_date <= current_date + timedelta(days=7):
                    game_pk = str(game[""gamePk""])
                    doc_ref = db.collection(""highlights"").document(game_pk)

                    # Check if game already exists in Firestore
                    if not doc_ref.get().exists:
                        next_game = {
                            ""gamePk"": game_pk,
                            ""gameDate"": game[""gameDate""],
                            ""homeTeam"": {
                                ""team_id"": game[""teams""][""home""][""team""][""id""],
                                ""name"": game[""teams""][""home""][""team""][""name""],
                                ""shortName"": game[""teams""][""home""][""team""].get(""abbreviation"", """"),
                                ""logo_url"": f""https://www.mlbstatic.com/team-logos/{game['teams']['home']['team']['id']}.svg""
                            },
                            ""awayTeam"": {
                                ""team_id"": game[""teams""][""away""][""team""][""id""],
                                ""name"": game[""teams""][""away""][""team""][""name""],
                                ""shortName"": game[""teams""][""away""][""team""].get(""abbreviation"", """"),
                                ""logo_url"": f""https://www.mlbstatic.com/team-logos/{game['teams']['away']['team']['id']}.svg""
                            },
                            ""status"": game[""status""][""detailedState""],
                            ""updatedAt"": datetime.utcnow().replace(tzinfo=timezone.utc),
                            ""createdAt"": datetime.utcnow().replace(tzinfo=timezone.utc)
                        }
                        
                        doc_ref.set(next_game)
                        print(f""Stored upcoming game {game_pk} in 'highlights' collection."")

                        # Publish event to Pub/Sub for game status tracking
                        publish_game_status_event(game_pk, game[""gameDate""])
                    
                    return next_game

        return None
    except Exception as e:
        print(f""Error checking next game: {e}"")
        return None
# Endpoint to process final game data and queue upcoming games
@app.route(""/highlights/process/<int:teamId>/<int:season>"", methods=[""GET""])
def process_highlights(teamId, season):
    """"""API endpoint to process past games and find next upcoming game""""""
    try:
        current_year = datetime.utcnow().year
        if season < current_year:
            return jsonify({""error"": f""Invalid season: {season}. The season must be {current_year} or later.""}), 400
        past_highlights = process_past_games(teamId, season)
        next_game = check_next_game(teamId, season)
        return jsonify({
            ""processedHighlights"": past_highlights,
            ""nextGame"": next_game if next_game else ""No upcoming games within 7 days.""
        }), 200
        print(f""Error processing highlights: {e}"")
@app.route(""/highlights/<string:gamePk>"", methods=[""PATCH""])
def update_highlight(gamePk):
        doc_ref = db.collection(""highlights"").document(gamePk)
            return jsonify({""error"": f""Highlight with gamePk {gamePk} not found""}), 404
        return jsonify({""message"": f""Highlight {gamePk} updated successfully""}), 200
        print(f""Error updating highlight {gamePk}: {e}"")
import functions_framework
import json
from google.cloud import firestore, pubsub_v1
# Automatically retrieves the best available credentials
credentials, project = default()
# Initialize Firestore and Pub/Sub
# Initialize Firestore and Pub/Sub
    project=""slimeify"",  # Google Cloud project ID
    database=""mlb-sluggers""  # Must be declared if it's not ""(default)""
publisher = pubsub_v1.PublisherClient()

        # Simulate AI-generated assets
        bucket_name = ""mlb-sluggers-assets""
        image_url = f""https://storage.googleapis.com/{bucket_name}/game_{game_pk}_highlight.jpg""
        audio_url = f""https://storage.googleapis.com/{bucket_name}/game_{game_pk}_audio.mp3""

                #Everything works this is commented out so things dont overwrite a valid record while testing
                #doc_ref = db.collection(""highlights"").document(str(game_pk))
                #doc_ref.update({
                #    ""storyboard"": [put the good stuff in here]
                #})
                print(f""AI processing complete for game {game_pk}. Firestore updated."")
                print(f""Attempt {attempt}: Failed to update Firestore for game {game_pk}. Error: {e}"")
                    print(f""Firestore update failed after {max_retries} attempts. Logging error."")
                    return {""error"": f""Failed to update Firestore for game {game_pk}""}
import functions_framework
import json
from google.cloud import firestore, pubsub_v1
from google.cloud import pubsub_v1

# Automatically retrieves the best available credentials
credentials, project = default()
# Initialize Firestore and Pub/Sub
    project=""slimeify"",  # Google Cloud project ID
    database=""mlb-sluggers""  # Must be declared if it's not ""(default)""",buggy
"import logging
from datetime import datetime, timezone


from apps.backend.api.highlight_generation.highlight_generator import generate_game_highlights
from apps.backend.api.mlb_data_fetching.team_schedules_processor import process_past_games, check_next_game
from apps.backend.config import PROJECT_ID, DATABASE_ID
from apps.backend.utils.constants import TEAMS, ISO_FORMAT
    project=PROJECT_ID,  # Your Google Cloud project ID
    database=DATABASE_ID
    return jsonify(TEAMS), 200
@app.route(""/highlights/<int:team_id>"", methods=[""GET""])
def get_highlights(team_id):
        query_home = highlights_ref.where(""homeTeam"", ""=="", team_id).stream()
        query_away = highlights_ref.where(""awayTeam"", ""=="", team_id).stream()

        results = {}
        def process_query(query, label):
            print(f""Processing {label} query for team ID {team_id}..."")
            for doc in query:
                highlight = doc.to_dict()
                game_pk = highlight.get(""gamePk"")
                # Validate storyboard existence (now a dict, not a list)
                if game_pk and isinstance(highlight.get(""storyboard""), dict):
                    results[game_pk] = highlight  # Store highlight by gamePk
        # Process both queries
        process_query(query_home, ""home"")
        process_query(query_away, ""away"")
        # If no results, return 404
            print(f""No highlights found for team {team_id}."")
            return jsonify({""error"": f""No highlights found for team {team_id}""}), 404

        # Ensure sorting by gameDate in descending order
        sorted_highlights = sorted(results.values(), key=lambda h: h[""gameDate""], reverse=True)

        return jsonify({""highlights"": sorted_highlights}), 200
        print(f""Error fetching highlights for team {team_id}: {e}"")
# Endpoint to create a new highlight
        if not isinstance(data[""homeTeam""], int) or not isinstance(data[""awayTeam""], int):
        # Validate 'storyboard' - it must be a dictionary
        if not isinstance(data.get(""storyboard""), dict):
            return jsonify({""error"": ""'storyboard' must be an object, not an array.""}), 400
        # Validate required storyboard fields
        required_storyboard_fields = [""storyTitle"", ""teaserSummary"", ""scenes""]
        missing_storyboard_fields = [field for field in required_storyboard_fields if field not in data[""storyboard""]]
        if missing_storyboard_fields:
            return jsonify(
                {""error"": f""Missing required storyboard fields: {', '.join(missing_storyboard_fields)}""}), 400

        # Validate 'scenes' inside storyboard - it must be a list of objects
        if not isinstance(data[""storyboard""][""scenes""], list) or not all(
                isinstance(scene, dict) for scene in data[""storyboard""][""scenes""]):
            return jsonify({""error"": ""'scenes' inside 'storyboard' must be an array of objects.""}), 400

        data[""gameDate""] = datetime.fromisoformat(data[""gameDate""].replace(""Z"", ISO_FORMAT))
        logging.error(f""Error adding highlight: {e}"")
# Endpoint to process final game data and queue upcoming games
@app.route(""/highlights/process/<int:season>/"", methods=[""GET""])
def process_highlights(season):
    """"""API endpoint to process past games for a specific season, requiring a date and optionally filtering by team.""""""
    try:
        # Get required date param
        date_param = request.args.get(""date"")
        if not date_param:
            return jsonify({""error"": ""Missing required parameter: date (YYYY-MM-DD)""}), 400
        # Validate date format
            datetime.strptime(date_param, ""%Y-%m-%d"")  # Validate format
        except ValueError:
            return jsonify({""error"": ""Invalid date format. Use YYYY-MM-DD.""}), 400
        # Get optional team filter
        team_param = request.args.get(""teamId"")
        team_id = int(team_param) if team_param else None
        # Process past games for the specific date (team filter is optional)
        past_highlights = process_past_games(season, team_id, date_param)
        next_game = check_next_game(season, team_id, date_param)
        response = {
            ""processedHighlights"": past_highlights,
            ""nextGame"": next_game if next_game else ""No upcoming games within 7 days."",
            ""message"": f""Highlights processed for {date_param} {f'and team {team_id}' if team_id else ''}""
        }
        return jsonify(response), 200
    except Exception as e:
        logging.error(f""Error processing highlights: {e}"")
        return jsonify({""error"": f""An internal error occurred - {str(e)}""}), 500
@app.route(""/highlights/generate/<string:game_pk>"", methods=[""GET""])
def generate_highlights(game_pk):
    try:
        generated_highlights = generate_game_highlights(game_pk)
        return jsonify(generated_highlights), 200
        # Log and return the error
        logging.error(f""Error generating highlights for game_pk: {game_pk}: {e}"")


@app.route(""/highlights/<string:game_pk>"", methods=[""PATCH""])
def update_highlight(game_pk):
        doc_ref = db.collection(""highlights"").document(game_pk)
            return jsonify({""error"": f""Highlight with gamePk {game_pk} not found""}), 404
        return jsonify({""message"": f""Highlight {game_pk} updated successfully""}), 200
        logging.error(f""Error updating highlight {game_pk}: {e}"")

import json
import os

import functions_framework
from google.cloud import firestore
from apps.backend.config import PROJECT_ID, DATABASE_ID
    project=PROJECT_ID,
    database=DATABASE_ID

API_BASE_URL = os.getenv(""SLIME_API_BASE_URL"")
# Automatically retrieves the best available credentials
credentials, project = default()

                # Call the Flask API endpoint
                response = requests.get(f""{API_BASE_URL}highlights/generate/{game_pk}"")
                if response.status_code != 200:
                    raise Exception(f""API call failed with status {response.status_code}: {response.text}"")
                print(f""AI processing complete for game {game_pk}. API call successful."")
                print(f""Attempt {attempt}: Failed to process game {game_pk}. Error: {e}"")
                    print(f""Processing failed after {max_retries} attempts. Logging error."")
                    return {""error"": f""Failed to process game {game_pk}""}
import json

import functions_framework
from google.cloud import firestore, pubsub_v1
    project = ""slimeify"",  # Your Google Cloud project ID
    database = ""mlb-sluggers""

# Initialize Pub/Sub Publisher
game_status_topic_path = publisher.topic_path(""slimeify"", ""sluggers-process-game-status"")
# Automatically retrieves the best available credentials
credentials, project = default()
",bug-free
"from gs.sun import ephemeris
from gs.sun import ephemeris_parser as ep
from gs.sun.ephemeris import DataPoint, ErrorCode
from gs.sun import ephemeris
from gs.sun import ephemeris_parser as ep
",buggy
"from gs.backend.sun import ephemeris
from gs.backend.sun import ephemeris_parser as ep
from gs.backend.sun.ephemeris import DataPoint, ErrorCode
from gs.backend.sun import ephemeris
from gs.backend.sun import ephemeris_parser as ep
",bug-free
"from packaging.version import Version as PackageVersion
        # XXX: Prerelease or postrelease specifiers will fail here, but I guess we can
        # just ignore them for now.
    @classmethod
    def equal_to(cls, version: PackageVersion) -> ""PySpecSet"":
        """"""Create a specifierset that is equal to the given version.""""""
        if not version.is_prerelease:
            return cls(f""=={version}"")
        spec = cls(f""=={version}"", analyze=False)
        spec._upper_bound = Version((version.major, version.minor, 0))
        lower_bound = Version((version.major, version.minor - 1))
        spec._lower_bound = lower_bound.complete(
            cls.PY_MAX_MINOR_VERSION[lower_bound] + 1
        )
        return spec

        if lower[-1] == 0:
        if upper[-1] == 0:
from typing import Any, Tuple, Union, cast, overload
    parts are kept, plus prereleases or postreleases are not supported.
            try:
                version = cast(
                    Tuple[VersionBit, ...],
                    tuple(int(v) if v != ""*"" else v for v in version_str.split("".""))[
                        :3
                    ],
                )
            except ValueError:
                raise InvalidPyVersion(
                    f""{version_str}: Prereleases or postreleases are not supported ""
                    ""for python version specifers.""
                )
        return type(self)(new_tuple)
        Increment the last version bit by default.
        head, value = version[:idx], int(version[idx])
        return type(self)((*head, value + 1)).complete()
        return ""."".join(map(str, self._version))
        return self._version == other._version
        def comp_key(version: Version) -> Tuple[int, ...]:
            return tuple(-1 if v == ""*"" else v for v in version._version)
        return hash(self._version)
            env.python_requires = PySpecSet.equal_to(self.python.version)
def test_unsupported_prerelease_version():
        Version(""3.9.0a4"")",buggy
"        if lower[-1] == 0 and not lower.is_prerelease:
        if upper[-1] == 0 and not upper.is_prerelease:
from typing import Any, List, Optional, Tuple, Union, overload
PRE_RELEASE_SEGMENT_RE = re.compile(
    r""(?P<digit>\d+)(?P<type>a|b|rc)(?P<n>\d*)"",
    flags=re.IGNORECASE,
)
    parts are kept, plus optional prerelease suffix.

    This is a slightly different purpose than packaging.version.Version which is
    focused on supporting PEP 440 version identifiers, not specifiers.
    # Pre-release may follow version with {a|b|rc}N
    # https://docs.python.org/3/faq/general.html#how-does-the-python-version-numbering-scheme-work
    pre: Optional[Tuple[str, int]] = None
            bits: List[VersionBit] = []
            for v in version_str.split(""."")[:3]:
                try:
                    bits.append(int(v))
                except ValueError:
                    pre_m = PRE_RELEASE_SEGMENT_RE.match(v)
                    if v == ""*"":
                        bits.append(""*"")
                        break  # .* is only allowed at the end, per PEP 440
                    elif pre_m:
                        bits.append(int(pre_m.group(""digit"")))
                        pre_type = pre_m.group(""type"").lower()
                        pre_n = int(pre_m.group(""n"") or ""0"")
                        self.pre = (pre_type, pre_n)
                        break  # pre release version is only at the end
                    else:
                        raise InvalidPyVersion(
                            f""{version_str}: postreleases are not supported ""
                            ""for python version specifiers.""
                        )
            version = tuple(bits)
        ret = type(self)(new_tuple)
        ret.pre = self.pre
        return ret
        If index is not provided: increment the last version bit unless version
        is a pre-release, in which case, increment the pre-release number.
        if idx == -1 and self.pre:
            ret = type(self)(version).complete()
            ret.pre = (self.pre[0], self.pre[1] + 1)
        else:
            head, value = version[:idx], int(version[idx])
            ret = type(self)((*head, value + 1)).complete()
            ret.pre = None
        return ret
    @property
    def is_prerelease(self) -> bool:
        """"""Check if the version is a prerelease.""""""
        return self.pre is not None

        parts = []
        parts.append(""."".join(map(str, self._version)))

        if self.pre:
            parts.append("""".join(str(x) for x in self.pre))

        return """".join(parts)
        return self._version == other._version and self.pre == other.pre
        def comp_key(version: Version) -> List[float]:
            ret: List[float] = [-1 if v == ""*"" else v for v in version._version]
            if version.pre:
                # Get the ascii value of first character, a < b < r[c]
                ret += [ord(version.pre[0][0]), version.pre[1]]
            else:
                ret += [float(""inf"")]

            return ret
        return hash((self._version, self.pre))
            env.python_requires = PySpecSet(f""=={self.python.version}"")
def test_unsupported_post_version() -> None:
        Version(""3.10.0post1"")


def test_support_prerelease_version() -> None:
    assert not Version(""3.9.0"").is_prerelease
    v = Version(""3.9.0a4"")
    assert v.is_prerelease
    assert str(v) == ""3.9.0a4""
    assert v.complete() == v
    assert v.bump() == Version(""3.9.0a5"")
    assert v.bump(2) == Version(""3.9.1"")
    assert Version(""3.9.0a"") != Version(""3.9.0"")
    assert Version(""3.9.0a"") == Version(""3.9.0a0"")
    assert Version(""3.10.0a9"") < Version(""3.10.0a12"")
    assert Version(""3.10.0a12"") < Version(""3.10.0b1"")
    assert Version(""3.7.*"") < Version(""3.7.1b"")
",bug-free
"root.mainloop()










",buggy
root.mainloop(),bug-free
"from .server.features import completion, validate
    validate(ls, params)
    validate(ls, params)
    lsp.TEXT_DOCUMENT_COMPLETION, lsp.CompletionOptions(trigger_characters=["" ""])
from .shadows import LanguageServerContext, ProjectBuilderShadow
    instances: dict[Path, LanguageServerContext] = dict()
        self.instances = {}
                    self.instances[config_path.parent] = config
        if config_path not in self.instances or self.instances[config_path] is None:
                self.instances[config_path] = instance
            return instance
        else:
            return self.instances[config_path]
    def get_context(self, document: TextDocument):
        for parent_path in self.instances.keys():
        instance = self.get_instance(parents[-1])
        return instance
from .completion import *
from .validate import *
from functools import reduce
from language_server.server.features.helpers import get_node_at_position
from language_server.server.shadows import CompiledDocument, LanguageServerContext
from ..indexing import get_type_annotation
    ctx = ls.get_context(text_doc)
    if ctx is None:
        items = []
    else:
        items = get_completions(ls, ctx, params.position, text_doc)
    return lsp.CompletionList(False, items)
    ls: MechaLanguageServer,
    
    if not (compiled_doc := get_compilation_data(ls, ctx, text_doc)):
        # if isinstance(current_node, AstResourceLocation):
        #     resolved_path = current_node.__dict__.get(""resolved_path"")
        #     represents = current_node.__dict__.get(""represents"")
        #     # logging.debug(GAME_REGISTRIES)
        #     if represents and issubclass(represents, File):
        #         file_type = cast(type[NamespaceFile], represents)
        #         for pack in ctx.packs:
        #             if file_type not in pack:
        #                 continue
        #             logging.debug(ctx.data[file_type])
        #             for path in pack[file_type]:
        #                 items.append(lsp.CompletionItem(label=path))

        #     elif isinstance(represents, str):
        #         add_registry_items(items, represents)
        #         add_registry_items(
        #             items, ""tag/"" + represents, ""#"", lsp.CompletionItemKind.Constant
        #         )
        
        
        if isinstance(current_node, AstIdentifier) or isinstance(current_node, AstAttribute):
    

    pos: lsp.Position, mecha: Mecha, runtime: Runtime, diagnostics: list[InvalidSyntax]
    items.append(lsp.CompletionItem(name, documentation=documentation, kind=lsp.CompletionItemKind.Class))
    items.append(lsp.CompletionItem(name, documentation=documentation, kind=lsp.CompletionItemKind.Function))
    if compiled_doc is None or compiled_doc.compiled_module is None:
    ast = compiled_doc.compiled_module.ast
    node = get_node_at_position(ast, params.position)
    if isinstance(node, AstIdentifier) or isinstance(node, AstTargetIdentifier):
from typing import Any
from mecha import AstNode
def node_location_to_range(node: AstNode):
        start=lsp.Position(
            line=node.location.lineno - 1, character=node.location.colno - 1
        ),
        end=lsp.Position(
            line=node.end_location.lineno - 1, character=node.end_location.colno - 1
        ),
    start = lsp.Position(
        line=node.location.lineno - 1, character=node.location.colno - 1
    )
    ctx = ls.get_context(text_doc)
    if ctx is None:
        return None
    compiled_doc = get_compilation_data(ls, ctx, text_doc)
    return compiled_doc

            namespace = node.namespace or ""minecraft""
            if isinstance(node, AstNestedLocation):
                path = node.__dict__.get(""resolved_path"")
                
                if path is not None:
                    namespace, path = resolve_relative_location(
                        path,
                        compiled_doc.resource_location.split(""/"")[0],
                        include_root_file=False,
                    )
                else:
                    path = node.path
            else:
                path = node.path
                    f""**type**: `{represents}`\n```yaml\n{namespace or 'minecraft'}:{path}\n```"",
        case _:
            if DEBUG_AST:
                return lsp.Hover(
                    lsp.MarkupContent(
                        lsp.MarkupKind.Markdown,
                        f""Repr: `{node.__repr__()}`\n\nDict: ```{node.__dict__.__repr__()}```"",
                    ),
                    range,
                )
    if compiled_doc is None or compiled_doc.compiled_module is None:
    ast = compiled_doc.compiled_module.ast
    node = get_node_at_position(ast, params.position)
                    colno=node.location.colno + name_length
                    if ""subcommand"" not in node.identifier or node.identifier == ""execute:subcommand""
    ctx = ls.get_context(text_doc)

    if ctx is None:
        data = []
    else:
        if compiled_doc := get_compilation_data(ls, ctx, text_doc):
            ast = compiled_doc.ast

            data = SemanticTokenCollector(ctx=ctx).walk(ast) if ast else []
        else:
from dataclasses import dataclass
from pathlib import Path, PurePath
from typing import Any

from beet import Context, DataPack, Function, PackageablePath, PackLoadUrl, TextFileBase
from beet.contrib.load import load
from bolt import CompiledModule, Module, Runtime
from lsprotocol import types as lsp
from mecha import AstChildren, AstNode, AstRoot, CompilationUnit, Mecha
from tokenstream import InvalidSyntax, TokenStream, UnexpectedToken
from language_server.server.indexing import Bindings, index_function_ast
from language_server.server.shadows import (
    LanguageServerContext,

from .. import MechaLanguageServer
def validate(
    ls: MechaLanguageServer,
    params: lsp.DidOpenTextDocumentParams | lsp.DidChangeTextDocumentParams,
):
    text_doc = ls.workspace.get_document(params.text_document.uri)
    ctx = ls.get_context(text_doc)

    if not ctx:
        diagnostics = []
    else:
        diagnostics = validate_function(ls, ctx, text_doc)
        diagnostics = [
            tokenstream_error_to_lsp_diag(d, type(ls).__name__, text_doc.filename)
            for d in diagnostics
        ]

    # logging.debug(f""Sending diagnostics: {diagnostics}"")

    ls.publish_diagnostics(
        params.text_document.uri,
        diagnostics,
    )


def tokenstream_error_to_lsp_diag(
    exec: InvalidSyntax, source: str, filename: str | None
) -> lsp.Diagnostic:
    range = [exec.location, exec.end_location]
    if isinstance(exec, UnexpectedToken):
        range = [exec.token.location, exec.token.end_location]

    trace = ""\n"".join(traceback.format_tb(exec.__traceback__))
    # logging.debug(trace)

    return lsp.Diagnostic(
        range=lsp.Range(
            start=lsp.Position(line=range[0].lineno - 1, character=range[0].colno - 1),
            end=lsp.Position(line=range[1].lineno - 1, character=range[1].colno - 1),
        ),
        message=f""{exec.format(filename if filename is not None else 'file')}\n{type(exec).__name__}"",  # \n{exec.format(filename)}\n\n{trace}
        source=source,
    )


def get_compilation_data(
    ls: MechaLanguageServer, ctx: LanguageServerContext, text_doc: TextDocument
):
    
    validate_function(ls, ctx, text_doc)
    ls: MechaLanguageServer, ctx: LanguageServerContext, text_doc: TextDocument
) -> list[InvalidSyntax]:
    # logging.debug(f""Parsing function:\n{text_doc.source}"")

    # file.text = text_doc.source

    # file.set_content(text_doc.source)

        ctx, location, type(file)(text_doc.source, text_doc.path)
    # logging.debug(COMPILATION_RESULTS)
def parse_function(
    ctx: LanguageServerContext, location: str, function: Function | Module
) -> CompiledDocument:
    mecha = ctx.inject(Mecha)

    # Create the token stream
    stream = TokenStream(
        source=function.text,
        preprocessor=mecha.preprocessor,
    )

    # Configure the database to compile the file
    mecha.database.current = function
    compiled_unit = CompilationUnit(resource_location=location, pack=ctx.data)
    mecha.database[function] = compiled_unit
    diagnostics = []
    # Parse the stream
    ast = AstRoot(commands=AstChildren())
    try:
        ast: AstNode = mecha.parse_stream(
            mecha.spec.multiline, None, AstRoot.parser, stream  # type: ignore
        )
        for node in ast.walk():
            if isinstance(node, AstError):
                diagnostics.append(node.error)
    except InvalidSyntax as exec:
        logging.error(f""Failed to parse: {exec}"")
        diagnostics.append(exec)
    except KeyError as exec:
        tb = ""\n"".join(traceback.format_tb(exec.__traceback__))
        logging.error(f""{tb}"")
    except Exception as exec:
        logging.error(f""{type(exec)}: {exec}"")
    dependents = set()
    compiled_module = None
    runtime = ctx.inject(Runtime)
    if location in COMPILATION_RESULTS:
        prev_compilation = COMPILATION_RESULTS[location]
        dependents = prev_compilation.dependents
        compiled_module = prev_compilation.compiled_module
    if len(diagnostics) == 0 and Module in ctx.data.extend_namespace:
        if fresh_module := runtime.modules.get(function):
            fresh_module.ast = index_function_ast(
                fresh_module.ast, location, mecha, runtime, fresh_module
            )
            for dependency in fresh_module.dependencies:
                if dependency in COMPILATION_RESULTS:
                    COMPILATION_RESULTS[dependency].dependents.add(location)
            compiled_module = fresh_module
    ast = index_function_ast(
        ast, location, mecha, runtime=runtime, module=compiled_module
    )
    for dependent in dependents:
        if not dependent in COMPILATION_RESULTS:
            continue
        parse_function(
            ctx,
            dependency,
            ctx.data.functions[dependent] or ctx.data[Module][dependent],
        )
        del COMPILATION_RESULTS[dependency]
        resource_location=location,
        diagnostics=diagnostics,
        compiled_unit=compiled_unit,
        dependents=dependents,
from dataclasses import dataclass, field
from typing import Any, Optional, TypeVar, get_args, get_origin
from beet import File, Function, LootTable
from beet.core.utils import extra_field, required_field
    AstTarget,
    AstTargetIdentifier,
from mecha.contrib.nested_location import AstNestedLocation
PARSER_TO_FILE_TYPE = {
    ""minecraft:function"": Function,
    ""minecraft:loot_table"": LootTable,
}
@dataclass(frozen=True, slots=True)
class AstTypedTarget(AstTarget):
    type_annotation: list[Any] = field(default_factory=list)


@dataclass(frozen=True, slots=True)
class AstTypedTargetIdentifier(AstTargetIdentifier):
    type_annotation: list[Any] = field(default_factory=list)


T = TypeVar(""T"", bound=AstNode)


def index_function_ast(
    ast: T,
    function_location: str,
    mecha: Mecha,
    runtime: Runtime | None = None,
    module: CompiledModule | None = None,
) -> T:
    resolve_paths(ast, path=""/"".join(function_location.split("":"")[1:]))
    try:
        initial_values = InitialValues()
        bindings = Bindings(module=module, runtime=runtime, mecha=mecha)

        return bindings(initial_values(ast))
    except Exception as e:
        logging.error(e)
        raise e


def resolve_paths(root: AstNode, path: str = ""current""):
    next_path = path
    for child in root:
        if isinstance(child, AstNestedLocation):
            child.__dict__[""resolved_path""] = path + ""/"" + child.path
            next_path = path + ""/"" + child.path
        elif isinstance(child, AstResourceLocation):
            next_path = child.path

        resolve_paths(child, next_path)


def add_representation(arg_node: AstNode, type: str):
class InitialValues(Reducer):
class Bindings(Reducer):
    module: Optional[CompiledModule] = required_field()
    runtime: Optional[Runtime] = required_field()
                    command_tree_node = self.mecha.spec.tree.get(
                        prototype.get_argument(i).scope
                    )
                    if command_tree_node and command_tree_node.parser:
                        add_representation(
                            argument,
                            PARSER_TO_FILE_TYPE.get(command_tree_node.parser)
                            or command_tree_node.parser,
                        )

            "" = "" + parameter.default.__repr__() # type: ignore
import pytest
from beet import Function, ProjectConfig, run_beet
from lsprotocol import types as lsp
from mecha import Mecha
from .. import mecha_server
from ..server import MechaLanguageServer
from ..server.features.completion import get_completions
from ..server.features.validate import parse_function, validate, validate_function


@pytest.fixture
def ls():
    with run_beet(ProjectConfig(require=[""bolt""])) as ctx:
        mecha_server.mecha = ctx.inject(Mecha)
    return mecha_server


def test_bolt_python(ls: MechaLanguageServer):
    diagnostics = validate_function(
        ls,
        Function(
            """"""
foo = 1
if foo == 1:
    print(""hi"")
""""""
        ),
    )
    assert len(diagnostics) == 0


def test_mcfunction(ls: MechaLanguageServer):
    diagnostics = validate_function(
        ls,
        Function(
            """"""
scoreboard players set @a dummy 1
""""""
        ),
    )
    assert len(diagnostics) == 0


COMPLETIONS = [[""scoreboard "", lsp.Position(1, 11), 2], [""s"", lsp.Position(1, 1), 2]]


def test_completions(ls: MechaLanguageServer):
    for [function, pos, expected] in COMPLETIONS:
        items = get_completions(ls, pos, function)
        assert len(items) == expected",buggy
"from .server.indexing import ProjectIndex
from .server.features.completion import completion
from .server.features.diagnostics import publish_diagnostics
    publish_diagnostics(ls, params)
    publish_diagnostics(ls, params)
    lsp.TEXT_DOCUMENT_COMPLETION, lsp.CompletionOptions(trigger_characters=["" "", ""/"", "".""])
@mecha_server.command('mecha.server.dumpIndices')
def dump(ls: MechaLanguageServer, *args):
    ls.show_message_log(ProjectIndex.dump())

@mecha_server.command('mecha.server.toggleASTDebug')
def toggle_ast_debug(ls: MechaLanguageServer, *args):
    language_server.server.features.hover.DEBUG_AST = not language_server.server.features.hover.DEBUG_AST
    mecha_server._kill()

import time
from contextlib import contextmanager
from threading import Lock, Thread
from typing import Generator, cast
    Function,
from bolt import Module
from .features.validate import validate_function
from .shadows.compile_document import COMPILATION_RESULTS
from .shadows.context import LanguageServerContext
from .shadows.project_builder import ProjectBuilderShadow
    _instances: dict[Path, tuple[Lock, LanguageServerContext]] = dict()
    _index_thread: Thread
    _alive: bool = True
        self._instances = {}
        self._index_thread = Thread(
            target=lambda self: self.scan_functions(), args=[self]
        )
        self._index_thread.start()

    def index_functions(self, ctx: LanguageServerContext):
        for function, file in cast(
            list[tuple[str, Function | Module]],
            [*ctx.data.functions.items(), *ctx.data[Module].items()],
        ):
            if function not in COMPILATION_RESULTS and file.source_path:
                self.show_message_log(""indexing "" + function, lsp.MessageType.Debug)
                validate_function(
                    ctx, self.workspace.get_document(Path(file.source_path).as_uri())
                )
                break

    def scan_functions(self):
        try:

            while self._alive:
                for lock, ctx in self._instances.values():
                    if not lock.acquire(blocking=False):
                        continue

                    self.index_functions(ctx)

                    lock.release()
                    time.sleep(0.1)
        except Exception as exc:
            lock.release()
            logging.error(f""Fatal error occured while indexing function!\n{exc}"")
                    self._instances[config_path.parent] = (Lock(), config)
        if config_path not in self._instances or self._instances[config_path] is None:
                self._instances[config_path] = (Lock(), instance)
        return self._instances[config_path]
    @contextmanager
    def context(
        self, document: TextDocument
    ) -> Generator[LanguageServerContext | None, None, None]:
        for parent_path in self._instances.keys():
        if len(parents) <= 0:
            yield None

        (lock, context) = self.get_instance(parents[-1])
        lock.acquire()
        yield context
        lock.release()

    def _kill(self):
        self._alive = False
# from .completion import *
# from .validate import *
from pathlib import Path
from functools import reduce
from language_server.server.features.helpers import (
    get_node_at_position,
    node_location_to_range,
)
from ..indexing import ProjectIndex, get_type_annotation
from ..shadows.context import LanguageServerContext
from ..shadows.compile_document import CompilationError
    with ls.context(text_doc) as ctx:
        if ctx is None:
            items = []
        else:
            items = get_completions(ctx, params.position, text_doc)
        return lsp.CompletionList(False, items)


def get_path(path: str) -> tuple[str | None, Path]:
    segments = path.split("":"")
    if len(segments) == 1:
        return (None, Path(segments[0]))
    else:
        return (segments[0], Path(segments[1]))

    if not (compiled_doc := get_compilation_data(ctx, text_doc)):
        if isinstance(current_node, AstResourceLocation):
            represents = current_node.__dict__.get(""represents"")
            # logging.debug(GAME_REGISTRIES)
            if represents and issubclass(represents, File):
                file_type = cast(type[NamespaceFile], represents)


                path = current_node.get_canonical_value()

                if current_node.is_tag:
                    path = path[1:]
                    
                project_index = ProjectIndex.get(ctx)

                resolved = get_path(path)

                unresolved = get_path(current_node.__dict__[""unresolved_path""])

                if unresolved[1].name == ""~"":
                    resolved_parent = resolved[1]
                    unresolved_parent = unresolved[1]
                else:
                    resolved_parent = resolved[1].parent
                    unresolved_parent = unresolved[1].parent

                for file in project_index[file_type]:
                    file_path = get_path(file)

                    if not (
                        file_path[0] == resolved[0]
                        and file_path[1].is_relative_to(resolved_parent)
                    ):
                        continue

                    relative = file_path[1].relative_to(resolved_parent)

                    if unresolved[0] is None and unresolved[1].name == """":
                            new_path = ""./"" + str(relative)
                    else:
                        new_path = str(unresolved_parent / relative)


                    insert_text = f""{unresolved[0] + ':' if unresolved[0] else ''}{new_path}""
                    if current_node.is_tag:
                        insert_text = ""#"" + insert_text

                    items.append(
                        lsp.CompletionItem(
                            label=insert_text,
                            documentation=file,
                            text_edit=lsp.InsertReplaceEdit(
                                insert_text,
                                node_location_to_range(current_node),
                                node_location_to_range(current_node),
                            ),
                        )
                    )

            elif isinstance(represents, str):
                add_registry_items(items, represents)
                add_registry_items(
                    items, ""tag/"" + represents, ""#"", lsp.CompletionItemKind.Constant
                )

        if isinstance(current_node, AstIdentifier) or isinstance(
            current_node, AstAttribute
        ):



    pos: lsp.Position,
    mecha: Mecha,
    runtime: Runtime,
    diagnostics: list[CompilationError],
    items.append(
        lsp.CompletionItem(
            name, documentation=documentation, kind=lsp.CompletionItemKind.Class
        )
    )

    items.append(
        lsp.CompletionItem(
            name, documentation=documentation, kind=lsp.CompletionItemKind.Function
        )
    )

from pathlib import Path
from typing import cast
from beet import NamespaceFile
from mecha import AstResourceLocation

from ..indexing import ProjectIndex
    get_representation_file,
    if compiled_doc is None or compiled_doc.ast is None:
        return

    project_index = ProjectIndex.get(compiled_doc.ctx)
    node = get_node_at_position(compiled_doc.ast, params.position)

    if isinstance(node, AstResourceLocation):
        if not (represents := get_representation_file(project_index, node)):
            return 
        
        path = node.get_canonical_value()
        definitions = project_index[represents].get_definitions(path)
        
        return [
            lsp.LocationLink(
                target_uri=Path(path).as_uri(),
                target_range=node_location_to_range(location),
                target_selection_range=node_location_to_range(location),
                origin_selection_range=node_location_to_range(node)
            ) for path, *location in definitions
        ]

    if compiled_doc.compiled_module is None:
    if isinstance(node, AstIdentifier):
        
from typing import Any, Iterable, cast
from beet import NamespaceFile
from mecha import AstNode, AstResourceLocation
from ..indexing import ProjectIndex

def get_representation_file(project_index: ProjectIndex, node: AstResourceLocation):
    if not (represents := cast(type[NamespaceFile]|str|None, node.__dict__.get(""represents""))):
            return None
        
    if isinstance(represents, str):
        return None
        
    return represents


def node_location_to_range(node: AstNode | Iterable[SourceLocation]):
    if isinstance(node, AstNode):
        location = node.location
        end_location = node.end_location
    else:
        location, end_location = node

        start=location_to_position(location), end=location_to_position(end_location)
    start = location_to_position(node.location)
def location_to_position(location: SourceLocation) -> lsp.Position:
    return lsp.Position(
        line=max(location.lineno - 1, 0),
        character=max(location.colno - 1, 0),
    )


    with ls.context(text_doc) as ctx:
        if ctx is None:
            return None
        compiled_doc = get_compilation_data(ctx, text_doc)
        return compiled_doc
from beet import File
      
    if DEBUG_AST:
        return lsp.Hover(
            lsp.MarkupContent(
                lsp.MarkupKind.Markdown,
                f""Repr: `{node.__repr__()}`\n\nDict: ```{node.__dict__.__repr__()}```"",
            ),
            range,
        )
    
            if represents is None:
                path_type = None
            elif isinstance(represents, str):
                path_type = represents
            elif issubclass(represents, File):
                path_type = represents.snake_name
            type_line = f""**{path_type}**\n"" if path_type else """"
                    f""{type_line}```yaml\n{node.get_canonical_value()}\n```"",
  
from pathlib import Path
from mecha import AstResourceLocation

from ..indexing import ProjectIndex
    get_representation_file,
    if compiled_doc is None or compiled_doc.ast is None:
        return

    project_index = ProjectIndex.get(compiled_doc.ctx)
    node = get_node_at_position(compiled_doc.ast, params.position)


    if isinstance(node, AstResourceLocation):
        if not (represents := get_representation_file(project_index, node)):
            return 
        
        path = node.get_canonical_value()
        references = project_index[represents].get_references(path)
        
        return [
            lsp.Location(
                Path(path).as_uri(),
                node_location_to_range(location)
            ) for path, *location in references
        ]
    
    if  compiled_doc.compiled_module is None:
                    colno=node.location.colno + name_length,
                    if ""subcommand"" not in node.identifier
                    or node.identifier == ""execute:subcommand""
    with ls.context(text_doc) as ctx:
        if ctx is None:
        else:
            if compiled_doc := get_compilation_data(ctx, text_doc):
                ast = compiled_doc.ast

                data = SemanticTokenCollector(ctx=ctx).walk(ast) if ast else []
            else:
                data = []
from contextlib import contextmanager
from dataclasses import dataclass
from functools import partial
from pathlib import PurePath
from typing import Any, TypeVar

from beet import Context, DataPack, Function, NamespaceFile, PackLoadUrl, TextFileBase
from beet.core.utils import required_field, extra_field
from bolt import Module, Runtime
from mecha import (
    AbstractNode,
    AstChildren,
    AstNode,
    AstRoot,
    CompilationUnit,
    Diagnostic,
    DiagnosticCollection,
    Dispatcher,
    Mecha,
    MutatingReducer,
    rule,
)
from mecha.contrib.nested_location import (
    NestedLocationTransformer,
    NestedLocationResolver,
)
from tokenstream import InvalidSyntax, TokenStream
from ..indexing import Indexer, ProjectIndex
from ..shadows.compile_document import (
    CompilationError
from ..shadows.context import LanguageServerContext
T = TypeVar(""T"", bound=AstNode)
def get_compilation_data(ctx: LanguageServerContext, text_doc: TextDocument):

    validate_function(ctx, text_doc)
    ctx: LanguageServerContext, text_doc: TextDocument
) -> list[CompilationError]:
    
        ctx, location, text_doc.path, type(file)(text_doc.source, text_doc.path)

@dataclass
class ErrorAccumulator(MutatingReducer):
    _errors: list[InvalidSyntax] = extra_field(default_factory=list)
    resource_location: str = required_field()
    filename: str | None = required_field()
    file_instance: TextFileBase[Any] = required_field()
    @rule(AstError)
    def error(self, error: AstError):
        self._errors.append(error.error)
        return None
    def collect(self, root: T | None) -> tuple[T | None, list[InvalidSyntax]]:
        if root is None:
            return (root, [])
        root = self.__call__(root)
        return (root, self._errors)
Node = TypeVar(""Node"", bound=AbstractNode)
def parse_function(
    ctx: LanguageServerContext,
    resource_location: str,
    source_path: str,
    file_instance: Function | Module,
) -> CompiledDocument:
    ast, errors = compile(ctx, resource_location, source_path, file_instance)
    # # Parse the stream
    mecha = ctx.inject(Mecha)
    compilation_unit = mecha.database[file_instance]
    runtime = ctx.inject(Runtime)
    compiled_module = runtime.modules.registry.get(file_instance)
        resource_location=resource_location,
        diagnostics=[*errors, *compilation_unit.diagnostics.exceptions],
        compiled_unit=compilation_unit,
        dependents=set(),
    )

@contextmanager
def use_steps(mecha: Mecha, steps):
    initial_steps = mecha.steps 
    mecha.steps = steps
    yield 
    mecha.steps = initial_steps

def compile(
    ctx: LanguageServerContext,
    resource_location: str,
    source_path: str,
    source_file: Function | Module,
) -> tuple[AstRoot, list[InvalidSyntax]]:
    mecha = ctx.inject(Mecha)
    diagnostics = []

    indexer = Indexer(
        ctx=ctx,
        resource_location=resource_location,
        source_path=source_path,
        file_instance=source_file,

    with use_steps(mecha, [indexer, *mecha.steps]):
        mecha.database.setup_compilation()

        # Configure the database to compile the file
        compiled_unit = CompilationUnit(resource_location=resource_location, pack=ctx.data)
        mecha.database[source_file] = compiled_unit
        mecha.database.enqueue(source_file)

        for step, file_instance in mecha.database.process_queue():
            compilation_unit = mecha.database[file_instance]

            if step < 0:
                try:
                    compilation_unit.source = file_instance.text
                    # Create the token stream
                    stream = TokenStream(
                        source=compilation_unit.source,
                        preprocessor=mecha.preprocessor,
                    )

                    ast = mecha.parse_stream(
                        mecha.spec.multiline, None, AstRoot.parser, stream  # type: ignore
                    )

                    ast, errors = ErrorAccumulator(
                        resource_location=resource_location,
                        filename=compilation_unit.filename,
                        file_instance=file_instance,
                    ).collect(ast)

                    diagnostics.extend(errors)

                    compilation_unit.ast = ast
                    mecha.database.enqueue(file_instance, 0)

                except InvalidSyntax as exec:
                    logging.error(f""Failed to parse: {exec}"")
                except KeyError as exec:
                    tb = ""\n"".join(traceback.format_tb(exec.__traceback__))
                    logging.error(f""{tb}"")
                except Exception as exec:
                    logging.error(f""{type(exec)}: {exec}"")

            elif step < len(mecha.steps):
                if not compilation_unit.ast:
                    continue
                step_diagnostics = DiagnosticCollection()
                try:
                    with mecha.steps[step].use_diagnostics(step_diagnostics):
                        if ast := mecha.steps[step](compilation_unit.ast):
                            if not step_diagnostics.error:
                                compilation_unit.ast = ast
                                mecha.database.enqueue(
                                    key=file_instance,
                                    step=step + 1,
                                    priority=compilation_unit.priority,
                                )

                            compilation_unit.diagnostics.extend(step_diagnostics)
                except Exception as e:
                    tb = ""\n"".join(traceback.format_tb(e.__traceback__))
                    logging.error(f""{type(e)} {e}\n{tb}"")

    return indexer.output_ast, diagnostics
from copy import deepcopy
from dataclasses import dataclass
from pathlib import Path
import re
from threading import Lock
import traceback
from typing import (
    Any,
    Callable,
    ClassVar,
    Optional,
    Self,
    TypeVar,
    get_args,
    get_origin,
)
from beet import (
    Advancement,
    Context,
    File,
    Function,
    LootTable,
    NamespaceFile,
    Predicate,
    TextFileBase,
)
from beet.core.utils import required_field, extra_field
    Module,
    AbstractNode,
    AstChildren,
    AstJson,
    AstJsonObject,
    AstRoot,
    CompilationError,
    Dispatcher,
    MutatingReducer,
from mecha.contrib.nested_location import (
    AstNestedLocation,
    NestedLocationResolver,
    NestedLocationTransformer,
)
from tokenstream import SourceLocation
from .patches import AstRelativeLocation, RelativeLocationTransformer

from .shadows.context import LanguageServerContext
FilePointer = tuple[SourceLocation, SourceLocation]

Node = TypeVar(""Node"", bound=AstNode)


@dataclass
class ResourceIndice:
    definitions: dict[str, set[FilePointer]] = extra_field(default_factory=dict)
    references: dict[str, set[FilePointer]] = extra_field(default_factory=dict)

    def _dump(self) -> str:
        dump = """"

        dump += ""definitions:\n""
        for path, pointers in self.definitions.items():
            for pointer in pointers:
                dump += f""\t- {path} {pointer[0].lineno}:{pointer[0].colno} -> {pointer[1].lineno}:{pointer[1].colno}\n""
        dump += ""references:\n""
        for path, pointers in self.references.items():
            for pointer in pointers:
                dump += f""\t- {path} {pointer[0].lineno}:{pointer[0].colno} -> {pointer[1].lineno}:{pointer[1].colno}\n""

        return dump


def valid_resource_location(path: str):
    return bool(re.match(r""^[a-z0-9_\.]+:[a-z0-9_\.]+(\/?[a-z0-9_\.]+)*$"", path))


@dataclass
class ResourceIndex:
    _files: dict[str, ResourceIndice] = extra_field(default_factory=dict)
    _lock: Lock = extra_field(default_factory=Lock)

    def remove_associated(self, path: str | File):
        self._lock.acquire()

        if isinstance(path, File):
            path = str(Path(path.ensure_source_path()).absolute())

        for file, indice in list(self._files.items()):
            if path in indice.definitions:
                del indice.definitions[path]
            if path in indice.references:
                del indice.references[path]

            if len(indice.definitions) == 0:
                del self._files[file]

        self._lock.release()

    def add_definition(
        self,
        resource_path: str,
        source_path: str,
        source_location: FilePointer = (
            SourceLocation(0, 0, 0),
            SourceLocation(0, 0, 0),
        ),
    ):
        if not valid_resource_location(resource_path):
            raise Exception(f""Invalid resource location {resource_path}"")

        self._lock.acquire()

        indice = self._files.setdefault(resource_path, ResourceIndice())
        locations = indice.definitions.setdefault(source_path, set())
        locations.add(source_location)

        self._lock.release()

    def get_definitions(
        self, resource_path: str
    ) -> list[tuple[str, SourceLocation, SourceLocation]]:
        if not (file := self._files.get(resource_path)):
            return []

        definitions = []
        for path, locations in file.definitions.items():
            for location in locations:
                definitions.append((path, *location))

        return definitions
    
    def get_references(
        self, resource_path: str
    ) -> list[tuple[str, SourceLocation, SourceLocation]]:
        if not (file := self._files.get(resource_path)):
            return []

        references = []
        for path, locations in file.references.items():
            for location in locations:
                references.append((path, *location))

        return references

    def add_reference(
        self,
        resource_path: str,
        source_path: str,
        source_location: FilePointer = (
            SourceLocation(0, 0, 0),
            SourceLocation(0, 0, 0),
        ),
    ):
        if not valid_resource_location(resource_path):
            raise Exception(f""Invalid resource location {resource_path}"")

        self._lock.acquire()

        indice = self._files.setdefault(resource_path, ResourceIndice())
        locations = indice.references.setdefault(source_path, set())
        locations.add(source_location)

        self._lock.release()

    def __iter__(self):
        items = self._files.keys()

        for item in items:
            yield item

    def _dump(self) -> str:
        dump = """"

        for file, indice in self._files.items():
            dump += f""\n- '{file}':\n""
            dump += ""\t"" + ""\n\t"".join(indice._dump().splitlines())

        return dump


class ProjectIndex:
    _projects: ClassVar[dict[str, Self]] = dict()
    _resources: dict[type[NamespaceFile], ResourceIndex] = dict()
    _ctx: Context

    resource_name_to_type: dict[str, type[NamespaceFile]] = dict()

    def __init__(self, ctx: Context):
        self._ctx = ctx

        self.resource_name_to_type = {t.snake_name: t for t in ctx.get_file_types()}

    def __getitem__(self, key: type[NamespaceFile]):
        return self._resources.setdefault(key, ResourceIndex())
    @staticmethod
    def get(ctx: ""LanguageServerContext"") -> ""ProjectIndex"":
        return ProjectIndex._projects.setdefault(ctx.project_uuid, ProjectIndex(ctx))

    def remove_associated(self, path: str):
        for resource in self._resources.values():
            resource.remove_associated(path)

    def _dump(self) -> str:
        dump = """"
        for resource, index in self._resources.items():
            dump += f""\nResource {resource.__name__}:""
            dump += ""\t"" + ""\n\t"".join(index._dump().splitlines())

        return dump

    @staticmethod
    def dump() -> str:
        dump = """"
        for uuid, index in ProjectIndex._projects.items():
            dump += f""\nProject {uuid}:""
            dump += ""\t"" + ""\n\t"".join(index._dump().splitlines())
        return dump.replace(""\t"", "" "" * 4)
def add_representation(arg_node: AstNode, type: Any):
class InitialStep(Reducer):
    @rule(AstResourceLocation)
    def resource_location(self, node: AstResourceLocation):
        if isinstance(node, AstRelativeLocation):
            node.__dict__[""unresolved_path""] = node.path
        elif isinstance(node, AstNestedLocation):
            node.__dict__[""unresolved_path""] = f""~/"" + node.path
        else:
            node.__dict__[""unresolved_path""] = node.get_value()

class BindingStep(Reducer):
    index: ProjectIndex = required_field()
    source_path: str = required_field()
    runtime: Runtime = required_field()
    parser_to_file_type: dict[str, type[NamespaceFile]] = required_field()

    module: Optional[CompiledModule] = required_field()

        # If the callable is a type of a type
        # then its type annotation should be the
        # method signature of its constructor
                    # Attempt to get the parser for the argument
                    argument_tree = prototype.get_argument(i)
                    command_tree_node = self.mecha.spec.tree.get(argument_tree.scope)
                    if not (command_tree_node and command_tree_node.parser):
                        continue

                    # If the parser is registered or the parent argument's name is registered
                    # use that file type for its representation
                    file_type = self.parser_to_file_type.get(
                        command_tree_node.parser
                    ) or self.index.resource_name_to_type.get(argument_tree.scope[-2])

                    if file_type is None:
                        continue


                    # Ensure that unfinished paths are not added to the project index
                    resolved_path = argument.get_canonical_value()

                    # If the argument is a tag then we need to remove the leading
                    # ""#"" and try to change the file type to the tag equivalent
                    # ex. Function -> FunctionTag
                    if argument.is_tag:
                        resolved_path = resolved_path[1:]
                        if not (
                            file_type := self.index.resource_name_to_type.get(
                                file_type.snake_name + ""_tag""
                            )
                        ):
                            continue

                    add_representation(argument, file_type)

                    if not valid_resource_location(resolved_path):
                        continue

                    # Check the command tree for the pattern:
                    # resource_location, defintion
                    # which is used by the nested resource plugin to define a new resource
                    if i + 1 < len(command.arguments) and isinstance(
                        command.arguments[i + 1], (AstRoot, AstJson)
                    ):
                        self.index[file_type].add_definition(
                            resolved_path,
                            self.source_path,
                            (argument.location, argument.end_location),
                        )
                    # If the pattern isn't matched then just treat it as a reference
                    # and not a definition of thre resource
                    else:
                        self.index[file_type].add_reference(
                            resolved_path,
                            self.source_path,
                            (argument.location, argument.end_location),
                        )
            case ""predicate"":
                add_representation(value, Predicate)


@dataclass
class Indexer(MutatingReducer):
    ctx: LanguageServerContext = required_field()
    resource_location: str = required_field()
    source_path: str = required_field()
    file_instance: Function | Module = required_field()

    output_ast: AstRoot = extra_field(
        default=AstRoot(commands=AstChildren(children=[]))
    )

    def __call__(self, ast: AstRoot, *args) -> AbstractNode:
        project_index = ProjectIndex.get(self.ctx)

        mecha = self.ctx.inject(Mecha)
        runtime = self.ctx.inject(Runtime)
        module = runtime.modules.get(self.file_instance)

        # A file always defines itself
        source_type = type(self.file_instance)
        project_index.remove_associated(self.source_path)

        project_index[source_type].add_definition(
            self.resource_location, self.source_path
        )

        # TODO: See if these steps can be merged into one

        # Attaches the type annotations for assignments
        initial_values = InitialStep()

        # The binding step is responsible for attaching the majority of type annotations
        bindings = BindingStep(
            index=project_index,
            source_path=self.source_path,
            module=module,
            runtime=self.ctx.inject(Runtime),
            mecha=self.ctx.inject(Mecha),
            # argument parser to resource type
            parser_to_file_type={
                ""minecraft:advancement"": Advancement,
                ""minecraft:function"": Function,
                ""minecraft:predicate"": Predicate,
                ""minecraft:loot_table"": LootTable,
            },
        )

        # Transform paths to absolute versions
        relative_locations = RelativeLocationTransformer(database=mecha.database)

        # This has to been done through extension because i'm too lazy to shadow or patch it
        self.extend(
            NestedLocationTransformer(
                nested_location_resolver=NestedLocationResolver(ctx=self.ctx)
            )
        )

        steps: list[Callable[[AstRoot], AstRoot]] = [
            initial_values,
            relative_locations,
            super().__call__,
            bindings,
        ]

        for step in steps:
            try:
                ast = step(ast)
            except CompilationError as e:
                raise e.__cause__
            except Exception as e:
                tb = ""\n"".join(traceback.format_tb(e.__traceback__))
                logging.error(f""Error occured during {step}\n{e}\n{tb}"")

        self.output_ast = ast

        # Return a deepcopy so subsequent compilation steps don't modify the parsed state
        return deepcopy(ast)
            "" = "" + parameter.default.__repr__()  # type: ignore
# TODO: Actually write LSP tests",bug-free
"        name = getattr(self, 'canonical_name', self.op)
    @classmethod
    def from_Tuple(cls, t):
        if (isinstance(t, TypedExpr)
                            and (not isinstance(t, Tuple) or len(t) != 2)):
            raise parsing.ParseError(
                ""Partial requires a Tuple of length 2.  (Received `%s`.)""
                % repr(t))
        return Partial(t[0], t[1])
        
TypedExpr.add_local(""Partial"", Partial.from_Tuple)

    @classmethod
    def from_tuple(cls, t):
        return Disjunctive(*t)

    @classmethod
    def from_tuple(cls, t):
        return cls(*t)

    from .core import TypedTerm # can these be done without isinstance checks?
    from .meta import MetaTerm
    if isinstance(result, MetaTerm) and result.derivation is None:
    elif isinstance(result, TypedTerm) and result.derivation is None:
    teb = te(b)
    self.assertEqual(intermediate, teb,
        execed_a = meta.exec(a)
        execed_b = meta.exec(teb)
        self.assertEqual(execed_a, execed_b,
                f""Failed exec test: '{repr(a)} == {repr(b)}' (got `{repr(execed_a)}` == `{repr(execed_b)}`)"")",buggy
"    @classmethod
    def from_tuple(cls, tup, **kwargs):
        try:
            return cls(*tup, **kwargs)
        except TypeError as e:
            raise parsing.ParseError(f""{cls.__name__} instantiated with incorrect argument signature (`{str(e)}`)"") from None

        name = getattr(self, 'canonical_name')
        if name is None:
            name = self.op
TypedExpr.add_local(""Partial"", Partial.from_tuple)
    if result.meta():
    elif result.term():
def testexec(self, a, b, **kwargs):
    execed_a = meta.exec(a, **kwargs)
    execed_b = meta.exec(te(b), **kwargs)
    self.assertEqual(execed_a, execed_b,
            f""Failed exec test: '{repr(a)} == {repr(b)}' (got `{repr(execed_a)}` == `{repr(execed_b)}`)"")


    self.assertEqual(intermediate, te(b),
        testexec(self, a, b, **kwargs)
        # Case
        testsimp(self, te(""Case(p_t | ~p_t, _c1, Case(p_t | ~p_t, _c2, _c3))""),
            te('_c1'), all=True, exec=True, p=True)
        testsimp(self, te(""Case(p_t & ~p_t, _c1, Case(p_t | ~p_t, _c2, _c3))""),
            te('_c2'), all=True, exec=True, p=True)
        testsimp(self, te(""Case(p_t & ~p_t, _c1, Case(p_t & ~p_t, _c2, _c3))""),
            te('_c3'), all=True, exec=True, p=True)

        testexec(self, te(""Case(p_t, _c1, Case(q_t, _c2, _c3))""), '_c1', p=True, q=True)
        testexec(self, te(""Case(p_t, _c1, Case(q_t, _c2, _c3))""), '_c2', p=False, q=True)
        testexec(self, te(""Case(p_t, _c1, Case(q_t, _c2, _c3))""), '_c3', p=False, q=False)
        # test short-circuiting behavior: `q` should be completely ignored by
        # the raw compiled code for this case. (Note that `exec` still complains.)
        self.assertEqual(te(""Case(p_t, _c1, Case(q_t, _c2, _c3))"")._compiled({'p':True}), '_c1')
",bug-free
"state_template = '''State
script_foler = ""script""
print(""Hey, this is script generator for SpellForce Lua Scripts if you're trying to modding your units in editor, and you don't wan't to write a lot of copy-paste code. This script is best offer for lazy ass like me :D\n\n"")

npc_map_name = input(""What is the name of your npc that you create in editor?\n"")
npc_count = int(input(""How much npc you created in the map?\n""))
main_script = input(""Enter the main script filename that will be in the npc file you generate:\n"")
counter = 0
lua_command = f'dofile(GetScriptPath()..""{main_script}.lua"")'

main_script_template = '''State
{
	StateName = ""INIT"",

	OnOneTimeEvent
	{
		Conditions =
		{
	    	-- fill_me
		},
		Actions =
		{

		},
		GotoState = ""MAIN"",
	},
};

State
{
	StateName = ""MAIN"",

	OnOneTimeEvent
	{
		Conditions =
		{
		    -- fill_me
		},
		Actions =
		{
            -- fill_me
		},
	},

};'''

with open(main_script + '.lua','w') as file:
	file.write(main_script_template)
print(f'The file {main_script} is created\n')

while npc_count > counter:

  counter += 1
  generated_npc = f'{npc_map_name}{counter}.lua'

  with open(generated_npc,'w') as file:
    file.write(lua_command)
  print(f'Your file {generated_npc} is created')",buggy
"map_state_template = '''State
script_folder = ""script/""
def main():
	generateNpc()
	generateNpcActions()

main()

def generateNpc():
	
	npc_name = input(""What is the name of your npc that you create?\n"")
  npc_count = int(input(""How much npc you created in the map?\n""))
	main_script = input(""Enter the main spawn script:\n"")
  counter = 0
  lua_command = f'dofile(GetScriptPath()..""{main_script}.lua"")'
  print(npc_name)",bug-free
"def print_unicode(text):
    """"""Print in a portable manner.""""""
    if sys.version_info[0] < 3:
        text = text.encode('utf-8')

    print(text)


        guess_language = None
        if args.language:
            if args.language.lower() == 'auto':
                try:
                    from guess_language import guess_language
                except ImportError:
                    print('guess_language is unavailable.', file=sys.stderr)
                    return 1
                else:
                    language = guess_language(text)
                    print('Detected language: {}'.format(language),
                          file=sys.stderr)
                    if not language:
                        return 1
                    lang_tool.language = language
            else:
                lang_tool.language = args.language

                print_unicode(lang_tool.correct(text))
                    print_unicode('{}: {}: {}'.format(",buggy
"            language=args.language,
                print(lang_tool.correct(text))
                    print('{}: {}: {}'.format(",bug-free
"        gash = self.push(TerraformVariable, 'gash', type='string')
        self.push(TerraformOutput, 'gash', value=gash.to_string())
def synth(stack: NewStack) -> None:  # noqa: ARG001
    Accept the Git hASH (GASH) as a variable and output it.
    gash = stack.push(TerraformVariable, 'gash', type='string')
    stack.push(TerraformOutput, 'gash', value=gash.to_string())
            autoformatted = check_output(
                [format_with, 'fmt', '-'],  # noqa: S603
                input=unformatted.encode(),",buggy
"        giha = self.push(TerraformVariable, 'giha', type='string')
        self.push(TerraformOutput, 'giha', value=giha.to_string())
def synth(stack: NewStack) -> None:
    Accept the GIt HAsh (GIHA) as a variable and output it.
    giha = stack.push(TerraformVariable, 'giha', type='string')
    stack.push(TerraformOutput, 'giha', value=giha.to_string())
            autoformatted = check_output(  # noqa: S603
                [format_with, 'fmt', '-'], input=unformatted.encode()",bug-free
"from typing import List, Dict
            # Sử dụng model đã fine-tune cho NER tiếng Việt
            model_name = ""NlpHUST/ner-vietnamese-electra-base""
    @torch.no_grad()
    @lru_cache(maxsize=1000)
    def extract_entities(self, text: str) -> List[Dict]:
        """"""
        Trích xuất entities từ một đoạn text.
        
        Args:
            text (str): Đoạn text cần xử lý
            
        Returns:
            List[Dict]: Danh sách các entities được tìm thấy
        """"""
            # Tokenize input
            inputs = self.tokenizer(
                text,
                return_tensors=""pt"",
                padding=True,
                truncation=True,
                max_length=512  # Giới hạn độ dài input
            )
            inputs.to(self.device)

            # Model inference
            outputs = self.model(**inputs)
            # Tính softmax để lấy confidence scores
            probabilities = torch.softmax(outputs.logits, dim=2)
            confidence_scores = torch.max(probabilities, dim=2).values

            # Convert tokens và labels
            tokens = self.tokenizer.convert_ids_to_tokens(inputs[""input_ids""][0])
            labels = [self.id2label[p.item()] for p in predictions[0]]
            confidences = [score.item() for score in confidence_scores[0]]

            # Process entities
            entities = self._process_entities(tokens, labels, confidences, text)
            return entities
            logger.error(f""Error processing text: {e}"")
            return []
        current_entity = None
            entities = self.model.extract_entities(request.text)

            process_time = time.time() - start_time
            metrics.processing_time.labels(method='extract_entities').observe(process_time)
            metrics.request_counter.labels(method='extract', status='success').inc()

            return ner_pb2.ExtractEntitiesResponse(entities=[
                ner_pb2.Entity(
                    text=e['text'],
                    type=e['type'],
                    confidence=e['confidence'],
                    start_pos=e['start_pos'],
                    end_pos=e['end_pos']
                for e in entities
            ],
            process_time=process_time
            metrics.request_counter.labels(method='extract', status= 'error').inc()
    # Tạo request
    request = ner_pb2.ExtractEntitiesRequest(
        text=""Tôi có cuộc họp với anh Nam vào lúc 2 giờ chiều ngày mai tại văn phòng công ty ABC""
    )
    
    try:
        # Gọi service
        response = await stub.ExtractEntities(request)
        print(""\nKết quả trích xuất:"")
        print(""-"" * 50)
        for entity in response.entities:
            print(f""Text: {entity.text}"")
            print(f""Type: {entity.type}"")
            print(f""Confidence: {entity.confidence:.2f}"")
            print(f""Position: {entity.start_pos} -> {entity.end_pos}"")
            print(""-"" * 50)
        print(f""Thời gian xử lý: {response.process_time:.2f}s"")
    except grpc.RpcError as e:
        print(f""Lỗi RPC: {e.details()}"")",buggy
"from typing import List, Dict, Optional, Tuple
            # Sử dụng model đa ngôn ngữ cho NER
            model_name = ""Davlan/xlm-roberta-base-ner-hrl""
            logger.info(f""Model labels: {self.id2label}"")
    def extract_entities(self, text: str) -> Tuple[List[Dict], float]:
            # Kiểm tra cache
            if text in self.cache:
                logger.info(""Using cached result"")
                return self.cache[text]
            
            # Tokenize
            inputs = self.tokenizer(text, return_tensors=""pt"", padding=True, truncation=True)
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            # Inference
            with torch.no_grad():
                outputs = self.model(**inputs)
                
            # Lấy predictions
            scores = torch.softmax(outputs.logits, dim=2)
            
            # Debug info
            logger.info(f""Raw predictions shape: {predictions.shape}"")
            logger.info(f""Predictions: {predictions[0].tolist()}"")
            
            # Chuyển tokens thành text
            tokens = self.tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])
            logger.info(f""Tokens: {tokens}"")
            
            # Xử lý kết quả
            entities = []
            current_entity: Optional[Dict] = None
            
            for idx, (token, pred_id) in enumerate(zip(tokens, predictions[0])):
                pred_label = self.id2label[pred_id.item()]
                confidence = scores[0][idx][pred_id].item()
                
                logger.info(f""Token: {token}, Label: {pred_label}, Confidence: {confidence:.2f}"")
                
                if pred_label != ""O"":
                    # Bỏ qua special tokens
                    if token in [self.tokenizer.cls_token, self.tokenizer.sep_token, self.tokenizer.pad_token]:
                        continue
                        
                    # Xử lý B- tags (beginning of entity)
                    if pred_label.startswith(""B-""):
                        if current_entity is not None:
                            entities.append(current_entity.copy())
                        current_entity = {
                            ""text"": token.replace('▁', ''),
                            ""type"": pred_label[2:],
                            ""confidence"": confidence,
                            ""start_pos"": idx,
                            ""end_pos"": idx
                        }
                    
                    # Xử lý I- tags (inside of entity)
                    elif pred_label.startswith(""I-""):
                        if current_entity is not None and current_entity[""type""] == pred_label[2:]:
                            current_entity[""text""] += token.replace('▁', '')
                            current_entity[""end_pos""] = idx
                            current_entity[""confidence""] = (current_entity[""confidence""] + confidence) / 2
                
                else:  # O tag
                    if current_entity is not None:
                        entities.append(current_entity.copy())
                        current_entity = None
            
            # Thêm entity cuối cùng nếu có
            if current_entity is not None:
                entities.append(current_entity.copy())
            # Cache kết quả
            self.cache[text] = (entities, process_time)
            return entities, process_time
            logger.error(f""Error extracting entities: {e}"")
            return [], 0.0
        current_entity: Optional[Dict] = None
            entities, process_time = self.model.extract_entities(request.text)
            
            # Convert entities to gRPC format
            grpc_entities = []
            for entity in entities:
                grpc_entity = ner_pb2.Entity(
                    text=str(entity.get(""text"", """")),
                    type=str(entity.get(""type"", """")), 
                    confidence=float(entity.get(""confidence"", 0.0)),
                    start_pos=int(entity.get(""start_pos"", 0)),
                    end_pos=int(entity.get(""end_pos"", 0))
                grpc_entities.append(grpc_entity)

            return ner_pb2.ExtractEntitiesResponse(
                entities=grpc_entities,
                process_time=float(process_time)
            metrics.request_counter.labels(method='extract', status='error').inc()
    # Test cases cho nhiều ngôn ngữ
    test_cases = [
        # Tiếng Việt
        ""Tôi có cuộc họp với anh Nam và chị Hương vào lúc 2 giờ chiều ngày mai tại văn phòng công ty ABC ở Hà Nội"",
        ""Bộ trưởng Nguyễn Văn A đã có chuyến thăm chính thức tới Microsoft tại Singapore vào tháng trước"",
        ""Trường Đại học Bách Khoa Hà Nội tổ chức hội thảo về AI tại Việt Nam"",
        
        # Tiếng Anh
        ""John Smith and Mary Johnson will meet with Google's CEO at their New York office tomorrow"",
        ""Apple announced their new iPhone at their headquarters in Cupertino, California"",
        ""The United Nations conference in Geneva discussed climate change with representatives from China and Russia"",
        
        # Tiếng Trung
        ""李明和王芳将在明天下午在北京微软公司与张总监会面讨论新项目"",
        ""中国科学院的研究人员在上海举办了一场关于人工智能的研讨会"",
        ""阿里巴巴集团在杭州总部宣布与腾讯合作新计划"",
        # Tiếng Nhật
        ""田中さんは明日東京のソニー本社で佐藤部長と山本社長と会議があります"",
        ""トヨタ自動車は名古屋工場で新型電気自動車の発表会を開催する"",
        ""日立製作所の鈴木部長は大阪支社の山田課長と打ち合わせを行う"",
        
        # Tiếng Hàn
        ""김영희는 내일 삼성전자 서울사무소에서 이부장과 박차장을 만날 예정입니다"",
        ""현대자동차는 울산공장에서 신형 전기차를 공개했습니다"",
        ""LG전자의 정회장은 부산지사의 최부장과 회의를 가졌습니다""
    ]
    for text in test_cases:
        try:
            # Gọi service
            request = ner_pb2.ExtractEntitiesRequest(text=text)
            response = await stub.ExtractEntities(request)
            
            print(f""\nInput text: {text}"")
            print(""\nKết quả trích xuất:"")
            print(""-"" * 50)
            for entity in response.entities:
                print(f""Text: {entity.text}"")
                print(f""Type: {entity.type}"")
                print(f""Confidence: {entity.confidence:.2f}"")
                print(f""Position: {entity.start_pos} -> {entity.end_pos}"")
                print(""-"" * 50)
            print(f""Thời gian xử lý: {response.process_time:.2f}s"")
            print(""\n"" + ""="" * 80 + ""\n"")
            
        except grpc.RpcError as e:
            print(f""Lỗi RPC: {e.details()}"")
            ",bug-free
"# Map items in `dynamic-library-alist' to source pakages
# Emacs style path to dependancy DLLs on build system
# Return dependancies listed in Emacs
parser.add_argument(""-e"", help=""extract direct dependancies"",",buggy
"# Map items in `dynamic-library-alist' to source packages
# Emacs style path to dependency DLLs on build system
# Return dependencies listed in Emacs
parser.add_argument(""-e"", help=""extract direct dependencies"",",bug-free
"# Map items in `dynamic-library-alist' to source pakages
# Emacs style path to dependancy DLLs on build system
# Return dependancies listed in Emacs
parser.add_argument(""-e"", help=""extract direct dependancies"",",buggy
"# Map items in `dynamic-library-alist' to source packages
# Emacs style path to dependency DLLs on build system
# Return dependencies listed in Emacs
parser.add_argument(""-e"", help=""extract direct dependencies"",",bug-free
"    print(f""Language:\t\t\tRust"")",buggy
"    print(f""Language:\t\t\tPython"")",bug-free
"log()
    palette = {
        ""ERROR"": ""[white on #F43F5E]"",
        ""WARNING"": ""[black on #EAB308]"",
        ""SUCCESS"": ""[black on #10B981]"",
    color = get_safe(palette, level, """") or get_safe(palette, indent, """") or ""[white]""
    print(indent * ""    "" + color + str(message) + ""[/]"", end="""", flush=True)
        log(e, 3)",buggy
"log()
    colors = {
        ""ERROR"": ""[#F43F5E]"",
        ""WARNING"": ""[#EAB308]"",
        ""SUCCESS"": ""[#10B981]"",
    prefixes = {
        ""ERROR"": "" ERROR: "",
        ""WARNING"": "" WARNING: "",
    }
    color = get_safe(colors, level, """") or get_safe(colors, indent, """") or ""[white]""
    prefix = get_safe(prefixes, level, """")
    print(indent * ""    "" + color + prefix + str(message) + ""[/]"", end="""", flush=True)
        log(e, indent=3)",bug-free
"state_template = '''State
script_foler = ""script""
print(""Hey, this is script generator for SpellForce Lua Scripts if you're trying to modding your units in editor, and you don't wan't to write a lot of copy-paste code. This script is best offer for lazy ass like me :D\n\n"")

npc_map_name = input(""What is the name of your npc that you create in editor?\n"")
npc_count = int(input(""How much npc you created in the map?\n""))
main_script = input(""Enter the main script filename that will be in the npc file you generate:\n"")
counter = 0
lua_command = f'dofile(GetScriptPath()..""{main_script}.lua"")'

main_script_template = '''State
{
	StateName = ""INIT"",

	OnOneTimeEvent
	{
		Conditions =
		{
	    	-- fill_me
		},
		Actions =
		{

		},
		GotoState = ""MAIN"",
	},
};

State
{
	StateName = ""MAIN"",

	OnOneTimeEvent
	{
		Conditions =
		{
		    -- fill_me
		},
		Actions =
		{
            -- fill_me
		},
	},

};'''

with open(main_script + '.lua','w') as file:
	file.write(main_script_template)
print(f'The file {main_script} is created\n')

while npc_count > counter:

  counter += 1
  generated_npc = f'{npc_map_name}{counter}.lua'

  with open(generated_npc,'w') as file:
    file.write(lua_command)
  print(f'Your file {generated_npc} is created')",buggy
"map_state_template = '''State
script_folder = ""script/""
def main():
	generateNpc()
	generateNpcActions()

main()

def generateNpc():
	
	npc_name = input(""What is the name of your npc that you create?\n"")
  npc_count = int(input(""How much npc you created in the map?\n""))
	main_script = input(""Enter the main spawn script:\n"")
  counter = 0
  lua_command = f'dofile(GetScriptPath()..""{main_script}.lua"")'
  print(npc_name)",bug-free
"state_template = '''State
script_foler = ""script""
print(""Hey, this is script generator for SpellForce Lua Scripts if you're trying to modding your units in editor, and you don't wan't to write a lot of copy-paste code. This script is best offer for lazy ass like me :D\n\n"")

npc_map_name = input(""What is the name of your npc that you create in editor?\n"")
npc_count = int(input(""How much npc you created in the map?\n""))
main_script = input(""Enter the main script filename that will be in the npc file you generate:\n"")
counter = 0
lua_command = f'dofile(GetScriptPath()..""{main_script}.lua"")'

main_script_template = '''State
{
	StateName = ""INIT"",

	OnOneTimeEvent
	{
		Conditions =
		{
	    	-- fill_me
		},
		Actions =
		{

		},
		GotoState = ""MAIN"",
	},
};

State
{
	StateName = ""MAIN"",

	OnOneTimeEvent
	{
		Conditions =
		{
		    -- fill_me
		},
		Actions =
		{
            -- fill_me
		},
	},

};'''

with open(main_script + '.lua','w') as file:
	file.write(main_script_template)
print(f'The file {main_script} is created\n')

while npc_count > counter:

  counter += 1
  generated_npc = f'{npc_map_name}{counter}.lua'

  with open(generated_npc,'w') as file:
    file.write(lua_command)
  print(f'Your file {generated_npc} is created')",buggy
"map_state_template = '''State
script_folder = ""script/""
def main():
	generateNpc()
	generateNpcActions()

main()

def generateNpc():
	
	npc_name = input(""What is the name of your npc that you create?\n"")
  npc_count = int(input(""How much npc you created in the map?\n""))
	main_script = input(""Enter the main spawn script:\n"")
  counter = 0
  lua_command = f'dofile(GetScriptPath()..""{main_script}.lua"")'
  print(npc_name)",bug-free
"state_template = '''State
script_foler = ""script""
print(""Hey, this is script generator for SpellForce Lua Scripts if you're trying to modding your units in editor, and you don't wan't to write a lot of copy-paste code. This script is best offer for lazy ass like me :D\n\n"")

npc_map_name = input(""What is the name of your npc that you create in editor?\n"")
npc_count = int(input(""How much npc you created in the map?\n""))
main_script = input(""Enter the main script filename that will be in the npc file you generate:\n"")
counter = 0
lua_command = f'dofile(GetScriptPath()..""{main_script}.lua"")'

main_script_template = '''State
{
	StateName = ""INIT"",

	OnOneTimeEvent
	{
		Conditions =
		{
	    	-- fill_me
		},
		Actions =
		{

		},
		GotoState = ""MAIN"",
	},
};

State
{
	StateName = ""MAIN"",

	OnOneTimeEvent
	{
		Conditions =
		{
		    -- fill_me
		},
		Actions =
		{
            -- fill_me
		},
	},

};'''

with open(main_script + '.lua','w') as file:
	file.write(main_script_template)
print(f'The file {main_script} is created\n')

while npc_count > counter:

  counter += 1
  generated_npc = f'{npc_map_name}{counter}.lua'

  with open(generated_npc,'w') as file:
    file.write(lua_command)
  print(f'Your file {generated_npc} is created')",buggy
"map_state_template = '''State
script_folder = ""script/""
def main():
	generateNpc()
	generateNpcActions()

main()

def generateNpc():
	
	npc_name = input(""What is the name of your npc that you create?\n"")
  npc_count = int(input(""How much npc you created in the map?\n""))
	main_script = input(""Enter the main spawn script:\n"")
  counter = 0
  lua_command = f'dofile(GetScriptPath()..""{main_script}.lua"")'
  print(npc_name)",bug-free
"                max_age=0 if 'assets' in self.session.debug else STATIC_CACHE,",buggy
"            debug = (
                'assets' in self.session.debug and
                ' wkhtmltopdf ' not in self.httprequest.user_agent.string
            )
                max_age=0 if debug else STATIC_CACHE,",bug-free
"""""""
Python implementation of `cucumber tag-expressions`_.
Tag-expressions are used in cucumber, behave and other BDD frameworks
Theses selected items are normally included in a test run.
.. see also:: https://cucumber.io/docs/cucumber/api/#tag-expressions
    # pylint: disable=line-too-long
.. _`cucumber tag-expressions`: https://cucumber.io/docs/cucumber/api/#tag-expressions
.. _`Gherkin`: https://cucumber.io/docs/gherkin/reference/
    # pylint: disable=line-too-long
.. _`behave: Gherkin`: https://behave.readthedocs.io/en/latest/philosophy.html#the-gherkin-language
""""""
Provides model classes to evaluate parsed boolean tag expressions.

.. code-block:: python

    # -- Expression := a and b
    expression = And(Literal(""a""), Literal(""b""))
    assert True  == expression.evaluate([""a"", ""b""])
    assert False == expression.evaluate([""a""])
    assert False == expression.evaluate([])

    # -- Expression := a or b
    expression = Or(Literal(""a""), Literal(""b""))
    assert True  == expression.evaluate([""a"", ""b""])
    assert True  == expression.evaluate([""a""])
    assert False == expression.evaluate([])

    # -- Expression := not a
    expression = Not(Literal(""a""))
    assert False == expression.evaluate([""a""])
    assert True  == expression.evaluate([""other""])
    assert True  == expression.evaluate([])

    # -- Expression := (a or b) and c
    expression = And(Or(Literal(""a""), Literal(""b"")), Literal(""c""))
    assert True  == expression.evaluate([""a"", ""c""])
    assert False == expression.evaluate([""c"", ""other""])
    assert False == expression.evaluate([])
    """"""Abstract base class for boolean expression terms of a tag-expression
    (or representing a parsed tag-expression (evaluation-tree)).
        """"""Call operator to make an expression-object callable.""""""
    """"""Used as placeholder for a tag in a boolean tag-expression.""""""
""""""
Provides parsing of boolean tag expressions.

.. code-block:: python

    expression = TagExpressionParser.parse(""a and (b or not c)"")
    assert True == expression.evaluate([""a"", ""other""])
    assert ""( a and ( b or not (c) ) )"" == str(expression)

    """"""Describes associativity of boolean operations.""""""
    """"""Describes tokens and their abilities for tag-expression parsing.""""""
    OPEN_PARENTHESIS  = (""("", -2) # Java, Javascript: -2, Ruby: 1
        """"""Checks if this token has lower precedence than other token.""""""
    """"""Raised by parser if an invalid tag-expression is detected.""""""
    """"""Parser class to parse boolean tag-expressions.
    This class uses the `Shunting Yard algorithm`_ to parse the tag-expression.
    In addition, parenthesis can be used to group expressions, like::

        a and (b or c)
        (a and not b) or (c and d)

    EXAMPLES:

    .. code-block:: python

        # -- UNARY OPTIONS
        text11 = ""not foo"" = ""(not foo)""
        expression = TagExpressionParser.parse(text11)
        assert False == expression.evaluate([""foo""])
        assert True  == expression.evaluate([""other""])

        # -- BINARY OPERATIONS:
        text21 = ""foo and bar"" = ""(foo and bar)""
        expression = TagExpressionParser.parse(text21)
        assert True  == expression.evaluate([""foo"", ""bar""])
        assert False == expression.evaluate([""foo""])
        assert False == expression.evaluate([])

        text22 = ""foo or bar""  = ""(foo or bar)""
        expression = TagExpressionParser.parse(text22)
        assert True  == expression.evaluate([""foo"", ""bar""])
        assert True  == expression.evaluate([""foo"", ""other""])
        assert False == expression.evaluate([])

    .. see::

        * `Shunting Yard algorithm`_
        * http://rosettacode.org/wiki/Parsing/Shunting-yard_algorithm

    # pylint: disable=line-too-long
    .. _`Shunting Yard algorithm`: https://en.wikipedia.org/wiki/Shunting-yard_algorithm
        """"""Select the token that matches the text or return None.
        :param text: Text to select the matching token.
        :return: Token object or None, if not found.
        """"""Creates operand-object from parsed text.""""""
        # -- EXTENSION-POINT: For #406 or similar.
        :param text: Textual tag-expression (as string).
        :raises: TagExpressionError, if the escape is incorrectly used.
        :return: list of tokens (strings).
        """"""Parse a textual tag-expression and return the expression (tree).
        :param text: Textual tag-expression (as string).
        :return: Tag expression (instance of :class:`Expression`).
        :raises: TagExpressionError, if the tag-expression is invalid.
            #  -- CASE: Empty tag-expression is always true.
        # -- FINALLY: Return boolean tag-expression.
        """"""Push a new boolean-expression on the expression-stack.
        Retrieves operands for operation from the expression-stack and
        :param token:  Token for new expression (instance of class:`Token`).
        :param expressions: Expression stack to use (as inout param).
        :raises: TagExpressionError, if too few args are in expression-stack.
    """"""Parse a tag-expression as text and return the expression tree.
    .. code-block:: python
        tags = [""foo"", ""bar""]
        tag_expression = parse(""foo and bar or not baz"")
        assert tag_expression.evaluate(tags) == True
    :param text:    Tag expression as text to parse.
    :param parser_class:  Optional p
    :return: Parsed expression",buggy
"""""""Python implementation of `Cucumber Tag Expressions`_.
Tag expressions are used in cucumber, behave and other BDD frameworks
These selected items are normally included in a test run.
.. _Cucumber Tag Expressions:
    https://cucumber.io/docs/cucumber/api/#tag-expressions
.. _Gherkin:
    https://cucumber.io/docs/gherkin/reference/
""""""Model classes to evaluate parsed boolean tag expressions.

Examples:
    >>> expression = And(Literal(""a""), Literal(""b""))
    >>> expression({""a"", ""b""})
    True
    >>> expression({""a"", ""b""})
    True
    >>> expression({""a""})
    False
    >>> expression({})
    False

    >>> expression = Or(Literal(""a""), Literal(""b""))
    >>> expression({""a"", ""b""})
    True
    >>> expression({""a""})
    True
    >>> expression({})
    False

    >>> expression = Not(Literal(""a""))
    >>> expression({""a""})
    False
    >>> expression({""other""})
    True
    >>> expression({})
    True

    >>> expression = And(Or(Literal(""a""), Literal(""b"")), Literal(""c""))
    >>> expression({""a"", ""c""})
    True
    >>> expression({""c"", ""other""})
    False
    >>> expression({})
    False
    """"""Abstract base class for boolean expression terms of a tag expression
    (or representing a parsed tag expression (evaluation-tree)).
        """"""Evaluate whether expression matches values.

        Args:
            values (Iterable[str]): Tag names to evaluate.

        Returns:
            bool: Whether expression evaluates with values.
        """"""
        """"""Call operator to make an expression object callable.
        
        Args:
            values (Iterable[str]): Tag names to evaluate.

        Returns:
            bool: True if expression is true, False otherwise
        """"""
    """"""Used as placeholder for a tag in a boolean tag expression.""""""
        """"""Initialise literal with tag name.

        Args:
            name (str): Tag name to represent as a literal.
        """"""
        """"""Create Boolean-AND expression.

        Args:
            terms (Iterable[Expression]): List of boolean expressions to AND.

        Returns:
            None
        """"""
        """"""Create Boolean-OR expression.

        Args:
            terms (Iterable[Expression]): List of boolean expressions to OR.

        Returns:
            None
        """"""
        """"""Create Boolean-AND expression.

        Args:
            term (Expression): Boolean expression to negate.

        Returns:
            None
        """"""
        """"""Evaluates to True.

        Args:
            values (Any): Required by API though not used.

        Returns:
            Literal[True]
        """"""
""""""Parsing of boolean tag expressions.

Examples:
    >>> expression = parse(""a and (b or not c)"")
    >>> expression({""a"", ""other""})
    True
    >>> ""( a and ( b or not ( c ) ) )"" == str(expression)
    True
    """"""Associativity of boolean operations.

    How operators of same precedence are grouped in the absence of parentheses.

    * LEFT: Groups `a and b and c` to `(a and b) and c`.
    * RIGHT: Groups `a or b or c` to `a or (b or c)`.
    """"""
    """"""Types of tag expression tokens.""""""
    """"""Describes tokens and their abilities for tag expression parsing.""""""
    OPEN_PARENTHESIS  = (""("", -2) # Java, Javascript: -2; Ruby: 1
        """"""Create a new token with keyword, precedence and associativity.

        Args:
            keyword (str): Keyword for the token.
            precedence (int): Precedence of the token.
            assoc (Associative | None): Associativity of the token.
            token_type (TokenType): Type of the token.

        Returns:
            None
        """"""
        """"""Check if this token is an operator.

        Returns:
            bool: Whether this token is an operator.
        """"""
        """"""Check if this token is a binary operator.

        Returns:
            bool: Whether this token is a binary operator.
        """"""
        """"""Check if this token is a unary operator.

        Returns:
            bool: Whether this token is a unary operator.
        """"""
        """"""Checks if this token has lower precedence than another token.

        Args:
            other (Token): Token to compare with.

        Returns:
            bool: Whether this token has lower precedence than other token.
        """"""
        """"""Check if the keyword of this token matches provided text.

        Args:
            text (str): Text to compare against.

        Returns:
            bool: Whether this token matches the provided text.
        """"""
    """"""Raised by parser if an invalid tag expression is detected.""""""
    """"""Parser class to parse boolean tag expressions.
    In addition, parenthesis can be used to group expressions, like:

        ""a and (b or c)""
        ""(a and not b) or (c and d)""

    Uses the `Shunting Yard algorithm`_ to parse the tag expression.

    Examples:
        Unary operations
        >>> expression = TagExpressionParser.parse(""not foo"")
        >>> expression({""foo""})
        False
        >>> expression({""other""})
        True

        Binary operations - And
        >>> expression = TagExpressionParser.parse(""foo and bar"")
        >>> expression({""foo"", ""bar""})
        True
        >>> expression({""foo""})
        False
        >>> expression({})
        False

        Binary operations - Or
        >>> expression = TagExpressionParser.parse(""foo or bar"")
        >>> expression({""foo"", ""bar""})
        True
        >>> expression({""foo"", ""other""})
        True
        >>> expression({})
        False

    .. _Shunting Yard algorithm:
        http://rosettacode.org/wiki/Parsing/Shunting-yard_algorithm
        """"""Select the token that matches the text.
        Args:
            text (str): Text to select the matching token.

        Returns:
            Token | None: Token object or None, if not found.
        """"""Creates operand object from parsed text.

        Args:
            text (str): Text to create operand from.

        Returns:
            Literal: Operand object created from text.
        """"""
        # -- EXTENSION-POINT: For cucumber/common#406 or similar.
        Args:
            text (str): Tag expression as text to parse.

        Returns:
            list[str]: List of selected tokens.

        Raises:
            TagExpressionError: If the tag expression is invalid.
                Such as an illegal escape character.
        """"""Parse a tag expression as text and return the expression tree.
        Args:
            text (str): Tag expression as text to parse.

        Returns:
            model.Expression: Parsed expression tree.

        Raises:
            TagExpressionError: If the tag expression is invalid.

        Examples:
            >>> expression = TagExpressionParser().parse(""foo and bar or not baz"")
            >>> expression({""foo"", ""bar""})
            True
            #  -- CASE: Empty tag expression is always true.
        # -- FINALLY: Return boolean tag expression.
        """"""Push a new boolean expression on the expression stack.
        Retrieves operands for operation from the expression stack and
        Args:
            token (Token): Token for new expression.
            expressions (list[model.Expression]): Expression stack to use.

        Returns:
            None

        Raises:
            TagExpressionError: If the expression stack contains an unexpected token
                or too few operands for an operator.
            """"""Check if enough operands are in the expression stack.

            Args:
                number (int): Number of operands required.

            Returns:
                None

            Raises:
                TagExpressionError: If the expression stack contains an unexpected
                    token or too few operands for an operator.
            """"""
        """"""Construct a detailed error message for a tag expression error.

        Args:
            message (str): Error message to display.
            parts (list[str]): List of parts of the tag expression.
            error_index (int): Index of the error in the parts list.

        Returns:
            str: Detailed error message with error-position marked.
        """"""
    """"""Parse a tag expression as text and return the expression tree.

    Args:
        text (str): Tag expression as text to parse.
    Returns:
        model.Expression: Parsed expression tree.
    Raises:
        TagExpressionError: If the tag expression is invalid.
    Examples:
        >>> expression = parse(""foo and bar or not baz"")
        >>> expression({""foo"", ""bar""})
        True",bug-free
"            environ[""GRPC_RUN_AUDITWHEEL_REPAIR""] = ""TRUE""
            if self.arch == ""x86"":
                timeout_seconds=60 * 60 * 2,
    def __init__(self):
            ""tools/dockerfile/grpc_artifact_python_manylinux2014_x64"",",buggy
"            if self.arch in (""x86"", ""aarch64""):
            if self.arch == ""aarch64"":
                # As we won't strip the binary with auditwheel (see below), strip
                # it at link time.
                environ[""LDFLAGS""] = ""-s""
                # We're using musllinux aarch64 image to build this artifact so no crosscompiling required.
                environ[""GRPC_BUILD_GRPCIO_TOOLS_DEPENDENTS""] = ""TRUE""
            else:
                environ[""GRPC_RUN_AUDITWHEEL_REPAIR""] = ""TRUE""

                timeout_seconds=60 * 60 * 4,
            PythonArtifact(
                ""musllinux_1_1"", ""aarch64"", ""cp38-cp38"", presubmit=True
            ),
            PythonArtifact(""musllinux_1_1"", ""aarch64"", ""cp39-cp39""),
            PythonArtifact(""musllinux_1_1"", ""aarch64"", ""cp310-cp310""),
            PythonArtifact(""musllinux_1_1"", ""aarch64"", ""cp311-cp311""),
            PythonArtifact(""musllinux_1_1"", ""aarch64"", ""cp312-cp312""),
            PythonArtifact(
                ""musllinux_1_1"", ""aarch64"", ""cp313-cp313"", presubmit=True
            ),
    def __init__(self, platform="""", arch=""""):
        self.platform = platform
        self.arch = arch
        if self.platform:
            self.labels.append(platform)
            self.name += ""_"" + platform
        if self.arch:
            self.labels.append(arch)
            self.name += ""_"" + arch
        dockerfile_dir = (
            ""tools/dockerfile/grpc_artifact_python_manylinux2014_x64""
        )
        if ""musllinux_1_1"" in self.platform and ""aarch64"" in self.arch:
            dockerfile_dir = (
                ""tools/dockerfile/grpc_artifact_python_musllinux_1_1_aarch64""
            )
            dockerfile_dir,
        PythonPackage(""musllinux_1_1"", ""aarch64""),",bug-free
"            environ[""GRPC_RUN_AUDITWHEEL_REPAIR""] = ""TRUE""
            if self.arch == ""x86"":
                timeout_seconds=60 * 60 * 2,
    def __init__(self):
            ""tools/dockerfile/grpc_artifact_python_manylinux2014_x64"",",buggy
"            if self.arch in (""x86"", ""aarch64""):
            if self.arch == ""aarch64"":
                # As we won't strip the binary with auditwheel (see below), strip
                # it at link time.
                environ[""LDFLAGS""] = ""-s""
                # We're using musllinux aarch64 image to build this artifact so no crosscompiling required.
                environ[""GRPC_BUILD_GRPCIO_TOOLS_DEPENDENTS""] = ""TRUE""
            else:
                environ[""GRPC_RUN_AUDITWHEEL_REPAIR""] = ""TRUE""

                timeout_seconds=60 * 60 * 4,
            PythonArtifact(
                ""musllinux_1_1"", ""aarch64"", ""cp38-cp38"", presubmit=True
            ),
            PythonArtifact(""musllinux_1_1"", ""aarch64"", ""cp39-cp39""),
            PythonArtifact(""musllinux_1_1"", ""aarch64"", ""cp310-cp310""),
            PythonArtifact(""musllinux_1_1"", ""aarch64"", ""cp311-cp311""),
            PythonArtifact(""musllinux_1_1"", ""aarch64"", ""cp312-cp312""),
            PythonArtifact(
                ""musllinux_1_1"", ""aarch64"", ""cp313-cp313"", presubmit=True
            ),
    def __init__(self, platform="""", arch=""""):
        self.platform = platform
        self.arch = arch
        if self.platform:
            self.labels.append(platform)
            self.name += ""_"" + platform
        if self.arch:
            self.labels.append(arch)
            self.name += ""_"" + arch
        dockerfile_dir = (
            ""tools/dockerfile/grpc_artifact_python_manylinux2014_x64""
        )
        if ""musllinux_1_1"" in self.platform and ""aarch64"" in self.arch:
            dockerfile_dir = (
                ""tools/dockerfile/grpc_artifact_python_musllinux_1_1_aarch64""
            )
            dockerfile_dir,
        PythonPackage(""musllinux_1_1"", ""aarch64""),",bug-free
"LOG_FILE = os.path.join(os.path.dirname(sys.argv[1]), ""lsp.log"")

# def did_change_watched_files(server: HelixLanguageServer, params: DidChangeTextDocumentParams) -> None:
#     """"""Handles watched file changes.""""""
#     logger.info('Watched files changed: {}', params.text_document.uri)",buggy
"    DidChangeWatchedFilesParams,
LOG_FILE = os.path.join(os.path.dirname(__file__), ""lsp.log"")
    @property
    def server_capabilities(self):
        """"""Override server capabilities.""""""
        capabilities = super().server_capabilities
        capabilities.text_document_sync = {
            ""openClose"": True,
            ""change"": None,  # Disable incremental sync
            ""willSave"": False,
            ""willSaveWaitUntil"": False,
            ""save"": True,
        }
        
        return capabilities
    
# def did_change_watched_files(server: HelixLanguageServer, params: DidChangeWatchedFilesParams) -> None:
#     """"""Handles document saving.""""""
#     logger.info('Document saved: {}', params.text_document.uri)",bug-free
"from typing import List, Dict, Any
from transformers import AutoModelForCausalLM, AutoTokenizer
print(""Loading UI-TARS model..."")
model_path = ""../ui-tars-7b-dpo""
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    torch_dtype=torch.float16,
    device_map=""auto""
)
def format_dom_for_model(dom_content: str) -> str:
    """"""Format DOM content for UI-TARS model input""""""
    return f""""""
DOM Structure:
{dom_content}
""""""

def generate_action_plan(instruction: str, dom_content: str = None) -> Dict:
    """"""Generate UI action plan using UI-TARS model""""""
    prompt = f""""""Task: {instruction}\n""""""
    if dom_content:
        prompt += format_dom_for_model(dom_content)
    
    prompt += ""\nGenerate a detailed action plan:""

    # Generate response from model
    inputs = tokenizer(prompt, return_tensors=""pt"").to(model.device)
    outputs = model.generate(
        **inputs,
        max_length=500,
        temperature=0.1,
        do_sample=True,
        num_return_sequences=1
    )
    
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    
        # Extract JSON plan
        plan_start = response.find('{')
        plan_end = response.rfind('}') + 1
        plan_json = response[plan_start:plan_end]
        # Parse and validate action plan
        plan = json.loads(plan_json)
        return {
            ""actions"": plan.get(""actions"", []),
            ""elements"": plan.get(""elements"", [])
        print(f""Error parsing model output: {e}"")
        print(f""Raw output: {response}"")
        return {""error"": ""Could not generate action plan""}
        # Extract instruction and DOM content
        dom_content = message[""content""][1].get(""dom"", """") if len(message[""content""]) > 1 else None
        
        # Generate action plan using UI-TARS
        action_plan = generate_action_plan(instruction, dom_content)
        
                    ""content"": json.dumps(action_plan)
    uvicorn.run(app, host=""0.0.0.0"", port=8000)",buggy
"from typing import List, Dict, Any, Optional
import os
from transformers import AutoConfig, AutoModelForVision2Seq, AutoTokenizer, AutoProcessor
from PIL import Image
import base64
import io
import logging

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
# Enable CORS
# Model initialization with proper error handling
def initialize_model():
    model_path = ""/models/ui-tars-7b-dpo""
    logger.info(f""Initializing UI-TARS model from {model_path}"")

    try:
        # Load configuration
        config = AutoConfig.from_pretrained(
            model_path,
            trust_remote_code=True
        )
        logger.info(""Configuration loaded successfully"")

        # Load tokenizer with special token handling
        tokenizer = AutoTokenizer.from_pretrained(
            model_path,
            trust_remote_code=True
        )
        logger.info(""Tokenizer loaded successfully"")

        # Load image processor
        processor = AutoProcessor.from_pretrained(
            model_path,
            trust_remote_code=True
        )
        logger.info(""Processor loaded successfully"")

        # Initialize model with proper configuration
        model = AutoModelForVision2Seq.from_pretrained(
            model_path,
            config=config,
            torch_dtype=torch.float16,
            device_map=""auto"",
            trust_remote_code=True
        )
        model.eval()
        logger.info(""Model loaded successfully"")

        return model, tokenizer, processor

    except Exception as e:
        logger.error(f""Error initializing model: {str(e)}"")
        if os.path.exists(model_path):
            logger.error(f""Model directory contents: {os.listdir(model_path)}"")
        raise

# Initialize model components
model, tokenizer, processor = initialize_model()
    max_tokens: Optional[int] = 500
    temperature: Optional[float] = 0.1
def preprocess_image(image_data: str) -> Image.Image:
    """"""Convert base64 screenshot to PIL Image with error handling""""""
        image_bytes = base64.b64decode(image_data)
        return Image.open(io.BytesIO(image_bytes))
    except Exception as e:
        logger.error(f""Error processing image: {str(e)}"")
        raise ValueError(""Invalid image data"")

def generate_response(instruction: str, screenshot: Optional[str] = None) -> Dict:
    """"""Generate UI interaction plan using UI-TARS model""""""
    try:
        # Prepare the instruction prompt
        prompt = f""Based on the webpage shown, {instruction}""
        # Prepare inputs for the model
        inputs = {
            ""text"": tokenizer(
                prompt,
                return_tensors=""pt"",
                padding=True,
                truncation=True
            ).to(model.device)

        # Process screenshot if provided
        if screenshot:
            image = preprocess_image(screenshot)
            image_inputs = processor(images=image, return_tensors=""pt"").to(model.device)
            inputs.update(image_inputs)

        # Generate response with the model
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_length=500,
                temperature=0.1,
                do_sample=True,
                num_return_sequences=1
            )

        # Decode and process the response
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        logger.info(f""Generated response: {response[:100]}..."")  # Log first 100 chars

        # Extract and validate the JSON plan
        try:
            plan_start = response.find('{')
            plan_end = response.rfind('}') + 1
            if plan_start == -1 or plan_end <= plan_start:
                raise ValueError(""No valid JSON found in response"")

            plan_json = response[plan_start:plan_end]
            plan = json.loads(plan_json)

            return {
                ""actions"": plan.get(""actions"", []),
                ""elements"": plan.get(""elements"", []),
                ""understanding"": plan.get(""understanding"", """"),
                ""verification"": plan.get(""verification"", [])
            }
        except json.JSONDecodeError as e:
            logger.error(f""JSON parsing error: {str(e)}"")
            logger.error(f""Response text: {response}"")
            raise ValueError(""Invalid response format"")

        logger.error(f""Error generating response: {str(e)}"")
        return {""error"": str(e)}
        # Extract the latest message
        screenshot = message[""content""][1].get(""screenshot"", None) if len(message[""content""]) > 1 else None

        # Generate the interaction plan
        plan = generate_response(instruction, screenshot)

                    ""content"": json.dumps(plan)
        logger.error(f""Error in chat completion: {str(e)}"")
@app.get(""/health"")
async def health_check():
    """"""Health check endpoint""""""
    try:
        # Verify model components are loaded
        if not all([model, tokenizer, processor]):
            raise Exception(""One or more model components not initialized"")
        return {""status"": ""healthy"", ""model"": ""loaded""}
    except Exception as e:
        raise HTTPException(status_code=503, detail=str(e))

    uvicorn.run(app, host=""0.0.0.0"", port=8000)",bug-free
"        post_id = request.form.get(""post_id"", None)
from google.cloud import firestore
    db = firestore.Client()
    with open(""../data/blog_entries.json"", 'r') as file:
            document = db.collection(""posts"").document(id)
    print(""get_unsplash_image()"")
        print(response.json()[""urls""][""small""])",buggy
"        post_id = request.form.get(""post-id"", None)
from extensions.my_firestore import db
from config import config


    post_collection = config[""development""].POSTS
    
    with open(""sample_data/blog_entries.json"", 'r') as file:
            document = db.collection(post_collection).document(id)
    # print(""get_unsplash_image()"")
        # print(response.json()[""urls""][""small""])",bug-free
"    forecast_df: pl.DataFrame,
    id_cols: list[str] = [""draw""],
    strict: bool = False,
    Aggregate daily values (e.g.
    forecast_df
        A polars dataframe with draws and dates
        as columns. This dataframe will likely
        have come from an InferenceData object
        that was converted using `idata_w_dates_to_df`.
        The name of the column with the fitted
        and or forecasted quantity. Defaults
        to ""value"".
        Defaults to ""date"".
        Defaults to ["".draw""].
        Defaults to ""weekly_value"".
        values. If False, then incomplete weeks
        will be aggregated. Defaults to False.
    forecast_df = forecast_df.with_columns(
        pl.col([""date""])
    grouped_df = forecast_df.group_by(group_cols)
        message = f""Problematic trajectories with more than 7 values per epiweek per year: {problematic_trajectories}""
        raise ValueError(
            f""At least one trajectory has more than 7 values for a given epiweek of a given year.\n{message}""
        )
    # check if any week has more than 7 dates
    if not n_elements[""n_elements""].to_numpy().max() <= 7:
            ""At least one trajectory has more than 7 values for a given epiweek of a given year.""
    # if strict, filter out groups that do not have exactly 7 contributing dates
        forecast_df = forecast_df.join(
    # aggregate; sum values in the specified value_col
        forecast_df.group_by(group_cols)
        .sort([""epiyear"", ""epiweek"", ""draw""])",buggy
"from forecasttools.utils import ensure_listlike

    df: pl.DataFrame,
    id_cols: str | list[str] = [""draw""],
    strict: bool = True,
    Aggregate a dataframe of daily values (e.g.
    df
        Tidy data frame of daily values to aggregate.
        The name of the column containing daily trajectory /
        timeseries values to aggregate. Defaults
        to ```""value""``.
        Defaults to ``""date""``.
        Defaults to ``""draw""``.
        Defaults to ``""weekly_value""``.
        values. If ``False``, then incomplete weeks
        will be aggregated. Defaults to ``True``.
    id_cols = ensure_listlike(id_cols)
    df = df.with_columns(
        pl.col(date_col)
    grouped_df = df.group_by(group_cols)
            ""At least one trajectory has more than 7 values ""
            ""for a given epiweek of a given epiyear.\n""
            ""Problematic trajectories with more than 7 ""
            ""values: ""
            f""{problematic_trajectories}""

        df = df.join(
        df.group_by(group_cols)
        .sort(group_cols)",bug-free
"class TracingProvider(Generic[T], metaclass=abc.ABCMeta):
class ComputationBuildingBlock(typed_object.TypedObject, metaclass=abc.ABCMeta):
class BoundVariableTracker(metaclass=abc.ABCMeta):
class TransformSpec(metaclass=abc.ABCMeta):
class Computation(typed_object.TypedObject, metaclass=abc.ABCMeta):
class SyncContext(metaclass=abc.ABCMeta):
class AsyncContext(metaclass=abc.ABCMeta):
class ContextStack(metaclass=abc.ABCMeta):
class Executor(metaclass=abc.ABCMeta):
class ExecutorFactory(metaclass=abc.ABCMeta):
class ExecutorValue(abc.ABC, typed_object.TypedObject):
class Value(typed_object.TypedObject, metaclass=abc.ABCMeta):
class MaterializableValueReference(abc.ABC, typed_object.TypedObject):
class Type(metaclass=abc.ABCMeta):
class TypedObject(metaclass=abc.ABCMeta):",buggy
"class TracingProvider(Generic[T], abc.ABC):
class ComputationBuildingBlock(typed_object.TypedObject, abc.ABC):
class BoundVariableTracker(abc.ABC):
class TransformSpec(abc.ABC):
class Computation(typed_object.TypedObject, abc.ABC):
class SyncContext(abc.ABC):
class AsyncContext(abc.ABC):
class ContextStack(abc.ABC):
class Executor(abc.ABC):
class ExecutorFactory(abc.ABC):
class ExecutorValue(typed_object.TypedObject, abc.ABC):
class Value(typed_object.TypedObject, abc.ABC):
class MaterializableValueReference(typed_object.TypedObject, abc.ABC):
class Type(abc.ABC):
class TypedObject(abc.ABC):",bug-free
"                max_age=0 if 'assets' in self.session.debug else STATIC_CACHE,",buggy
"            debug = (
                'assets' in self.session.debug and
                ' wkhtmltopdf ' not in self.httprequest.user_agent.string
            )
                max_age=0 if debug else STATIC_CACHE,",bug-free
"""""""
Python implementation of `cucumber tag-expressions`_.
Tag-expressions are used in cucumber, behave and other BDD frameworks
Theses selected items are normally included in a test run.
.. see also:: https://cucumber.io/docs/cucumber/api/#tag-expressions
    # pylint: disable=line-too-long
.. _`cucumber tag-expressions`: https://cucumber.io/docs/cucumber/api/#tag-expressions
.. _`Gherkin`: https://cucumber.io/docs/gherkin/reference/
    # pylint: disable=line-too-long
.. _`behave: Gherkin`: https://behave.readthedocs.io/en/latest/philosophy.html#the-gherkin-language
""""""
Provides model classes to evaluate parsed boolean tag expressions.

.. code-block:: python

    # -- Expression := a and b
    expression = And(Literal(""a""), Literal(""b""))
    assert True  == expression.evaluate([""a"", ""b""])
    assert False == expression.evaluate([""a""])
    assert False == expression.evaluate([])

    # -- Expression := a or b
    expression = Or(Literal(""a""), Literal(""b""))
    assert True  == expression.evaluate([""a"", ""b""])
    assert True  == expression.evaluate([""a""])
    assert False == expression.evaluate([])

    # -- Expression := not a
    expression = Not(Literal(""a""))
    assert False == expression.evaluate([""a""])
    assert True  == expression.evaluate([""other""])
    assert True  == expression.evaluate([])

    # -- Expression := (a or b) and c
    expression = And(Or(Literal(""a""), Literal(""b"")), Literal(""c""))
    assert True  == expression.evaluate([""a"", ""c""])
    assert False == expression.evaluate([""c"", ""other""])
    assert False == expression.evaluate([])
    """"""Abstract base class for boolean expression terms of a tag-expression
    (or representing a parsed tag-expression (evaluation-tree)).
        """"""Call operator to make an expression-object callable.""""""
    """"""Used as placeholder for a tag in a boolean tag-expression.""""""
""""""
Provides parsing of boolean tag expressions.

.. code-block:: python

    expression = TagExpressionParser.parse(""a and (b or not c)"")
    assert True == expression.evaluate([""a"", ""other""])
    assert ""( a and ( b or not (c) ) )"" == str(expression)

    """"""Describes associativity of boolean operations.""""""
    """"""Describes tokens and their abilities for tag-expression parsing.""""""
    OPEN_PARENTHESIS  = (""("", -2) # Java, Javascript: -2, Ruby: 1
        """"""Checks if this token has lower precedence than other token.""""""
    """"""Raised by parser if an invalid tag-expression is detected.""""""
    """"""Parser class to parse boolean tag-expressions.
    This class uses the `Shunting Yard algorithm`_ to parse the tag-expression.
    In addition, parenthesis can be used to group expressions, like::

        a and (b or c)
        (a and not b) or (c and d)

    EXAMPLES:

    .. code-block:: python

        # -- UNARY OPTIONS
        text11 = ""not foo"" = ""(not foo)""
        expression = TagExpressionParser.parse(text11)
        assert False == expression.evaluate([""foo""])
        assert True  == expression.evaluate([""other""])

        # -- BINARY OPERATIONS:
        text21 = ""foo and bar"" = ""(foo and bar)""
        expression = TagExpressionParser.parse(text21)
        assert True  == expression.evaluate([""foo"", ""bar""])
        assert False == expression.evaluate([""foo""])
        assert False == expression.evaluate([])

        text22 = ""foo or bar""  = ""(foo or bar)""
        expression = TagExpressionParser.parse(text22)
        assert True  == expression.evaluate([""foo"", ""bar""])
        assert True  == expression.evaluate([""foo"", ""other""])
        assert False == expression.evaluate([])

    .. see::

        * `Shunting Yard algorithm`_
        * http://rosettacode.org/wiki/Parsing/Shunting-yard_algorithm

    # pylint: disable=line-too-long
    .. _`Shunting Yard algorithm`: https://en.wikipedia.org/wiki/Shunting-yard_algorithm
        """"""Select the token that matches the text or return None.
        :param text: Text to select the matching token.
        :return: Token object or None, if not found.
        """"""Creates operand-object from parsed text.""""""
        # -- EXTENSION-POINT: For #406 or similar.
        :param text: Textual tag-expression (as string).
        :raises: TagExpressionError, if the escape is incorrectly used.
        :return: list of tokens (strings).
        """"""Parse a textual tag-expression and return the expression (tree).
        :param text: Textual tag-expression (as string).
        :return: Tag expression (instance of :class:`Expression`).
        :raises: TagExpressionError, if the tag-expression is invalid.
            #  -- CASE: Empty tag-expression is always true.
        # -- FINALLY: Return boolean tag-expression.
        """"""Push a new boolean-expression on the expression-stack.
        Retrieves operands for operation from the expression-stack and
        :param token:  Token for new expression (instance of class:`Token`).
        :param expressions: Expression stack to use (as inout param).
        :raises: TagExpressionError, if too few args are in expression-stack.
    """"""Parse a tag-expression as text and return the expression tree.
    .. code-block:: python
        tags = [""foo"", ""bar""]
        tag_expression = parse(""foo and bar or not baz"")
        assert tag_expression.evaluate(tags) == True
    :param text:    Tag expression as text to parse.
    :param parser_class:  Optional p
    :return: Parsed expression",buggy
"""""""Python implementation of `Cucumber Tag Expressions`_.
Tag expressions are used in cucumber, behave and other BDD frameworks
These selected items are normally included in a test run.
.. _Cucumber Tag Expressions:
    https://cucumber.io/docs/cucumber/api/#tag-expressions
.. _Gherkin:
    https://cucumber.io/docs/gherkin/reference/
""""""Model classes to evaluate parsed boolean tag expressions.

Examples:
    >>> expression = And(Literal(""a""), Literal(""b""))
    >>> expression({""a"", ""b""})
    True
    >>> expression({""a"", ""b""})
    True
    >>> expression({""a""})
    False
    >>> expression({})
    False

    >>> expression = Or(Literal(""a""), Literal(""b""))
    >>> expression({""a"", ""b""})
    True
    >>> expression({""a""})
    True
    >>> expression({})
    False

    >>> expression = Not(Literal(""a""))
    >>> expression({""a""})
    False
    >>> expression({""other""})
    True
    >>> expression({})
    True

    >>> expression = And(Or(Literal(""a""), Literal(""b"")), Literal(""c""))
    >>> expression({""a"", ""c""})
    True
    >>> expression({""c"", ""other""})
    False
    >>> expression({})
    False
    """"""Abstract base class for boolean expression terms of a tag expression
    (or representing a parsed tag expression (evaluation-tree)).
        """"""Evaluate whether expression matches values.

        Args:
            values (Iterable[str]): Tag names to evaluate.

        Returns:
            bool: Whether expression evaluates with values.
        """"""
        """"""Call operator to make an expression object callable.
        
        Args:
            values (Iterable[str]): Tag names to evaluate.

        Returns:
            bool: True if expression is true, False otherwise
        """"""
    """"""Used as placeholder for a tag in a boolean tag expression.""""""
        """"""Initialise literal with tag name.

        Args:
            name (str): Tag name to represent as a literal.
        """"""
        """"""Create Boolean-AND expression.

        Args:
            terms (Iterable[Expression]): List of boolean expressions to AND.

        Returns:
            None
        """"""
        """"""Create Boolean-OR expression.

        Args:
            terms (Iterable[Expression]): List of boolean expressions to OR.

        Returns:
            None
        """"""
        """"""Create Boolean-AND expression.

        Args:
            term (Expression): Boolean expression to negate.

        Returns:
            None
        """"""
        """"""Evaluates to True.

        Args:
            values (Any): Required by API though not used.

        Returns:
            Literal[True]
        """"""
""""""Parsing of boolean tag expressions.

Examples:
    >>> expression = parse(""a and (b or not c)"")
    >>> expression({""a"", ""other""})
    True
    >>> ""( a and ( b or not ( c ) ) )"" == str(expression)
    True
    """"""Associativity of boolean operations.

    How operators of same precedence are grouped in the absence of parentheses.

    * LEFT: Groups `a and b and c` to `(a and b) and c`.
    * RIGHT: Groups `a or b or c` to `a or (b or c)`.
    """"""
    """"""Types of tag expression tokens.""""""
    """"""Describes tokens and their abilities for tag expression parsing.""""""
    OPEN_PARENTHESIS  = (""("", -2) # Java, Javascript: -2; Ruby: 1
        """"""Create a new token with keyword, precedence and associativity.

        Args:
            keyword (str): Keyword for the token.
            precedence (int): Precedence of the token.
            assoc (Associative | None): Associativity of the token.
            token_type (TokenType): Type of the token.

        Returns:
            None
        """"""
        """"""Check if this token is an operator.

        Returns:
            bool: Whether this token is an operator.
        """"""
        """"""Check if this token is a binary operator.

        Returns:
            bool: Whether this token is a binary operator.
        """"""
        """"""Check if this token is a unary operator.

        Returns:
            bool: Whether this token is a unary operator.
        """"""
        """"""Checks if this token has lower precedence than another token.

        Args:
            other (Token): Token to compare with.

        Returns:
            bool: Whether this token has lower precedence than other token.
        """"""
        """"""Check if the keyword of this token matches provided text.

        Args:
            text (str): Text to compare against.

        Returns:
            bool: Whether this token matches the provided text.
        """"""
    """"""Raised by parser if an invalid tag expression is detected.""""""
    """"""Parser class to parse boolean tag expressions.
    In addition, parenthesis can be used to group expressions, like:

        ""a and (b or c)""
        ""(a and not b) or (c and d)""

    Uses the `Shunting Yard algorithm`_ to parse the tag expression.

    Examples:
        Unary operations
        >>> expression = TagExpressionParser.parse(""not foo"")
        >>> expression({""foo""})
        False
        >>> expression({""other""})
        True

        Binary operations - And
        >>> expression = TagExpressionParser.parse(""foo and bar"")
        >>> expression({""foo"", ""bar""})
        True
        >>> expression({""foo""})
        False
        >>> expression({})
        False

        Binary operations - Or
        >>> expression = TagExpressionParser.parse(""foo or bar"")
        >>> expression({""foo"", ""bar""})
        True
        >>> expression({""foo"", ""other""})
        True
        >>> expression({})
        False

    .. _Shunting Yard algorithm:
        http://rosettacode.org/wiki/Parsing/Shunting-yard_algorithm
        """"""Select the token that matches the text.
        Args:
            text (str): Text to select the matching token.

        Returns:
            Token | None: Token object or None, if not found.
        """"""Creates operand object from parsed text.

        Args:
            text (str): Text to create operand from.

        Returns:
            Literal: Operand object created from text.
        """"""
        # -- EXTENSION-POINT: For cucumber/common#406 or similar.
        Args:
            text (str): Tag expression as text to parse.

        Returns:
            list[str]: List of selected tokens.

        Raises:
            TagExpressionError: If the tag expression is invalid.
                Such as an illegal escape character.
        """"""Parse a tag expression as text and return the expression tree.
        Args:
            text (str): Tag expression as text to parse.

        Returns:
            model.Expression: Parsed expression tree.

        Raises:
            TagExpressionError: If the tag expression is invalid.

        Examples:
            >>> expression = TagExpressionParser().parse(""foo and bar or not baz"")
            >>> expression({""foo"", ""bar""})
            True
            #  -- CASE: Empty tag expression is always true.
        # -- FINALLY: Return boolean tag expression.
        """"""Push a new boolean expression on the expression stack.
        Retrieves operands for operation from the expression stack and
        Args:
            token (Token): Token for new expression.
            expressions (list[model.Expression]): Expression stack to use.

        Returns:
            None

        Raises:
            TagExpressionError: If the expression stack contains an unexpected token
                or too few operands for an operator.
            """"""Check if enough operands are in the expression stack.

            Args:
                number (int): Number of operands required.

            Returns:
                None

            Raises:
                TagExpressionError: If the expression stack contains an unexpected
                    token or too few operands for an operator.
            """"""
        """"""Construct a detailed error message for a tag expression error.

        Args:
            message (str): Error message to display.
            parts (list[str]): List of parts of the tag expression.
            error_index (int): Index of the error in the parts list.

        Returns:
            str: Detailed error message with error-position marked.
        """"""
    """"""Parse a tag expression as text and return the expression tree.

    Args:
        text (str): Tag expression as text to parse.
    Returns:
        model.Expression: Parsed expression tree.
    Raises:
        TagExpressionError: If the tag expression is invalid.
    Examples:
        >>> expression = parse(""foo and bar or not baz"")
        >>> expression({""foo"", ""bar""})
        True",bug-free
"            environ[""GRPC_RUN_AUDITWHEEL_REPAIR""] = ""TRUE""
            if self.arch == ""x86"":
                timeout_seconds=60 * 60 * 2,
    def __init__(self):
            ""tools/dockerfile/grpc_artifact_python_manylinux2014_x64"",",buggy
"            if self.arch in (""x86"", ""aarch64""):
            if self.arch == ""aarch64"":
                # As we won't strip the binary with auditwheel (see below), strip
                # it at link time.
                environ[""LDFLAGS""] = ""-s""
                # We're using musllinux aarch64 image to build this artifact so no crosscompiling required.
                environ[""GRPC_BUILD_GRPCIO_TOOLS_DEPENDENTS""] = ""TRUE""
            else:
                environ[""GRPC_RUN_AUDITWHEEL_REPAIR""] = ""TRUE""

                timeout_seconds=60 * 60 * 4,
            PythonArtifact(
                ""musllinux_1_1"", ""aarch64"", ""cp38-cp38"", presubmit=True
            ),
            PythonArtifact(""musllinux_1_1"", ""aarch64"", ""cp39-cp39""),
            PythonArtifact(""musllinux_1_1"", ""aarch64"", ""cp310-cp310""),
            PythonArtifact(""musllinux_1_1"", ""aarch64"", ""cp311-cp311""),
            PythonArtifact(""musllinux_1_1"", ""aarch64"", ""cp312-cp312""),
            PythonArtifact(
                ""musllinux_1_1"", ""aarch64"", ""cp313-cp313"", presubmit=True
            ),
    def __init__(self, platform="""", arch=""""):
        self.platform = platform
        self.arch = arch
        if self.platform:
            self.labels.append(platform)
            self.name += ""_"" + platform
        if self.arch:
            self.labels.append(arch)
            self.name += ""_"" + arch
        dockerfile_dir = (
            ""tools/dockerfile/grpc_artifact_python_manylinux2014_x64""
        )
        if ""musllinux_1_1"" in self.platform and ""aarch64"" in self.arch:
            dockerfile_dir = (
                ""tools/dockerfile/grpc_artifact_python_musllinux_1_1_aarch64""
            )
            dockerfile_dir,
        PythonPackage(""musllinux_1_1"", ""aarch64""),",bug-free
"            environ[""GRPC_RUN_AUDITWHEEL_REPAIR""] = ""TRUE""
            if self.arch == ""x86"":
                timeout_seconds=60 * 60 * 2,
    def __init__(self):
            ""tools/dockerfile/grpc_artifact_python_manylinux2014_x64"",",buggy
"            if self.arch in (""x86"", ""aarch64""):
            if self.arch == ""aarch64"":
                # As we won't strip the binary with auditwheel (see below), strip
                # it at link time.
                environ[""LDFLAGS""] = ""-s""
                # We're using musllinux aarch64 image to build this artifact so no crosscompiling required.
                environ[""GRPC_BUILD_GRPCIO_TOOLS_DEPENDENTS""] = ""TRUE""
            else:
                environ[""GRPC_RUN_AUDITWHEEL_REPAIR""] = ""TRUE""

                timeout_seconds=60 * 60 * 4,
            PythonArtifact(
                ""musllinux_1_1"", ""aarch64"", ""cp38-cp38"", presubmit=True
            ),
            PythonArtifact(""musllinux_1_1"", ""aarch64"", ""cp39-cp39""),
            PythonArtifact(""musllinux_1_1"", ""aarch64"", ""cp310-cp310""),
            PythonArtifact(""musllinux_1_1"", ""aarch64"", ""cp311-cp311""),
            PythonArtifact(""musllinux_1_1"", ""aarch64"", ""cp312-cp312""),
            PythonArtifact(
                ""musllinux_1_1"", ""aarch64"", ""cp313-cp313"", presubmit=True
            ),
    def __init__(self, platform="""", arch=""""):
        self.platform = platform
        self.arch = arch
        if self.platform:
            self.labels.append(platform)
            self.name += ""_"" + platform
        if self.arch:
            self.labels.append(arch)
            self.name += ""_"" + arch
        dockerfile_dir = (
            ""tools/dockerfile/grpc_artifact_python_manylinux2014_x64""
        )
        if ""musllinux_1_1"" in self.platform and ""aarch64"" in self.arch:
            dockerfile_dir = (
                ""tools/dockerfile/grpc_artifact_python_musllinux_1_1_aarch64""
            )
            dockerfile_dir,
        PythonPackage(""musllinux_1_1"", ""aarch64""),",bug-free
"            organization (str, optional): The expected organization ID (org_id) or orgnization name (org_name) claim value. This should be specified
            organization (str, optional): The expected organization ID (org_id) or orgnization name (org_name) claim value. This should be specified
        params = {""page"": page, ""per_page"": per_page}
        self.assertEqual(kwargs[""params""], {""page"": None, ""per_page"": None})
        c.all_organization_member_roles(""test-org"", ""test-user"", page=7, per_page=25)
        self.assertEqual(kwargs[""params""], {""page"": 7, ""per_page"": 25})",buggy
"            organization (str, optional): The expected organization ID (org_id) or organization name (org_name) claim value. This should be specified
            organization (str, optional): The expected organization ID (org_id) or organization name (org_name) claim value. This should be specified
        include_totals: bool = False,
           include_totals (bool, optional): True if the query summary is
              to be included in the result, False otherwise. Defaults to False.

        params = {
            ""page"": page,
            ""per_page"": per_page,
            ""include_totals"": str(include_totals).lower()
        }
        self.assertEqual(
            kwargs[""params""], 
            {
                ""page"": None, 
                ""per_page"": None,
                ""include_totals"": ""false"",
            }
        )
        c.all_organization_member_roles(""test-org"", ""test-user"", page=7, per_page=25, include_totals=True)
        self.assertEqual(
            kwargs[""params""], 
            {
                ""page"": 7, 
                ""per_page"": 25,
                ""include_totals"": ""true"",
            }
        )",bug-free
"LOG_FILE = os.path.join(os.path.dirname(sys.argv[1]), ""lsp.log"")

# def did_change_watched_files(server: HelixLanguageServer, params: DidChangeTextDocumentParams) -> None:
#     """"""Handles watched file changes.""""""
#     logger.info('Watched files changed: {}', params.text_document.uri)",buggy
"    DidChangeWatchedFilesParams,
LOG_FILE = os.path.join(os.path.dirname(__file__), ""lsp.log"")
    @property
    def server_capabilities(self):
        """"""Override server capabilities.""""""
        capabilities = super().server_capabilities
        capabilities.text_document_sync = {
            ""openClose"": True,
            ""change"": None,  # Disable incremental sync
            ""willSave"": False,
            ""willSaveWaitUntil"": False,
            ""save"": True,
        }
        
        return capabilities
    
# def did_change_watched_files(server: HelixLanguageServer, params: DidChangeWatchedFilesParams) -> None:
#     """"""Handles document saving.""""""
#     logger.info('Document saved: {}', params.text_document.uri)",bug-free
"from typing import List, Dict, Any
from transformers import AutoModelForCausalLM, AutoTokenizer
print(""Loading UI-TARS model..."")
model_path = ""../ui-tars-7b-dpo""
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    torch_dtype=torch.float16,
    device_map=""auto""
)
def format_dom_for_model(dom_content: str) -> str:
    """"""Format DOM content for UI-TARS model input""""""
    return f""""""
DOM Structure:
{dom_content}
""""""

def generate_action_plan(instruction: str, dom_content: str = None) -> Dict:
    """"""Generate UI action plan using UI-TARS model""""""
    prompt = f""""""Task: {instruction}\n""""""
    if dom_content:
        prompt += format_dom_for_model(dom_content)
    
    prompt += ""\nGenerate a detailed action plan:""

    # Generate response from model
    inputs = tokenizer(prompt, return_tensors=""pt"").to(model.device)
    outputs = model.generate(
        **inputs,
        max_length=500,
        temperature=0.1,
        do_sample=True,
        num_return_sequences=1
    )
    
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    
        # Extract JSON plan
        plan_start = response.find('{')
        plan_end = response.rfind('}') + 1
        plan_json = response[plan_start:plan_end]
        # Parse and validate action plan
        plan = json.loads(plan_json)
        return {
            ""actions"": plan.get(""actions"", []),
            ""elements"": plan.get(""elements"", [])
        print(f""Error parsing model output: {e}"")
        print(f""Raw output: {response}"")
        return {""error"": ""Could not generate action plan""}
        # Extract instruction and DOM content
        dom_content = message[""content""][1].get(""dom"", """") if len(message[""content""]) > 1 else None
        
        # Generate action plan using UI-TARS
        action_plan = generate_action_plan(instruction, dom_content)
        
                    ""content"": json.dumps(action_plan)
    uvicorn.run(app, host=""0.0.0.0"", port=8000)",buggy
"from typing import List, Dict, Any, Optional
import os
from transformers import AutoConfig, AutoModelForVision2Seq, AutoTokenizer, AutoProcessor
from PIL import Image
import base64
import io
import logging

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
# Enable CORS
# Model initialization with proper error handling
def initialize_model():
    model_path = ""/models/ui-tars-7b-dpo""
    logger.info(f""Initializing UI-TARS model from {model_path}"")

    try:
        # Load configuration
        config = AutoConfig.from_pretrained(
            model_path,
            trust_remote_code=True
        )
        logger.info(""Configuration loaded successfully"")

        # Load tokenizer with special token handling
        tokenizer = AutoTokenizer.from_pretrained(
            model_path,
            trust_remote_code=True
        )
        logger.info(""Tokenizer loaded successfully"")

        # Load image processor
        processor = AutoProcessor.from_pretrained(
            model_path,
            trust_remote_code=True
        )
        logger.info(""Processor loaded successfully"")

        # Initialize model with proper configuration
        model = AutoModelForVision2Seq.from_pretrained(
            model_path,
            config=config,
            torch_dtype=torch.float16,
            device_map=""auto"",
            trust_remote_code=True
        )
        model.eval()
        logger.info(""Model loaded successfully"")

        return model, tokenizer, processor

    except Exception as e:
        logger.error(f""Error initializing model: {str(e)}"")
        if os.path.exists(model_path):
            logger.error(f""Model directory contents: {os.listdir(model_path)}"")
        raise

# Initialize model components
model, tokenizer, processor = initialize_model()
    max_tokens: Optional[int] = 500
    temperature: Optional[float] = 0.1
def preprocess_image(image_data: str) -> Image.Image:
    """"""Convert base64 screenshot to PIL Image with error handling""""""
        image_bytes = base64.b64decode(image_data)
        return Image.open(io.BytesIO(image_bytes))
    except Exception as e:
        logger.error(f""Error processing image: {str(e)}"")
        raise ValueError(""Invalid image data"")

def generate_response(instruction: str, screenshot: Optional[str] = None) -> Dict:
    """"""Generate UI interaction plan using UI-TARS model""""""
    try:
        # Prepare the instruction prompt
        prompt = f""Based on the webpage shown, {instruction}""
        # Prepare inputs for the model
        inputs = {
            ""text"": tokenizer(
                prompt,
                return_tensors=""pt"",
                padding=True,
                truncation=True
            ).to(model.device)

        # Process screenshot if provided
        if screenshot:
            image = preprocess_image(screenshot)
            image_inputs = processor(images=image, return_tensors=""pt"").to(model.device)
            inputs.update(image_inputs)

        # Generate response with the model
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_length=500,
                temperature=0.1,
                do_sample=True,
                num_return_sequences=1
            )

        # Decode and process the response
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        logger.info(f""Generated response: {response[:100]}..."")  # Log first 100 chars

        # Extract and validate the JSON plan
        try:
            plan_start = response.find('{')
            plan_end = response.rfind('}') + 1
            if plan_start == -1 or plan_end <= plan_start:
                raise ValueError(""No valid JSON found in response"")

            plan_json = response[plan_start:plan_end]
            plan = json.loads(plan_json)

            return {
                ""actions"": plan.get(""actions"", []),
                ""elements"": plan.get(""elements"", []),
                ""understanding"": plan.get(""understanding"", """"),
                ""verification"": plan.get(""verification"", [])
            }
        except json.JSONDecodeError as e:
            logger.error(f""JSON parsing error: {str(e)}"")
            logger.error(f""Response text: {response}"")
            raise ValueError(""Invalid response format"")

        logger.error(f""Error generating response: {str(e)}"")
        return {""error"": str(e)}
        # Extract the latest message
        screenshot = message[""content""][1].get(""screenshot"", None) if len(message[""content""]) > 1 else None

        # Generate the interaction plan
        plan = generate_response(instruction, screenshot)

                    ""content"": json.dumps(plan)
        logger.error(f""Error in chat completion: {str(e)}"")
@app.get(""/health"")
async def health_check():
    """"""Health check endpoint""""""
    try:
        # Verify model components are loaded
        if not all([model, tokenizer, processor]):
            raise Exception(""One or more model components not initialized"")
        return {""status"": ""healthy"", ""model"": ""loaded""}
    except Exception as e:
        raise HTTPException(status_code=503, detail=str(e))

    uvicorn.run(app, host=""0.0.0.0"", port=8000)",bug-free
"        post_id = request.form.get(""post_id"", None)
from google.cloud import firestore
    db = firestore.Client()
    with open(""../data/blog_entries.json"", 'r') as file:
            document = db.collection(""posts"").document(id)
    print(""get_unsplash_image()"")
        print(response.json()[""urls""][""small""])",buggy
"        post_id = request.form.get(""post-id"", None)
from extensions.my_firestore import db
from config import config


    post_collection = config[""development""].POSTS
    
    with open(""sample_data/blog_entries.json"", 'r') as file:
            document = db.collection(post_collection).document(id)
    # print(""get_unsplash_image()"")
        # print(response.json()[""urls""][""small""])",bug-free
"    forecast_df: pl.DataFrame,
    id_cols: list[str] = [""draw""],
    strict: bool = False,
    Aggregate daily values (e.g.
    forecast_df
        A polars dataframe with draws and dates
        as columns. This dataframe will likely
        have come from an InferenceData object
        that was converted using `idata_w_dates_to_df`.
        The name of the column with the fitted
        and or forecasted quantity. Defaults
        to ""value"".
        Defaults to ""date"".
        Defaults to ["".draw""].
        Defaults to ""weekly_value"".
        values. If False, then incomplete weeks
        will be aggregated. Defaults to False.
    forecast_df = forecast_df.with_columns(
        pl.col([""date""])
    grouped_df = forecast_df.group_by(group_cols)
        message = f""Problematic trajectories with more than 7 values per epiweek per year: {problematic_trajectories}""
        raise ValueError(
            f""At least one trajectory has more than 7 values for a given epiweek of a given year.\n{message}""
        )
    # check if any week has more than 7 dates
    if not n_elements[""n_elements""].to_numpy().max() <= 7:
            ""At least one trajectory has more than 7 values for a given epiweek of a given year.""
    # if strict, filter out groups that do not have exactly 7 contributing dates
        forecast_df = forecast_df.join(
    # aggregate; sum values in the specified value_col
        forecast_df.group_by(group_cols)
        .sort([""epiyear"", ""epiweek"", ""draw""])",buggy
"from forecasttools.utils import ensure_listlike

    df: pl.DataFrame,
    id_cols: str | list[str] = [""draw""],
    strict: bool = True,
    Aggregate a dataframe of daily values (e.g.
    df
        Tidy data frame of daily values to aggregate.
        The name of the column containing daily trajectory /
        timeseries values to aggregate. Defaults
        to ```""value""``.
        Defaults to ``""date""``.
        Defaults to ``""draw""``.
        Defaults to ``""weekly_value""``.
        values. If ``False``, then incomplete weeks
        will be aggregated. Defaults to ``True``.
    id_cols = ensure_listlike(id_cols)
    df = df.with_columns(
        pl.col(date_col)
    grouped_df = df.group_by(group_cols)
            ""At least one trajectory has more than 7 values ""
            ""for a given epiweek of a given epiyear.\n""
            ""Problematic trajectories with more than 7 ""
            ""values: ""
            f""{problematic_trajectories}""

        df = df.join(
        df.group_by(group_cols)
        .sort(group_cols)",bug-free
"class TracingProvider(Generic[T], metaclass=abc.ABCMeta):
class ComputationBuildingBlock(typed_object.TypedObject, metaclass=abc.ABCMeta):
class BoundVariableTracker(metaclass=abc.ABCMeta):
class TransformSpec(metaclass=abc.ABCMeta):
class Computation(typed_object.TypedObject, metaclass=abc.ABCMeta):
class SyncContext(metaclass=abc.ABCMeta):
class AsyncContext(metaclass=abc.ABCMeta):
class ContextStack(metaclass=abc.ABCMeta):
class Executor(metaclass=abc.ABCMeta):
class ExecutorFactory(metaclass=abc.ABCMeta):
class ExecutorValue(abc.ABC, typed_object.TypedObject):
class Value(typed_object.TypedObject, metaclass=abc.ABCMeta):
class MaterializableValueReference(abc.ABC, typed_object.TypedObject):
class Type(metaclass=abc.ABCMeta):
class TypedObject(metaclass=abc.ABCMeta):",buggy
"class TracingProvider(Generic[T], abc.ABC):
class ComputationBuildingBlock(typed_object.TypedObject, abc.ABC):
class BoundVariableTracker(abc.ABC):
class TransformSpec(abc.ABC):
class Computation(typed_object.TypedObject, abc.ABC):
class SyncContext(abc.ABC):
class AsyncContext(abc.ABC):
class ContextStack(abc.ABC):
class Executor(abc.ABC):
class ExecutorFactory(abc.ABC):
class ExecutorValue(typed_object.TypedObject, abc.ABC):
class Value(typed_object.TypedObject, abc.ABC):
class MaterializableValueReference(typed_object.TypedObject, abc.ABC):
class Type(abc.ABC):
class TypedObject(abc.ABC):",bug-free
"import json
from enum import Enum
from pydantic import TypeAdapter, ValidationError",buggy
"import platform
import sys
from pydantic import TypeAdapter
        platform_str = platform.platform()
        py_impl_version = sys.implementation.cache_tag
        py_lang_version = platform.python_version()
        print(f""Python: {py_impl_version} ({py_lang_version})"")
        print(f""Platform: {platform_str}"")",bug-free
        self.master.geometry('280x300'),buggy
"        self.master.geometry('400x300') 
            
        def get_zodiac_sign(day, month):
            astro_sign = [""Capricorn"", ""Aquarius"", ""Pisces"", ""Aries"", ""Taurus"", ""Gemini"", ""Cancer"", ""Leo"", ""Virgo"", ""Libra"", ""Scorpio"", ""Sagittarius""]    
            if month == 1:
                if day < 20:
                    astro_sign_index = astro_sign[0]
                else:
                    astro_sign_index = astro_sign[1]    
            elif month == 2:
                if day < 19:
                    astro_sign_index = astro_sign[1]
                else:
                    astro_sign_index = astro_sign[2]
            elif month == 3:
                if day < 21:
                    astro_sign_index = astro_sign[2]
                else:
                    astro_sign_index = astro_sign[3]    
            elif month == 4:
                if day < 20:
                    astro_sign_index = astro_sign[3]
                else:
                    astro_sign_index = astro_sign[4]    
            elif month == 5:
                if day < 21:
                    astro_sign_index = astro_sign[4]
                else:
                    astro_sign_index = astro_sign[5]    
            elif month == 6:
                if day < 21:
                    astro_sign_index = astro_sign[5]
                else:
                    astro_sign_index = astro_sign[6]    
            elif month == 7:
                if day < 23:
                    astro_sign_index = astro_sign[6]
                else:
                    astro_sign_index = astro_sign[7]    
            elif month == 8:
                if day < 23:
                    astro_sign_index = astro_sign[7]
                else:
                    astro_sign_index = astro_sign[8]    
            elif month == 9:
                if day < 23:
                    astro_sign_index = astro_sign[8]
                else:
                    astro_sign_index = astro_sign[9]    
            elif month == 10:
                if day < 23:
                    astro_sign_index = astro_sign[9]
                else:
                    astro_sign_index = astro_sign[10]    
            elif month == 11:
                if day < 22:
                    astro_sign_index = astro_sign[10]
                else:
                    astro_sign_index = astro_sign[11]
            elif month == 12:
                if day < 22:
                    astro_sign_index = astro_sign[11]
                else:
                    astro_sign_index = astro_sign[0]                
            return astro_sign_index        ",bug-free
"def print_unicode(text):
    """"""Print in a portable manner.""""""
    if sys.version_info[0] < 3:
        text = text.encode('utf-8')

    print(text)


        guess_language = None
        if args.language:
            if args.language.lower() == 'auto':
                try:
                    from guess_language import guess_language
                except ImportError:
                    print('guess_language is unavailable.', file=sys.stderr)
                    return 1
                else:
                    language = guess_language(text)
                    print('Detected language: {}'.format(language),
                          file=sys.stderr)
                    if not language:
                        return 1
                    lang_tool.language = language
            else:
                lang_tool.language = args.language

                print_unicode(lang_tool.correct(text))
                    print_unicode('{}: {}: {}'.format(",buggy
"            language=args.language,
                print(lang_tool.correct(text))
                    print('{}: {}: {}'.format(",bug-free
"        if not getattr(func, ""__annotations__"", None):
    def setUp(self):
        pass",buggy
"        if not getattr(func, ""__annotations__"", None):  # pragma: no cover
from typing import Optional, Union
class JArray:
    """"""Java Array""""""

    @classmethod
    @annotate('JArray', size=int)
    def newBooleanArray(cls, size):
        ...

    @annotate(borrowed=bool)
    def __init__(self, borrowed=False):
        ...

    @annotate(int)
    def getLength(self):
        ...

    @annotate(bool, idx=int)
    def getBoolean(self, idx):
        ...

    @annotate(int, idx=int)
    def getInt(self, idx, val):
        ...

    @annotate(float, idx=int)
    def getDouble(self, idx):
        ...

    @annotate(Optional[str], idx=int)
    def getString(self, idx):
        ...

    @annotate(idx=int, val=bool)
    def setBoolean(self, idx, val):
        ...

    @annotate(idx=int, val=int)
    def setInt(self, idx, val):
        ...

    @annotate(idx=int, val=float)
    def setDouble(self, idx, val):
        ...

    @annotate(idx=int, val=Optional[str])
    def setString(self, idx, val):
        ...


    def test_main(self):
        self.assertEqual(JArray.newBooleanArray.__annotations__, {""size"": int, ""return"": ""JArray""})
        self.assertEqual(JArray.__init__.__annotations__,        {""borrowed"": bool})
        self.assertEqual(JArray.getLength.__annotations__,       {""return"": int})
        self.assertEqual(JArray.getBoolean.__annotations__,      {""idx"": int, ""return"": bool})
        self.assertEqual(JArray.getInt.__annotations__,          {""idx"": int, ""return"": int})
        self.assertEqual(JArray.getDouble.__annotations__,       {""idx"": int, ""return"": float})
        self.assertEqual(JArray.getString.__annotations__,       {""idx"": int, ""return"": Optional[str]})
        self.assertEqual(JArray.setBoolean.__annotations__,      {""idx"": int, ""val"": bool})
        self.assertEqual(JArray.setInt.__annotations__,          {""idx"": int, ""val"": int})
        self.assertEqual(JArray.setDouble.__annotations__,       {""idx"": int, ""val"": float})
        self.assertEqual(JArray.setString.__annotations__,       {""idx"": int, ""val"": Optional[str]})",bug-free
"import bow_client as bow
        self.master.title(""BOW >< OpenAI"")
        bow.close_client_interface()
    while True:
        # Test for completed functions and relay results to openai assistant as ""assistant"" messages
        if controller.searchComplete is not None:
            if controller.searchComplete == ""success"":
                brain.request(""Search Successful"", ""assistant"", gui)
            elif controller.searchComplete == ""failure"":
                brain.request(""Search Failed"", ""assistant"", gui)
            controller.searchComplete = None

        # Get camera images from BOW robot
        image_list, err = controller.robot.get_modality(""vision"", True)
        if err.Success:
            if len(image_list) > 0:
                img_data = image_list[0]
                img_data.image = imutils.rotate_bound(img_data.image, img_data.transform.EulerAngles.X * 180 / math.pi)
                # Set camera parameters on first instance
                if controller.VFOV is None:
                    if img_data.vfov == 0:
                        controller.VFOV = 40
                    else:
                        controller.VFOV = img_data.vfov

                    if img_data.hfov == 0:
                        controller.HFOV = 80
                        controller.HFOV = img_data.hfov

                # Pass image into yolo model
                results = model.predict(source=img_data.image, show=False, stream_buffer=False,
                                        verbose=False)

                # Iterate though detected objects and populate objects list and details
                if len(results) > 0:
                    for box in results[0].boxes.cpu():
                        obj = DetectedObject()
                        obj.classification = model.names[int(box.data[0][-1])]
                        obj.confidence = box.conf.numpy()[0]
                        obj.box = box.xyxy.numpy()[0]
                        width = obj.box[2] - obj.box[0]
                        height = obj.box[3] - obj.box[1]
                        area = width * height
                        imgArea = img_data.shape[0] * img_data.shape[1]
                        obj.area = area / imgArea
                        center = (int(obj.box[0] + width / 2), int(obj.box[1] + height / 2))
                        obj.center[0] = center[0] * (1/img_data.shape[0])
                        obj.center[1] = 1-(center[1] * (1 / img_data.shape[1]))
                        objects.append(obj)

                # Draw detections on image
                annotated_img = img_data.image
                for obj in objects:
                    colour = (61, 201, 151)
                    if controller.targetClass is not None or controller.prevTargetClass is not None:
                        if obj.classification == controller.targetClass:
                            colour = (36, 108, 243)
                        if obj.classification == controller.prevTargetClass:
                            colour = (36, 108, 243)

                    annotated_img = cv2.rectangle(annotated_img, (int(obj.box[0]), int(obj.box[1])),
                                                  (int(obj.box[2]), int(obj.box[3])), colour, thickness=3)
                    # Set the label position
                    label_x = int(obj.box[0])
                    label_y = int(obj.box[1]) - 10  # Position above the box by default

                    # Check if the label is going off-screen
                    if label_y < 10:
                        label_y = int(obj.box[3]) + 20  # Position below the box

                    # Draw the label
                    cv2.putText(annotated_img, obj.classification, (label_x, label_y),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, colour, 1)

                # Pass objects list to robot controller
                controller.object_list = objects

                # Update gui image
                gui.update_image(annotated_img)

                # Update controller
                ret = controller.update()

            # Update the Tkinter window
            objects = []
            root.update_idletasks()
            root.update()
assistant_id = ""asst_BF4jtnh3Mt0lAA2p4Uyvzm9f""
        self.robot.set_modality(""speech"", full_message[0].text.value)
import math
import bow_client as bow
import bow_utils as utils
        self.log = utils.create_logger(""BOW >< OpenAI"", logging.INFO)
        self.log.info(bow.version())
        self.audio_params = utils.AudioParams(
        self.searchVelocity = 0.15  # The Angular velocity commanded during a search
        self.robot, error = bow.quick_connect(pylog=self.log,
                                              modalities=[""vision"", ""motor"", ""speech""],
                                              verbose=False,
                                              audio_params=self.audio_params)
        self.robot.set_modality(""speech"", ""ChatGPT embodied successfully"")
        motor_sample = utils.MotorSample()
        ret = self.robot.set_modality(""motor"", motor_sample)
import bow_client as bow
import bow_utils
log = bow_utils.create_logger(""Bow Tutorial: Vision - Object Detection"", logging.INFO)
log.info(bow.version())
myrobot, error = bow.quick_connect(pylog=log, modalities=[""vision""])
    log.error(""Failed to connect to robot"", error)
        image_list, err = myrobot.get_modality(""vision"", True)
        if not err.Success or len(image_list) == 0:
        img_data = image_list[0]
        if img_data is not None and img_data.new_data_flag:
            myIm = img_data.image
            cv2.imshow(img_data.source, myIm)
    log.info(""Closing down"")
bow.close_client_interface()
import bow_client as bow
import bow_utils
COMPRESSION_FORMAT = bow_utils.AudioSample.CompressionFormatEnum.RAW
        self.log = bow_utils.create_logger(""Bow Tutorial 6"", logging.INFO)
        self.log.info(bow.version())
        # Audio parameters for voice modality
        self.audio_params = bow_utils.AudioParams(
        self.robot, error = bow.quick_connect(
            pylog=self.log,
            modalities=[""voice"", ""vision"", ""motor""],
            self.log.error(""Failed to connect to robot"", error)
        # Print robot input and output modalities for debugging
    def show_all_images(self, images_list: List[bow_utils.ImageSampleHelper]):
            for i, img_data in enumerate(images_list):
                window_name = f""RobotView{i} - {img_data.source}""
                self.window_names[img_data.source] = window_name
        for img_data in images_list:
            if img_data.new_data_flag:
                cv2.imshow(self.window_names[img_data.source], img_data.image)
            self.log.error(""Failed to retrieve audio segment."")
            audio_sample = bow_utils.AudioSample(
            result = self.robot.set_modality(""voice"", audio_sample)
                self.log.error(result.Description, result.Code)
                self.log.error(f""Failed to send audio sample chunk {i // CHUNK_SIZE} to the robot."")
                # Fetch and display images from the robot's vision modality
                image_list, err = self.robot.get_modality(""vision"", True)
                motor_sample = bow_utils.MotorSample()
                self.robot.set_modality(""motor"", motor_sample)
            self.log.info(""Closing down"")
            bow.close_client_interface()
	   	prop = (self.Value - self.ValueMin) / (self.ValueMax - self.ValueMin)
	   	j = round(prop * (length-1))
	   	s = '|'
	   	for i in range(length):
	   		if i==j:
	   			s+='!'
	   		else:
	   			s+="".""
	   	return s+'|'
		self.mainwin.keypad(1)
		while (True):
				break
		self.mainwin.keypad(0) 
		self.mainwin.refresh();
		curses.endwin();
import bow_client as bow
import bow_utils
import math
		motorSample = bow_utils.MotorSample()
		motorSample.ControlMode = bow_utils.MotorSample.USE_DIRECT_JOINTS
		motorSample.RawJoints.append(bow_utils.Joint(Name=joint.Name, Position=joint.Value))
		Robot.set_modality(""motor"", motorSample)
# Disable logging once connection established (so we can see the display)
log = bow_utils.create_logger(""BOW Tutorial"", logging.INFO)
log.info(bow.version())
for handler in log.handlers[:]:
    if isinstance(handler, logging.StreamHandler):
        log.removeHandler(handler)
Robot, error = bow.quick_connect(pylog=log, verbose=False, modalities=[""motor"", ""proprioception""])
	log.error(""Failed to connect to robot"", error)
while(True):
	prop_msg, err = Robot.get_modality(""proprioception"", True)
			if joint.Type == bow_utils.Joint.FIXED:
display.Run()
import bow_client as bow
import bow_utils as utils
import logging
    mSamp = utils.MotorSample()
    mSamp.IKSettings.Preset = utils.IKOptimiser.HIGH_ACCURACY
    objective_command = utils.ObjectiveCommand()
    objective_command.ControlMode = utils.ControllerEnum.POSITION_CONTROLLER
    objective_command.PoseTarget.Action = utils.ActionEnum.GOTO
    objective_command.PoseTarget.TargetType = utils.PoseTarget.TargetTypeEnum.TRANSFORM
    objective_command.PoseTarget.TargetScheduleType = utils.PoseTarget.SchedulerEnum.INSTANTANEOUS
    setResult = myRobot.set_modality(""motor"", mSamp)
    if not setResult.Success:
        log.info(""Failed to set motor modality"")

# Initialize the logger
log = utils.create_logger(""BOW Tutorial - Inverse Kinematics"", logging.INFO)
# List of required modalities for this tutorial
modalities = [""proprioception"", ""motor""]

# Use quick connect to connect to robot
myRobot, error = bow.quick_connect(log, modalities)
    log.error(""Failed to connect to robot"", error)
    propMsg, error = myRobot.get_modality(""proprioception"", True)
repeatCount = 0
while repeatCount < repeatCountLim:
    angle = 0
    while angle <=2*math.pi:
        x = circleRadius * math.cos(angle)
        y = circleRadius * math.sin(angle)
        z = selectedUpDown*(circleHeight + (wobbleAmplitude * math.cos(angle*wobbleFreqMultiplier)))
        SendObjective(myRobot, selectedEffector, x, y, z)
        angle += stepSize
        time.sleep(stepSize)
    repeatCount += 1
bow.close_client_interface()
import bow_client as bow
import bow_utils
    # Create a window to display images from each camera on first call
        for i in range(len(images_list)):
            window_name = f""RobotView{i} - {images_list[i].source}""
            window_names[images_list[i].source] = window_name
    # display each image in its window
    for i, img_data in enumerate(images_list):
        myim = img_data.image
        if img_data.new_data_flag:
            cv2.imshow(window_names[img_data.source], myim)
        if sensor.OperationType == bow_utils.Range.OperationTypeEnum.Ultrasound:
log = bow_utils.create_logger(""Exteroception - Sonar"", logging.INFO)
log.info(bow.version())
myrobot, error = bow.quick_connect(pylog=log, modalities=[""vision"", ""motor"", ""exteroception""])
    log.error(""Failed to connect to robot"", error)
ext_sample, err = myrobot.get_modality(""exteroception"", True)
    ext_sample, err = myrobot.get_modality(""exteroception"", True)
        image_list, err = myrobot.get_modality(""vision"", True)
        if not err.Success or len(image_list) == 0:
        ext_sample, err = myrobot.get_modality(""exteroception"", True)
        motor_command = bow_utils.MotorSample()
        myrobot.set_modality(""motor"", motor_command)
    log.info(""Closing down"")
bow.close_client_interface()
        if len(robot_0_images) == 0:
        for image in robot_0_images:
        if len(robot_1_images) == 0:
        for image in robot_1_images:
        all_images = robot_0_images + robot_1_images
        for i in range(len(images_list)):
            window_name = f""RobotView{i} - {images_list[i].Source}""
            window_names[images_list[i].Source] = window_name
    for i, img_data in enumerate(images_list):
myrobot, error = bow_api.quick_connect(app_name=""BOW Sending Commands"", modalities=[""vision"", ""motor""])
        if len(image_samples) == 0:
        for i in range(len(images_list)):
            window_name = f""RobotView{i} - {images_list[i].Source}""
            window_names[images_list[i].Source] = window_name
    for i, img_data in enumerate(images_list):
myrobot, error = bow_api.quick_connect(app_name=""BOW Streaming Data"", modalities=[""vision""])
        if len(image_samples) == 0:",buggy
"import bow_api
import bow_data

import numpy as np
        self.master.title(""BOW x OpenAI"")
        bow_api.close_client_interface()
    try:
        while True:
            # Test for completed functions and relay results to openai assistant as ""assistant"" messages
            if controller.searchComplete is not None:
                if controller.searchComplete == ""success"":
                    brain.request(""Search Successful"", ""assistant"", gui)
                elif controller.searchComplete == ""failure"":
                    brain.request(""Search Failed"", ""assistant"", gui)
                controller.searchComplete = None

            # Get camera images from BOW robot
            image_list, err = controller.robot.vision.get(True)
            if err.Success:
                if len(image_list.Samples) > 0:
                    imsample = image_list.Samples[0]

                    if imsample is None or not imsample.NewDataFlag:
                        continue

                    if imsample.ImageType == bow_data.ImageSample.ImageTypeEnum.RGB:
                        npimage = np.frombuffer(imsample.Data, np.uint8).reshape(
                            [int(imsample.DataShape[1] * 3 / 2), imsample.DataShape[0]])
                        cvImage = cv2.cvtColor(npimage, cv2.COLOR_YUV2RGB_I420)
                    elif imsample.ImageType == bow_data.ImageSample.ImageTypeEnum.DEPTH:
                        cvImage = np.frombuffer(imsample.Data, np.uint16).reshape(
                            [imsample.DataShape[1], imsample.DataShape[0]])
                        continue

                    cvImage = imutils.rotate_bound(cvImage, imsample.Transform.EulerAngles.X * 180 / math.pi)
                    # Set camera parameters on first instance
                    if controller.VFOV is None:
                        if imsample.VFOV == 0:
                            controller.VFOV = 40
                        else:
                            controller.VFOV = imsample.VFOV

                        if imsample.HFOV == 0:
                            controller.HFOV = 80
                        else:
                            controller.HFOV = imsample.HFOV

                    # Pass image into yolo model
                    results = model.predict(source=cvImage, show=False, stream_buffer=False, verbose=False)

                    # Iterate though detected objects and populate objects list and details
                    if len(results) > 0:
                        for box in results[0].boxes.cpu():
                            obj = DetectedObject()
                            obj.classification = model.names[int(box.data[0][-1])]
                            obj.confidence = box.conf.numpy()[0]
                            obj.box = box.xyxy.numpy()[0]
                            width = obj.box[2] - obj.box[0]
                            height = obj.box[3] - obj.box[1]
                            area = width * height
                            imgArea = imsample.DataShape[0] * imsample.DataShape[1]
                            obj.area = area / imgArea
                            center = (int(obj.box[0] + width / 2), int(obj.box[1] + height / 2))
                            obj.center[0] = center[0] * (1/imsample.DataShape[0])
                            obj.center[1] = 1-(center[1] * (1 / imsample.DataShape[1]))
                            objects.append(obj)

                    # Draw detections on image
                    annotated_img = cvImage
                    for obj in objects:
                        colour = (61, 201, 151)
                        if controller.targetClass is not None or controller.prevTargetClass is not None:
                            if obj.classification == controller.targetClass:
                                colour = (36, 108, 243)
                            if obj.classification == controller.prevTargetClass:
                                colour = (36, 108, 243)

                        annotated_img = cv2.rectangle(annotated_img, (int(obj.box[0]), int(obj.box[1])),
                                                      (int(obj.box[2]), int(obj.box[3])), colour, thickness=3)
                        # Set the label position
                        label_x = int(obj.box[0])
                        label_y = int(obj.box[1]) - 10  # Position above the box by default

                        # Check if the label is going off-screen
                        if label_y < 10:
                            label_y = int(obj.box[3]) + 20  # Position below the box

                        # Draw the label
                        cv2.putText(annotated_img, obj.classification, (label_x, label_y),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, colour, 1)

                    # Pass objects list to robot controller
                    controller.object_list = objects

                    # Update gui image
                    gui.update_image(annotated_img)

                    # Update controller
                    ret = controller.update()

                # Update the Tkinter window
                objects = []
                root.update_idletasks()
                root.update()
    except KeyboardInterrupt or SystemExit:
        print(""Closing down"")
        stopFlag = True

    controller.robot.disconnect()
    bow_api.close_client_interface()
assistant_id = ""asst_NrS487lWUMCFJf0MhjCsprGe""
        self.robot.speech.set(full_message[0].text.value)
import bow_api
import bow_data

        self.log = bow_data.create_logger(""BOW x OpenAI"", logging.INFO)
        self.log.info(bow_api.version())
        self.audio_params = bow_data.AudioParams(
        self.searchVelocity = 0.4  # The Angular velocity commanded during a search
        self.robot, error = bow_api.quick_connect(app_name=self.log.name,
                                                  channels=[""vision"", ""motor"", ""speech""],
                                                  verbose=False,
                                                  audio_params=self.audio_params)
        self.robot.speech.set(""ChatGPT embodied successfully"")
        motor_sample = bow_data.MotorSample()
        ret = self.robot.motor.set(motor_sample)
import bow_api
import bow_data

import numpy as np
print(bow_api.version())
myrobot, error = bow_api.quick_connect(app_name=""Vision - Object Detection"", channels=[""vision""])
    print(""Failed to connect to robot"", error)
        image_list, err = myrobot.vision.get(True)
        if not err.Success or len(image_list.Samples) == 0:
        img_data = image_list.Samples[0]
        if img_data is not None and img_data.NewDataFlag:
            if img_data.ImageType == bow_data.ImageSample.ImageTypeEnum.RGB:
                npimage = np.frombuffer(img_data.Data, np.uint8).reshape(
                    [int(img_data.DataShape[1] * 3 / 2), img_data.DataShape[0]])
                myIm = cv2.cvtColor(npimage, cv2.COLOR_YUV2RGB_I420)
            elif img_data.ImageType == bow_data.ImageSample.ImageTypeEnum.DEPTH:
                myIm = np.frombuffer(img_data.Data, np.uint16).reshape(
                    [img_data.DataShape[1], img_data.DataShape[0]])
            else:
                continue
            cv2.imshow(img_data.Source, myIm)
    print(""Closing down"")
bow_api.close_client_interface()
import bow_api
import bow_data
import numpy as np
COMPRESSION_FORMAT = bow_data.AudioSample.CompressionFormatEnum.RAW
        print(bow_api.version())
        # Audio parameters for voice channel
        self.audio_params = bow_data.AudioParams(
        self.robot, error = bow_api.quick_connect(
            app_name=""Text to Speech"",
            channels=[""voice"", ""vision"", ""motor""],
            print(""Failed to connect to robot"", error)
        # Print robot input and output channels for debugging
    def show_all_images(self, images_list: List[bow_data.ImageSample]):
            for i in range(len(images_list)):
                window_name = f""RobotView{i} - {images_list[i].Source}""
                self.window_names[images_list[i].Source] = window_name
        for i, img_data in enumerate(images_list):
            if len(img_data.Data) != 0:
                if img_data.NewDataFlag:
                    if img_data.ImageType == bow_data.ImageSample.ImageTypeEnum.RGB:
                        npimage = np.frombuffer(img_data.Data, np.uint8).reshape(
                            [int(img_data.DataShape[1] * 3 / 2), img_data.DataShape[0]])
                        npimage = cv2.cvtColor(npimage, cv2.COLOR_YUV2RGB_I420)
                        cv2.imshow(self.window_names[img_data.Source], npimage)
                    elif img_data.ImageType == bow_data.ImageSample.ImageTypeEnum.DEPTH:
                        npimage = np.frombuffer(img_data.Data, np.uint16).reshape(
                            [img_data.DataShape[1], img_data.DataShape[0]])
                        cv2.imshow(self.window_names[img_data.Source], npimage)
                    else:
                        print(""Unhandled image type"")
            print(""Failed to retrieve audio segment."")
            audio_sample = bow_data.AudioSample(
            result = self.robot.voice.set(audio_sample)
                print(result.Description, result.Code)
                print(f""Failed to send audio sample chunk {i // CHUNK_SIZE} to the robot."")
                # Fetch and display images from the robot's vision channel
                image_list, err = self.robot.vision.get(True)
                motor_sample = bow_data.MotorSample()
                self.robot.motor.set(motor_sample)
            print(""Closing down"")
            bow_api.close_client_interface()
		prop = (self.Value - self.ValueMin) / (self.ValueMax - self.ValueMin)
		j = round(prop * (length-1))
		s = '|'
		for i in range(length):
			if i==j:
				s+='!'
			else:
				s+="".""
		return s+'|'
		self.mainwin.keypad(True)
		while True:
				raise SystemExit
		self.mainwin.keypad(False)
		self.mainwin.refresh()
		curses.endwin()
import bow_api
import bow_data

		motorSample = bow_data.MotorSample()
		motorSample.ControlMode = bow_data.MotorSample.USE_DIRECT_JOINTS
		motorSample.RawJoints.append(bow_data.Joint(Name=joint.Name, Position=joint.Value))
		robot.motor.set(motorSample)
print(bow_api.version())
robot, error = bow_api.quick_connect(app_name=""Controlling Joints"", channels=[""motor"", ""proprioception""], verbose=False)
	print(""Failed to connect to robot"", error)
while True:
	prop_msg, err = robot.proprioception.get(True)
			if joint.Type == bow_data.Joint.FIXED:
try:
	display.Run()
except KeyboardInterrupt or SystemExit:
	print(""Closing down"")
	stopFlag = True

robot.disconnect()
bow_api.close_client_interface()
import bow_api
import bow_data

    mSamp = bow_data.MotorSample()
    mSamp.IKSettings.Preset = bow_data.IKOptimiser.HIGH_ACCURACY
    objective_command = bow_data.ObjectiveCommand()
    objective_command.ControlMode = bow_data.ControllerEnum.POSITION_CONTROLLER
    objective_command.PoseTarget.Action = bow_data.ActionEnum.GOTO
    objective_command.PoseTarget.TargetType = bow_data.PoseTarget.TargetTypeEnum.TRANSFORM
    objective_command.PoseTarget.TargetScheduleType = bow_data.PoseTarget.SchedulerEnum.INSTANTANEOUS
    set_result = myRobot.motor.set(mSamp)
    if not set_result.Success:
        print(""Failed to set motor channel"")
# Use quick_connect to connect to robot
myRobot, error = bow_api.quick_connect(app_name=""Inverse Kinematics"", channels=[""proprioception"", ""motor""])
    print(""Failed to connect to robot"", error)
    propMsg, error = myRobot.proprioception.get(True)
try:
    repeatCount = 0
    while repeatCount < repeatCountLim:
        angle = 0
        while angle <=2*math.pi:
            x = circleRadius * math.cos(angle)
            y = circleRadius * math.sin(angle)
            z = selectedUpDown*(circleHeight + (wobbleAmplitude * math.cos(angle*wobbleFreqMultiplier)))

            SendObjective(myRobot, selectedEffector, x, y, z)
            angle += stepSize
            time.sleep(stepSize)
        repeatCount += 1
except KeyboardInterrupt or SystemExit:
    print(""Closing down"")
    stopFlag = True
myRobot.disconnect()
bow_api.close_client_interface()
import bow_api
import bow_data

import numpy as np

        for i in range(len(images_list.Samples)):
            window_name = f""RobotView{i} - {images_list.Samples[i].Source}""
            window_names[images_list.Samples[i].Source] = window_name
    for i, img_data in enumerate(images_list.Samples):
        if len(img_data.Data) != 0:
            if img_data.NewDataFlag:
                if img_data.ImageType == bow_data.ImageSample.ImageTypeEnum.RGB:
                    npimage = np.frombuffer(img_data.Data, np.uint8).reshape(
                        [int(img_data.DataShape[1] * 3 / 2), img_data.DataShape[0]])
                    npimage = cv2.cvtColor(npimage, cv2.COLOR_YUV2RGB_I420)
                    cv2.imshow(window_names[img_data.Source], npimage)
                elif img_data.ImageType == bow_data.ImageSample.ImageTypeEnum.DEPTH:
                    npimage = np.frombuffer(img_data.Data, np.uint16).reshape(
                        [img_data.DataShape[1], img_data.DataShape[0]])
                    cv2.imshow(window_names[img_data.Source], npimage)
                else:
                    print(""Unhandled image type"")

        if sensor.OperationType == bow_data.Range.OperationTypeEnum.Ultrasound:
print(bow_api.version())
myrobot, error = bow_api.quick_connect(app_name=""Obstacle Avoidance"", channels=[""vision"", ""motor"", ""exteroception""])
    print(""Failed to connect to robot"", error)
ext_sample, err = myrobot.exteroception.get(True)
    ext_sample, err = myrobot.exteroception.get(True)
        image_list, err = myrobot.vision.get(True)
        if not err.Success or len(image_list.Samples) == 0:
        ext_sample, err = myrobot.exteroception.get(True)
        motor_command = bow_data.MotorSample()
        myrobot.motor.set(motor_command)
    print(""Closing down"")
bow_api.close_client_interface()
        all_images = []
        if len(robot_0_images.Samples) == 0:
        for image in robot_0_images.Samples:
            all_images.append(image)
        if len(robot_1_images.Samples) == 0:
        for image in robot_1_images.Samples:
            all_images.append(image)
        for i in range(len(images_list.Samples)):
            window_name = f""RobotView{i} - {images_list.Samples[i].Source}""
            window_names[images_list.Samples[i].Source] = window_name
    for i, img_data in enumerate(images_list.Samples):
myrobot, error = bow_api.quick_connect(app_name=""BOW Sending Commands"", channels=[""vision"", ""motor""])
        if len(image_samples.Samples) == 0:
        for i in range(len(images_list.Samples)):
            window_name = f""RobotView{i} - {images_list.Samples[i].Source}""
            window_names[images_list.Samples[i].Source] = window_name
    for i, img_data in enumerate(images_list.Samples):
myrobot, error = bow_api.quick_connect(app_name=""BOW Streaming Data"", channels=[""vision""])
        if len(image_samples.Samples) == 0:",bug-free
"LOG_FILE = os.path.join(os.path.dirname(sys.argv[1]), ""lsp.log"")

# def did_change_watched_files(server: HelixLanguageServer, params: DidChangeTextDocumentParams) -> None:
#     """"""Handles watched file changes.""""""
#     logger.info('Watched files changed: {}', params.text_document.uri)",buggy
"    DidChangeWatchedFilesParams,
LOG_FILE = os.path.join(os.path.dirname(__file__), ""lsp.log"")
    @property
    def server_capabilities(self):
        """"""Override server capabilities.""""""
        capabilities = super().server_capabilities
        capabilities.text_document_sync = {
            ""openClose"": True,
            ""change"": None,  # Disable incremental sync
            ""willSave"": False,
            ""willSaveWaitUntil"": False,
            ""save"": True,
        }
        
        return capabilities
    
# def did_change_watched_files(server: HelixLanguageServer, params: DidChangeWatchedFilesParams) -> None:
#     """"""Handles document saving.""""""
#     logger.info('Document saved: {}', params.text_document.uri)",bug-free
"from typing import List, Dict, Any
from transformers import AutoModelForCausalLM, AutoTokenizer
print(""Loading UI-TARS model..."")
model_path = ""../ui-tars-7b-dpo""
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    torch_dtype=torch.float16,
    device_map=""auto""
)
def format_dom_for_model(dom_content: str) -> str:
    """"""Format DOM content for UI-TARS model input""""""
    return f""""""
DOM Structure:
{dom_content}
""""""

def generate_action_plan(instruction: str, dom_content: str = None) -> Dict:
    """"""Generate UI action plan using UI-TARS model""""""
    prompt = f""""""Task: {instruction}\n""""""
    if dom_content:
        prompt += format_dom_for_model(dom_content)
    
    prompt += ""\nGenerate a detailed action plan:""

    # Generate response from model
    inputs = tokenizer(prompt, return_tensors=""pt"").to(model.device)
    outputs = model.generate(
        **inputs,
        max_length=500,
        temperature=0.1,
        do_sample=True,
        num_return_sequences=1
    )
    
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    
        # Extract JSON plan
        plan_start = response.find('{')
        plan_end = response.rfind('}') + 1
        plan_json = response[plan_start:plan_end]
        # Parse and validate action plan
        plan = json.loads(plan_json)
        return {
            ""actions"": plan.get(""actions"", []),
            ""elements"": plan.get(""elements"", [])
        print(f""Error parsing model output: {e}"")
        print(f""Raw output: {response}"")
        return {""error"": ""Could not generate action plan""}
        # Extract instruction and DOM content
        dom_content = message[""content""][1].get(""dom"", """") if len(message[""content""]) > 1 else None
        
        # Generate action plan using UI-TARS
        action_plan = generate_action_plan(instruction, dom_content)
        
                    ""content"": json.dumps(action_plan)
    uvicorn.run(app, host=""0.0.0.0"", port=8000)",buggy
"from typing import List, Dict, Any, Optional
import os
from transformers import AutoConfig, AutoModelForVision2Seq, AutoTokenizer, AutoProcessor
from PIL import Image
import base64
import io
import logging

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
# Enable CORS
# Model initialization with proper error handling
def initialize_model():
    model_path = ""/models/ui-tars-7b-dpo""
    logger.info(f""Initializing UI-TARS model from {model_path}"")

    try:
        # Load configuration
        config = AutoConfig.from_pretrained(
            model_path,
            trust_remote_code=True
        )
        logger.info(""Configuration loaded successfully"")

        # Load tokenizer with special token handling
        tokenizer = AutoTokenizer.from_pretrained(
            model_path,
            trust_remote_code=True
        )
        logger.info(""Tokenizer loaded successfully"")

        # Load image processor
        processor = AutoProcessor.from_pretrained(
            model_path,
            trust_remote_code=True
        )
        logger.info(""Processor loaded successfully"")

        # Initialize model with proper configuration
        model = AutoModelForVision2Seq.from_pretrained(
            model_path,
            config=config,
            torch_dtype=torch.float16,
            device_map=""auto"",
            trust_remote_code=True
        )
        model.eval()
        logger.info(""Model loaded successfully"")

        return model, tokenizer, processor

    except Exception as e:
        logger.error(f""Error initializing model: {str(e)}"")
        if os.path.exists(model_path):
            logger.error(f""Model directory contents: {os.listdir(model_path)}"")
        raise

# Initialize model components
model, tokenizer, processor = initialize_model()
    max_tokens: Optional[int] = 500
    temperature: Optional[float] = 0.1
def preprocess_image(image_data: str) -> Image.Image:
    """"""Convert base64 screenshot to PIL Image with error handling""""""
        image_bytes = base64.b64decode(image_data)
        return Image.open(io.BytesIO(image_bytes))
    except Exception as e:
        logger.error(f""Error processing image: {str(e)}"")
        raise ValueError(""Invalid image data"")

def generate_response(instruction: str, screenshot: Optional[str] = None) -> Dict:
    """"""Generate UI interaction plan using UI-TARS model""""""
    try:
        # Prepare the instruction prompt
        prompt = f""Based on the webpage shown, {instruction}""
        # Prepare inputs for the model
        inputs = {
            ""text"": tokenizer(
                prompt,
                return_tensors=""pt"",
                padding=True,
                truncation=True
            ).to(model.device)

        # Process screenshot if provided
        if screenshot:
            image = preprocess_image(screenshot)
            image_inputs = processor(images=image, return_tensors=""pt"").to(model.device)
            inputs.update(image_inputs)

        # Generate response with the model
        with torch.no_grad():
            outputs = model.generate(
                **inputs,
                max_length=500,
                temperature=0.1,
                do_sample=True,
                num_return_sequences=1
            )

        # Decode and process the response
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        logger.info(f""Generated response: {response[:100]}..."")  # Log first 100 chars

        # Extract and validate the JSON plan
        try:
            plan_start = response.find('{')
            plan_end = response.rfind('}') + 1
            if plan_start == -1 or plan_end <= plan_start:
                raise ValueError(""No valid JSON found in response"")

            plan_json = response[plan_start:plan_end]
            plan = json.loads(plan_json)

            return {
                ""actions"": plan.get(""actions"", []),
                ""elements"": plan.get(""elements"", []),
                ""understanding"": plan.get(""understanding"", """"),
                ""verification"": plan.get(""verification"", [])
            }
        except json.JSONDecodeError as e:
            logger.error(f""JSON parsing error: {str(e)}"")
            logger.error(f""Response text: {response}"")
            raise ValueError(""Invalid response format"")

        logger.error(f""Error generating response: {str(e)}"")
        return {""error"": str(e)}
        # Extract the latest message
        screenshot = message[""content""][1].get(""screenshot"", None) if len(message[""content""]) > 1 else None

        # Generate the interaction plan
        plan = generate_response(instruction, screenshot)

                    ""content"": json.dumps(plan)
        logger.error(f""Error in chat completion: {str(e)}"")
@app.get(""/health"")
async def health_check():
    """"""Health check endpoint""""""
    try:
        # Verify model components are loaded
        if not all([model, tokenizer, processor]):
            raise Exception(""One or more model components not initialized"")
        return {""status"": ""healthy"", ""model"": ""loaded""}
    except Exception as e:
        raise HTTPException(status_code=503, detail=str(e))

    uvicorn.run(app, host=""0.0.0.0"", port=8000)",bug-free
"        post_id = request.form.get(""post_id"", None)
from google.cloud import firestore
    db = firestore.Client()
    with open(""../data/blog_entries.json"", 'r') as file:
            document = db.collection(""posts"").document(id)
    print(""get_unsplash_image()"")
        print(response.json()[""urls""][""small""])",buggy
"        post_id = request.form.get(""post-id"", None)
from extensions.my_firestore import db
from config import config


    post_collection = config[""development""].POSTS
    
    with open(""sample_data/blog_entries.json"", 'r') as file:
            document = db.collection(post_collection).document(id)
    # print(""get_unsplash_image()"")
        # print(response.json()[""urls""][""small""])",bug-free
"    forecast_df: pl.DataFrame,
    id_cols: list[str] = [""draw""],
    strict: bool = False,
    Aggregate daily values (e.g.
    forecast_df
        A polars dataframe with draws and dates
        as columns. This dataframe will likely
        have come from an InferenceData object
        that was converted using `idata_w_dates_to_df`.
        The name of the column with the fitted
        and or forecasted quantity. Defaults
        to ""value"".
        Defaults to ""date"".
        Defaults to ["".draw""].
        Defaults to ""weekly_value"".
        values. If False, then incomplete weeks
        will be aggregated. Defaults to False.
    forecast_df = forecast_df.with_columns(
        pl.col([""date""])
    grouped_df = forecast_df.group_by(group_cols)
        message = f""Problematic trajectories with more than 7 values per epiweek per year: {problematic_trajectories}""
        raise ValueError(
            f""At least one trajectory has more than 7 values for a given epiweek of a given year.\n{message}""
        )
    # check if any week has more than 7 dates
    if not n_elements[""n_elements""].to_numpy().max() <= 7:
            ""At least one trajectory has more than 7 values for a given epiweek of a given year.""
    # if strict, filter out groups that do not have exactly 7 contributing dates
        forecast_df = forecast_df.join(
    # aggregate; sum values in the specified value_col
        forecast_df.group_by(group_cols)
        .sort([""epiyear"", ""epiweek"", ""draw""])",buggy
"from forecasttools.utils import ensure_listlike

    df: pl.DataFrame,
    id_cols: str | list[str] = [""draw""],
    strict: bool = True,
    Aggregate a dataframe of daily values (e.g.
    df
        Tidy data frame of daily values to aggregate.
        The name of the column containing daily trajectory /
        timeseries values to aggregate. Defaults
        to ```""value""``.
        Defaults to ``""date""``.
        Defaults to ``""draw""``.
        Defaults to ``""weekly_value""``.
        values. If ``False``, then incomplete weeks
        will be aggregated. Defaults to ``True``.
    id_cols = ensure_listlike(id_cols)
    df = df.with_columns(
        pl.col(date_col)
    grouped_df = df.group_by(group_cols)
            ""At least one trajectory has more than 7 values ""
            ""for a given epiweek of a given epiyear.\n""
            ""Problematic trajectories with more than 7 ""
            ""values: ""
            f""{problematic_trajectories}""

        df = df.join(
        df.group_by(group_cols)
        .sort(group_cols)",bug-free
"class TracingProvider(Generic[T], metaclass=abc.ABCMeta):
class ComputationBuildingBlock(typed_object.TypedObject, metaclass=abc.ABCMeta):
class BoundVariableTracker(metaclass=abc.ABCMeta):
class TransformSpec(metaclass=abc.ABCMeta):
class Computation(typed_object.TypedObject, metaclass=abc.ABCMeta):
class SyncContext(metaclass=abc.ABCMeta):
class AsyncContext(metaclass=abc.ABCMeta):
class ContextStack(metaclass=abc.ABCMeta):
class Executor(metaclass=abc.ABCMeta):
class ExecutorFactory(metaclass=abc.ABCMeta):
class ExecutorValue(abc.ABC, typed_object.TypedObject):
class Value(typed_object.TypedObject, metaclass=abc.ABCMeta):
class MaterializableValueReference(abc.ABC, typed_object.TypedObject):
class Type(metaclass=abc.ABCMeta):
class TypedObject(metaclass=abc.ABCMeta):",buggy
"class TracingProvider(Generic[T], abc.ABC):
class ComputationBuildingBlock(typed_object.TypedObject, abc.ABC):
class BoundVariableTracker(abc.ABC):
class TransformSpec(abc.ABC):
class Computation(typed_object.TypedObject, abc.ABC):
class SyncContext(abc.ABC):
class AsyncContext(abc.ABC):
class ContextStack(abc.ABC):
class Executor(abc.ABC):
class ExecutorFactory(abc.ABC):
class ExecutorValue(typed_object.TypedObject, abc.ABC):
class Value(typed_object.TypedObject, abc.ABC):
class MaterializableValueReference(typed_object.TypedObject, abc.ABC):
class Type(abc.ABC):
class TypedObject(abc.ABC):",bug-free
"import json
from enum import Enum
from pydantic import TypeAdapter, ValidationError",buggy
"import platform
import sys
from pydantic import TypeAdapter
        platform_str = platform.platform()
        py_impl_version = sys.implementation.cache_tag
        py_lang_version = platform.python_version()
        print(f""Python: {py_impl_version} ({py_lang_version})"")
        print(f""Platform: {platform_str}"")",bug-free
        self.master.geometry('280x300'),buggy
"        self.master.geometry('400x300') 
            
        def get_zodiac_sign(day, month):
            astro_sign = [""Capricorn"", ""Aquarius"", ""Pisces"", ""Aries"", ""Taurus"", ""Gemini"", ""Cancer"", ""Leo"", ""Virgo"", ""Libra"", ""Scorpio"", ""Sagittarius""]    
            if month == 1:
                if day < 20:
                    astro_sign_index = astro_sign[0]
                else:
                    astro_sign_index = astro_sign[1]    
            elif month == 2:
                if day < 19:
                    astro_sign_index = astro_sign[1]
                else:
                    astro_sign_index = astro_sign[2]
            elif month == 3:
                if day < 21:
                    astro_sign_index = astro_sign[2]
                else:
                    astro_sign_index = astro_sign[3]    
            elif month == 4:
                if day < 20:
                    astro_sign_index = astro_sign[3]
                else:
                    astro_sign_index = astro_sign[4]    
            elif month == 5:
                if day < 21:
                    astro_sign_index = astro_sign[4]
                else:
                    astro_sign_index = astro_sign[5]    
            elif month == 6:
                if day < 21:
                    astro_sign_index = astro_sign[5]
                else:
                    astro_sign_index = astro_sign[6]    
            elif month == 7:
                if day < 23:
                    astro_sign_index = astro_sign[6]
                else:
                    astro_sign_index = astro_sign[7]    
            elif month == 8:
                if day < 23:
                    astro_sign_index = astro_sign[7]
                else:
                    astro_sign_index = astro_sign[8]    
            elif month == 9:
                if day < 23:
                    astro_sign_index = astro_sign[8]
                else:
                    astro_sign_index = astro_sign[9]    
            elif month == 10:
                if day < 23:
                    astro_sign_index = astro_sign[9]
                else:
                    astro_sign_index = astro_sign[10]    
            elif month == 11:
                if day < 22:
                    astro_sign_index = astro_sign[10]
                else:
                    astro_sign_index = astro_sign[11]
            elif month == 12:
                if day < 22:
                    astro_sign_index = astro_sign[11]
                else:
                    astro_sign_index = astro_sign[0]                
            return astro_sign_index        ",bug-free
"def print_unicode(text):
    """"""Print in a portable manner.""""""
    if sys.version_info[0] < 3:
        text = text.encode('utf-8')

    print(text)


        guess_language = None
        if args.language:
            if args.language.lower() == 'auto':
                try:
                    from guess_language import guess_language
                except ImportError:
                    print('guess_language is unavailable.', file=sys.stderr)
                    return 1
                else:
                    language = guess_language(text)
                    print('Detected language: {}'.format(language),
                          file=sys.stderr)
                    if not language:
                        return 1
                    lang_tool.language = language
            else:
                lang_tool.language = args.language

                print_unicode(lang_tool.correct(text))
                    print_unicode('{}: {}: {}'.format(",buggy
"            language=args.language,
                print(lang_tool.correct(text))
                    print('{}: {}: {}'.format(",bug-free
"        if not getattr(func, ""__annotations__"", None):
    def setUp(self):
        pass",buggy
"        if not getattr(func, ""__annotations__"", None):  # pragma: no cover
from typing import Optional, Union
class JArray:
    """"""Java Array""""""

    @classmethod
    @annotate('JArray', size=int)
    def newBooleanArray(cls, size):
        ...

    @annotate(borrowed=bool)
    def __init__(self, borrowed=False):
        ...

    @annotate(int)
    def getLength(self):
        ...

    @annotate(bool, idx=int)
    def getBoolean(self, idx):
        ...

    @annotate(int, idx=int)
    def getInt(self, idx, val):
        ...

    @annotate(float, idx=int)
    def getDouble(self, idx):
        ...

    @annotate(Optional[str], idx=int)
    def getString(self, idx):
        ...

    @annotate(idx=int, val=bool)
    def setBoolean(self, idx, val):
        ...

    @annotate(idx=int, val=int)
    def setInt(self, idx, val):
        ...

    @annotate(idx=int, val=float)
    def setDouble(self, idx, val):
        ...

    @annotate(idx=int, val=Optional[str])
    def setString(self, idx, val):
        ...


    def test_main(self):
        self.assertEqual(JArray.newBooleanArray.__annotations__, {""size"": int, ""return"": ""JArray""})
        self.assertEqual(JArray.__init__.__annotations__,        {""borrowed"": bool})
        self.assertEqual(JArray.getLength.__annotations__,       {""return"": int})
        self.assertEqual(JArray.getBoolean.__annotations__,      {""idx"": int, ""return"": bool})
        self.assertEqual(JArray.getInt.__annotations__,          {""idx"": int, ""return"": int})
        self.assertEqual(JArray.getDouble.__annotations__,       {""idx"": int, ""return"": float})
        self.assertEqual(JArray.getString.__annotations__,       {""idx"": int, ""return"": Optional[str]})
        self.assertEqual(JArray.setBoolean.__annotations__,      {""idx"": int, ""val"": bool})
        self.assertEqual(JArray.setInt.__annotations__,          {""idx"": int, ""val"": int})
        self.assertEqual(JArray.setDouble.__annotations__,       {""idx"": int, ""val"": float})
        self.assertEqual(JArray.setString.__annotations__,       {""idx"": int, ""val"": Optional[str]})",bug-free
"import bow_client as bow
        self.master.title(""BOW >< OpenAI"")
        bow.close_client_interface()
    while True:
        # Test for completed functions and relay results to openai assistant as ""assistant"" messages
        if controller.searchComplete is not None:
            if controller.searchComplete == ""success"":
                brain.request(""Search Successful"", ""assistant"", gui)
            elif controller.searchComplete == ""failure"":
                brain.request(""Search Failed"", ""assistant"", gui)
            controller.searchComplete = None

        # Get camera images from BOW robot
        image_list, err = controller.robot.get_modality(""vision"", True)
        if err.Success:
            if len(image_list) > 0:
                img_data = image_list[0]
                img_data.image = imutils.rotate_bound(img_data.image, img_data.transform.EulerAngles.X * 180 / math.pi)
                # Set camera parameters on first instance
                if controller.VFOV is None:
                    if img_data.vfov == 0:
                        controller.VFOV = 40
                    else:
                        controller.VFOV = img_data.vfov

                    if img_data.hfov == 0:
                        controller.HFOV = 80
                        controller.HFOV = img_data.hfov

                # Pass image into yolo model
                results = model.predict(source=img_data.image, show=False, stream_buffer=False,
                                        verbose=False)

                # Iterate though detected objects and populate objects list and details
                if len(results) > 0:
                    for box in results[0].boxes.cpu():
                        obj = DetectedObject()
                        obj.classification = model.names[int(box.data[0][-1])]
                        obj.confidence = box.conf.numpy()[0]
                        obj.box = box.xyxy.numpy()[0]
                        width = obj.box[2] - obj.box[0]
                        height = obj.box[3] - obj.box[1]
                        area = width * height
                        imgArea = img_data.shape[0] * img_data.shape[1]
                        obj.area = area / imgArea
                        center = (int(obj.box[0] + width / 2), int(obj.box[1] + height / 2))
                        obj.center[0] = center[0] * (1/img_data.shape[0])
                        obj.center[1] = 1-(center[1] * (1 / img_data.shape[1]))
                        objects.append(obj)

                # Draw detections on image
                annotated_img = img_data.image
                for obj in objects:
                    colour = (61, 201, 151)
                    if controller.targetClass is not None or controller.prevTargetClass is not None:
                        if obj.classification == controller.targetClass:
                            colour = (36, 108, 243)
                        if obj.classification == controller.prevTargetClass:
                            colour = (36, 108, 243)

                    annotated_img = cv2.rectangle(annotated_img, (int(obj.box[0]), int(obj.box[1])),
                                                  (int(obj.box[2]), int(obj.box[3])), colour, thickness=3)
                    # Set the label position
                    label_x = int(obj.box[0])
                    label_y = int(obj.box[1]) - 10  # Position above the box by default

                    # Check if the label is going off-screen
                    if label_y < 10:
                        label_y = int(obj.box[3]) + 20  # Position below the box

                    # Draw the label
                    cv2.putText(annotated_img, obj.classification, (label_x, label_y),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.7, colour, 1)

                # Pass objects list to robot controller
                controller.object_list = objects

                # Update gui image
                gui.update_image(annotated_img)

                # Update controller
                ret = controller.update()

            # Update the Tkinter window
            objects = []
            root.update_idletasks()
            root.update()
assistant_id = ""asst_BF4jtnh3Mt0lAA2p4Uyvzm9f""
        self.robot.set_modality(""speech"", full_message[0].text.value)
import math
import bow_client as bow
import bow_utils as utils
        self.log = utils.create_logger(""BOW >< OpenAI"", logging.INFO)
        self.log.info(bow.version())
        self.audio_params = utils.AudioParams(
        self.searchVelocity = 0.15  # The Angular velocity commanded during a search
        self.robot, error = bow.quick_connect(pylog=self.log,
                                              modalities=[""vision"", ""motor"", ""speech""],
                                              verbose=False,
                                              audio_params=self.audio_params)
        self.robot.set_modality(""speech"", ""ChatGPT embodied successfully"")
        motor_sample = utils.MotorSample()
        ret = self.robot.set_modality(""motor"", motor_sample)
import bow_client as bow
import bow_utils
log = bow_utils.create_logger(""Bow Tutorial: Vision - Object Detection"", logging.INFO)
log.info(bow.version())
myrobot, error = bow.quick_connect(pylog=log, modalities=[""vision""])
    log.error(""Failed to connect to robot"", error)
        image_list, err = myrobot.get_modality(""vision"", True)
        if not err.Success or len(image_list) == 0:
        img_data = image_list[0]
        if img_data is not None and img_data.new_data_flag:
            myIm = img_data.image
            cv2.imshow(img_data.source, myIm)
    log.info(""Closing down"")
bow.close_client_interface()
import bow_client as bow
import bow_utils
COMPRESSION_FORMAT = bow_utils.AudioSample.CompressionFormatEnum.RAW
        self.log = bow_utils.create_logger(""Bow Tutorial 6"", logging.INFO)
        self.log.info(bow.version())
        # Audio parameters for voice modality
        self.audio_params = bow_utils.AudioParams(
        self.robot, error = bow.quick_connect(
            pylog=self.log,
            modalities=[""voice"", ""vision"", ""motor""],
            self.log.error(""Failed to connect to robot"", error)
        # Print robot input and output modalities for debugging
    def show_all_images(self, images_list: List[bow_utils.ImageSampleHelper]):
            for i, img_data in enumerate(images_list):
                window_name = f""RobotView{i} - {img_data.source}""
                self.window_names[img_data.source] = window_name
        for img_data in images_list:
            if img_data.new_data_flag:
                cv2.imshow(self.window_names[img_data.source], img_data.image)
            self.log.error(""Failed to retrieve audio segment."")
            audio_sample = bow_utils.AudioSample(
            result = self.robot.set_modality(""voice"", audio_sample)
                self.log.error(result.Description, result.Code)
                self.log.error(f""Failed to send audio sample chunk {i // CHUNK_SIZE} to the robot."")
                # Fetch and display images from the robot's vision modality
                image_list, err = self.robot.get_modality(""vision"", True)
                motor_sample = bow_utils.MotorSample()
                self.robot.set_modality(""motor"", motor_sample)
            self.log.info(""Closing down"")
            bow.close_client_interface()
	   	prop = (self.Value - self.ValueMin) / (self.ValueMax - self.ValueMin)
	   	j = round(prop * (length-1))
	   	s = '|'
	   	for i in range(length):
	   		if i==j:
	   			s+='!'
	   		else:
	   			s+="".""
	   	return s+'|'
		self.mainwin.keypad(1)
		while (True):
				break
		self.mainwin.keypad(0) 
		self.mainwin.refresh();
		curses.endwin();
import bow_client as bow
import bow_utils
import math
		motorSample = bow_utils.MotorSample()
		motorSample.ControlMode = bow_utils.MotorSample.USE_DIRECT_JOINTS
		motorSample.RawJoints.append(bow_utils.Joint(Name=joint.Name, Position=joint.Value))
		Robot.set_modality(""motor"", motorSample)
# Disable logging once connection established (so we can see the display)
log = bow_utils.create_logger(""BOW Tutorial"", logging.INFO)
log.info(bow.version())
for handler in log.handlers[:]:
    if isinstance(handler, logging.StreamHandler):
        log.removeHandler(handler)
Robot, error = bow.quick_connect(pylog=log, verbose=False, modalities=[""motor"", ""proprioception""])
	log.error(""Failed to connect to robot"", error)
while(True):
	prop_msg, err = Robot.get_modality(""proprioception"", True)
			if joint.Type == bow_utils.Joint.FIXED:
display.Run()
import bow_client as bow
import bow_utils as utils
import logging
    mSamp = utils.MotorSample()
    mSamp.IKSettings.Preset = utils.IKOptimiser.HIGH_ACCURACY
    objective_command = utils.ObjectiveCommand()
    objective_command.ControlMode = utils.ControllerEnum.POSITION_CONTROLLER
    objective_command.PoseTarget.Action = utils.ActionEnum.GOTO
    objective_command.PoseTarget.TargetType = utils.PoseTarget.TargetTypeEnum.TRANSFORM
    objective_command.PoseTarget.TargetScheduleType = utils.PoseTarget.SchedulerEnum.INSTANTANEOUS
    setResult = myRobot.set_modality(""motor"", mSamp)
    if not setResult.Success:
        log.info(""Failed to set motor modality"")

# Initialize the logger
log = utils.create_logger(""BOW Tutorial - Inverse Kinematics"", logging.INFO)
# List of required modalities for this tutorial
modalities = [""proprioception"", ""motor""]

# Use quick connect to connect to robot
myRobot, error = bow.quick_connect(log, modalities)
    log.error(""Failed to connect to robot"", error)
    propMsg, error = myRobot.get_modality(""proprioception"", True)
repeatCount = 0
while repeatCount < repeatCountLim:
    angle = 0
    while angle <=2*math.pi:
        x = circleRadius * math.cos(angle)
        y = circleRadius * math.sin(angle)
        z = selectedUpDown*(circleHeight + (wobbleAmplitude * math.cos(angle*wobbleFreqMultiplier)))
        SendObjective(myRobot, selectedEffector, x, y, z)
        angle += stepSize
        time.sleep(stepSize)
    repeatCount += 1
bow.close_client_interface()
import bow_client as bow
import bow_utils
    # Create a window to display images from each camera on first call
        for i in range(len(images_list)):
            window_name = f""RobotView{i} - {images_list[i].source}""
            window_names[images_list[i].source] = window_name
    # display each image in its window
    for i, img_data in enumerate(images_list):
        myim = img_data.image
        if img_data.new_data_flag:
            cv2.imshow(window_names[img_data.source], myim)
        if sensor.OperationType == bow_utils.Range.OperationTypeEnum.Ultrasound:
log = bow_utils.create_logger(""Exteroception - Sonar"", logging.INFO)
log.info(bow.version())
myrobot, error = bow.quick_connect(pylog=log, modalities=[""vision"", ""motor"", ""exteroception""])
    log.error(""Failed to connect to robot"", error)
ext_sample, err = myrobot.get_modality(""exteroception"", True)
    ext_sample, err = myrobot.get_modality(""exteroception"", True)
        image_list, err = myrobot.get_modality(""vision"", True)
        if not err.Success or len(image_list) == 0:
        ext_sample, err = myrobot.get_modality(""exteroception"", True)
        motor_command = bow_utils.MotorSample()
        myrobot.set_modality(""motor"", motor_command)
    log.info(""Closing down"")
bow.close_client_interface()
        if len(robot_0_images) == 0:
        for image in robot_0_images:
        if len(robot_1_images) == 0:
        for image in robot_1_images:
        all_images = robot_0_images + robot_1_images
        for i in range(len(images_list)):
            window_name = f""RobotView{i} - {images_list[i].Source}""
            window_names[images_list[i].Source] = window_name
    for i, img_data in enumerate(images_list):
myrobot, error = bow_api.quick_connect(app_name=""BOW Sending Commands"", modalities=[""vision"", ""motor""])
        if len(image_samples) == 0:
        for i in range(len(images_list)):
            window_name = f""RobotView{i} - {images_list[i].Source}""
            window_names[images_list[i].Source] = window_name
    for i, img_data in enumerate(images_list):
myrobot, error = bow_api.quick_connect(app_name=""BOW Streaming Data"", modalities=[""vision""])
        if len(image_samples) == 0:",buggy
"import bow_api
import bow_data

import numpy as np
        self.master.title(""BOW x OpenAI"")
        bow_api.close_client_interface()
    try:
        while True:
            # Test for completed functions and relay results to openai assistant as ""assistant"" messages
            if controller.searchComplete is not None:
                if controller.searchComplete == ""success"":
                    brain.request(""Search Successful"", ""assistant"", gui)
                elif controller.searchComplete == ""failure"":
                    brain.request(""Search Failed"", ""assistant"", gui)
                controller.searchComplete = None

            # Get camera images from BOW robot
            image_list, err = controller.robot.vision.get(True)
            if err.Success:
                if len(image_list.Samples) > 0:
                    imsample = image_list.Samples[0]

                    if imsample is None or not imsample.NewDataFlag:
                        continue

                    if imsample.ImageType == bow_data.ImageSample.ImageTypeEnum.RGB:
                        npimage = np.frombuffer(imsample.Data, np.uint8).reshape(
                            [int(imsample.DataShape[1] * 3 / 2), imsample.DataShape[0]])
                        cvImage = cv2.cvtColor(npimage, cv2.COLOR_YUV2RGB_I420)
                    elif imsample.ImageType == bow_data.ImageSample.ImageTypeEnum.DEPTH:
                        cvImage = np.frombuffer(imsample.Data, np.uint16).reshape(
                            [imsample.DataShape[1], imsample.DataShape[0]])
                        continue

                    cvImage = imutils.rotate_bound(cvImage, imsample.Transform.EulerAngles.X * 180 / math.pi)
                    # Set camera parameters on first instance
                    if controller.VFOV is None:
                        if imsample.VFOV == 0:
                            controller.VFOV = 40
                        else:
                            controller.VFOV = imsample.VFOV

                        if imsample.HFOV == 0:
                            controller.HFOV = 80
                        else:
                            controller.HFOV = imsample.HFOV

                    # Pass image into yolo model
                    results = model.predict(source=cvImage, show=False, stream_buffer=False, verbose=False)

                    # Iterate though detected objects and populate objects list and details
                    if len(results) > 0:
                        for box in results[0].boxes.cpu():
                            obj = DetectedObject()
                            obj.classification = model.names[int(box.data[0][-1])]
                            obj.confidence = box.conf.numpy()[0]
                            obj.box = box.xyxy.numpy()[0]
                            width = obj.box[2] - obj.box[0]
                            height = obj.box[3] - obj.box[1]
                            area = width * height
                            imgArea = imsample.DataShape[0] * imsample.DataShape[1]
                            obj.area = area / imgArea
                            center = (int(obj.box[0] + width / 2), int(obj.box[1] + height / 2))
                            obj.center[0] = center[0] * (1/imsample.DataShape[0])
                            obj.center[1] = 1-(center[1] * (1 / imsample.DataShape[1]))
                            objects.append(obj)

                    # Draw detections on image
                    annotated_img = cvImage
                    for obj in objects:
                        colour = (61, 201, 151)
                        if controller.targetClass is not None or controller.prevTargetClass is not None:
                            if obj.classification == controller.targetClass:
                                colour = (36, 108, 243)
                            if obj.classification == controller.prevTargetClass:
                                colour = (36, 108, 243)

                        annotated_img = cv2.rectangle(annotated_img, (int(obj.box[0]), int(obj.box[1])),
                                                      (int(obj.box[2]), int(obj.box[3])), colour, thickness=3)
                        # Set the label position
                        label_x = int(obj.box[0])
                        label_y = int(obj.box[1]) - 10  # Position above the box by default

                        # Check if the label is going off-screen
                        if label_y < 10:
                            label_y = int(obj.box[3]) + 20  # Position below the box

                        # Draw the label
                        cv2.putText(annotated_img, obj.classification, (label_x, label_y),
                                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, colour, 1)

                    # Pass objects list to robot controller
                    controller.object_list = objects

                    # Update gui image
                    gui.update_image(annotated_img)

                    # Update controller
                    ret = controller.update()

                # Update the Tkinter window
                objects = []
                root.update_idletasks()
                root.update()
    except KeyboardInterrupt or SystemExit:
        print(""Closing down"")
        stopFlag = True

    controller.robot.disconnect()
    bow_api.close_client_interface()
assistant_id = ""asst_NrS487lWUMCFJf0MhjCsprGe""
        self.robot.speech.set(full_message[0].text.value)
import bow_api
import bow_data

        self.log = bow_data.create_logger(""BOW x OpenAI"", logging.INFO)
        self.log.info(bow_api.version())
        self.audio_params = bow_data.AudioParams(
        self.searchVelocity = 0.4  # The Angular velocity commanded during a search
        self.robot, error = bow_api.quick_connect(app_name=self.log.name,
                                                  channels=[""vision"", ""motor"", ""speech""],
                                                  verbose=False,
                                                  audio_params=self.audio_params)
        self.robot.speech.set(""ChatGPT embodied successfully"")
        motor_sample = bow_data.MotorSample()
        ret = self.robot.motor.set(motor_sample)
import bow_api
import bow_data

import numpy as np
print(bow_api.version())
myrobot, error = bow_api.quick_connect(app_name=""Vision - Object Detection"", channels=[""vision""])
    print(""Failed to connect to robot"", error)
        image_list, err = myrobot.vision.get(True)
        if not err.Success or len(image_list.Samples) == 0:
        img_data = image_list.Samples[0]
        if img_data is not None and img_data.NewDataFlag:
            if img_data.ImageType == bow_data.ImageSample.ImageTypeEnum.RGB:
                npimage = np.frombuffer(img_data.Data, np.uint8).reshape(
                    [int(img_data.DataShape[1] * 3 / 2), img_data.DataShape[0]])
                myIm = cv2.cvtColor(npimage, cv2.COLOR_YUV2RGB_I420)
            elif img_data.ImageType == bow_data.ImageSample.ImageTypeEnum.DEPTH:
                myIm = np.frombuffer(img_data.Data, np.uint16).reshape(
                    [img_data.DataShape[1], img_data.DataShape[0]])
            else:
                continue
            cv2.imshow(img_data.Source, myIm)
    print(""Closing down"")
bow_api.close_client_interface()
import bow_api
import bow_data
import numpy as np
COMPRESSION_FORMAT = bow_data.AudioSample.CompressionFormatEnum.RAW
        print(bow_api.version())
        # Audio parameters for voice channel
        self.audio_params = bow_data.AudioParams(
        self.robot, error = bow_api.quick_connect(
            app_name=""Text to Speech"",
            channels=[""voice"", ""vision"", ""motor""],
            print(""Failed to connect to robot"", error)
        # Print robot input and output channels for debugging
    def show_all_images(self, images_list: List[bow_data.ImageSample]):
            for i in range(len(images_list)):
                window_name = f""RobotView{i} - {images_list[i].Source}""
                self.window_names[images_list[i].Source] = window_name
        for i, img_data in enumerate(images_list):
            if len(img_data.Data) != 0:
                if img_data.NewDataFlag:
                    if img_data.ImageType == bow_data.ImageSample.ImageTypeEnum.RGB:
                        npimage = np.frombuffer(img_data.Data, np.uint8).reshape(
                            [int(img_data.DataShape[1] * 3 / 2), img_data.DataShape[0]])
                        npimage = cv2.cvtColor(npimage, cv2.COLOR_YUV2RGB_I420)
                        cv2.imshow(self.window_names[img_data.Source], npimage)
                    elif img_data.ImageType == bow_data.ImageSample.ImageTypeEnum.DEPTH:
                        npimage = np.frombuffer(img_data.Data, np.uint16).reshape(
                            [img_data.DataShape[1], img_data.DataShape[0]])
                        cv2.imshow(self.window_names[img_data.Source], npimage)
                    else:
                        print(""Unhandled image type"")
            print(""Failed to retrieve audio segment."")
            audio_sample = bow_data.AudioSample(
            result = self.robot.voice.set(audio_sample)
                print(result.Description, result.Code)
                print(f""Failed to send audio sample chunk {i // CHUNK_SIZE} to the robot."")
                # Fetch and display images from the robot's vision channel
                image_list, err = self.robot.vision.get(True)
                motor_sample = bow_data.MotorSample()
                self.robot.motor.set(motor_sample)
            print(""Closing down"")
            bow_api.close_client_interface()
		prop = (self.Value - self.ValueMin) / (self.ValueMax - self.ValueMin)
		j = round(prop * (length-1))
		s = '|'
		for i in range(length):
			if i==j:
				s+='!'
			else:
				s+="".""
		return s+'|'
		self.mainwin.keypad(True)
		while True:
				raise SystemExit
		self.mainwin.keypad(False)
		self.mainwin.refresh()
		curses.endwin()
import bow_api
import bow_data

		motorSample = bow_data.MotorSample()
		motorSample.ControlMode = bow_data.MotorSample.USE_DIRECT_JOINTS
		motorSample.RawJoints.append(bow_data.Joint(Name=joint.Name, Position=joint.Value))
		robot.motor.set(motorSample)
print(bow_api.version())
robot, error = bow_api.quick_connect(app_name=""Controlling Joints"", channels=[""motor"", ""proprioception""], verbose=False)
	print(""Failed to connect to robot"", error)
while True:
	prop_msg, err = robot.proprioception.get(True)
			if joint.Type == bow_data.Joint.FIXED:
try:
	display.Run()
except KeyboardInterrupt or SystemExit:
	print(""Closing down"")
	stopFlag = True

robot.disconnect()
bow_api.close_client_interface()
import bow_api
import bow_data

    mSamp = bow_data.MotorSample()
    mSamp.IKSettings.Preset = bow_data.IKOptimiser.HIGH_ACCURACY
    objective_command = bow_data.ObjectiveCommand()
    objective_command.ControlMode = bow_data.ControllerEnum.POSITION_CONTROLLER
    objective_command.PoseTarget.Action = bow_data.ActionEnum.GOTO
    objective_command.PoseTarget.TargetType = bow_data.PoseTarget.TargetTypeEnum.TRANSFORM
    objective_command.PoseTarget.TargetScheduleType = bow_data.PoseTarget.SchedulerEnum.INSTANTANEOUS
    set_result = myRobot.motor.set(mSamp)
    if not set_result.Success:
        print(""Failed to set motor channel"")
# Use quick_connect to connect to robot
myRobot, error = bow_api.quick_connect(app_name=""Inverse Kinematics"", channels=[""proprioception"", ""motor""])
    print(""Failed to connect to robot"", error)
    propMsg, error = myRobot.proprioception.get(True)
try:
    repeatCount = 0
    while repeatCount < repeatCountLim:
        angle = 0
        while angle <=2*math.pi:
            x = circleRadius * math.cos(angle)
            y = circleRadius * math.sin(angle)
            z = selectedUpDown*(circleHeight + (wobbleAmplitude * math.cos(angle*wobbleFreqMultiplier)))

            SendObjective(myRobot, selectedEffector, x, y, z)
            angle += stepSize
            time.sleep(stepSize)
        repeatCount += 1
except KeyboardInterrupt or SystemExit:
    print(""Closing down"")
    stopFlag = True
myRobot.disconnect()
bow_api.close_client_interface()
import bow_api
import bow_data

import numpy as np

        for i in range(len(images_list.Samples)):
            window_name = f""RobotView{i} - {images_list.Samples[i].Source}""
            window_names[images_list.Samples[i].Source] = window_name
    for i, img_data in enumerate(images_list.Samples):
        if len(img_data.Data) != 0:
            if img_data.NewDataFlag:
                if img_data.ImageType == bow_data.ImageSample.ImageTypeEnum.RGB:
                    npimage = np.frombuffer(img_data.Data, np.uint8).reshape(
                        [int(img_data.DataShape[1] * 3 / 2), img_data.DataShape[0]])
                    npimage = cv2.cvtColor(npimage, cv2.COLOR_YUV2RGB_I420)
                    cv2.imshow(window_names[img_data.Source], npimage)
                elif img_data.ImageType == bow_data.ImageSample.ImageTypeEnum.DEPTH:
                    npimage = np.frombuffer(img_data.Data, np.uint16).reshape(
                        [img_data.DataShape[1], img_data.DataShape[0]])
                    cv2.imshow(window_names[img_data.Source], npimage)
                else:
                    print(""Unhandled image type"")

        if sensor.OperationType == bow_data.Range.OperationTypeEnum.Ultrasound:
print(bow_api.version())
myrobot, error = bow_api.quick_connect(app_name=""Obstacle Avoidance"", channels=[""vision"", ""motor"", ""exteroception""])
    print(""Failed to connect to robot"", error)
ext_sample, err = myrobot.exteroception.get(True)
    ext_sample, err = myrobot.exteroception.get(True)
        image_list, err = myrobot.vision.get(True)
        if not err.Success or len(image_list.Samples) == 0:
        ext_sample, err = myrobot.exteroception.get(True)
        motor_command = bow_data.MotorSample()
        myrobot.motor.set(motor_command)
    print(""Closing down"")
bow_api.close_client_interface()
        all_images = []
        if len(robot_0_images.Samples) == 0:
        for image in robot_0_images.Samples:
            all_images.append(image)
        if len(robot_1_images.Samples) == 0:
        for image in robot_1_images.Samples:
            all_images.append(image)
        for i in range(len(images_list.Samples)):
            window_name = f""RobotView{i} - {images_list.Samples[i].Source}""
            window_names[images_list.Samples[i].Source] = window_name
    for i, img_data in enumerate(images_list.Samples):
myrobot, error = bow_api.quick_connect(app_name=""BOW Sending Commands"", channels=[""vision"", ""motor""])
        if len(image_samples.Samples) == 0:
        for i in range(len(images_list.Samples)):
            window_name = f""RobotView{i} - {images_list.Samples[i].Source}""
            window_names[images_list.Samples[i].Source] = window_name
    for i, img_data in enumerate(images_list.Samples):
myrobot, error = bow_api.quick_connect(app_name=""BOW Streaming Data"", channels=[""vision""])
        if len(image_samples.Samples) == 0:",bug-free
"        :type l1: ListNode
        :type l2: ListNode
        :rtype: ListNode
        #===============================#
        # Greedy-based traversal method #
        #===============================#
        ##### Record summary values (i.e. l1, l2) #####
        record_sum_l1, record_sum_l2 = 0, 0
        ##### Record digits #####
        record_digit = 0
        lres = ltmp = ListNode((-1))
        ##########################################################
        #Greedy-based loop traversal with recorded summary values
        ##### Step 1: Record summary values with list-nodes (i.e. l1, l2) #####
        while (l1):
            record_sum_l1 += ((10 ** record_digit) * (l1.val)) #Keep updating/accumulating
            record_digit += 1 #Keep updating/accumulating
            l1 = (l1.next) #Keep updating/overwriting
        record_digit &= 0 #Update/Reset
        while (l2):
            record_sum_l2 += ((10 ** record_digit) * (l2.val)) #Keep updating/accumulating
            record_digit += 1 #Keep updating/accumulating
            l2 = (l2.next) #Keep updating/overwriting
        ##### Step 2: Looped-traversal with recorded summary values #####
        res_str = ((str((record_sum_l1 + record_sum_l2)))[::(-1)]) #Keep updating/overwriting
        for res_char in res_str:
            (ltmp.next) = ListNode(int(res_char)) #Keep updating/newing
            ltmp = (ltmp.next) #Keep updating/overwriting

        return (lres.next)",buggy
"        :type l1: Optional[ListNode]
        :type l2: Optional[ListNode]
        :rtype: Optional[ListNode]
        #========================================#
        # One-pass update based traversal method #
        #========================================#
        ##### Record list-node #####
        lrecord = ListNode((-1))
        ##### Record quotient #####
        record_quot = 0
        lres = lrecord
        ######################################
        #One-pass update based loop traversal
        while (l1 or l2):
            res_sum_val = record_quot #Result summary value
            ##### Check if the current list-node existed or not #####
            if (l1):
                res_sum_val += l1.val #Keep updating/accumulating
                l1 = l1.next #Keep updating/overwriting
            else:
                pass
            if (l2):
                res_sum_val += l2.val #Keep updating/accumulating
                l2 = l2.next #Keep updating/overwriting
            else:
                pass
            record_quot = (res_sum_val // 10) #Keep updating/overwriting
            record_mod = (res_sum_val % 10) #Record mod
            lrecord.next = ListNode(record_mod) #Keep updating/recording
            lrecord = lrecord.next #Keep updating/overwriting
        ##### Check if the current quotient matched conditions or not #####
        if (record_quot):
            lrecord.next = ListNode(record_quot) #Keep updating/recording
        else:
            pass
        return lres.next",bug-free
"class Point:
    def __init__(self, x, y) -> None:
        self.x = x
        self.y = y


def draw_point(p):
    print(""."",end="" "")


class Line:
    def __init__(self, start, end) -> None:
        self.start = start
        self.end = end

class Rectangle(list):
    def __init__(self,x,y,width,height):
        super().__init__()
        self.append(Line(Point(x,y),Point(x+width,y)))
        self.append(Line(Point(x+width,y),Point(x+width,y+height)))
        self.append(Line(Point(x,y),Point(x,y+height)))
        self.append(Line(Point(x,y+height),Point(x+width,y+height)))

class LineToPoint:
    cache = {}

    def __init__(self, line):
        self.h = hash(line)
        if self.h in self.cache:
            return self.cache[self.h]
        print(f'Generating points for line [{line.start.x},{line.start.y}]->[{line.end.x},{line.end.y}]')
        left = min(line.start.x, line.end.x)
        right = max(line.start.x,line.end.x)
        top = max(line.start.y, line.end.y)
        bottom = min(line.start.y, line.end.y)
        points = []
        if right - left == 0:
            for y in range(top, bottom):
                points.append(Point(left,y))
        elif line.end.y - line.start.y == 0:
            for x in range(left, right):
                points.append(Point(x,top))
        self.cache[self.h] = points
    
    def __iter__(self):
        return iter(self.cache[self.h])




def draw(rcs):
    print(""\n\n ---------------drawing some stuff---------------------\n\n"")
    for rc in rcs:
        for line in rc:
            adapter = LineToPoint(line)
            for p in adapter:
                draw_point(p)



if __name__ == ""__main__"":
    rs = [
        Rectangle(1,1,10,10),
        Rectangle(3,3,6,6)
    ]
class Point:
    def __init__(self, x, y) -> None:
        self.x = x
        self.y = y


def draw_point(p):
    print(""."",end="" "")


class Line:
    def __init__(self, start, end) -> None:
        self.start = start
        self.end = end

class Rectangle(list):
    def __init__(self,x,y,width,height):
        super().__init__()
        self.append(Line(Point(x,y),Point(x+width,y)))
        self.append(Line(Point(x+width,y),Point(x+width,y+height)))
        self.append(Line(Point(x,y),Point(x,y+height)))
        self.append(Line(Point(x,y+height),Point(x+width,y+height)))

class LineToPoint(list):
    count = 0

    def __init__(self, line):
        super().__init__()
        self.count+=1
        print(f'{self.count}: Generating points for line [{line.start.x},{line.start.y}]->[{line.end.x},{line.end.y}]')
        left = min(line.start.x, line.end.x)
        right = max(line.start.x,line.end.x)
        top = max(line.start.y, line.end.y)
        bottom = min(line.start.y, line.end.y)
        if right - left == 0:
            for y in range(top, bottom):
                self.append(Point(left,y))
        elif line.end.y - line.start.y == 0:
            for x in range(left, right):
                self.append(Point(x,top))




def draw(rcs):
    print(""\n\n ---------------drawing some stuff---------------------\n\n"")
    for rc in rcs:
        for line in rc:
            adapter = LineToPoint(line)
            for p in adapter:
                draw_point(p)



if __name__ == ""__main__"":
    rs = [
        Rectangle(1,1,10,10),
        Rectangle(3,3,6,6)
    ]
import copy


class Address:
    def __init__(self, street_address, suite, city):
        self.suite = suite
        self.city = city
        self.street_address = street_address

    def __str__(self):
        return f'{self.street_address}, Suite #{self.suite}, {self.city}'

class Employee:
    def __init__(self, name, address):
        self.address = address
        self.name = name

    def __str__(self):
        return f'{self.name} works at {self.address}'


class EmployeeFactory:
    main_office_employee = Employee("""",Address(""123 East Dr"", 0, ""London""))
    aux_office_employee = Employee("""",Address(""123B East Dr"", 0, ""London""))    


    @staticmethod
    def __new_employee(proto, name, suite):
        result = copy.deepcopy(proto)
        result.name = name
        result.address.suite = suite
        return result

    @staticmethod
    def new_main_office_employee(name, suite):
        return EmployeeFactory.__new_employee(EmployeeFactory.main_office_employee,name,suite)
    
    @staticmethod
    def new_aux_office_employee(name, suite):
        return EmployeeFactory.__new_employee(EmployeeFactory.aux_office_employee,name,suite)

john = EmployeeFactory.new_main_office_employee(""John"",101)
jane = EmployeeFactory.new_main_office_employee(""Jane"",500)
from typing import Self


class CEO:
    __shared_state = {
        ""name"":""Steve"",
        ""age"":55
    }
    def __init__(self) -> None:
        self.__dict__ = self.__shared_state

    def __str__(self) -> str:
        return f'{self.name} is {self.age} years old.'
    
class Monostate:
    _shared_state = {}
    def __new__(cls, *args, **kwargs) -> Self:
        obj = super(Monostate, cls).__new__(cls, * args, **kwargs)
        obj.__dict__ = cls._shared_state
        return obj

class CFO(Monostate):

    def __init__(self) -> None:
        self.name = """"
        self.money_managed = 0
    
    def __str__(self):
        return f'{self.name} manages ${self.money_managed}'

if __name__==""__main__"":
    ceo1 = CFO()
    print(ceo1)
    ceo2 = CFO()
    print(ceo2)

def singleton(class_):
    instances = {}
    
    def get_instance(*args, **kwargs):
        if class_ not in instances:
            instances[class_] = class_(*args, **kwargs)
        return instances[class_]
    
    return get_instance

@singleton
class Database:
    def __init__(self) -> None:
        print('Loading database')

if __name__==""__main__"":
    d1=Database()
    d2=Database()
from typing import Any


class Singleton(type):
    _instances = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
        if cls not in cls._instances:
            cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)

        return cls._instances[cls]

class Database(metaclass=Singleton):
    def __init__(self) -> None:
        print('Loading database')

if __name__==""__main__"":
    d1=Database()
    d2=Database()
    print(d1==d2)
from typing import Any
import unittest


class Singleton(type):
    _instances = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
        if cls not in cls._instances:
            cls._instances[cls] = super(Singleton,cls).__call__(*args, **kwargs)
        return cls._instances[cls]

class Database(metaclass=Singleton):
    def __init__(self) -> None:
        self.population = {}
        f = open('capitals.txt','r')
        lines = f.readlines()
        for i in range(0, len(lines),2):
            self.population[lines[i].strip()]= int(lines[i+1].strip())
        f.close()

class SingletonRecordFinder:
    def total_population(self, cities):
        result = 0
        for c in cities:
            result+= Database().population[c]
        return result
    
class SingletonTests(unittest.TestCase):
    def test_is_singleton(self):
        db1 = Database()
        db2 = Database()
        self.assertEqual(db1,db2)

    def test_singleton_total_population(self):
        rf = SingletonRecordFinder()
        names = ['Seoul','Mexico City']
        tp = rf.total_population(names)
        self.assertEqual(17500000+17400000,tp)
    

if __name__ == ""__main__"":
import random
class Database:
    _instance = None

    def __init__(self) -> None:
        print(""Loading connection"")
        id = random.randint(1,101)
        print(f'id={id}')

    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            super(Database,cls).__new__(cls, *args, **kwargs)
        return cls._instance

if __name__==""__main__"":
    d1=Database()
    d2=Database()
    print(d1==d2)
",buggy
"class Point:
    def __init__(self, x, y) -> None:
        self.x = x
        self.y = y


def draw_point(p):
    print(""."",end="" "")


class Line:
    def __init__(self, start, end) -> None:
        self.start = start
        self.end = end

class Rectangle(list):
    def __init__(self,x,y,width,height):
        super().__init__()
        self.append(Line(Point(x,y),Point(x+width,y)))
        self.append(Line(Point(x+width,y),Point(x+width,y+height)))
        self.append(Line(Point(x,y),Point(x,y+height)))
        self.append(Line(Point(x,y+height),Point(x+width,y+height)))

class LineToPoint:
    cache = {}

    def __init__(self, line):
        self.h = hash(line)
        if self.h in self.cache:
            return self.cache[self.h]
        print(f'Generating points for line [{line.start.x},{line.start.y}]->[{line.end.x},{line.end.y}]')
        left = min(line.start.x, line.end.x)
        right = max(line.start.x,line.end.x)
        top = max(line.start.y, line.end.y)
        bottom = min(line.start.y, line.end.y)
        points = []
        if right - left == 0:
            for y in range(top, bottom):
                points.append(Point(left,y))
        elif line.end.y - line.start.y == 0:
            for x in range(left, right):
                points.append(Point(x,top))
        self.cache[self.h] = points
    
    def __iter__(self):
        return iter(self.cache[self.h])




def draw(rcs):
    print(""\n\n ---------------drawing some stuff---------------------\n\n"")
    for rc in rcs:
        for line in rc:
            adapter = LineToPoint(line)
            for p in adapter:
                draw_point(p)



if __name__ == ""__main__"":
    rs = [
        Rectangle(1,1,10,10),
        Rectangle(3,3,6,6)
    ]
class Point:
    def __init__(self, x, y) -> None:
        self.x = x
        self.y = y


def draw_point(p):
    print(""."",end="" "")


class Line:
    def __init__(self, start, end) -> None:
        self.start = start
        self.end = end

class Rectangle(list):
    def __init__(self,x,y,width,height):
        super().__init__()
        self.append(Line(Point(x,y),Point(x+width,y)))
        self.append(Line(Point(x+width,y),Point(x+width,y+height)))
        self.append(Line(Point(x,y),Point(x,y+height)))
        self.append(Line(Point(x,y+height),Point(x+width,y+height)))

class LineToPoint(list):
    count = 0

    def __init__(self, line):
        super().__init__()
        self.count+=1
        print(f'{self.count}: Generating points for line [{line.start.x},{line.start.y}]->[{line.end.x},{line.end.y}]')
        left = min(line.start.x, line.end.x)
        right = max(line.start.x,line.end.x)
        top = max(line.start.y, line.end.y)
        bottom = min(line.start.y, line.end.y)
        if right - left == 0:
            for y in range(top, bottom):
                self.append(Point(left,y))
        elif line.end.y - line.start.y == 0:
            for x in range(left, right):
                self.append(Point(x,top))




def draw(rcs):
    print(""\n\n ---------------drawing some stuff---------------------\n\n"")
    for rc in rcs:
        for line in rc:
            adapter = LineToPoint(line)
            for p in adapter:
                draw_point(p)



if __name__ == ""__main__"":
    rs = [
        Rectangle(1,1,10,10),
        Rectangle(3,3,6,6)
    ]
import copy


class Address:
    def __init__(self, street_address, suite, city):
        self.suite = suite
        self.city = city
        self.street_address = street_address

    def __str__(self):
        return f'{self.street_address}, Suite #{self.suite}, {self.city}'

class Employee:
    def __init__(self, name, address):
        self.address = address
        self.name = name

    def __str__(self):
        return f'{self.name} works at {self.address}'


class EmployeeFactory:
    main_office_employee = Employee("""",Address(""123 East Dr"", 0, ""London""))
    aux_office_employee = Employee("""",Address(""123B East Dr"", 0, ""London""))    


    @staticmethod
    def __new_employee(proto, name, suite):
        result = copy.deepcopy(proto)
        result.name = name
        result.address.suite = suite
        return result

    @staticmethod
    def new_main_office_employee(name, suite):
        return EmployeeFactory.__new_employee(EmployeeFactory.main_office_employee,name,suite)
    
    @staticmethod
    def new_aux_office_employee(name, suite):
        return EmployeeFactory.__new_employee(EmployeeFactory.aux_office_employee,name,suite)

john = EmployeeFactory.new_main_office_employee(""John"",101)
jane = EmployeeFactory.new_main_office_employee(""Jane"",500)
from typing import Self


class CEO:
    __shared_state = {
        ""name"":""Steve"",
        ""age"":55
    }
    def __init__(self) -> None:
        self.__dict__ = self.__shared_state

    def __str__(self) -> str:
        return f'{self.name} is {self.age} years old.'
    
class Monostate:
    _shared_state = {}
    def __new__(cls, *args, **kwargs) -> Self:
        obj = super(Monostate, cls).__new__(cls, * args, **kwargs)
        obj.__dict__ = cls._shared_state
        return obj

class CFO(Monostate):

    def __init__(self) -> None:
        self.name = """"
        self.money_managed = 0
    
    def __str__(self):
        return f'{self.name} manages ${self.money_managed}'

if __name__==""__main__"":
    ceo1 = CFO()
    print(ceo1)
    ceo2 = CFO()
    print(ceo2)

def singleton(class_):
    instances = {}
    
    def get_instance(*args, **kwargs):
        if class_ not in instances:
            instances[class_] = class_(*args, **kwargs)
        return instances[class_]
    
    return get_instance

@singleton
class Database:
    def __init__(self) -> None:
        print('Loading database')

if __name__==""__main__"":
    d1=Database()
    d2=Database()
from typing import Any


class Singleton(type):
    _instances = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
        if cls not in cls._instances:
            cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)

        return cls._instances[cls]

class Database(metaclass=Singleton):
    def __init__(self) -> None:
        print('Loading database')

if __name__==""__main__"":
    d1=Database()
    d2=Database()
    print(d1==d2)
from typing import Any
import unittest


class Singleton(type):
    _instances = {}

    def __call__(cls, *args: Any, **kwargs: Any) -> Any:
        if cls not in cls._instances:
            cls._instances[cls] = super(Singleton,cls).__call__(*args, **kwargs)
        return cls._instances[cls]

class Database(metaclass=Singleton):
    def __init__(self) -> None:
        self.population = {}
        f = open('capitals.txt','r')
        lines = f.readlines()
        for i in range(0, len(lines),2):
            self.population[lines[i].strip()]= int(lines[i+1].strip())
        f.close()

class SingletonRecordFinder:
    def total_population(self, cities):
        result = 0
        for c in cities:
            result+= Database().population[c]
        return result
    
class SingletonTests(unittest.TestCase):
    def test_is_singleton(self):
        db1 = Database()
        db2 = Database()
        self.assertEqual(db1,db2)

    def test_singleton_total_population(self):
        rf = SingletonRecordFinder()
        names = ['Seoul','Mexico City']
        tp = rf.total_population(names)
        self.assertEqual(17500000+17400000,tp)
    

if __name__ == ""__main__"":
import random
class Database:
    _instance = None

    def __init__(self) -> None:
        print(""Loading connection"")
        id = random.randint(1,101)
        print(f'id={id}')

    def __new__(cls, *args, **kwargs):
        if not cls._instance:
            super(Database,cls).__new__(cls, *args, **kwargs)
        return cls._instance

if __name__==""__main__"":
    d1=Database()
    d2=Database()
    print(d1==d2)

",bug-free
"            model_name = values.get(""model_name"", cls.__fields__[""model_name""].default)
            checkpoint = values.get(""checkpoint"", cls.__fields__[""checkpoint""].default)",buggy
"from langchain_core.utils.pydantic import get_fields
            model_name = values.get(""model_name"", get_fields(cls)[""model_name""].default)
            checkpoint = values.get(""checkpoint"", get_fields(cls)[""checkpoint""].default)",bug-free
"            model_name = values.get(""model_name"", cls.__fields__[""model_name""].default)
            checkpoint = values.get(""checkpoint"", cls.__fields__[""checkpoint""].default)",buggy
"from langchain_core.utils.pydantic import get_fields
            model_name = values.get(""model_name"", get_fields(cls)[""model_name""].default)
            checkpoint = values.get(""checkpoint"", get_fields(cls)[""checkpoint""].default)",bug-free
"            model_name = values.get(""model_name"", cls.__fields__[""model_name""].default)
            checkpoint = values.get(""checkpoint"", cls.__fields__[""checkpoint""].default)",buggy
"from langchain_core.utils.pydantic import get_fields
            model_name = values.get(""model_name"", get_fields(cls)[""model_name""].default)
            checkpoint = values.get(""checkpoint"", get_fields(cls)[""checkpoint""].default)",bug-free
"            model_name = values.get(""model_name"", cls.__fields__[""model_name""].default)
            checkpoint = values.get(""checkpoint"", cls.__fields__[""checkpoint""].default)",buggy
"from langchain_core.utils.pydantic import get_fields
            model_name = values.get(""model_name"", get_fields(cls)[""model_name""].default)
            checkpoint = values.get(""checkpoint"", get_fields(cls)[""checkpoint""].default)",bug-free
"            model_name = values.get(""model_name"", cls.__fields__[""model_name""].default)
            checkpoint = values.get(""checkpoint"", cls.__fields__[""checkpoint""].default)",buggy
"from langchain_core.utils.pydantic import get_fields
            model_name = values.get(""model_name"", get_fields(cls)[""model_name""].default)
            checkpoint = values.get(""checkpoint"", get_fields(cls)[""checkpoint""].default)",bug-free
"            model_name = values.get(""model_name"", cls.__fields__[""model_name""].default)
            checkpoint = values.get(""checkpoint"", cls.__fields__[""checkpoint""].default)",buggy
"from langchain_core.utils.pydantic import get_fields
            model_name = values.get(""model_name"", get_fields(cls)[""model_name""].default)
            checkpoint = values.get(""checkpoint"", get_fields(cls)[""checkpoint""].default)",bug-free
"            model_name = values.get(""model_name"", cls.__fields__[""model_name""].default)
            checkpoint = values.get(""checkpoint"", cls.__fields__[""checkpoint""].default)",buggy
"from langchain_core.utils.pydantic import get_fields
            model_name = values.get(""model_name"", get_fields(cls)[""model_name""].default)
            checkpoint = values.get(""checkpoint"", get_fields(cls)[""checkpoint""].default)",bug-free
"            model_name = values.get(""model_name"", cls.__fields__[""model_name""].default)
            checkpoint = values.get(""checkpoint"", cls.__fields__[""checkpoint""].default)",buggy
"from langchain_core.utils.pydantic import get_fields
            model_name = values.get(""model_name"", get_fields(cls)[""model_name""].default)
            checkpoint = values.get(""checkpoint"", get_fields(cls)[""checkpoint""].default)",bug-free
"            model_name = values.get(""model_name"", cls.__fields__[""model_name""].default)
            checkpoint = values.get(""checkpoint"", cls.__fields__[""checkpoint""].default)",buggy
"from langchain_core.utils.pydantic import get_fields
            model_name = values.get(""model_name"", get_fields(cls)[""model_name""].default)
            checkpoint = values.get(""checkpoint"", get_fields(cls)[""checkpoint""].default)",bug-free
"            model_name = values.get(""model_name"", cls.__fields__[""model_name""].default)
            checkpoint = values.get(""checkpoint"", cls.__fields__[""checkpoint""].default)",buggy
"from langchain_core.utils.pydantic import get_fields
            model_name = values.get(""model_name"", get_fields(cls)[""model_name""].default)
            checkpoint = values.get(""checkpoint"", get_fields(cls)[""checkpoint""].default)",bug-free
"            model_name = values.get(""model_name"", cls.__fields__[""model_name""].default)
            checkpoint = values.get(""checkpoint"", cls.__fields__[""checkpoint""].default)",buggy
"from langchain_core.utils.pydantic import get_fields
            model_name = values.get(""model_name"", get_fields(cls)[""model_name""].default)
            checkpoint = values.get(""checkpoint"", get_fields(cls)[""checkpoint""].default)",bug-free
"            model_name = values.get(""model_name"", cls.__fields__[""model_name""].default)
            checkpoint = values.get(""checkpoint"", cls.__fields__[""checkpoint""].default)",buggy
"from langchain_core.utils.pydantic import get_fields
            model_name = values.get(""model_name"", get_fields(cls)[""model_name""].default)
            checkpoint = values.get(""checkpoint"", get_fields(cls)[""checkpoint""].default)",bug-free
"            model_name = values.get(""model_name"", cls.__fields__[""model_name""].default)
            checkpoint = values.get(""checkpoint"", cls.__fields__[""checkpoint""].default)",buggy
"from langchain_core.utils.pydantic import get_fields
            model_name = values.get(""model_name"", get_fields(cls)[""model_name""].default)
            checkpoint = values.get(""checkpoint"", get_fields(cls)[""checkpoint""].default)",bug-free
"from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        extra = Extra.allow",buggy
"from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""allow""",bug-free
"from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        extra = Extra.allow",buggy
"from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""allow""",bug-free
"from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        extra = Extra.allow",buggy
"from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""allow""",bug-free
"from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        extra = Extra.allow",buggy
"from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""allow""",bug-free
"from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        extra = Extra.allow",buggy
"from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""allow""",bug-free
"from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        extra = Extra.allow",buggy
"from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""allow""",bug-free
"from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        extra = Extra.allow",buggy
"from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""allow""",bug-free
"from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        extra = Extra.allow",buggy
"from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""allow""",bug-free
"from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        extra = Extra.allow",buggy
"from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""allow""",bug-free
"from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        extra = Extra.allow",buggy
"from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""allow""",bug-free
"from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        extra = Extra.allow",buggy
"from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""allow""",bug-free
"from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        extra = Extra.allow",buggy
"from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""allow""",bug-free
"from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_experimental.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        extra = Extra.allow",buggy
"from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_experimental.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""allow""",bug-free
"    tool_cls.__fields__[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import is_basemodel_subclass
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in llm_cls.__fields__:
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = doc.keys() if isinstance(doc, dict) else doc.__fields__
        for field_name in self.__fields__.keys():
        for field_name in self.__fields__.keys():
    for field in llm.__fields__.keys():
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            if skip_tools_without_default_names and tool_class.__fields__[
    names = sorted([tool_cls.__fields__[""name""].default for tool_cls in tool_classes])",buggy
"from langchain_core.utils.pydantic import get_fields
    get_fields(tool_cls)[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import get_fields, is_basemodel_subclass
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in get_fields(llm_cls):
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = doc.keys() if isinstance(doc, dict) else get_fields(doc)
from langchain_core.utils.pydantic import get_fields
        for field_name in get_fields(self).keys():
        for field_name in get_fields(self).keys():
from langchain_core.utils.pydantic import get_fields
    for field in get_fields(llm).keys():
from langchain_core.utils.pydantic import get_fields
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            if skip_tools_without_default_names and get_fields(tool_class)[
    names = sorted([get_fields(tool_cls)[""name""].default for tool_cls in tool_classes])",bug-free
"    tool_cls.__fields__[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import is_basemodel_subclass
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in llm_cls.__fields__:
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = doc.keys() if isinstance(doc, dict) else doc.__fields__
        for field_name in self.__fields__.keys():
        for field_name in self.__fields__.keys():
    for field in llm.__fields__.keys():
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            if skip_tools_without_default_names and tool_class.__fields__[
    names = sorted([tool_cls.__fields__[""name""].default for tool_cls in tool_classes])",buggy
"from langchain_core.utils.pydantic import get_fields
    get_fields(tool_cls)[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import get_fields, is_basemodel_subclass
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in get_fields(llm_cls):
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = doc.keys() if isinstance(doc, dict) else get_fields(doc)
from langchain_core.utils.pydantic import get_fields
        for field_name in get_fields(self).keys():
        for field_name in get_fields(self).keys():
from langchain_core.utils.pydantic import get_fields
    for field in get_fields(llm).keys():
from langchain_core.utils.pydantic import get_fields
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            if skip_tools_without_default_names and get_fields(tool_class)[
    names = sorted([get_fields(tool_cls)[""name""].default for tool_cls in tool_classes])",bug-free
"    tool_cls.__fields__[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import is_basemodel_subclass
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in llm_cls.__fields__:
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = doc.keys() if isinstance(doc, dict) else doc.__fields__
        for field_name in self.__fields__.keys():
        for field_name in self.__fields__.keys():
    for field in llm.__fields__.keys():
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            if skip_tools_without_default_names and tool_class.__fields__[
    names = sorted([tool_cls.__fields__[""name""].default for tool_cls in tool_classes])",buggy
"from langchain_core.utils.pydantic import get_fields
    get_fields(tool_cls)[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import get_fields, is_basemodel_subclass
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in get_fields(llm_cls):
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = doc.keys() if isinstance(doc, dict) else get_fields(doc)
from langchain_core.utils.pydantic import get_fields
        for field_name in get_fields(self).keys():
        for field_name in get_fields(self).keys():
from langchain_core.utils.pydantic import get_fields
    for field in get_fields(llm).keys():
from langchain_core.utils.pydantic import get_fields
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            if skip_tools_without_default_names and get_fields(tool_class)[
    names = sorted([get_fields(tool_cls)[""name""].default for tool_cls in tool_classes])",bug-free
"    tool_cls.__fields__[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import is_basemodel_subclass
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in llm_cls.__fields__:
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = doc.keys() if isinstance(doc, dict) else doc.__fields__
        for field_name in self.__fields__.keys():
        for field_name in self.__fields__.keys():
    for field in llm.__fields__.keys():
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            if skip_tools_without_default_names and tool_class.__fields__[
    names = sorted([tool_cls.__fields__[""name""].default for tool_cls in tool_classes])",buggy
"from langchain_core.utils.pydantic import get_fields
    get_fields(tool_cls)[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import get_fields, is_basemodel_subclass
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in get_fields(llm_cls):
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = doc.keys() if isinstance(doc, dict) else get_fields(doc)
from langchain_core.utils.pydantic import get_fields
        for field_name in get_fields(self).keys():
        for field_name in get_fields(self).keys():
from langchain_core.utils.pydantic import get_fields
    for field in get_fields(llm).keys():
from langchain_core.utils.pydantic import get_fields
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            if skip_tools_without_default_names and get_fields(tool_class)[
    names = sorted([get_fields(tool_cls)[""name""].default for tool_cls in tool_classes])",bug-free
"    tool_cls.__fields__[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import is_basemodel_subclass
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in llm_cls.__fields__:
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = doc.keys() if isinstance(doc, dict) else doc.__fields__
        for field_name in self.__fields__.keys():
        for field_name in self.__fields__.keys():
    for field in llm.__fields__.keys():
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            if skip_tools_without_default_names and tool_class.__fields__[
    names = sorted([tool_cls.__fields__[""name""].default for tool_cls in tool_classes])",buggy
"from langchain_core.utils.pydantic import get_fields
    get_fields(tool_cls)[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import get_fields, is_basemodel_subclass
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in get_fields(llm_cls):
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = doc.keys() if isinstance(doc, dict) else get_fields(doc)
from langchain_core.utils.pydantic import get_fields
        for field_name in get_fields(self).keys():
        for field_name in get_fields(self).keys():
from langchain_core.utils.pydantic import get_fields
    for field in get_fields(llm).keys():
from langchain_core.utils.pydantic import get_fields
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            if skip_tools_without_default_names and get_fields(tool_class)[
    names = sorted([get_fields(tool_cls)[""name""].default for tool_cls in tool_classes])",bug-free
"    tool_cls.__fields__[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import is_basemodel_subclass
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in llm_cls.__fields__:
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = doc.keys() if isinstance(doc, dict) else doc.__fields__
        for field_name in self.__fields__.keys():
        for field_name in self.__fields__.keys():
    for field in llm.__fields__.keys():
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            if skip_tools_without_default_names and tool_class.__fields__[
    names = sorted([tool_cls.__fields__[""name""].default for tool_cls in tool_classes])",buggy
"from langchain_core.utils.pydantic import get_fields
    get_fields(tool_cls)[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import get_fields, is_basemodel_subclass
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in get_fields(llm_cls):
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = doc.keys() if isinstance(doc, dict) else get_fields(doc)
from langchain_core.utils.pydantic import get_fields
        for field_name in get_fields(self).keys():
        for field_name in get_fields(self).keys():
from langchain_core.utils.pydantic import get_fields
    for field in get_fields(llm).keys():
from langchain_core.utils.pydantic import get_fields
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            if skip_tools_without_default_names and get_fields(tool_class)[
    names = sorted([get_fields(tool_cls)[""name""].default for tool_cls in tool_classes])",bug-free
"    tool_cls.__fields__[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import is_basemodel_subclass
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in llm_cls.__fields__:
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = doc.keys() if isinstance(doc, dict) else doc.__fields__
        for field_name in self.__fields__.keys():
        for field_name in self.__fields__.keys():
    for field in llm.__fields__.keys():
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            if skip_tools_without_default_names and tool_class.__fields__[
    names = sorted([tool_cls.__fields__[""name""].default for tool_cls in tool_classes])",buggy
"from langchain_core.utils.pydantic import get_fields
    get_fields(tool_cls)[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import get_fields, is_basemodel_subclass
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in get_fields(llm_cls):
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = doc.keys() if isinstance(doc, dict) else get_fields(doc)
from langchain_core.utils.pydantic import get_fields
        for field_name in get_fields(self).keys():
        for field_name in get_fields(self).keys():
from langchain_core.utils.pydantic import get_fields
    for field in get_fields(llm).keys():
from langchain_core.utils.pydantic import get_fields
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            if skip_tools_without_default_names and get_fields(tool_class)[
    names = sorted([get_fields(tool_cls)[""name""].default for tool_cls in tool_classes])",bug-free
"    tool_cls.__fields__[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import is_basemodel_subclass
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in llm_cls.__fields__:
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = doc.keys() if isinstance(doc, dict) else doc.__fields__
        for field_name in self.__fields__.keys():
        for field_name in self.__fields__.keys():
    for field in llm.__fields__.keys():
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            if skip_tools_without_default_names and tool_class.__fields__[
    names = sorted([tool_cls.__fields__[""name""].default for tool_cls in tool_classes])",buggy
"from langchain_core.utils.pydantic import get_fields
    get_fields(tool_cls)[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import get_fields, is_basemodel_subclass
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in get_fields(llm_cls):
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = doc.keys() if isinstance(doc, dict) else get_fields(doc)
from langchain_core.utils.pydantic import get_fields
        for field_name in get_fields(self).keys():
        for field_name in get_fields(self).keys():
from langchain_core.utils.pydantic import get_fields
    for field in get_fields(llm).keys():
from langchain_core.utils.pydantic import get_fields
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            if skip_tools_without_default_names and get_fields(tool_class)[
    names = sorted([get_fields(tool_cls)[""name""].default for tool_cls in tool_classes])",bug-free
"    tool_cls.__fields__[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import is_basemodel_subclass
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in llm_cls.__fields__:
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = doc.keys() if isinstance(doc, dict) else doc.__fields__
        for field_name in self.__fields__.keys():
        for field_name in self.__fields__.keys():
    for field in llm.__fields__.keys():
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            if skip_tools_without_default_names and tool_class.__fields__[
    names = sorted([tool_cls.__fields__[""name""].default for tool_cls in tool_classes])",buggy
"from langchain_core.utils.pydantic import get_fields
    get_fields(tool_cls)[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import get_fields, is_basemodel_subclass
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in get_fields(llm_cls):
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = doc.keys() if isinstance(doc, dict) else get_fields(doc)
from langchain_core.utils.pydantic import get_fields
        for field_name in get_fields(self).keys():
        for field_name in get_fields(self).keys():
from langchain_core.utils.pydantic import get_fields
    for field in get_fields(llm).keys():
from langchain_core.utils.pydantic import get_fields
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            if skip_tools_without_default_names and get_fields(tool_class)[
    names = sorted([get_fields(tool_cls)[""name""].default for tool_cls in tool_classes])",bug-free
"    tool_cls.__fields__[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import is_basemodel_subclass
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in llm_cls.__fields__:
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = doc.keys() if isinstance(doc, dict) else doc.__fields__
        for field_name in self.__fields__.keys():
        for field_name in self.__fields__.keys():
    for field in llm.__fields__.keys():
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            if skip_tools_without_default_names and tool_class.__fields__[
    names = sorted([tool_cls.__fields__[""name""].default for tool_cls in tool_classes])",buggy
"from langchain_core.utils.pydantic import get_fields
    get_fields(tool_cls)[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import get_fields, is_basemodel_subclass
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in get_fields(llm_cls):
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = doc.keys() if isinstance(doc, dict) else get_fields(doc)
from langchain_core.utils.pydantic import get_fields
        for field_name in get_fields(self).keys():
        for field_name in get_fields(self).keys():
from langchain_core.utils.pydantic import get_fields
    for field in get_fields(llm).keys():
from langchain_core.utils.pydantic import get_fields
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            if skip_tools_without_default_names and get_fields(tool_class)[
    names = sorted([get_fields(tool_cls)[""name""].default for tool_cls in tool_classes])",bug-free
"    tool_cls.__fields__[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import is_basemodel_subclass
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in llm_cls.__fields__:
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = doc.keys() if isinstance(doc, dict) else doc.__fields__
        for field_name in self.__fields__.keys():
        for field_name in self.__fields__.keys():
    for field in llm.__fields__.keys():
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            if skip_tools_without_default_names and tool_class.__fields__[
    names = sorted([tool_cls.__fields__[""name""].default for tool_cls in tool_classes])",buggy
"from langchain_core.utils.pydantic import get_fields
    get_fields(tool_cls)[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import get_fields, is_basemodel_subclass
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in get_fields(llm_cls):
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = doc.keys() if isinstance(doc, dict) else get_fields(doc)
from langchain_core.utils.pydantic import get_fields
        for field_name in get_fields(self).keys():
        for field_name in get_fields(self).keys():
from langchain_core.utils.pydantic import get_fields
    for field in get_fields(llm).keys():
from langchain_core.utils.pydantic import get_fields
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            if skip_tools_without_default_names and get_fields(tool_class)[
    names = sorted([get_fields(tool_cls)[""name""].default for tool_cls in tool_classes])",bug-free
"    tool_cls.__fields__[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import is_basemodel_subclass
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in llm_cls.__fields__:
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = doc.keys() if isinstance(doc, dict) else doc.__fields__
        for field_name in self.__fields__.keys():
        for field_name in self.__fields__.keys():
    for field in llm.__fields__.keys():
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            if skip_tools_without_default_names and tool_class.__fields__[
    names = sorted([tool_cls.__fields__[""name""].default for tool_cls in tool_classes])",buggy
"from langchain_core.utils.pydantic import get_fields
    get_fields(tool_cls)[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import get_fields, is_basemodel_subclass
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in get_fields(llm_cls):
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = doc.keys() if isinstance(doc, dict) else get_fields(doc)
from langchain_core.utils.pydantic import get_fields
        for field_name in get_fields(self).keys():
        for field_name in get_fields(self).keys():
from langchain_core.utils.pydantic import get_fields
    for field in get_fields(llm).keys():
from langchain_core.utils.pydantic import get_fields
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            if skip_tools_without_default_names and get_fields(tool_class)[
    names = sorted([get_fields(tool_cls)[""name""].default for tool_cls in tool_classes])",bug-free
"    tool_cls.__fields__[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import is_basemodel_subclass
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
            for name, field in cls.__fields__.items()
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = set(cls.__fields__.keys())
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in llm_cls.__fields__:
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        all_required_field_names = {field.alias for field in cls.__fields__.values()}
        fields = doc.keys() if isinstance(doc, dict) else doc.__fields__
        for field_name in self.__fields__.keys():
        for field_name in self.__fields__.keys():
    for field in llm.__fields__.keys():
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
                            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            ""model_name"": BaseOpenAI.__fields__[""model_name""].default,
            if skip_tools_without_default_names and tool_class.__fields__[
    names = sorted([tool_cls.__fields__[""name""].default for tool_cls in tool_classes])",buggy
"from langchain_core.utils.pydantic import get_fields
    get_fields(tool_cls)[""name""].default: tool_cls for tool_cls in _FILE_TOOLS
from langchain_core.utils.pydantic import get_fields, is_basemodel_subclass
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
            for name, field in get_fields(cls).items()
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = set(get_fields(cls).keys())
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
    if _ALLOW_DANGEROUS_DESERIALIZATION_ARG in get_fields(llm_cls):
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        all_required_field_names = {field.alias for field in get_fields(cls).values()}
from langchain_core.utils.pydantic import get_fields
        fields = doc.keys() if isinstance(doc, dict) else get_fields(doc)
from langchain_core.utils.pydantic import get_fields
        for field_name in get_fields(self).keys():
        for field_name in get_fields(self).keys():
from langchain_core.utils.pydantic import get_fields
    for field in get_fields(llm).keys():
from langchain_core.utils.pydantic import get_fields
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
                            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            ""model_name"": get_fields(BaseOpenAI)[""model_name""].default,
from langchain_core.utils.pydantic import get_fields
            if skip_tools_without_default_names and get_fields(tool_class)[
    names = sorted([get_fields(tool_cls)[""name""].default for tool_cls in tool_classes])",bug-free
"from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the PairwiseStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the ScoreStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        arbitrary_types_allowed = True",buggy
"from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
        extra = ""ignore""
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
        arbitrary_types_allowed = True",bug-free
"from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the PairwiseStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the ScoreStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        arbitrary_types_allowed = True",buggy
"from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
        extra = ""ignore""
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
        arbitrary_types_allowed = True",bug-free
"from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the PairwiseStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the ScoreStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        arbitrary_types_allowed = True",buggy
"from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
        extra = ""ignore""
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
        arbitrary_types_allowed = True",bug-free
"from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the PairwiseStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the ScoreStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        arbitrary_types_allowed = True",buggy
"from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
        extra = ""ignore""
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
        arbitrary_types_allowed = True",bug-free
"from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the PairwiseStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the ScoreStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        arbitrary_types_allowed = True",buggy
"from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
        extra = ""ignore""
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
        arbitrary_types_allowed = True",bug-free
"from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the PairwiseStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the ScoreStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        arbitrary_types_allowed = True",buggy
"from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
        extra = ""ignore""
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
        arbitrary_types_allowed = True",bug-free
"from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the PairwiseStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the ScoreStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        arbitrary_types_allowed = True",buggy
"from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
        extra = ""ignore""
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
        arbitrary_types_allowed = True",bug-free
"from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the PairwiseStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the ScoreStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        arbitrary_types_allowed = True",buggy
"from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
        extra = ""ignore""
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
        arbitrary_types_allowed = True",bug-free
"from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the PairwiseStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the ScoreStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        arbitrary_types_allowed = True",buggy
"from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
        extra = ""ignore""
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
        arbitrary_types_allowed = True",bug-free
"from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the PairwiseStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the ScoreStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        arbitrary_types_allowed = True",buggy
"from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
        extra = ""ignore""
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
        arbitrary_types_allowed = True",bug-free
"from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the PairwiseStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the ScoreStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        arbitrary_types_allowed = True",buggy
"from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
        extra = ""ignore""
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
        arbitrary_types_allowed = True",bug-free
"from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the PairwiseStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the ScoreStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        arbitrary_types_allowed = True",buggy
"from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
        extra = ""ignore""
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
        arbitrary_types_allowed = True",bug-free
"from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the PairwiseStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
        """"""Configuration for the QAEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for the ScoreStringEvalChain.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        arbitrary_types_allowed = True",buggy
"from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
        extra = ""ignore""
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""ignore""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
        arbitrary_types_allowed = True",bug-free
"        """"""Pydantic config.""""""

        # Allow extra fields. This is needed for the `interface` field.
        validate_all = True
        # Allow arbitrary types. This is needed for the `interface` field.
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
class ChatParams(BaseModel, extra=Extra.allow):
        """"""Configuration for this pydantic object.""""""

from langchain_core.pydantic_v1 import BaseModel, Extra
class ChatParams(BaseModel, extra=Extra.allow):
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = ""forbid""
from langchain_core.pydantic_v1 import Extra, Field, PrivateAttr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
        env_prefix = """"
        """"""Config for OneNoteGraphSettings.""""""

        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid  # Forbid extra attributes during model initialization
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
    Extra,
class Highlight(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
    BaseModel, extra=Extra.allow
class AdditionalResultAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=Extra.allow):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Pydantic config.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid",buggy
"        validate_all = True
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, PrivateAttr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        env_prefix = """"
        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""allow""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""ignore""
        extra = ""ignore""
class Highlight(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=""allow""):  # type: ignore[call-arg]
    BaseModel, extra=""allow""
class AdditionalResultAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=""allow""):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""",bug-free
"        """"""Pydantic config.""""""

        # Allow extra fields. This is needed for the `interface` field.
        validate_all = True
        # Allow arbitrary types. This is needed for the `interface` field.
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
class ChatParams(BaseModel, extra=Extra.allow):
        """"""Configuration for this pydantic object.""""""

from langchain_core.pydantic_v1 import BaseModel, Extra
class ChatParams(BaseModel, extra=Extra.allow):
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = ""forbid""
from langchain_core.pydantic_v1 import Extra, Field, PrivateAttr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
        env_prefix = """"
        """"""Config for OneNoteGraphSettings.""""""

        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid  # Forbid extra attributes during model initialization
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
    Extra,
class Highlight(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
    BaseModel, extra=Extra.allow
class AdditionalResultAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=Extra.allow):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Pydantic config.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid",buggy
"        validate_all = True
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, PrivateAttr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        env_prefix = """"
        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""allow""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""ignore""
        extra = ""ignore""
class Highlight(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=""allow""):  # type: ignore[call-arg]
    BaseModel, extra=""allow""
class AdditionalResultAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=""allow""):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""",bug-free
"        """"""Pydantic config.""""""

        # Allow extra fields. This is needed for the `interface` field.
        validate_all = True
        # Allow arbitrary types. This is needed for the `interface` field.
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
class ChatParams(BaseModel, extra=Extra.allow):
        """"""Configuration for this pydantic object.""""""

from langchain_core.pydantic_v1 import BaseModel, Extra
class ChatParams(BaseModel, extra=Extra.allow):
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = ""forbid""
from langchain_core.pydantic_v1 import Extra, Field, PrivateAttr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
        env_prefix = """"
        """"""Config for OneNoteGraphSettings.""""""

        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid  # Forbid extra attributes during model initialization
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
    Extra,
class Highlight(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
    BaseModel, extra=Extra.allow
class AdditionalResultAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=Extra.allow):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Pydantic config.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid",buggy
"        validate_all = True
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, PrivateAttr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        env_prefix = """"
        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""allow""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""ignore""
        extra = ""ignore""
class Highlight(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=""allow""):  # type: ignore[call-arg]
    BaseModel, extra=""allow""
class AdditionalResultAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=""allow""):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""",bug-free
"        """"""Pydantic config.""""""

        # Allow extra fields. This is needed for the `interface` field.
        validate_all = True
        # Allow arbitrary types. This is needed for the `interface` field.
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
class ChatParams(BaseModel, extra=Extra.allow):
        """"""Configuration for this pydantic object.""""""

from langchain_core.pydantic_v1 import BaseModel, Extra
class ChatParams(BaseModel, extra=Extra.allow):
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = ""forbid""
from langchain_core.pydantic_v1 import Extra, Field, PrivateAttr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
        env_prefix = """"
        """"""Config for OneNoteGraphSettings.""""""

        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid  # Forbid extra attributes during model initialization
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
    Extra,
class Highlight(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
    BaseModel, extra=Extra.allow
class AdditionalResultAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=Extra.allow):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Pydantic config.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid",buggy
"        validate_all = True
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, PrivateAttr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        env_prefix = """"
        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""allow""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""ignore""
        extra = ""ignore""
class Highlight(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=""allow""):  # type: ignore[call-arg]
    BaseModel, extra=""allow""
class AdditionalResultAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=""allow""):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""",bug-free
"        """"""Pydantic config.""""""

        # Allow extra fields. This is needed for the `interface` field.
        validate_all = True
        # Allow arbitrary types. This is needed for the `interface` field.
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
class ChatParams(BaseModel, extra=Extra.allow):
        """"""Configuration for this pydantic object.""""""

from langchain_core.pydantic_v1 import BaseModel, Extra
class ChatParams(BaseModel, extra=Extra.allow):
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = ""forbid""
from langchain_core.pydantic_v1 import Extra, Field, PrivateAttr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
        env_prefix = """"
        """"""Config for OneNoteGraphSettings.""""""

        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid  # Forbid extra attributes during model initialization
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
    Extra,
class Highlight(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
    BaseModel, extra=Extra.allow
class AdditionalResultAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=Extra.allow):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Pydantic config.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid",buggy
"        validate_all = True
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, PrivateAttr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        env_prefix = """"
        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""allow""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""ignore""
        extra = ""ignore""
class Highlight(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=""allow""):  # type: ignore[call-arg]
    BaseModel, extra=""allow""
class AdditionalResultAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=""allow""):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""",bug-free
"        """"""Pydantic config.""""""

        # Allow extra fields. This is needed for the `interface` field.
        validate_all = True
        # Allow arbitrary types. This is needed for the `interface` field.
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
class ChatParams(BaseModel, extra=Extra.allow):
        """"""Configuration for this pydantic object.""""""

from langchain_core.pydantic_v1 import BaseModel, Extra
class ChatParams(BaseModel, extra=Extra.allow):
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = ""forbid""
from langchain_core.pydantic_v1 import Extra, Field, PrivateAttr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
        env_prefix = """"
        """"""Config for OneNoteGraphSettings.""""""

        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid  # Forbid extra attributes during model initialization
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
    Extra,
class Highlight(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
    BaseModel, extra=Extra.allow
class AdditionalResultAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=Extra.allow):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Pydantic config.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid",buggy
"        validate_all = True
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, PrivateAttr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        env_prefix = """"
        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""allow""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""ignore""
        extra = ""ignore""
class Highlight(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=""allow""):  # type: ignore[call-arg]
    BaseModel, extra=""allow""
class AdditionalResultAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=""allow""):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""",bug-free
"        """"""Pydantic config.""""""

        # Allow extra fields. This is needed for the `interface` field.
        validate_all = True
        # Allow arbitrary types. This is needed for the `interface` field.
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
class ChatParams(BaseModel, extra=Extra.allow):
        """"""Configuration for this pydantic object.""""""

from langchain_core.pydantic_v1 import BaseModel, Extra
class ChatParams(BaseModel, extra=Extra.allow):
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = ""forbid""
from langchain_core.pydantic_v1 import Extra, Field, PrivateAttr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
        env_prefix = """"
        """"""Config for OneNoteGraphSettings.""""""

        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid  # Forbid extra attributes during model initialization
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
    Extra,
class Highlight(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
    BaseModel, extra=Extra.allow
class AdditionalResultAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=Extra.allow):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Pydantic config.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid",buggy
"        validate_all = True
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, PrivateAttr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        env_prefix = """"
        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""allow""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""ignore""
        extra = ""ignore""
class Highlight(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=""allow""):  # type: ignore[call-arg]
    BaseModel, extra=""allow""
class AdditionalResultAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=""allow""):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""",bug-free
"        """"""Pydantic config.""""""

        # Allow extra fields. This is needed for the `interface` field.
        validate_all = True
        # Allow arbitrary types. This is needed for the `interface` field.
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
class ChatParams(BaseModel, extra=Extra.allow):
        """"""Configuration for this pydantic object.""""""

from langchain_core.pydantic_v1 import BaseModel, Extra
class ChatParams(BaseModel, extra=Extra.allow):
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = ""forbid""
from langchain_core.pydantic_v1 import Extra, Field, PrivateAttr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
        env_prefix = """"
        """"""Config for OneNoteGraphSettings.""""""

        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid  # Forbid extra attributes during model initialization
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
    Extra,
class Highlight(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
    BaseModel, extra=Extra.allow
class AdditionalResultAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=Extra.allow):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Pydantic config.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid",buggy
"        validate_all = True
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, PrivateAttr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        env_prefix = """"
        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""allow""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""ignore""
        extra = ""ignore""
class Highlight(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=""allow""):  # type: ignore[call-arg]
    BaseModel, extra=""allow""
class AdditionalResultAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=""allow""):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""",bug-free
"        """"""Pydantic config.""""""

        # Allow extra fields. This is needed for the `interface` field.
        validate_all = True
        # Allow arbitrary types. This is needed for the `interface` field.
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
class ChatParams(BaseModel, extra=Extra.allow):
        """"""Configuration for this pydantic object.""""""

from langchain_core.pydantic_v1 import BaseModel, Extra
class ChatParams(BaseModel, extra=Extra.allow):
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = ""forbid""
from langchain_core.pydantic_v1 import Extra, Field, PrivateAttr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
        env_prefix = """"
        """"""Config for OneNoteGraphSettings.""""""

        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid  # Forbid extra attributes during model initialization
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
    Extra,
class Highlight(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
    BaseModel, extra=Extra.allow
class AdditionalResultAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=Extra.allow):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Pydantic config.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid",buggy
"        validate_all = True
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, PrivateAttr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        env_prefix = """"
        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""allow""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""ignore""
        extra = ""ignore""
class Highlight(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=""allow""):  # type: ignore[call-arg]
    BaseModel, extra=""allow""
class AdditionalResultAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=""allow""):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""",bug-free
"        """"""Pydantic config.""""""

        # Allow extra fields. This is needed for the `interface` field.
        validate_all = True
        # Allow arbitrary types. This is needed for the `interface` field.
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
class ChatParams(BaseModel, extra=Extra.allow):
        """"""Configuration for this pydantic object.""""""

from langchain_core.pydantic_v1 import BaseModel, Extra
class ChatParams(BaseModel, extra=Extra.allow):
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = ""forbid""
from langchain_core.pydantic_v1 import Extra, Field, PrivateAttr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
        env_prefix = """"
        """"""Config for OneNoteGraphSettings.""""""

        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid  # Forbid extra attributes during model initialization
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
    Extra,
class Highlight(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
    BaseModel, extra=Extra.allow
class AdditionalResultAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=Extra.allow):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Pydantic config.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid",buggy
"        validate_all = True
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, PrivateAttr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        env_prefix = """"
        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""allow""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""ignore""
        extra = ""ignore""
class Highlight(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=""allow""):  # type: ignore[call-arg]
    BaseModel, extra=""allow""
class AdditionalResultAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=""allow""):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""",bug-free
"        """"""Pydantic config.""""""

        # Allow extra fields. This is needed for the `interface` field.
        validate_all = True
        # Allow arbitrary types. This is needed for the `interface` field.
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
class ChatParams(BaseModel, extra=Extra.allow):
        """"""Configuration for this pydantic object.""""""

from langchain_core.pydantic_v1 import BaseModel, Extra
class ChatParams(BaseModel, extra=Extra.allow):
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = ""forbid""
from langchain_core.pydantic_v1 import Extra, Field, PrivateAttr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
        env_prefix = """"
        """"""Config for OneNoteGraphSettings.""""""

        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid  # Forbid extra attributes during model initialization
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
    Extra,
class Highlight(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
    BaseModel, extra=Extra.allow
class AdditionalResultAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=Extra.allow):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Pydantic config.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid",buggy
"        validate_all = True
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, PrivateAttr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        env_prefix = """"
        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""allow""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""ignore""
        extra = ""ignore""
class Highlight(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=""allow""):  # type: ignore[call-arg]
    BaseModel, extra=""allow""
class AdditionalResultAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=""allow""):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""",bug-free
"        """"""Pydantic config.""""""

        # Allow extra fields. This is needed for the `interface` field.
        validate_all = True
        # Allow arbitrary types. This is needed for the `interface` field.
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
class ChatParams(BaseModel, extra=Extra.allow):
        """"""Configuration for this pydantic object.""""""

from langchain_core.pydantic_v1 import BaseModel, Extra
class ChatParams(BaseModel, extra=Extra.allow):
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = ""forbid""
from langchain_core.pydantic_v1 import Extra, Field, PrivateAttr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
        env_prefix = """"
        """"""Config for OneNoteGraphSettings.""""""

        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid  # Forbid extra attributes during model initialization
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
    Extra,
class Highlight(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
    BaseModel, extra=Extra.allow
class AdditionalResultAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=Extra.allow):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Pydantic config.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid",buggy
"        validate_all = True
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, PrivateAttr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        env_prefix = """"
        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""allow""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""ignore""
        extra = ""ignore""
class Highlight(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=""allow""):  # type: ignore[call-arg]
    BaseModel, extra=""allow""
class AdditionalResultAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=""allow""):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""",bug-free
"        """"""Pydantic config.""""""

        # Allow extra fields. This is needed for the `interface` field.
        validate_all = True
        # Allow arbitrary types. This is needed for the `interface` field.
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
class ChatParams(BaseModel, extra=Extra.allow):
        """"""Configuration for this pydantic object.""""""

from langchain_core.pydantic_v1 import BaseModel, Extra
class ChatParams(BaseModel, extra=Extra.allow):
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = ""forbid""
from langchain_core.pydantic_v1 import Extra, Field, PrivateAttr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        arbitrary_types_allowed = True
        env_prefix = """"
        """"""Config for OneNoteGraphSettings.""""""

        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid  # Forbid extra attributes during model initialization
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.ignore
from langchain_core.pydantic_v1 import Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
class Params(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, root_validator
        """"""Configuration for this pydantic config.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, Field, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, root_validator
        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
        """"""Configuration for this pydantic object.""""""

        extra = Extra.ignore
    Extra,
class Highlight(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
    BaseModel, extra=Extra.allow
class AdditionalResultAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=Extra.allow):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=Extra.allow):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import Extra, SecretStr
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field
        """"""Pydantic config.""""""

        extra = Extra.allow
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
    Extra,
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, Field, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, SecretStr, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
from langchain_core.pydantic_v1 import BaseModel, Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import Extra, root_validator
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid
        """"""Configuration for this pydantic object.""""""

        extra = Extra.forbid",buggy
"        validate_all = True
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
class ChatParams(BaseModel, extra=""allow""):
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, PrivateAttr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        arbitrary_types_allowed = True
        extra = ""forbid""
        env_prefix = """"
        env_prefix = """"
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""ignore""
from langchain_core.pydantic_v1 import Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
class Params(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import Field, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
        extra = ""allow""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""ignore""
        extra = ""ignore""
class Highlight(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class TextWithHighLights(BaseModel, extra=""allow""):  # type: ignore[call-arg]
    BaseModel, extra=""allow""
class AdditionalResultAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttributeValue(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class DocumentAttribute(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class ResultItem(BaseModel, ABC, extra=""allow""):  # type: ignore[call-arg]
class QueryResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
class RetrieveResult(BaseModel, extra=""allow""):  # type: ignore[call-arg]
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import SecretStr
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field
        extra = ""allow""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel
        extra = ""forbid""
        extra = ""forbid""
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, Field, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, SecretStr, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
from langchain_core.pydantic_v1 import BaseModel, root_validator
        extra = ""forbid""
        env_prefix = ""apache_doris_""
        env_prefix = ""clickhouse_""
        env_prefix = ""kinetica_""
        env_prefix = ""manticore_""
        env_prefix = ""myscale_""
        env_prefix = ""starrocks_""
from langchain_core.pydantic_v1 import root_validator
        extra = ""forbid""
        extra = ""forbid""",bug-free
"      import nonexistant_path.to.my_module  # doesn't exist
        nonexistant_path = ...  # type: Any
        def kill(__pid: int, __signal: int) -> None: ...",buggy
"      import nonexistent_path.to.my_module  # doesn't exist
        nonexistent_path = ...  # type: Any
        def kill(pid: int, signal: int, /) -> None: ...",bug-free
"from .utils import get_mac_address_and_interface, get_debug
    assert 'error' in response.json()
    assert 'error' in response.json()",buggy
"from .utils import get_mac_address_and_interface, get_debug, validate_serial
    assert 'detail' in response.json()
    assert 'detail' in response.json()
#    assert 'error' in response.json()",bug-free
"from klingon_serial.generate_serial import generate_serial
from datetime import datetime
    epoch = int(datetime.utcnow().timestamp() * 1000)
    print(""Epoch datetime (ms):     "",int(datetime.utcnow().timestamp() * 1000))

    """"""Convert a string representation of truth to true (1) or false (0).
    Args:
        val (str): The string representation of truth value.

    Returns:
        int: 1 if the value is true, 0 if the value is false.

    Raises:
        ValueError: If the value is not a valid truth value.
    val = val.lower()
    if val in ('y', 'yes', 't', 'true', 'on', '1'):
        return 1
    elif val in ('n', 'no', 'f', 'false', 'off', '0'):
        return 0
    else:
        raise ValueError(""Invalid truth value %r"" % (val,))

###
### klingon_serial setup.py
### 
    name='klingon_serial',
        'datetime',
        'pytest',
        'uuid',
        'setuptools'
    python_requires='>=3.6',
)
from klingon_serial.generate_serial import generate_serial, get_mac_address_hex, get_process_id, get_millisecond_epoch_hex
    assert get_debug() is True
    assert get_debug() is False",buggy
"from klingon_serial.generate import generate_serial
from datetime import datetime, timezone
    epoch = int(datetime.now(timezone.utc).timestamp() * 1000)
    print(""Epoch datetime (ms):     "",int(datetime.now(timezone.utc).timestamp() * 1000))
from distutils.util import strtobool as str2bool

    """"""Convert a string representation of truth to true (True) or false (False).
    This function is a wrapper around str2bool for compatibility.
    return str2bool(val)
""""""
This module provides utility functions for the klingon_serial package, including
retrieving the MAC address and network interface, and determining the debug mode.
""""""

    try:
        # Get primary network interface by looking at the default route
        primary_interface = None
        for interface, addrs in psutil.net_if_addrs().items():
            for addr in addrs:
                if addr.family == psutil.AF_LINK:
                    primary_interface = interface
                    mac_address = addr.address
                    return mac_address, primary_interface  # Return on first found interface
    except Exception as e:
        print(f""Error retrieving network interface: {e}"")
    name='klingon-serial',
        'pytest>=6.0',  # Specify the minimum version required
        'str2bool',
    license='MIT',  # Add the license field
    python_requires='>=3.9',
)
from klingon_serial.generate import generate_serial, get_mac_address_hex, get_process_id, get_millisecond_epoch_hex
    assert get_debug() == True
    assert get_debug() == False",bug-free
"if sys.version_info >= (2, 6):
    def binary(obj):
        return bytes(obj)
else:
    def binary(obj):
        return buffer(obj)

if sys.version_info >= (3, 0):
    text_type = str
    base_text_type = str
else:
    text_type = unicode
    base_text_type = basestring
    _fields_ = [(""Data1"", DWORD),
                (""Data2"", WORD),
                (""Data3"", WORD),
                (""Data4"", BYTE * 8)]
            _CLSIDFromString(text_type(name), byref(self))
        return 'GUID(""%s"")' % text_type(self)
        return isinstance(other, GUID) and \
               binary(self) == binary(other)
        return GUID(text_type(self))
        """"""Get guid from progid, ...
        """"""
        elif isinstance(progid, base_text_type):
            _CLSIDFromProgID(text_type(progid), byref(inst))
from ctypes import _SimpleCData
from _ctypes import COMError
################################################################

def add_metaclass(metaclass):
    """"""Class decorator from six.py for creating a class with a metaclass.

    Copyright (c) 2010-2020 Benjamin Peterson

    Permission is hereby granted, free of charge, to any person obtaining a copy of
    this software and associated documentation files (the ""Software""), to deal in
    the Software without restriction, including without limitation the rights to
    use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
    the Software, and to permit persons to whom the Software is furnished to do so,
    subject to the following conditions:

    The above copyright notice and this permission notice shall be included in all
    copies or substantial portions of the Software.

    THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
    FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
    COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
    IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
    CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
    """"""
    def wrapper(cls):
        orig_vars = cls.__dict__.copy()
        slots = orig_vars.get('__slots__')
        if slots is not None:
            if isinstance(slots, text_type):
                slots = [slots]
            for slots_var in slots:
                orig_vars.pop(slots_var)
        orig_vars.pop('__dict__', None)
        orig_vars.pop('__weakref__', None)
        if hasattr(cls, '__qualname__'):
            orig_vars['__qualname__'] = cls.__qualname__
        return metaclass(cls.__name__, cls.__bases__, orig_vars)
    return wrapper

################################################################

# type hinting symbols
#
# `if TYPE_CHECKING:` code block must not be executed because `TYPE_CHECKING`
# is always `False` in runtime.
# see https://peps.python.org/pep-0484/#runtime-or-type-checking
#
if sys.version_info >= (3, 5):
    from typing import TYPE_CHECKING
else:  # typehints in this package don't support Py<3.5 due to importing symbols.
    TYPE_CHECKING = False
#
# Annotations must be placed in a `# type:` comment in according to PEP484.
# see https://peps.python.org/pep-0484/#suggested-syntax-for-python-2-7-and-straddling-code
# - `NameError` never raises by using those symbols.
# - It is not able to use any runtime introspections, such as
#   `typing.get_type_hints` or `typing.get_origin`.
#
    # _CData = _SimpleCData.__mro__[:-1][-1]  # defining in runtime
    from ctypes import _Pointer
    from typing import Any, ClassVar, overload, TypeVar
    # XXX: symbols for backward compatibility.
    # instead of `builtins`. see PEP585.
    from typing import Dict, List, Tuple, Type
    # instead of `collections.abc`. see PEP585.
    from typing import Callable, Iterable, Iterator
    # instead of `A | B` and `None | A`. see PEP604.
    from typing import Union as _UnionT  #  avoiding confusion with `ctypes.Union`
    from typing import Optional
    # utilities or workarounds for annotations.
    from comtypes import hints as hints

################################################################
    ComMemberGenerator, _ComMemberSpec, DispMemberGenerator, _DispMemberSpec,
    _encode_idl, _resolve_argspec,
################################################################
if sys.version_info >= (3, 0):
    text_type = str
else:
    text_type = unicode
if sys.version_info >= (3, 0):
    pythonapi.PyInstanceMethod_New.argtypes = [py_object]
    pythonapi.PyInstanceMethod_New.restype = py_object
    PyInstanceMethod_Type = type(pythonapi.PyInstanceMethod_New(id))
    def instancemethod(func, inst, cls):
        mth = PyInstanceMethod_Type(func)
        if inst is None:
            return mth
        return mth.__get__(inst)
else:
    def instancemethod(func, inst, cls):
        return types.MethodType(func, inst, cls)
##class IDLWarning(UserWarning):
##    ""Warn about questionable type information""
tagCLSCTX = c_int # enum

_ole32_nohresult = windll.ole32 # use this for functions that don't return a HRESULT
COINIT_MULTITHREADED     = 0x0
COINIT_DISABLE_OLE1DDE   = 0x4
def _shutdown(func=_ole32_nohresult.CoUninitialize,
             _debug=logger.debug,
             _exc_clear=getattr(sys, ""exc_clear"", lambda: None)):
        try: func()
        except WindowsError: pass
    if TYPE_CHECKING:
        _case_insensitive_ = hints.AnnoField()  # type: bool
        _iid_ = hints.AnnoField()  # type: GUID
        _methods_ = hints.AnnoField()  # type: List[_ComMemberSpec]
        _disp_methods_ = hints.AnnoField()  # type: List[_DispMemberSpec]
        p = type(_compointer_base)(""POINTER(%s)"" % new_cls.__name__,
                                   _ptr_bases,
                                   {""__com_interface__"": new_cls,
                                    ""_needs_com_addref_"": None})
                    if fixed_name != name: # prevent unbounded recursion
                    object.__setattr__(self,
                                       self.__map_case__.get(name.lower(), name),
                                       value)
##            assert self.__dict__.get(""_methods_"", None) is None
    def _make_dispmethods(self, methods):
        # type: (List[_DispMemberSpec]) -> None
    def _make_methods(self, methods):
        # type: (List[_ComMemberSpec]) -> None
            com_interface_registry[text_type(iid)] = self
@add_metaclass(_compointer_meta)
class _compointer_base(c_void_p):
        return cmp(super(_compointer_base, self).value, super(_compointer_base, other).value)
        return super(_compointer_base, self).value == super(_compointer_base, other).value
        if self._b_base_ is None \
               or self._needsfree:
class helpstring(text_type):
def STDMETHOD(restype, name, argtypes=()):
def DISPMETHOD(idlflags, restype, name, *argspec):
def DISPPROPERTY(idlflags, proptype, name):
def COMMETHOD(idlflags, restype, methodname, *argspec):
    _T_IUnknown = TypeVar(""_T_IUnknown"", bound=""IUnknown"")
    class _IUnknown_Base(c_void_p):
        __com_QueryInterface = hints.AnnoField()  # type: Callable[[Any, Any], int]
        __com_AddRef = hints.AnnoField()  # type: Callable[[], int]
        __com_Release = hints.AnnoField()  # type: Callable[[], int]
@add_metaclass(_cominterface_meta)
class IUnknown(_IUnknown_Base):
    _case_insensitive_ = False  # type: ClassVar[bool]
    _iid_ = GUID(""{00000000-0000-0000-C000-000000000046}"")  # type: ClassVar[GUID]
    _methods_ = [
        STDMETHOD(HRESULT, ""QueryInterface"",
                  [POINTER(GUID), POINTER(c_void_p)]),
        STDMETHOD(c_ulong, ""Release"")
    ]  # type: ClassVar[List[_ComMemberSpec]]
    def QueryInterface(self, interface, iid=None):
        # type: (Type[_T_IUnknown], Optional[GUID]) -> _T_IUnknown
        clsid = self.__dict__.get('__clsid')
            p.__dict__['__clsid'] = clsid
    def AddRef(self):
        # type: () -> int
    def Release(self):
        # type: () -> int
    _iid_ = GUID('{0000010C-0000-0000-C000-000000000046}')
        COMMETHOD([], HRESULT, 'GetClassID',
                  ( ['out'], POINTER(GUID), 'pClassID' )),
        ]
        # Returns the CLSID that uniquely represents an object class that
        # defines the code that can manipulate the object's data.
        GetClassID = hints.AnnoField()  # type: Callable[[], GUID]
    _iid_ = GUID('{6D5140C1-7436-11CE-8034-00AA006009FA}')
    if TYPE_CHECKING:
        _QueryService = hints.AnnoField()  # type: Callable[[Any, Any, Any], int]
    def QueryService(self, serviceIID, interface):
        # type: (GUID, Type[_T_IUnknown]) -> _T_IUnknown
        COMMETHOD([], HRESULT, 'QueryService',
                  ( ['in'], POINTER(GUID), 'guidService' ),
                  ( ['in'], POINTER(GUID), 'riid' ),
                  ( ['in'], POINTER(c_void_p), 'ppvObject' ))
        ]
if TYPE_CHECKING:
    @overload
    def CoGetObject(displayname, interface):  # `interface` can't be missing
        # type: (str, None) -> IUnknown
        pass
    @overload
    def CoGetObject(displayname, interface):  # it should be called this way
        # type: (str, Type[_T_IUnknown]) -> _T_IUnknown
        pass
def CoGetObject(displayname, interface):
    # type: (str, Optional[Type[IUnknown]]) -> IUnknown
    _ole32.CoGetObject(text_type(displayname),
                       None,
                       byref(interface._iid_),
                       byref(punk))
if TYPE_CHECKING:
    pUnkOuter = Type[_Pointer[IUnknown]]
    @overload
    def CoCreateInstance(clsid, interface=None, clsctx=None, punkouter=None):
        # type: (GUID, None, Optional[int], Optional[pUnkOuter]) -> IUnknown
        pass
    @overload
    def CoCreateInstance(clsid, interface, clsctx=None, punkouter=None):
        # type: (GUID, Type[_T_IUnknown], Optional[int], Optional[pUnkOuter]) -> _T_IUnknown
        pass
def CoCreateInstance(clsid, interface=None, clsctx=None, punkouter=None):
    # type: (GUID, Optional[Type[IUnknown]], Optional[int], Optional[pUnkOuter]) -> IUnknown
    _CoGetClassObject(clsid,
                      clsctx,
                      pServerInfo,
                      interface._iid_,
                      byref(p))
if TYPE_CHECKING:
    @overload
    def GetActiveObject(clsid, interface=None):
        # type: (GUID, None) -> IUnknown
        pass
    @overload
    def GetActiveObject(clsid, interface):
        # type: (GUID, Type[_T_IUnknown]) -> _T_IUnknown
        pass
def GetActiveObject(clsid, interface=None):
    # type: (GUID, Optional[Type[IUnknown]]) -> IUnknown
    _fields_ = [(""pIID"", POINTER(GUID)),
                (""pItf"", POINTER(c_void_p)),
                (""hr"", HRESULT)]
        pIID = hints.AnnoField()  # type: GUID
        pItf = hints.AnnoField()  # type: _Pointer[c_void_p]
        hr = hints.AnnoField()  # type: HRESULT
        ('User', POINTER(c_ushort)),
        ('UserLength', c_ulong),
        ('Domain', POINTER(c_ushort)),
        ('DomainLength', c_ulong),
        ('Password', POINTER(c_ushort)),
        ('PasswordLength', c_ulong),
        ('Flags', c_ulong),
        ('dwAuthnSvc', c_ulong),
        ('dwAuthzSvc', c_ulong),
        ('pwszServerPrincName', c_wchar_p),
        ('dwAuthnLevel', c_ulong),
        ('dwImpersonationLevel', c_ulong),
        ('pAuthIdentityData', POINTER(_COAUTHIDENTITY)),
        ('dwCapabilities', c_ulong),
        ('dwReserved1', c_ulong),
        ('pwszName', c_wchar_p),
        ('pAuthInfo', POINTER(_COAUTHINFO)),
        ('dwReserved2', c_ulong),
        dwReserved1 = hints.AnnoField()  # type: int
        pwszName = hints.AnnoField()  # type: Optional[str]
        pAuthInfo = hints.AnnoField()  # type: _COAUTHINFO
        dwReserved2 = hints.AnnoField()  # type: int
_CoGetClassObject.argtypes = [POINTER(GUID), DWORD, POINTER(COSERVERINFO),
                              POINTER(GUID), POINTER(c_void_p)]
        ('cbStruct', c_ulong),
        ('grfFlags', c_ulong),
        ('grfMode', c_ulong),
        ('dwTickCountDeadline', c_ulong)
        ('cbStruct', c_ulong),
        ('grfFlags', c_ulong),
        ('grfMode', c_ulong),
        ('dwTickCountDeadline', c_ulong),
        ('dwTrackFlags', c_ulong),
        ('dwClassContext', c_ulong),
        ('locale', c_ulong),
        ('pServerInfo', POINTER(_COSERVERINFO)),
#Structures for security setups
        ('User', POINTER(c_ushort)),
        ('UserLength', c_ulong),
        ('Domain', POINTER(c_ushort)),
        ('DomainLength', c_ulong),
        ('Password', POINTER(c_ushort)),
        ('PasswordLength', c_ulong),
        ('Flags', c_ulong),
        ('dwAuthnSvc', c_ulong),
        ('dwAuthzSvc', c_ulong),
        ('pAuthInfo', POINTER(_SEC_WINNT_AUTH_IDENTITY)),
        ('cAuthInfo', c_ulong),
        ('pAuthInfo', POINTER(_SOLE_AUTHENTICATION_INFO)),
SOLE_AUTHENTICATION_LIST = _SOLE_AUTHENTICATION_LIST
if TYPE_CHECKING:
    @overload
    def CoCreateInstanceEx(
        clsid, interface=None, clsctx=None, machine=None, pServerInfo=None):
        # type: (GUID, None, Optional[int], Optional[str], Optional[COSERVERINFO]) -> IUnknown
        pass
    @overload
    def CoCreateInstanceEx(
        clsid, interface=None, clsctx=None, machine=None, pServerInfo=None):
        # type: (GUID, Type[_T_IUnknown], Optional[int], Optional[str], Optional[COSERVERINFO]) -> _T_IUnknown
        pass
def CoCreateInstanceEx(clsid, interface=None,
                       clsctx=None,
                       machine=None,
                       pServerInfo=None):
    # type: (GUID, Optional[Type[IUnknown]], Optional[int], Optional[str], Optional[COSERVERINFO]) -> IUnknown
        clsctx=CLSCTX_LOCAL_SERVER|CLSCTX_REMOTE_SERVER
    _ole32.CoCreateInstanceEx(byref(clsid),
                             None,
                             clsctx,
                             pServerInfo,
                             1,
                             byref(multiqi))
@add_metaclass(_coclass_meta)
class CoClass(COMObject):
    'BIND_OPTS', 'tagBIND_OPTS', 'BINDOPTS2', 'tagBIND_OPTS2', 'BSTR',
    '_check_version', 'CLSCTX', 'tagCLSCTX', 'CLSCTX_ALL',
    'CLSCTX_DISABLE_AAA', 'CLSCTX_ENABLE_AAA', 'CLSCTX_ENABLE_CODE_DOWNLOAD',
    'CLSCTX_FROM_DEFAULT_CONTEXT', 'CLSCTX_INPROC', 'CLSCTX_INPROC_HANDLER',
    'CLSCTX_INPROC_HANDLER16', 'CLSCTX_INPROC_SERVER',
    'CLSCTX_INPROC_SERVER16', 'CLSCTX_LOCAL_SERVER', 'CLSCTX_NO_CODE_DOWNLOAD',
    'CLSCTX_NO_CUSTOM_MARSHAL', 'CLSCTX_NO_FAILURE_LOG',
    'CLSCTX_REMOTE_SERVER', 'CLSCTX_RESERVED1', 'CLSCTX_RESERVED2',
    'CLSCTX_RESERVED3', 'CLSCTX_RESERVED4', 'CLSCTX_RESERVED5',
    'CLSCTX_SERVER', '_COAUTHIDENTITY', 'COAUTHIDENTITY', '_COAUTHINFO',
    'COAUTHINFO', 'CoClass', 'CoCreateInstance', 'CoCreateInstanceEx',
    '_CoGetClassObject', 'CoGetClassObject', 'CoGetObject',
    'COINIT_APARTMENTTHREADED', 'COINIT_DISABLE_OLE1DDE',
    'COINIT_MULTITHREADED', 'COINIT_SPEED_OVER_MEMORY', 'CoInitialize',
    'CoInitializeEx', 'COMError', 'COMMETHOD', 'COMObject', '_COSERVERINFO',
    'COSERVERINFO', 'CoUninitialize', 'dispid', 'DISPMETHOD', 'DISPPROPERTY',
    'DWORD', 'EOAC_NONE', 'GetActiveObject', '_GUID', 'GUID', 'helpstring',
    'IID', 'IPersist', 'IServiceProvider', 'IUnknown', 'MULTI_QI',
    'ReturnHRESULT', 'RPC_C_AUTHN_LEVEL_CONNECT', 'RPC_C_AUTHN_WINNT',
    'RPC_C_AUTHZ_NONE', 'RPC_C_IMP_LEVEL_IMPERSONATE',
    '_SEC_WINNT_AUTH_IDENTITY', 'SEC_WINNT_AUTH_IDENTITY',
    'SEC_WINNT_AUTH_IDENTITY_UNICODE', '_SOLE_AUTHENTICATION_INFO',
    'SOLE_AUTHENTICATION_INFO', '_SOLE_AUTHENTICATION_LIST',
    'SOLE_AUTHENTICATION_LIST', 'STDMETHOD', 'wireHWND',
    FormatError, POINTER, Structure, WINFUNCTYPE, byref, c_long, c_void_p,
    oledll, pointer, windll
    DISP_E_BADINDEX, DISP_E_MEMBERNOTFOUND, E_FAIL, E_NOINTERFACE,
    E_INVALIDARG, E_NOTIMPL, RPC_E_CHANGED_MODE, S_FALSE, S_OK
if sys.version_info >= (3, 0):
    int_types = (int, )
else:
    int_types = (int, long)

        if isinstance(code, int_types):
    raise TypeError(""Expected comtypes.COMERROR or WindowsError instance, got %s"" % type(exc).__name__)
        _debug(""unimplemented method %s_%s called"", interface_name,
               method_name)
            return ReportError(text, iid=interface._iid_, clsid=clsid,
                               hresult=hresult)
            _error(""Exception in %s.%s implementation:"", interface.__name__,
                   mthname, exc_info=True)
            _warning(""Unimplemented method %s.%s called"", interface.__name__,
                     mthname)
            _error(""Exception in %s.%s implementation:"", interface.__name__,
                   mthname, exc_info=True)
        has_outargs = bool([x[0] for x in paramflags
                            if x[0] & 2])
        if a&2:
        if a&1 or a==0:
##    if args_in != code.co_argcount - 1:
##        return catch_errors(inst, mth, interface, mthname)
##        for a in outargs:
##            if not a:
##                return E_POINTER
        #make argument list for handler by index array built above
            return ReportError(text, iid=interface._iid_, clsid=clsid,
                               hresult=hresult)
            _error(""Exception in %s.%s implementation:"", interface.__name__,
                   mthname, exc_info=True)
            return ReportError(msg, iid=interface._iid_, clsid=clsid,
                               hresult=hr)
            _error(""Exception in %s.%s implementation:"", interface.__name__,
                   mthname, exc_info=True)
            _warning(""Unimplemented method %s.%s called"", interface.__name__,
                     mthname)
            _error(""Exception in %s.%s implementation:"", interface.__name__,
                   mthname, exc_info=True)
        _debug(""%r: %s.%s not implemented"", self.inst, interface.__name__,
               mthname)
        if sys.version_info >= (3, 0):
            import queue
        else:
            import Queue as queue

                if hasattr(self, ""_outgoing_interfaces_"") and \
                   IProvideClassInfo2 not in interfaces:
                    if 'propget' in idlflags:
                    elif 'propput' in idlflags:
                    elif 'propputref' in idlflags:
                            argspec = argspec + ((['out'], restype, """"),)
                    self.__make_dispentry(finder, interface, mthname,
                                          idlflags, argspec, invkind)
                        argspec += ((['out'], restype, """"),)
                    self.__make_dispentry(finder, interface,
                                          ""_get_"" + mthname,
                                          idlflags, argspec,
                                          2  # DISPATCH_PROPERTYGET
                                          )
                    if not 'readonly' in idlflags:
                        self.__make_dispentry(finder, interface,
                                              ""_set_"" + mthname,
                                              idlflags, argspec,
                                              4)  # DISPATCH_PROPERTYPUT
    def __make_dispentry(self,
                         finder, interface, mthname,
                         idlflags, argspec, invkind):
        paramflags = [((_encode_idl(x[0]), x[1]) + tuple(x[3:]))
                      for x in argspec]
        _debug(""%d active COM objects: Added   %r"", len(COMObject._instances_),
               obj)
            _debug(""%d active COM objects: Removed %r"",
                   len(COMObject._instances_), obj)
    def IUnknown_AddRef(self, this,
                        __InterlockedIncrement=_InterlockedIncrement,
                        _debug=_debug):
    def IUnknown_Release(self, this,
                         __InterlockedDecrement=_InterlockedDecrement,
                         _debug=_debug):
            raise COMError(E_NOINTERFACE, FormatError(E_NOINTERFACE),
                           (None, None, 0, None, None))
    def IDispatch_GetIDsOfNames(self, this, riid, rgszNames, cNames, lcid,
                                rgDispId):
        return windll.oleaut32.DispGetIDsOfNames(tinfo,
                                                 rgszNames, cNames, rgDispId)

    def IDispatch_Invoke(self, this, dispIdMember, riid, lcid, wFlags,
                         pDispParams, pVarResult, pExcepInfo, puArgErr):
                ptr, tinfo, dispIdMember, wFlags, pDispParams, pVarResult,
                pExcepInfo, puArgErr
            args = [params.rgvarg[i].value
                    for i in reversed(list(range(params.cNamedArgs)))]
            named_indexes = [params.rgdispidNamedArgs[i]
                             for i in range(params.cNamedArgs)]

from comtypes import TYPE_CHECKING
if TYPE_CHECKING:
    from comtypes import _CData
    from typing import (
        Any, Callable, Dict, Iterator, List, Optional, Tuple, Type, Union as _UnionT
    )
    PositionalParamFlagType = Tuple[int, Optional[str]]
    OptionalParamFlagType = Tuple[int, Optional[str], Any]
    ParamFlagType = _UnionT[PositionalParamFlagType, OptionalParamFlagType]
    PositionalArgSpecElmType = Tuple[List[str], Type[_CData], str]
    OptionalArgSpecElmType = Tuple[List[str], Type[_CData], str, Any]
    ArgSpecElmType = _UnionT[PositionalArgSpecElmType, OptionalArgSpecElmType]
    }
def _unpack_argspec(idl, typ, name=None, defval=_NOTHING):
    # type: (List[str], Type[_CData], Optional[str], Any) -> Tuple[List[str], Type[_CData], Optional[str], Any]
def _resolve_argspec(items):
    # type: (Tuple[ArgSpecElmType, ...]) -> Tuple[Tuple[ParamFlagType, ...], Tuple[Type[_CData], ...]]
class _MemberSpec(object):
    """"""Specifier of a slot of method or property.""""""
    __slots__ = (""name"", ""idlflags"", ""restype"")
    def __init__(self, name, idlflags, restype):
        self.name = name  # type: str
        self.idlflags = idlflags  # type: Tuple[_UnionT[str, int], ...]
        self.restype = restype  # type: Optional[Type[_CData]]

    def is_prop(self):
        # type: () -> bool
        propflags = (""propget"", ""propput"", ""propputref"")
        return any(f in propflags for f in self.idlflags)


class _ComMemberSpec(_MemberSpec):
    __slots__ = (""argtypes"", ""paramflags"", ""doc"")
    def __init__(self, restype, name, argtypes, paramflags, idlflags, doc):
        self.argtypes = argtypes  # type: Tuple[Type[_CData], ...]
        self.paramflags = paramflags  # type: Optional[Tuple[ParamFlagType, ...]]
        self.doc = doc  # type: Optional[str]
        super(_ComMemberSpec, self).__init__(name, idlflags, restype)
    def __iter__(self):
        # for backward compatibility:
        # A function that returns this object used to return a `tuple`.
        # So it is implemented as unpackable as well.
        for item in (self.restype, self.name, self.argtypes, self.paramflags, self.idlflags, self.doc):
            yield item
class _DispMemberSpec(_MemberSpec):
    __slots__ = (""what"", ""argspec"")
    def __init__(self, what, name, idlflags, restype, argspec):
        self.what = what  # type: str
        self.argspec = argspec  # type: Tuple[ArgSpecElmType, ...]
        super(_DispMemberSpec, self).__init__(name, idlflags, restype)
    def memid(self):
        # type: () -> int
    def __iter__(self):
        # for backward compatibility:
        # A function that returns this object used to return a `tuple`.
        # So it is implemented as unpackable as well.
        for item in (self.what, self.name, self.idlflags, self.restype, self.argspec):
            yield item
def _fix_inout_args(func, argtypes, paramflags):
    # type: (Callable[..., Any], Tuple[Type[_CData], ...], Tuple[ParamFlagType, ...]) -> Callable[..., Any]
        outargs = {}
            if direction & 3 == 3:
                atyp = argtypes[i]._type_
                try:
                    try:
                        v = args[i]
                    except IndexError:
                        v = kw[name]
                except KeyError:
                    # no parameter was passed, make an empty one
                    # of the required type
                    v = atyp()
                else:
                    # parameter was passed, call .from_param() to
                    # convert it to a ctypes type.
                        # Array of or pointer to type 'atyp' was
                        # passed, pointer to 'atyp' expected.
                        # The from_param method of simple types
                        # (c_int, c_double, ...) returns a byref()
                        # object which we cannot use since later
                        # it will be wrapped in a pointer.  Simply
                        # call the constructor with the argument
                        # in that case.
                outargs[outnum] = v
                outnum += 1
                if len(args) > i:
                    args[i] = v
                else:
            elif direction & 2 == 2:
        self._data = {}  # type: Dict[Tuple[str, Optional[str], int], List[Optional[Callable[..., Any]]]]
    def add_propget(self, name, doc, nargs, func):
        # type: (str, Optional[str], int, Callable[..., Any]) -> None
    def add_propput(self, name, doc, nargs, func):
        # type: (str, Optional[str], int, Callable[..., Any]) -> None
    def add_propputref(self, name, doc, nargs, func):
        # type: (str, Optional[str], int, Callable[..., Any]) -> None
    def __iter__(self):
        # type: () -> Iterator[Tuple[str, Optional[str], int, Optional[Callable[..., Any]], Optional[Callable[..., Any]]]]
    def __init__(self, cls_name):
        # type: (str) -> None
    def add(self, m, func):
        # type: (_MemberSpec, Callable[..., Any]) -> None
    def __iter__(self):
        # type: () -> Iterator[Tuple[str, _UnionT[property, named_property]]]
    def to_propget_keys(self, m):
        # type: (_MemberSpec) -> Tuple[str, Optional[str], int]
    def to_propput_keys(self, m):
        # type: (_MemberSpec) -> Tuple[str, Optional[str], int]
    def to_propputref_keys(self, m):
        # type: (_MemberSpec) -> Tuple[str, Optional[str], int]
    def to_propget_keys(self, m):
        # type: (_ComMemberSpec) -> Tuple[str, Optional[str], int]
        return m.name[len(""_get_""):], m.doc, nargs
    def to_propput_keys(self, m):
        # type: (_ComMemberSpec) -> Tuple[str, Optional[str], int]
        return m.name[len(""_set_""):], m.doc, nargs
    def to_propputref_keys(self, m):
        # type: (_ComMemberSpec) -> Tuple[str, Optional[str], int]
        return m.name[len(""_setref_""):], m.doc, nargs
    def to_propget_keys(self, m):
        # type: (_DispMemberSpec) -> Tuple[str, Optional[str], int]
    def to_propput_keys(self, m):
        # type: (_DispMemberSpec) -> Tuple[str, Optional[str], int]
    def to_propputref_keys(self, m):
        # type: (_DispMemberSpec) -> Tuple[str, Optional[str], int]
    def __init__(self, cls_name, vtbl_offset, iid):
        # type: (str, int, comtypes.GUID) -> None
        self._mths = []  # type: List[Tuple[str, Callable[..., Any], Callable[..., Any], bool]]
    def add(self, m):
        # type: (_ComMemberSpec) -> None
    def _fix_args(self, m, func):
        # type: (_ComMemberSpec, Callable[..., Any]) -> Callable[..., Any]
            dirflags = [(p[0]&3) for p in m.paramflags]
    def __init__(self, cls_name):
        # type: (str) -> None
        self._items = []  # type: List[Tuple[str, _UnionT[Callable[..., Any], property], bool]]
    def add(self, m):
        # type: (_DispMemberSpec) -> None
            assert not m.argspec # XXX does not yet work for properties with parameters
    def _make_disp_property(self, m):
        # type: (_DispMemberSpec) -> property
            return obj.Invoke(memid, _invkind=2) # DISPATCH_PROPERTYGET
    def _make_disp_method(self, m):
        # type: (_DispMemberSpec) -> Callable[..., Any]
                return obj.Invoke(memid, _invkind=2, *args, **kw) # DISPATCH_PROPERTYGET
                return obj.Invoke(memid, _invkind=4, *args, **kw) # DISPATCH_PROPERTYPUT
                return obj.Invoke(memid, _invkind=8, *args, **kw) # DISPATCH_PROPERTYPUTREF
            return obj.Invoke(memid, _invkind=1, *args, **kw) # DISPATCH_METHOD
        """""" Explicitly disallow iteration. """"""
        PTR = _coclass_pointer_meta(""POINTER(%s)"" % klass.__name__,
                                    (klass, c_void_p),
                                    {""__ctypes_from_outparam__"": _wrap_coclass,
                                     ""from_param"": classmethod(_coclass_from_param),
                                     })
    """""" Class encapsulating all the functionality necessary to allow interop of
        """""" Create a dtype for VARIANT. This requires support for Unions, which
        ptr_typecode = '<u8' if is_64bits else '<u4'
            ('pvRecord', ptr_typecode),
            ('pRecInfo', ptr_typecode),
                'VT_BOOL', 'VT_I1', 'VT_I2', 'VT_I4', 'VT_I8', 'VT_INT',
                'VT_UI1', 'VT_UI2', 'VT_UI4', 'VT_UI8', 'VT_UINT', 'VT_R4',
                'VT_R8', 'VT_CY', 'c_wchar_p', 'c_void_p', 'pparray',
                'bstrVal', '_tagBRECORD',
                '<i2', '<i1', '<i2', '<i4', '<i8', '<i4', '<u1', '<u2', '<u4',
                '<u8', '<u4', '<f4', '<f8', '<i8', ptr_typecode, ptr_typecode,
                ptr_typecode, ptr_typecode, _tagBRECORD_format,
            offsets=[0] * 19  # This is what makes it a union
            (""vt"", '<u2'),
            (""wReserved1"", '<u2'),
            (""wReserved2"", '<u2'),
            (""wReserved3"", '<u2'),
        """""" Check if a value is an ndarray.
        """""" Check if a value is a datetime64.
        """""" The numpy package.
        """"""
        """""" Enables numpy/comtypes interop.
        """"""
##if __debug__:
##    from ctypeslib.dynamic_module import include
##    include(""""""\
##    #define UNICODE
##    #define NO_STRICT
##    #include <windows.h>
##    """""",
##            persist=True)
        ('cElements', DWORD),
        ('lLbound', LONG),
]
        ('cDims', USHORT),
        ('fFeatures', USHORT),
        ('cbElements', DWORD),
        ('cLocks', DWORD),
        ('pvData', PVOID),
        ('rgsabound', SAFEARRAYBOUND * 1),
        ]

from comtypes import (
    BSTR, COMError, COMMETHOD, GUID, IID, IUnknown, STDMETHOD, TYPE_CHECKING,
from ctypes.wintypes import DWORD, LONG, UINT, VARIANT_BOOL, WCHAR, WORD

if TYPE_CHECKING:
    from typing import (
        Any, Callable, ClassVar, List, Optional, Tuple, Union as _UnionT,
    )
    from comtypes import hints


if sys.version_info >= (3, 0):
    int_types = (int, )
    str_types = (str, )
    base_text_type = str
else:
    int_types = (int, long)
    str_types = (unicode, str)
    base_text_type = basestring
VARENUM = c_int # enum
    _fields_ = [(""wReserved"", c_ushort),
                (""scale"", c_ubyte),
                (""sign"", c_ubyte),
                (""Hi32"", c_ulong),
                (""Lo64"", c_ulonglong)]
        """""" Convert a tagDEC struct to Decimal.
            '-' if self.sign else '',
        vt = hints.AnnoField()  # type: int
        _ = hints.AnnoField()  # type: U_VARIANT1.__tagVARIANT.U_VARIANT2
        null = hints.AnnoField()  # type: ClassVar[VARIANT]
        empty = hints.AnnoField()  # type: ClassVar[VARIANT]
        missing = hints.AnnoField()  # type: ClassVar[VARIANT]
                    _fields_ = [(""pvRecord"", c_void_p),
                                (""pRecInfo"", POINTER(IUnknown))]

                    ]
            _fields_ = [(""vt"", VARTYPE),
                        (""wReserved1"", c_ushort),
                        (""wReserved2"", c_ushort),
                        (""wReserved3"", c_ushort),
                        (""_"", U_VARIANT2)
        _fields_ = [(""__VARIANT_NAME_2"", __tagVARIANT),
                    (""decVal"", DECIMAL)]
        elif (hasattr(value, '__len__') and len(value) == 0
                and not isinstance(value, base_text_type)):
        elif isinstance(value, int_types):
        elif isinstance(value, str_types):
            com_days = delta.days + (delta.seconds + delta.microseconds * 1e-6) / 86400.
            com_days /= comtypes.npsupport.numpy.timedelta64(1, 'D')
                return None # XXX?
                return None # XXX?
        if self.vt == VT_BYREF|VT_VARIANT:

# these are missing:
##    getter[VT_ERROR]
##    getter[VT_ARRAY]
##    getter[VT_BYREF|VT_UI1]
##    getter[VT_BYREF|VT_I2]
##    getter[VT_BYREF|VT_I4]
##    getter[VT_BYREF|VT_R4]
##    getter[VT_BYREF|VT_R8]
##    getter[VT_BYREF|VT_BOOL]
##    getter[VT_BYREF|VT_ERROR]
##    getter[VT_BYREF|VT_CY]
##    getter[VT_BYREF|VT_DATE]
##    getter[VT_BYREF|VT_BSTR]
##    getter[VT_BYREF|VT_UNKNOWN]
##    getter[VT_BYREF|VT_DISPATCH]
##    getter[VT_BYREF|VT_ARRAY]
##    getter[VT_BYREF|VT_VARIANT]
##    getter[VT_BYREF]
##    getter[VT_BYREF|VT_DECIMAL]
##    getter[VT_BYREF|VT_I1]
##    getter[VT_BYREF|VT_UI2]
##    getter[VT_BYREF|VT_UI4]
##    getter[VT_BYREF|VT_INT]
##    getter[VT_BYREF|VT_UINT]
        _VariantChangeType(self,
                           self,
                           0,
                           typecode)
    _iid_ = GUID('{00020404-0000-0000-C000-000000000046}')
    _idlflags_ = ['hidden']
    if sys.version_info >= (3, 0):
        def __next__(self):
            item, fetched = self.Next(1)
            if fetched:
                return item
            raise StopIteration
    else:
        def next(self):
            item, fetched = self.Next(1)
            if fetched:
                return item
            raise StopIteration
##        if isinstance(index, slice):
##            self.Skip(index.start or 0)
##            return self.Next(index.stop or sys.maxint)
        result = [v._get_value(dynamic=self._dynamic) for v in array[:fetched.value]]
    COMMETHOD([], HRESULT, 'Next',
              ( ['in'], c_ulong, 'celt' ),
              ( ['out'], POINTER(VARIANT), 'rgvar' ),
              ( ['out'], POINTER(c_ulong), 'pceltFetched' )),
    COMMETHOD([], HRESULT, 'Skip',
              ( ['in'], c_ulong, 'celt' )),
    COMMETHOD([], HRESULT, 'Reset'),
    COMMETHOD([], HRESULT, 'Clone',
              ( ['out'], POINTER(POINTER(IEnumVARIANT)), 'ppenum' )),
        wCode = hints.AnnoField()  # type: int
        wReserved = hints.AnnoField()  # type: int
        bstrSource = hints.AnnoField()  # type: str
        bstrDescription = hints.AnnoField()  # type: str
        bstrHelpFile = hints.AnnoField()  # type: str
        dwHelpContext = hints.AnnoField()  # type: int
        pvReserved = hints.AnnoField()  # type: Optional[int]
        pfnDeferredFillIn = hints.AnnoField()  # type: Optional[int]
        scode = hints.AnnoField()  # type: int
        return ""<EXCEPINFO %s>"" % \
               ((self.wCode, self.bstrSource, self.bstrDescription, self.bstrHelpFile, self.dwHelpContext,
                self.pfnDeferredFillIn, self.scode),)
    ('wCode', WORD),
    ('wReserved', WORD),
    ('bstrSource', BSTR),
    ('bstrDescription', BSTR),
    ('bstrHelpFile', BSTR),
    ('dwHelpContext', DWORD),
    ('pvReserved', c_void_p),
##    ('pfnDeferredFillIn', WINFUNCTYPE(HRESULT, POINTER(tagEXCEPINFO))),
    ('pfnDeferredFillIn', c_void_p),
    ('scode', SCODE),
        rgvarg = hints.AnnoField()  # type: Array[VARIANT]
        rgdispidNamedArgs = hints.AnnoField()  # type: _Pointer[DISPID]
        cArgs = hints.AnnoField()  # type: int
        cNamedArgs = hints.AnnoField()  # type: int
        ('rgvarg', POINTER(VARIANTARG)),
        ('rgdispidNamedArgs', POINTER(DISPID)),
        ('cArgs', UINT),
        ('cNamedArgs', UINT),
if TYPE_CHECKING:
    RawGetIDsOfNamesFunc = Callable[
        [_byref_type, Array[c_wchar_p], int, int, Array[DISPID]], int,
    ]
    RawInvokeFunc = Callable[
        [
            int, _byref_type, int, int,  # dispIdMember, riid, lcid, wFlags
            _UnionT[_byref_type, DISPPARAMS],  # *pDispParams
            _UnionT[_byref_type, VARIANT],  # pVarResult
            _UnionT[_byref_type, EXCEPINFO, None],  # pExcepInfo
            _UnionT[_byref_type, c_uint],  # puArgErr
        ],
        int
    ]
    if TYPE_CHECKING:
        _disp_methods_ = hints.AnnoField()  # type: ClassVar[List[comtypes._DispMemberSpec]]
        _GetTypeInfo = hints.AnnoField()  # type: Callable[[int, int], IUnknown]
        __com_GetIDsOfNames = hints.AnnoField()  # type: RawGetIDsOfNamesFunc
        __com_Invoke = hints.AnnoField()  # type: RawInvokeFunc
        COMMETHOD([], HRESULT, 'GetTypeInfoCount',
                  (['out'], POINTER(UINT) ) ),
        COMMETHOD([], HRESULT, 'GetTypeInfo',
                  (['in'], UINT, 'index'),
                  (['in'], LCID, 'lcid', 0),
                # Normally, we would declare this parameter in this way:
                # (['out'], POINTER(POINTER(ITypeInfo)) ) ),
                # but we cannot import comtypes.typeinfo at the top level (recursive imports!).
                  (['out'], POINTER(POINTER(IUnknown)) ) ),
        STDMETHOD(HRESULT, 'GetIDsOfNames', [POINTER(IID), POINTER(c_wchar_p),
                                             UINT, LCID, POINTER(DISPID)]),
        STDMETHOD(HRESULT, 'Invoke', [DISPID, POINTER(IID), LCID, WORD,
                                      POINTER(DISPPARAMS), POINTER(VARIANT),
                                      POINTER(EXCEPINFO), POINTER(UINT)]),
    def GetTypeInfo(self, index, lcid=0):
        # type: (int, int) -> hints.ITypeInfo
    def GetIDsOfNames(self, *names, **kw):
        # type: (str, Any) -> List[int]
    def _invoke(self, memid, invkind, lcid, *args):
        # type: (int, int, int, Any) -> Any
        self.__com_Invoke(memid, riid_null, lcid, invkind,
                          dp, var, None, argerr)
    def Invoke(self, dispid, *args, **kw):
        # type: (int, Any, Any) -> Any
        _invkind = kw.pop(""_invkind"", 1) # DISPATCH_METHOD


        if _invkind in (DISPATCH_PROPERTYPUT, DISPATCH_PROPERTYPUTREF): # propput
            array = (VARIANT * len(args))()

            for i, a in enumerate(args[::-1]):
                array[i].value = a

            dp = DISPPARAMS()
            dp.cArgs = len(args)
            dp.cNamedArgs = 1
            dp.rgvarg = array
            dp.rgdispidNamedArgs = pointer(DISPID(DISPID_PROPERTYPUT))
        else:
            array = (VARIANT * len(args))()

            for i, a in enumerate(args[::-1]):
                array[i].value = a

            dp = DISPPARAMS()
            dp.cArgs = len(args)
            dp.cNamedArgs = 0
            dp.rgvarg = array

            self.__com_Invoke(dispid, riid_null, _lcid, _invkind, byref(dp),
                              byref(result), byref(excepinfo), byref(argerr))
                details = (excepinfo.bstrDescription, excepinfo.bstrSource,
                           excepinfo.bstrHelpFile, excepinfo.dwHelpContext,
                           excepinfo.scode)
                raise COMError(hresult, text,
                               (""TypeError: Parameter %s"" % (argerr.value + 1),
                                args))
    }







    POINTER(VARIANT): VT_BYREF|VT_VARIANT,

    POINTER(BSTR): VT_BYREF|VT_BSTR,

##    POINTER(IUnknown): VT_UNKNOWN,
##    POINTER(IDispatch): VT_DISPATCH,
    }

    'CURRENCY', 'CY', 'tagCY', 'DECIMAL', 'tagDEC', 'DISPATCH_METHOD',
    'DISPATCH_PROPERTYGET', 'DISPATCH_PROPERTYPUT', 'DISPATCH_PROPERTYPUTREF',
    'DISPID', 'DISPID_COLLECT', 'DISPID_CONSTRUCTOR', 'DISPID_DESTRUCTOR',
    'DISPID_EVALUATE', 'DISPID_NEWENUM', 'DISPID_PROPERTYPUT',
    'DISPID_UNKNOWN', 'DISPID_VALUE', 'DISPPARAMS', 'tagDISPPARAMS',
    'EXCEPINFO', 'tagEXCEPINFO', 'IDispatch', 'IEnumVARIANT', 'IID_NULL',
    'INVOKE_FUNC', 'INVOKE_PROPERTYGET', 'INVOKE_PROPERTYPUT',
    'INVOKE_PROPERTYPUTREF', 'INVOKEKIND', 'tagINVOKEKIND', '_midlSAFEARRAY',
    'SCODE', '_SysAllocStringLen', 'VARENUM', 'VARIANT','tagVARIANT', 
    'VARIANTARG', '_VariantChangeType', '_VariantClear', '_VariantCopy',
    '_VariantCopyInd', 'VARTYPE', 'VT_ARRAY', 'VT_BLOB', 'VT_BLOB_OBJECT',
    'VT_BOOL', 'VT_BSTR', 'VT_BSTR_BLOB', 'VT_BYREF', 'VT_CARRAY', 'VT_CF',
    'VT_CLSID', 'VT_CY', 'VT_DATE', 'VT_DECIMAL', 'VT_DISPATCH', 'VT_EMPTY',
    'VT_ERROR', 'VT_FILETIME', 'VT_HRESULT', 'VT_I1', 'VT_I2', 'VT_I4',
    'VT_I8', 'VT_ILLEGAL', 'VT_ILLEGALMASKED', 'VT_INT', 'VT_INT_PTR',
    'VT_LPSTR', 'VT_LPWSTR', 'VT_NULL', 'VT_PTR', 'VT_R4', 'VT_R8',
    'VT_RECORD', 'VT_RESERVED', 'VT_SAFEARRAY', 'VT_STORAGE',
    'VT_STORED_OBJECT', 'VT_STREAM', 'VT_STREAMED_OBJECT', 'VT_TYPEMASK',
    'VT_UI1', 'VT_UI2', 'VT_UI4', 'VT_UI8', 'VT_UINT', 'VT_UINT_PTR',
    'VT_UNKNOWN', 'VT_USERDEFINED', 'VT_VARIANT', 'VT_VECTOR',
    'VT_VERSIONED_STREAM', 'VT_VOID',
'''comtypes.client - High level client level COM support package.
'''
from comtypes import (
    automation, CoClass, GUID, IUnknown, TYPE_CHECKING, typeinfo,
)
if TYPE_CHECKING:
    from typing import Any, Optional, overload, Type, TypeVar, Union as _UnionT
    from comtypes import hints
    _T_IUnknown = TypeVar(""_T_IUnknown"", bound=IUnknown)

def wrap_outparam(punk):
    # type: (Any) -> Any
def GetBestInterface(punk):
    # type: (Any) -> Any
    if not punk: # NULL COM pointer
        return punk # or should we return None?
            logger.debug(""Does NOT implement IProvideClassInfo, trying IProvideClassInfo2"")
        tinfo = pci.GetClassInfo() # TypeInfo for the CoClass
    itf_name = tinfo.GetDocumentation(-1)[0] # interface name
    tlib = tinfo.GetContainingTypeLib()[0] # typelib
if comtypes.TYPE_CHECKING:
    @overload
    def GetActiveObject(progid):
        # type: (_UnionT[str, CoClass, GUID]) -> Any
        pass
    @overload
    def GetActiveObject(progid, interface):
        # type: (_UnionT[str, CoClass, GUID], Type[_T_IUnknown]) -> _T_IUnknown
        pass
def GetActiveObject(progid, interface=None, dynamic=False):
    # type: (_UnionT[str, CoClass, GUID], Optional[Any], bool) -> Any
def _manage(obj, clsid, interface):
    # type: (Any, Optional[GUID], Optional[Type[IUnknown]]) -> Any
    obj.__dict__['__clsid'] = str(clsid)
def GetClassObject(progid,
                   clsctx=None,
                   pServerInfo=None,
                   interface=None):
if TYPE_CHECKING:
    @overload
    def CreateObject(progid):
        # type: (_UnionT[str, CoClass, GUID]) -> Any
        pass
    @overload
    def CreateObject(progid, clsctx=None, machine=None, interface=None, dynamic=False, pServerInfo=None):
        # type: (_UnionT[str, CoClass, GUID], Optional[int], Optional[str], Optional[Type[_T_IUnknown]], bool, Optional[comtypes.COSERVERINFO]) -> _T_IUnknown
        pass
def CreateObject(progid,                  # which object to create
                 clsctx=None,             # how to create the object
                 machine=None,            # where to create the object
                 interface=None,          # the interface we want
                 dynamic=False,           # use dynamic dispatch
                 pServerInfo=None):       # server info struct for remoting
    # type: (_UnionT[str, CoClass, GUID], Optional[int], Optional[str], Optional[Type[IUnknown]], bool, Optional[comtypes.COSERVERINFO]) -> Any
        logger.debug(""CoCreateInstance(%s, clsctx=%s, interface=%s)"",
                     clsid, clsctx, interface)
        logger.debug(""CoCreateInstanceEx(%s, clsctx=%s, interface=%s, machine=%s,\
                     clsid, clsctx, interface, machine, pServerInfo)
            msg = ""You can notset both the machine name and server info.""
        obj = comtypes.CoCreateInstanceEx(clsid, clsctx=clsctx,
                interface=interface, machine=machine, pServerInfo=pServerInfo)
if TYPE_CHECKING:
    @overload
    def CoGetObject(displayname, interface):
        # type: (str, Type[_T_IUnknown]) -> _T_IUnknown
        pass
    @overload
    def CoGetObject(displayname, interface=None, dynamic=False):
        # type: (str, None, bool) -> Any
        pass
def CoGetObject(displayname, interface=None, dynamic=False):
    # type: (str, Optional[Type[comtypes.IUnknown]], bool) -> Any
    return _manage(punk,
                   clsid=None,
                   interface=interface)
        else: # ftype in ('windows_exe', 'console_exe')
SHGetSpecialFolderPath.argtypes = [ctypes.c_ulong, ctypes.c_wchar_p,
                                   ctypes.c_int, ctypes.c_int]
if sys.version_info >= (3, 0):
    base_text_type = str
else:
    base_text_type = basestring

        if isinstance(obj, base_text_type):
    clsid = source.__dict__.get('__clsid')
##    interface = find_single_connection_interface(source)
##    if interface:
##        return interface
    if func.__code__.co_varnames[:2] == ('self', 'this'):
            return comtypes.instancemethod(method,
                                           im_self,
                                           type(im_self))
def CreateEventReceiver(interface, handler):
    if issubclass(interface, comtypes.automation.IDispatch) \
           and not hasattr(sink, ""_dispimpl_""):
##    @ctypes.WINFUNCTYPE(ctypes.c_int, ctypes.c_uint)
        if dwCtrlType == 0: # CTRL+C
            res = ctypes.oledll.ole32.CoWaitForMultipleHandles(0,
                                                               int(timeout * 1000),
                                                               len(handles), handles,
                                                               ctypes.byref(ctypes.c_ulong()))
            if details.winerror != RPC_S_CALLPENDING: # timeout expired
if sys.version_info >= (3, 0):
    base_text_type = str
    import winreg
else:
    base_text_type = basestring
    import _winreg as winreg

from comtypes import GUID, TYPE_CHECKING, typeinfo
if TYPE_CHECKING:
    from typing import Any, Tuple, List, Optional, Dict, Union as _UnionT

def _my_import(fullname):
    # type: (str) -> types.ModuleType
def _resolve_filename(tlib_string, dirpath):
    # type: (str, str) -> Tuple[str, bool]
    assert isinstance(tlib_string, base_text_type)
def GetModule(tlib):
    # type: (_UnionT[Any, typeinfo.ITypeLib]) -> types.ModuleType
    if isinstance(tlib, base_text_type):
        _file_ = frame.f_globals.get(""__file__"", None)  # type: str
        pathname, is_abs = _resolve_filename(tlib_string, _file_ and os.path.dirname(_file_))
        assert not(os.path.isabs(pathname)) or os.path.exists(pathname)
    # create and import the real typelib wrapper module
    mod = _create_wrapper_module(tlib, pathname)
    # try to get the friendly-name, if not, returns the real typelib wrapper module
    modulename = codegenerator.name_friendly_module(tlib)
    if modulename is None:
        return mod
    if sys.version_info < (3, 0):
        modulename = modulename.encode(""mbcs"")
    # create and import the friendly-named module
    return _create_friendly_module(tlib, modulename)


def _load_tlib(obj):
    # type: (Any) -> typeinfo.ITypeLib
    if isinstance(obj, base_text_type):
        with winreg.OpenKey(winreg.HKEY_CLASSES_ROOT, r""CLSID\%s\TypeLib"" % clsid) as key:
        with winreg.OpenKey(winreg.HKEY_CLASSES_ROOT, r""CLSID\%s\Version"" % clsid) as key:
def _create_module_in_file(modulename, code):
    # type: (str, str) -> types.ModuleType
def _create_module_in_memory(modulename, code):
    # type: (str, str) -> types.ModuleType
def _create_friendly_module(tlib, modulename):
    # type: (typeinfo.ITypeLib, str) -> types.ModuleType
    """"""helper which creates and imports the friendly-named module.""""""
    try:
        mod = _my_import(modulename)
    except Exception as details:
        logger.info(""Could not import %s: %s"", modulename, details)
    else:
        return mod
    # the module is always regenerated if the import fails
    logger.info(""# Generating %s"", modulename)
    # determine the Python module name
    modname = codegenerator.name_wrapper_module(tlib).split(""."")[-1]
    code = ""from comtypes.gen import %s\n"" % modname
    code += ""globals().update(%s.__dict__)\n"" % modname
    code += ""__name__ = '%s'"" % modulename
    if comtypes.client.gen_dir is None:
        return _create_module_in_memory(modulename, code)
    return _create_module_in_file(modulename, code)


def _create_wrapper_module(tlib, pathname):
    # type: (typeinfo.ITypeLib, Optional[str]) -> types.ModuleType
    """"""helper which creates and imports the real typelib wrapper module.""""""
    modulename = codegenerator.name_wrapper_module(tlib)
    if modulename in sys.modules:
        return sys.modules[modulename]
    try:
        return _my_import(modulename)
    except Exception as details:
        logger.info(""Could not import %s: %s"", modulename, details)
    # generate the module since it doesn't exist or is out of date
    logger.info(""# Generating %s"", modulename)
    p = tlbparser.TypeLibParser(tlib)
    if pathname is None:
        pathname = tlbparser.get_tlib_filename(tlib)
    items = list(p.parse().values())
    codegen = codegenerator.CodeGenerator(_get_known_symbols())
    code = codegen.generate_code(items, filename=pathname)
    for ext_tlib in codegen.externals:  # generates dependency COM-lib modules
        GetModule(ext_tlib)
    if comtypes.client.gen_dir is None:
        return _create_module_in_memory(modulename, code)
    return _create_module_in_file(modulename, code)


def _get_known_symbols():
    # type: () -> Dict[str, str]
    known_symbols = {}  # type: Dict[str, str]
        ""ctypes""
            names = mod.__known_symbols__  # type: List[str]
import sys
import comtypes.automation
import comtypes.typeinfo
import comtypes.client
import comtypes.client.lazybind
from comtypes import COMError, IUnknown, _is_object
import comtypes.hresult as hres
    # Wrap an object in a Dispatch instance, exposing methods and properties
    # via fully dynamic dispatch
    if isinstance(obj, ctypes.POINTER(comtypes.automation.IDispatch)):
        except (comtypes.COMError, WindowsError):
        return comtypes.client.lazybind.Dispatch(obj, tinfo)
    def __init__(self, _id, _obj):
    def __call__(self, *args):
    def __getitem__(self, *args):
        return self._obj._comobj.Invoke(self._id, *args,
                                        **dict(_invkind=comtypes.automation.DISPATCH_PROPERTYGET))
    def __setitem__(self, *args):
            self._obj._comobj.Invoke(self._id, *args,
                                        **dict(_invkind=comtypes.automation.DISPATCH_PROPERTYPUTREF))
            self._obj._comobj.Invoke(self._id, *args,
                                        **dict(_invkind=comtypes.automation.DISPATCH_PROPERTYPUT))
    # Expose methods and properties via fully dynamic dispatch
    def __init__(self, comobj):
        self.__dict__[""_ids""] = {} # Tiny optimization: trying not to use GetIDsOfNames more than once
    def __enum(self):
        e = self._comobj.Invoke(-4) # DISPID_NEWENUM
        return e.QueryInterface(comtypes.automation.IEnumVARIANT)

    def __cmp__(self, other):
        if not isinstance(other, _Dispatch):
            return 1
        return cmp(self._comobj, other._comobj)
    def __hash__(self):
    def __getitem__(self, index):
    def QueryInterface(self, *args):
        ""QueryInterface is forwarded to the real com object.""
        return self._comobj.QueryInterface(*args)
    def _FlagAsMethod(self, *names):
    def __getattr__(self, name):
##        tc = self._comobj.GetTypeInfo(0).QueryInterface(comtypes.typeinfo.ITypeComp)
##        dispid = tc.Bind(name)[1].memid
        flags = comtypes.automation.DISPATCH_PROPERTYGET
            (hresult, text, details) = err.args
                # The line break is important for 2to3 to work correctly
                raise
        except:
            # The line break is important for 2to3 to work correctly
            raise
    def __setattr__(self, name, value):
    def __iter__(self):
##    def __setitem__(self, index, value):
##        self._comobj.Invoke(-3, index, value,
##                            _invkind=comtypes.automation.DISPATCH_PROPERTYPUT|comtypes.automation.DISPATCH_PROPERTYPUTREF)
    def __init__(self, enum):
    if sys.version_info >= (3, 0):
        def __next__(self):
            item, fetched = self.enum.Next(1)
            if fetched:
                return item
            raise StopIteration
    else:
        def next(self):
            item, fetched = self.enum.Next(1)
            if fetched:
                return item
            raise StopIteration
            return self.disp._comobj._invoke(self.get.memid,
                                             self.get.invkind,
                                             0,
                                             *arg)
            return self.disp._comobj._invoke(self.get.memid,
                                             self.get.invkind,
                                             0)
        return self.disp._comobj._invoke(self.get.memid,
                                         self.get.invkind,
                                         0,
                                         *[arg])
        return self.disp._comobj._invoke(self.get.memid,
                                            self.get.invkind,
                                            0,
                                            *args)
            self.disp._comobj._invoke(descr.memid,
                                      descr.invkind,
                                      0,
                                      *(name + (value,)))
            self.disp._comobj._invoke(descr.memid,
                                      descr.invkind,
                                      0,
                                      value)
            self.disp._comobj._invoke(descr.memid,
                                      descr.invkind,
                                      0,
                                      name,
                                      value)
        """""" Explicitly disallow iteration. """"""
##        self.__dict__[""_iid""] = tinfo.GetTypeAttr().guid
                info = FuncDesc(memid=descr.memid,
                                invkind=descr.invkind,
                                cParams=descr.cParams,
                                funckind=descr.funckind)
        return isinstance(other, Dispatch) and \
               self._comobj == other._comobj
        return self._comobj._invoke(DISPID_VALUE,
                                    DISPATCH_METHOD | DISPATCH_PROPERTYGET,
                                    0,
                                    *args)
            return self._comobj._invoke(DISPID_VALUE,
                                        DISPATCH_METHOD | DISPATCH_PROPERTYGET,
                                        0,
                                        *args)
        return self._comobj._invoke(DISPID_VALUE,
                                    invkind,
                                    0,
                                    *args)
        punk = self._comobj._invoke(DISPID_NEWENUM,
                                    DISPATCH_METHOD | DISPATCH_PROPERTYGET,
                                    0)
        ('pUnk', POINTER(IUnknown)),
        ('dwCookie', c_ulong),
    _iid_ = GUID('{B196B284-BAB4-101A-B69C-00AA00341D07}')
    _iid_ = GUID('{B196B286-BAB4-101A-B69C-00AA00341D07}')
    _iid_ = GUID('{B196B287-BAB4-101A-B69C-00AA00341D07}')
    if sys.version_info >= (3, 0):
        def __next__(self):
            cp, fetched = self.Next(1)
            if fetched == 0:
                raise StopIteration
            return cp
    else:
        def next(self):
            cp, fetched = self.Next(1)
            if fetched == 0:
                raise StopIteration
            return cp
    _iid_ = GUID('{B196B285-BAB4-101A-B69C-00AA00341D07}')
    if sys.version_info >= (3, 0):
        def __next__(self):
            cp, fetched = self.Next(1)
            if fetched == 0:
                raise StopIteration
            return cp
    else:
        def next(self):
            cp, fetched = self.Next(1)
            if fetched == 0:
                raise StopIteration
            return cp
    COMMETHOD([], HRESULT, 'EnumConnectionPoints',
              ( ['out'], POINTER(POINTER(IEnumConnectionPoints)), 'ppEnum' )),
    COMMETHOD([], HRESULT, 'FindConnectionPoint',
              ( ['in'], POINTER(_GUID), 'riid' ),
              ( ['out'], POINTER(POINTER(IConnectionPoint)), 'ppCP' )),
    COMMETHOD([], HRESULT, 'GetConnectionInterface',
              ( ['out'], POINTER(_GUID), 'pIID' )),
    COMMETHOD([], HRESULT, 'GetConnectionPointContainer',
              ( ['out'], POINTER(POINTER(IConnectionPointContainer)), 'ppCPC' )),
    COMMETHOD([], HRESULT, 'Advise',
              ( ['in'], POINTER(IUnknown), 'pUnkSink' ),
              ( ['out'], POINTER(c_ulong), 'pdwCookie' )),
    COMMETHOD([], HRESULT, 'Unadvise',
              ( ['in'], c_ulong, 'dwCookie' )),
    COMMETHOD([], HRESULT, 'EnumConnections',
              ( ['out'], POINTER(POINTER(IEnumConnections)), 'ppEnum' )),
    COMMETHOD([], HRESULT, 'Next',
              ( ['in'], c_ulong, 'cConnections' ),
              ( ['out'], POINTER(tagCONNECTDATA), 'rgcd' ),
              ( ['out'], POINTER(c_ulong), 'pcFetched' )),
    COMMETHOD([], HRESULT, 'Skip',
              ( ['in'], c_ulong, 'cConnections' )),
    COMMETHOD([], HRESULT, 'Reset'),
    COMMETHOD([], HRESULT, 'Clone',
              ( ['out'], POINTER(POINTER(IEnumConnections)), 'ppEnum' )),
    COMMETHOD([], HRESULT, 'Next',
              ( ['in'], c_ulong, 'cConnections' ),
              ( ['out'], POINTER(POINTER(IConnectionPoint)), 'ppCP' ),
              ( ['out'], POINTER(c_ulong), 'pcFetched' )),
    COMMETHOD([], HRESULT, 'Skip',
              ( ['in'], c_ulong, 'cConnections' )),
    COMMETHOD([], HRESULT, 'Reset'),
    COMMETHOD([], HRESULT, 'Clone',
              ( ['out'], POINTER(POINTER(IEnumConnectionPoints)), 'ppEnum' )),
if sys.version_info >= (3, 0):
    base_text_type = str
else:
    base_text_type = basestring
        COMMETHOD([], HRESULT, 'SetGUID',
                  (['in'], POINTER(GUID), ""rguid"")),
        COMMETHOD([], HRESULT, 'SetSource',
                  (['in'], LPCOLESTR, ""szSource"")),
        COMMETHOD([], HRESULT, 'SetDescription',
                  (['in'], LPCOLESTR, ""szDescription"")),
        COMMETHOD([], HRESULT, 'SetHelpFile',
                  (['in'], LPCOLESTR, ""szHelpFile"")),
        COMMETHOD([], HRESULT, 'SetHelpContext',
                  (['in'], DWORD, ""dwHelpContext""))
        ]
        COMMETHOD([], HRESULT, 'GetGUID',
                  (['out'], POINTER(GUID), ""pGUID"")),
        COMMETHOD([], HRESULT, 'GetSource',
                  (['out'], POINTER(BSTR), ""pBstrSource"")),
        COMMETHOD([], HRESULT, 'GetDescription',
                  (['out'], POINTER(BSTR), ""pBstrDescription"")),
        COMMETHOD([], HRESULT, 'GetHelpFile',
                  (['out'], POINTER(BSTR), ""pBstrHelpFile"")),
        COMMETHOD([], HRESULT, 'GetHelpContext',
                  (['out'], POINTER(DWORD), ""pdwHelpContext"")),
        ]
        COMMETHOD([], HRESULT, 'InterfaceSupportsErrorInfo',
                  (['in'], POINTER(GUID), 'riid'))
        ]
def ReportError(text, iid,
                clsid=None, helpfile=None, helpcontext=0, hresult=DISP_E_EXCEPTION):
        if isinstance(clsid, base_text_type):
            ei.SetSource(progid) # progid for the class or application that created the error
def ReportException(hresult, iid, clsid=None, helpfile=None, helpcontext=None,
                    stacklevel=None):
    return ReportError(text, iid,
                       clsid=clsid, helpfile=helpfile, helpcontext=helpcontext,
                       hresult=hresult)
__all__ = [""ICreateErrorInfo"", ""IErrorInfo"", ""ISupportErrorInfo"",
           ""ReportError"", ""ReportException"",
           ""SetErrorInfo"", ""GetErrorInfo"", ""CreateErrorInfo""]
from comtypes import IUnknown, STDMETHOD, COMMETHOD, \
     GUID, HRESULT, CoCreateInstance, CLSCTX_INPROC_SERVER
        STDMETHOD(HRESULT, ""RegisterInterfaceInGlobal"",
                  [POINTER(IUnknown), POINTER(GUID), POINTER(DWORD)]),
        STDMETHOD(HRESULT, ""GetInterfaceFromGlobal"",
                  [DWORD, POINTER(GUID), POINTER(POINTER(IUnknown))]),
        ]
git = CoCreateInstance(CLSID_StdGlobalInterfaceTable,
                       interface=IGlobalInterfaceTable,
                       clsctx=CLSCTX_INPROC_SERVER)
__all__ = [""RegisterInterfaceInGlobal"", ""RevokeInterfaceFromGlobal"", ""GetInterfaceFromGlobal""]
    tlib = CreateTypeLib(""foo.bar"") # we don not save it later
E_UNEXPECTED = -2147418113 #0x8000FFFFL
E_NOTIMPL = -2147467263 #0x80004001L
E_NOINTERFACE = -2147467262 #0x80004002L
E_POINTER = -2147467261 #0x80004003L
E_FAIL = -2147467259 #0x80004005L
E_INVALIDARG = -2147024809 #0x80070057L
E_OUTOFMEMORY = -2147024882 # 0x8007000EL
CLASS_E_NOAGGREGATION = -2147221232 #0x80040110L
CLASS_E_CLASSNOTAVAILABLE = -2147221231 #0x80040111L
CO_E_CLASSSTRING = -2147221005 #0x800401F3L
TYPE_E_ELEMENTNOTFOUND = -2147352077 #0x8002802BL
TYPE_E_REGISTRYACCESS = -2147319780 #0x8002801CL
TYPE_E_CANTLOADLIBRARY = -2147312566 #0x80029C4AL
DISP_E_PARAMNOTOPTIONAL = -2147352561 #0x8002000F
DISP_E_BADPARAMCOUNT = -2147352562 #0x8002000E
DISP_E_ARRAYISLOCKED = -2147352563 #0x8002000D
DISP_E_UNKNOWNLCID = -2147352564 #0x8002000C
DISP_E_BADINDEX = -2147352565 #0x8002000B
DISP_E_OVERFLOW = -2147352566 #0x8002000A
DISP_E_EXCEPTION = -2147352567 #0x80020009
DISP_E_BADVARTYPE = -2147352568 #0x80020008
DISP_E_NONAMEDARGS = -2147352569 #0x80020007
DISP_E_UNKNOWNNAME = -2147352570 #0x80020006
DISP_E_TYPEMISMATCH = -2147352571 #0800020005
DISP_E_PARAMNOTFOUND = -2147352572 #0x80020004
DISP_E_MEMBERNOTFOUND = -2147352573 #0x80020003
DISP_E_UNKNOWNINTERFACE = -2147352575 #0x80020001

RPC_E_CHANGED_MODE = -2147417850 # 0x80010106
RPC_E_SERVERFAULT = -2147417851 # 0x80010105
    def emit(self, record,
             writeA=ctypes.windll.kernel32.OutputDebugStringA,
             writeW=ctypes.windll.kernel32.OutputDebugStringW):
            writeW(text + u""\n"")
    parser.optionxform = str # use case sensitive option names!
    DEFAULTS = {""handler"": ""StreamHandler()"",
                ""format"": ""%(levelname)s:%(name)s:%(message)s"",
                ""level"": ""WARNING""}

                return # got WM_QUIT

            no_replace = getattr(value, '__no_replace', False)
    _iid_ = GUID('{3127CA40-446E-11CE-8135-00AA004BB851}')
        COMMETHOD([], HRESULT, 'AddError',
                  ( ['in'], WSTRING, 'pszPropName' ),
                  ( ['in'], POINTER(tagEXCEPINFO), 'pExcepInfo' )),
        ]
    _iid_ = GUID('{55272A00-42CB-11CE-8135-00AA004BB851}')
        COMMETHOD([], HRESULT, 'Read',
                  ( ['in'], WSTRING, 'pszPropName' ),
                  ( ['in', 'out'], POINTER(VARIANT), 'pVar' ),
                  ( ['in'], POINTER(IErrorLog), 'pErrorLog' )),
##                  ( ['in', 'out'], POINTER(IErrorLog), 'pErrorLog' )),
        COMMETHOD([], HRESULT, 'Write',
                  ( ['in'], WSTRING, 'pszPropName' ),
                  ( ['in'], POINTER(VARIANT), 'pVar' )),
        ]
    _iid_ = GUID('{37D84F60-42CB-11CE-8135-00AA004BB851}')
        COMMETHOD([], HRESULT, 'InitNew'),
        COMMETHOD([], HRESULT, 'Load',
                  ( ['in'], POINTER(IPropertyBag), 'pPropBag' ),
                  ( ['in'], POINTER(IErrorLog), 'pErrorLog' )),
        COMMETHOD([], HRESULT, 'Save',
                  ( ['in'], POINTER(IPropertyBag), 'pPropBag' ),
                  ( ['in'], c_int, 'fClearDirty' ),
                  ( ['in'], c_int, 'fSaveAllProperties' )),
        ]
        ('dwType', c_ulong),
        ('vt', c_ushort),
        ('cfType', CLIPFORMAT),
        ('dwHint', c_ulong),
        ('pstrName', WSTRING),
        ('clsid', GUID),
        ]
    _iid_ = GUID('{22F55882-280B-11D0-A8A9-00A0C90C2004}')
        COMMETHOD([], HRESULT, 'Read',
                  ( ['in'], c_ulong, 'cProperties' ),
                  ( ['in'], POINTER(tagPROPBAG2), 'pPropBag' ),
                  ( ['in'], POINTER(IErrorLog), 'pErrLog' ),
                  ( ['out'], POINTER(VARIANT), 'pvarValue' ),
                  ( ['out'], POINTER(HRESULT), 'phrError' )),
        COMMETHOD([], HRESULT, 'Write',
                  ( ['in'], c_ulong, 'cProperties' ),
                  ( ['in'], POINTER(tagPROPBAG2), 'pPropBag' ),
                  ( ['in'], POINTER(VARIANT), 'pvarValue' )),
        COMMETHOD([], HRESULT, 'CountProperties',
                  ( ['out'], POINTER(c_ulong), 'pcProperties' )),
        COMMETHOD([], HRESULT, 'GetPropertyInfo',
                  ( ['in'], c_ulong, 'iProperty' ),
                  ( ['in'], c_ulong, 'cProperties' ),
                  ( ['out'], POINTER(tagPROPBAG2), 'pPropBag' ),
                  ( ['out'], POINTER(c_ulong), 'pcProperties' )),
        COMMETHOD([], HRESULT, 'LoadObject',
                  ( ['in'], WSTRING, 'pstrName' ),
                  ( ['in'], c_ulong, 'dwHint' ),
                  ( ['in'], POINTER(IUnknown), 'punkObject' ),
                  ( ['in'], POINTER(IErrorLog), 'pErrLog' )),
        ]
    _iid_ = GUID('{22F55881-280B-11D0-A8A9-00A0C90C2004}')
        COMMETHOD([], HRESULT, 'InitNew'),
        COMMETHOD([], HRESULT, 'Load',
                  ( ['in'], POINTER(IPropertyBag2), 'pPropBag' ),
                  ( ['in'], POINTER(IErrorLog), 'pErrLog' )),
        COMMETHOD([], HRESULT, 'Save',
                  ( ['in'], POINTER(IPropertyBag2), 'pPropBag' ),
                  ( ['in'], c_int, 'fClearDirty' ),
                  ( ['in",buggy
"
def binary(obj):
    return bytes(obj)


    _fields_ = [(""Data1"", DWORD), (""Data2"", WORD), (""Data3"", WORD), (""Data4"", BYTE * 8)]
            _CLSIDFromString(str(name), byref(self))
        return 'GUID(""%s"")' % str(self)

        return isinstance(other, GUID) and binary(self) == binary(other)
        return GUID(str(self))
        """"""Get guid from progid, ...""""""
        elif isinstance(progid, str):
            _CLSIDFromProgID(str(progid), byref(inst))
from ctypes import _Pointer, _SimpleCData

try:
    from _ctypes import COMError
except ImportError as e:
    msg = ""\n"".join(
        (
            ""COM technology not available (maybe it's the wrong platform)."",
            ""Note that COM is only supported on Windows."",
            ""For more details, please check: ""
            ""https://learn.microsoft.com/en-us/windows/win32/com"",
        )
    )
    raise ImportError(msg) from e
# fmt: off
from typing import (
    Any, ClassVar, overload, TYPE_CHECKING, TypeVar,
    # instead of `builtins`. see PEP585
    Dict, List, Tuple, Type,
    # instead of `collections.abc`. see PEP585
    Callable, Iterable, Iterator,
    # instead of `A | B` and `None | A`. see PEP604
    Optional, Union as _UnionT,  # avoiding confusion with `ctypes.Union`
)
# fmt: on
    from comtypes import hints as hints  # type: ignore
else:
    _CData = _SimpleCData.__mro__[:-1][-1]
    ComMemberGenerator,
    _ComMemberSpec,
    DispMemberGenerator,
    _DispMemberSpec,
    _encode_idl,
    _resolve_argspec,





pythonapi.PyInstanceMethod_New.argtypes = [py_object]
pythonapi.PyInstanceMethod_New.restype = py_object
PyInstanceMethod_Type = type(pythonapi.PyInstanceMethod_New(id))


def instancemethod(func, inst, cls):
    mth = PyInstanceMethod_Type(func)
    if inst is None:
        return mth
    return mth.__get__(inst)


# class IDLWarning(UserWarning):
#    ""Warn about questionable type information""
tagCLSCTX = c_int  # enum
_ole32_nohresult = windll.ole32  # use this for functions that don't return a HRESULT
COINIT_MULTITHREADED = 0x0
COINIT_DISABLE_OLE1DDE = 0x4



def _shutdown(
    func=_ole32_nohresult.CoUninitialize,
    _debug=logger.debug,
    _exc_clear=getattr(sys, ""exc_clear"", lambda: None),
):
        try:
            func()
        except WindowsError:
            pass






    _case_insensitive_: bool
    _iid_: GUID
    _methods_: List[_ComMemberSpec]
    _disp_methods_: List[_DispMemberSpec]
        p = type(_compointer_base)(
            ""POINTER(%s)"" % new_cls.__name__,
            _ptr_bases,
            {""__com_interface__"": new_cls, ""_needs_com_addref_"": None},
        )

                    if fixed_name != name:  # prevent unbounded recursion
                    object.__setattr__(
                        self, self.__map_case__.get(name.lower(), name), value
                    )

            # assert self.__dict__.get(""_methods_"", None) is None




    def _make_dispmethods(self, methods: List[_DispMemberSpec]) -> None:
    def _make_methods(self, methods: List[_ComMemberSpec]) -> None:
            com_interface_registry[str(iid)] = self



class _compointer_base(c_void_p, metaclass=_compointer_meta):

        return cmp(
            super(_compointer_base, self).value, super(_compointer_base, other).value
        )
        return (
            super(_compointer_base, self).value == super(_compointer_base, other).value
        )




        if self._b_base_ is None or self._needsfree:


class helpstring(str):





def STDMETHOD(restype, name, argtypes=()) -> _ComMemberSpec:

def DISPMETHOD(idlflags, restype, name, *argspec) -> _DispMemberSpec:

def DISPPROPERTY(idlflags, proptype, name) -> _DispMemberSpec:


def COMMETHOD(idlflags, restype, methodname, *argspec) -> _ComMemberSpec:
_T_IUnknown = TypeVar(""_T_IUnknown"", bound=""IUnknown"")

    class _IUnknown_Base(c_void_p, metaclass=_cominterface_meta):

        __com_QueryInterface: Callable[[Any, Any], int]
        __com_AddRef: Callable[[], int]
        __com_Release: Callable[[], int]


class IUnknown(_IUnknown_Base, metaclass=_cominterface_meta):
    _case_insensitive_: ClassVar[bool] = False
    _iid_: ClassVar[GUID] = GUID(""{00000000-0000-0000-C000-000000000046}"")
    _methods_: ClassVar[List[_ComMemberSpec]] = [
        STDMETHOD(HRESULT, ""QueryInterface"", [POINTER(GUID), POINTER(c_void_p)]),
        STDMETHOD(c_ulong, ""Release""),
    ]
    def QueryInterface(
        self, interface: Type[_T_IUnknown], iid: Optional[GUID] = None
    ) -> _T_IUnknown:
        clsid = self.__dict__.get(""__clsid"")
            p.__dict__[""__clsid""] = clsid
    def AddRef(self) -> int:
    def Release(self) -> int:
    _iid_ = GUID(""{0000010C-0000-0000-C000-000000000046}"")
        COMMETHOD([], HRESULT, ""GetClassID"", ([""out""], POINTER(GUID), ""pClassID"")),
    ]
        # Should this be ""normal"" method that calls `self._GetClassID`?
        def GetClassID(self) -> GUID:
            """"""Returns the CLSID that uniquely represents an object class that
            defines the code that can manipulate the object's data.
            """"""
            ...
    _iid_ = GUID(""{6D5140C1-7436-11CE-8034-00AA006009FA}"")
    _QueryService: Callable[[Any, Any, Any], int]
    def QueryService(
        self, serviceIID: GUID, interface: Type[_T_IUnknown]
    ) -> _T_IUnknown:
        COMMETHOD(
            [],
            HRESULT,
            ""QueryService"",
            ([""in""], POINTER(GUID), ""guidService""),
            ([""in""], POINTER(GUID), ""riid""),
            ([""in""], POINTER(c_void_p), ""ppvObject""),
        )
    ]

@overload
def CoGetObject(displayname: str, interface: None) -> IUnknown:
    ...


@overload
def CoGetObject(displayname: str, interface: Type[_T_IUnknown]) -> _T_IUnknown:
    ...


def CoGetObject(displayname: str, interface: Optional[Type[IUnknown]]) -> IUnknown:
    _ole32.CoGetObject(str(displayname), None, byref(interface._iid_), byref(punk))
_pUnkOuter = Type[""_Pointer[IUnknown]""]


@overload
def CoCreateInstance(
    clsid: GUID,
    interface: None = None,
    clsctx: Optional[int] = None,
    punkouter: Optional[_pUnkOuter] = None,
) -> IUnknown:
    ...
@overload
def CoCreateInstance(
    clsid: GUID,
    interface: Type[_T_IUnknown],
    clsctx: Optional[int] = None,
    punkouter: Optional[_pUnkOuter] = None,
) -> _T_IUnknown:
    ...


def CoCreateInstance(
    clsid: GUID,
    interface: Optional[Type[IUnknown]] = None,
    clsctx: Optional[int] = None,
    punkouter: Optional[_pUnkOuter] = None,
) -> IUnknown:




    _CoGetClassObject(clsid, clsctx, pServerInfo, interface._iid_, byref(p))
@overload
def GetActiveObject(clsid: GUID, interface: None = None) -> IUnknown:
    ...


@overload
def GetActiveObject(clsid: GUID, interface: Type[_T_IUnknown]) -> _T_IUnknown:
    ...

def GetActiveObject(
    clsid: GUID, interface: Optional[Type[IUnknown]] = None
) -> IUnknown:
    _fields_ = [(""pIID"", POINTER(GUID)), (""pItf"", POINTER(c_void_p)), (""hr"", HRESULT)]
        pIID: GUID
        pItf: _Pointer[c_void_p]
        hr: HRESULT

        (""User"", POINTER(c_ushort)),
        (""UserLength"", c_ulong),
        (""Domain"", POINTER(c_ushort)),
        (""DomainLength"", c_ulong),
        (""Password"", POINTER(c_ushort)),
        (""PasswordLength"", c_ulong),
        (""Flags"", c_ulong),



        (""dwAuthnSvc"", c_ulong),
        (""dwAuthzSvc"", c_ulong),
        (""pwszServerPrincName"", c_wchar_p),
        (""dwAuthnLevel"", c_ulong),
        (""dwImpersonationLevel"", c_ulong),
        (""pAuthIdentityData"", POINTER(_COAUTHIDENTITY)),
        (""dwCapabilities"", c_ulong),



        (""dwReserved1"", c_ulong),
        (""pwszName"", c_wchar_p),
        (""pAuthInfo"", POINTER(_COAUTHINFO)),
        (""dwReserved2"", c_ulong),
        dwReserved1: int
        pwszName: Optional[str]
        pAuthInfo: _COAUTHINFO
        dwReserved2: int


_CoGetClassObject.argtypes = [
    POINTER(GUID),
    DWORD,
    POINTER(COSERVERINFO),
    POINTER(GUID),
    POINTER(c_void_p),
]

        (""cbStruct"", c_ulong),
        (""grfFlags"", c_ulong),
        (""grfMode"", c_ulong),
        (""dwTickCountDeadline"", c_ulong),



        (""cbStruct"", c_ulong),
        (""grfFlags"", c_ulong),
        (""grfMode"", c_ulong),
        (""dwTickCountDeadline"", c_ulong),
        (""dwTrackFlags"", c_ulong),
        (""dwClassContext"", c_ulong),
        (""locale"", c_ulong),
        (""pServerInfo"", POINTER(_COSERVERINFO)),


# Structures for security setups
        (""User"", POINTER(c_ushort)),
        (""UserLength"", c_ulong),
        (""Domain"", POINTER(c_ushort)),
        (""DomainLength"", c_ulong),
        (""Password"", POINTER(c_ushort)),
        (""PasswordLength"", c_ulong),
        (""Flags"", c_ulong),



        (""dwAuthnSvc"", c_ulong),
        (""dwAuthzSvc"", c_ulong),
        (""pAuthInfo"", POINTER(_SEC_WINNT_AUTH_IDENTITY)),



        (""cAuthInfo"", c_ulong),
        (""pAuthInfo"", POINTER(_SOLE_AUTHENTICATION_INFO)),
SOLE_AUTHENTICATION_LIST = _SOLE_AUTHENTICATION_LIST

@overload
def CoCreateInstanceEx(
    clsid: GUID,
    interface: None = None,
    clsctx: Optional[int] = None,
    machine: Optional[str] = None,
    pServerInfo: Optional[COSERVERINFO] = None,
) -> IUnknown:
    ...


@overload
def CoCreateInstanceEx(
    clsid: GUID,
    interface: Type[_T_IUnknown],
    clsctx: Optional[int] = None,
    machine: Optional[str] = None,
    pServerInfo: Optional[COSERVERINFO] = None,
) -> _T_IUnknown:
    ...


def CoCreateInstanceEx(
    clsid: GUID,
    interface: Optional[Type[IUnknown]] = None,
    clsctx: Optional[int] = None,
    machine: Optional[str] = None,
    pServerInfo: Optional[COSERVERINFO] = None,
) -> IUnknown:
        clsctx = CLSCTX_LOCAL_SERVER | CLSCTX_REMOTE_SERVER
    _ole32.CoCreateInstanceEx(
        byref(clsid), None, clsctx, pServerInfo, 1, byref(multiqi)
    )

class CoClass(COMObject, metaclass=_coclass_meta):


# fmt: off
    ""BIND_OPTS"", ""tagBIND_OPTS"", ""BINDOPTS2"", ""tagBIND_OPTS2"", ""BSTR"",
    ""_check_version"", ""CLSCTX"", ""tagCLSCTX"", ""CLSCTX_ALL"",
    ""CLSCTX_DISABLE_AAA"", ""CLSCTX_ENABLE_AAA"", ""CLSCTX_ENABLE_CODE_DOWNLOAD"",
    ""CLSCTX_FROM_DEFAULT_CONTEXT"", ""CLSCTX_INPROC"", ""CLSCTX_INPROC_HANDLER"",
    ""CLSCTX_INPROC_HANDLER16"", ""CLSCTX_INPROC_SERVER"",
    ""CLSCTX_INPROC_SERVER16"", ""CLSCTX_LOCAL_SERVER"", ""CLSCTX_NO_CODE_DOWNLOAD"",
    ""CLSCTX_NO_CUSTOM_MARSHAL"", ""CLSCTX_NO_FAILURE_LOG"",
    ""CLSCTX_REMOTE_SERVER"", ""CLSCTX_RESERVED1"", ""CLSCTX_RESERVED2"",
    ""CLSCTX_RESERVED3"", ""CLSCTX_RESERVED4"", ""CLSCTX_RESERVED5"",
    ""CLSCTX_SERVER"", ""_COAUTHIDENTITY"", ""COAUTHIDENTITY"", ""_COAUTHINFO"",
    ""COAUTHINFO"", ""CoClass"", ""CoCreateInstance"", ""CoCreateInstanceEx"",
    ""_CoGetClassObject"", ""CoGetClassObject"", ""CoGetObject"",
    ""COINIT_APARTMENTTHREADED"", ""COINIT_DISABLE_OLE1DDE"",
    ""COINIT_MULTITHREADED"", ""COINIT_SPEED_OVER_MEMORY"", ""CoInitialize"",
    ""CoInitializeEx"", ""COMError"", ""COMMETHOD"", ""COMObject"", ""_COSERVERINFO"",
    ""COSERVERINFO"", ""CoUninitialize"", ""dispid"", ""DISPMETHOD"", ""DISPPROPERTY"",
    ""DWORD"", ""EOAC_NONE"", ""GetActiveObject"", ""_GUID"", ""GUID"", ""helpstring"",
    ""IID"", ""IPersist"", ""IServiceProvider"", ""IUnknown"", ""MULTI_QI"",
    ""ReturnHRESULT"", ""RPC_C_AUTHN_LEVEL_CONNECT"", ""RPC_C_AUTHN_WINNT"",
    ""RPC_C_AUTHZ_NONE"", ""RPC_C_IMP_LEVEL_IMPERSONATE"",
    ""_SEC_WINNT_AUTH_IDENTITY"", ""SEC_WINNT_AUTH_IDENTITY"",
    ""SEC_WINNT_AUTH_IDENTITY_UNICODE"", ""_SOLE_AUTHENTICATION_INFO"",
    ""SOLE_AUTHENTICATION_INFO"", ""_SOLE_AUTHENTICATION_LIST"",
    ""SOLE_AUTHENTICATION_LIST"", ""STDMETHOD"", ""wireHWND"",
# fmt: on
    FormatError,
    POINTER,
    Structure,
    WINFUNCTYPE,
    byref,
    c_long,
    c_void_p,
    oledll,
    pointer,
    windll,
import queue
    DISP_E_BADINDEX,
    DISP_E_MEMBERNOTFOUND,
    E_FAIL,
    E_NOINTERFACE,
    E_INVALIDARG,
    E_NOTIMPL,
    RPC_E_CHANGED_MODE,
    S_FALSE,
    S_OK,
        if isinstance(code, int):
    raise TypeError(
        ""Expected comtypes.COMERROR or WindowsError instance, got %s""
        % type(exc).__name__
    )
        _debug(""unimplemented method %s_%s called"", interface_name, method_name)

            return ReportError(text, iid=interface._iid_, clsid=clsid, hresult=hresult)
            _error(
                ""Exception in %s.%s implementation:"",
                interface.__name__,
                mthname,
                exc_info=True,
            )
            _warning(""Unimplemented method %s.%s called"", interface.__name__, mthname)
            _error(
                ""Exception in %s.%s implementation:"",
                interface.__name__,
                mthname,
                exc_info=True,
            )

        has_outargs = bool([x[0] for x in paramflags if x[0] & 2])

        if a & 2:
        if a & 1 or a == 0:
    # if args_in != code.co_argcount - 1:
    #     return catch_errors(inst, mth, interface, mthname)
        # for a in outargs:
        #     if not a:
        #         return E_POINTER
        # make argument list for handler by index array built above
            return ReportError(text, iid=interface._iid_, clsid=clsid, hresult=hresult)
            _error(
                ""Exception in %s.%s implementation:"",
                interface.__name__,
                mthname,
                exc_info=True,
            )
            return ReportError(msg, iid=interface._iid_, clsid=clsid, hresult=hr)
            _error(
                ""Exception in %s.%s implementation:"",
                interface.__name__,
                mthname,
                exc_info=True,
            )
            _warning(""Unimplemented method %s.%s called"", interface.__name__, mthname)
            _error(
                ""Exception in %s.%s implementation:"",
                interface.__name__,
                mthname,
                exc_info=True,
            )

        _debug(""%r: %s.%s not implemented"", self.inst, interface.__name__, mthname)









                if (
                    hasattr(self, ""_outgoing_interfaces_"")
                    and IProvideClassInfo2 not in interfaces
                ):
                    if ""propget"" in idlflags:
                    elif ""propput"" in idlflags:
                    elif ""propputref"" in idlflags:
                            argspec = argspec + (([""out""], restype, """"),)
                    self.__make_dispentry(
                        finder, interface, mthname, idlflags, argspec, invkind
                    )
                        argspec += (([""out""], restype, """"),)
                    self.__make_dispentry(
                        finder,
                        interface,
                        ""_get_"" + mthname,
                        idlflags,
                        argspec,
                        2,  # DISPATCH_PROPERTYGET
                    )
                    if not ""readonly"" in idlflags:
                        self.__make_dispentry(
                            finder, interface, ""_set_"" + mthname, idlflags, argspec, 4
                        )  # DISPATCH_PROPERTYPUT
    def __make_dispentry(self, finder, interface, mthname, idlflags, argspec, invkind):
        paramflags = [((_encode_idl(x[0]), x[1]) + tuple(x[3:])) for x in argspec]
        _debug(""%d active COM objects: Added   %r"", len(COMObject._instances_), obj)
            _debug(""%d active COM objects: Removed %r"", len(COMObject._instances_), obj)

    def IUnknown_AddRef(
        self, this, __InterlockedIncrement=_InterlockedIncrement, _debug=_debug
    ):
    def IUnknown_Release(
        self, this, __InterlockedDecrement=_InterlockedDecrement, _debug=_debug
    ):
            raise COMError(
                E_NOINTERFACE, FormatError(E_NOINTERFACE), (None, None, 0, None, None)
            )
    def IDispatch_GetIDsOfNames(self, this, riid, rgszNames, cNames, lcid, rgDispId):
        return windll.oleaut32.DispGetIDsOfNames(tinfo, rgszNames, cNames, rgDispId)

    def IDispatch_Invoke(
        self,
        this,
        dispIdMember,
        riid,
        lcid,
        wFlags,
        pDispParams,
        pVarResult,
        pExcepInfo,
        puArgErr,
    ):
                ptr,
                tinfo,
                dispIdMember,
                wFlags,
                pDispParams,
                pVarResult,
                pExcepInfo,
                puArgErr,
            args = [
                params.rgvarg[i].value for i in reversed(list(range(params.cNamedArgs)))
            ]
            named_indexes = [
                params.rgdispidNamedArgs[i] for i in range(params.cNamedArgs)
            ]

from typing import (
    Any,
    Callable,
    Dict,
    Iterator,
    List,
    NamedTuple,
    Optional,
    Tuple,
    Type,
    Union as _UnionT,
)

from comtypes import _CData

_PositionalParamFlagType = Tuple[int, Optional[str]]
_OptionalParamFlagType = Tuple[int, Optional[str], Any]
_ParamFlagType = _UnionT[_PositionalParamFlagType, _OptionalParamFlagType]
_PositionalArgSpecElmType = Tuple[List[str], Type[_CData], str]
_OptionalArgSpecElmType = Tuple[List[str], Type[_CData], str, Any]
_ArgSpecElmType = _UnionT[_PositionalArgSpecElmType, _OptionalArgSpecElmType]
}
def _unpack_argspec(
    idl: List[str],
    typ: Type[_CData],
    name: Optional[str] = None,
    defval: Any = _NOTHING,
) -> Tuple[List[str], Type[_CData], Optional[str], Any]:
def _resolve_argspec(
    items: Tuple[_ArgSpecElmType, ...]
) -> Tuple[Tuple[_ParamFlagType, ...], Tuple[Type[_CData], ...]]:
class _ComMemberSpec(NamedTuple):
    restype: Optional[Type[_CData]]
    name: str
    argtypes: Tuple[Type[_CData], ...]
    paramflags: Optional[Tuple[_ParamFlagType, ...]]
    idlflags: Tuple[_UnionT[str, int], ...]
    doc: Optional[str]
    def is_prop(self) -> bool:
        return _is_spec_prop(self)
class _DispMemberSpec(NamedTuple):
    what: str
    name: str
    idlflags: Tuple[_UnionT[str, int], ...]
    restype: Optional[Type[_CData]]
    argspec: Tuple[_ArgSpecElmType, ...]
    def memid(self) -> int:
    def is_prop(self) -> bool:
        return _is_spec_prop(self)


# Specifier of a slot of method or property.
# This should be `typing.Protocol` if supporting Py3.8+ only.
_MemberSpec = _UnionT[_ComMemberSpec, _DispMemberSpec]


def _is_spec_prop(m: _MemberSpec):
    return any(f in (""propget"", ""propput"", ""propputref"") for f in m.idlflags)

_PropFunc = Optional[Callable[..., Any]]
_DocType = Optional[str]

def _fix_inout_args(
    func: Callable[..., Any],
    argtypes: Tuple[Type[_CData], ...],
    paramflags: Tuple[_ParamFlagType, ...],
) -> Callable[..., Any]:

        outargs: Dict[int, _UnionT[_CData, ""ctypes._CArgObject""]] = {}
        param_index = 0
        # Go through all expected arguments and match them to the provided arguments.
        # `param_index` first counts through the positional and then
        # through the keyword arguments.
            dir_in = direction & 1 == 1
            dir_out = direction & 2 == 2
            is_positional = param_index < len(args)
            if not (dir_in or dir_out):
                # The original code here did not check for this special case and
                # effectively treated `(dir_in, dir_out) == (False, False)` and
                # `(dir_in, dir_out) == (True, False)` the same.
                # In order not to break legacy code we do the same.
                # One example of a function that has neither `dir_in` nor `dir_out`
                # set is `IMFAttributes.GetString`.
                dir_in = True
            if dir_in and dir_out:
                atyp: Type[_CData] = getattr(argtypes[i], ""_type_"")

                def prepare_parameter(v):
                    # parameter was passed, call `from_param()` to
                    # convert it to a `ctypes` type.
                        # Array of or pointer to type `atyp` was passed,
                        # pointer to `atyp` expected.
                        # The `from_param` method of simple types
                        # (`c_int`, `c_double`, ...) returns a `byref` object which
                        # we cannot use since later it will be wrapped in a pointer.
                        # Simply call the constructor with the argument in that case.
                    return v

                if is_positional:
                    v = prepare_parameter(args[param_index])
                    args[param_index] = v
                elif name in kw:
                    v = prepare_parameter(kw[name])
                else:
                    # no parameter was passed, make an empty one of the required type
                    # and pass it as a keyword argument
                    v = atyp()
                    if name is not None:
                        kw[name] = v
                    else:
                        raise TypeError(""Unnamed inout parameters cannot be omitted"")
                outargs[outnum] = v
            if dir_out:
            if dir_in:
                param_index += 1


        # Our interpretation of this code
        # (jonschz, junkmd, see https://github.com/enthought/comtypes/pull/473):
        # - `outnum` counts the total number of 'out' and 'inout' arguments.
        # - `outargs` is a dict consisting of the supplied 'inout' arguments.
        # - The call to `func()` returns the 'out' and 'inout' arguments.
        #   Furthermore, it changes the variables in 'outargs' as a ""side effect""
        # - In a perfect world, it should be fine to just return `rescode`.
        #   But we assume there is a reason why the original authors did not do that.
        #   Instead, they replace the 'inout' variables in `rescode` by those in
        #   'outargs', and call `__ctypes_from_outparam__()` on them.

            # In this case, it is little faster than creating list with
            # `rescode = [rescode]` and getting item with index from the list.

        self._data: Dict[Tuple[str, _DocType, int], List[_PropFunc]] = {}
    def add_propget(
        self, name: str, doc: _DocType, nargs: int, func: Callable[..., Any]
    ) -> None:
    def add_propput(
        self, name: str, doc: _DocType, nargs: int, func: Callable[..., Any]
    ) -> None:
    def add_propputref(
        self, name: str, doc: _DocType, nargs: int, func: Callable[..., Any]
    ) -> None:
    def __iter__(self) -> Iterator[Tuple[str, _DocType, int, _PropFunc, _PropFunc]]:


    def __init__(self, cls_name: str) -> None:
    def add(self, m: _MemberSpec, func: Callable[..., Any]) -> None:
    def __iter__(self) -> Iterator[Tuple[str, _UnionT[property, ""named_property""]]]:
    def to_propget_keys(self, m: _MemberSpec) -> Tuple[str, _DocType, int]:
    def to_propput_keys(self, m: _MemberSpec) -> Tuple[str, _DocType, int]:
    def to_propputref_keys(self, m: _MemberSpec) -> Tuple[str, _DocType, int]:
    def to_propget_keys(self, m: _ComMemberSpec) -> Tuple[str, _DocType, int]:
        return m.name[len(""_get_"") :], m.doc, nargs
    def to_propput_keys(self, m: _ComMemberSpec) -> Tuple[str, _DocType, int]:
        return m.name[len(""_set_"") :], m.doc, nargs
    def to_propputref_keys(self, m: _ComMemberSpec) -> Tuple[str, _DocType, int]:
        return m.name[len(""_setref_"") :], m.doc, nargs
    def to_propget_keys(self, m: _DispMemberSpec) -> Tuple[str, _DocType, int]:
    def to_propput_keys(self, m: _DispMemberSpec) -> Tuple[str, _DocType, int]:
    def to_propputref_keys(self, m: _DispMemberSpec) -> Tuple[str, _DocType, int]:
    def __init__(self, cls_name: str, vtbl_offset: int, iid: comtypes.GUID) -> None:
        self._mths: List[Tuple[str, Callable[..., Any], Callable[..., Any], bool]] = []
    def add(self, m: _ComMemberSpec) -> None:
    def _fix_args(
        self, m: _ComMemberSpec, func: Callable[..., Any]
    ) -> Callable[..., Any]:
            dirflags = [(p[0] & 3) for p in m.paramflags]
    def __init__(self, cls_name: str) -> None:
        self._items: List[Tuple[str, _UnionT[Callable[..., Any], property], bool]] = []
    def add(self, m: _DispMemberSpec) -> None:
            assert not m.argspec  # XXX does not yet work for properties with parameters
    def _make_disp_property(self, m: _DispMemberSpec) -> property:

            return obj.Invoke(memid, _invkind=2)  # DISPATCH_PROPERTYGET



    def _make_disp_method(self, m: _DispMemberSpec) -> Callable[..., Any]:

                return obj.Invoke(
                    memid, _invkind=2, *args, **kw
                )  # DISPATCH_PROPERTYGET


                return obj.Invoke(
                    memid, _invkind=4, *args, **kw
                )  # DISPATCH_PROPERTYPUT


                return obj.Invoke(
                    memid, _invkind=8, *args, **kw
                )  # DISPATCH_PROPERTYPUTREF




            return obj.Invoke(memid, _invkind=1, *args, **kw)  # DISPATCH_METHOD


        """"""Explicitly disallow iteration.""""""




        PTR = _coclass_pointer_meta(
            ""POINTER(%s)"" % klass.__name__,
            (klass, c_void_p),
            {
                ""__ctypes_from_outparam__"": _wrap_coclass,
                ""from_param"": classmethod(_coclass_from_param),
            },
        )


    """"""Class encapsulating all the functionality necessary to allow interop of

        """"""Create a dtype for VARIANT. This requires support for Unions, which
        ptr_typecode = ""<u8"" if is_64bits else ""<u4""
            (""pvRecord"", ptr_typecode),
            (""pRecInfo"", ptr_typecode),
                ""VT_BOOL"",
                ""VT_I1"",
                ""VT_I2"",
                ""VT_I4"",
                ""VT_I8"",
                ""VT_INT"",
                ""VT_UI1"",
                ""VT_UI2"",
                ""VT_UI4"",
                ""VT_UI8"",
                ""VT_UINT"",
                ""VT_R4"",
                ""VT_R8"",
                ""VT_CY"",
                ""c_wchar_p"",
                ""c_void_p"",
                ""pparray"",
                ""bstrVal"",
                ""_tagBRECORD"",
                ""<i2"",
                ""<i1"",
                ""<i2"",
                ""<i4"",
                ""<i8"",
                ""<i4"",
                ""<u1"",
                ""<u2"",
                ""<u4"",
                ""<u8"",
                ""<u4"",
                ""<f4"",
                ""<f8"",
                ""<i8"",
                ptr_typecode,
                ptr_typecode,
                ptr_typecode,
                ptr_typecode,
                _tagBRECORD_format,
            offsets=[0] * 19,  # This is what makes it a union
            (""vt"", ""<u2""),
            (""wReserved1"", ""<u2""),
            (""wReserved2"", ""<u2""),
            (""wReserved3"", ""<u2""),

        """"""Check if a value is an ndarray.
        """"""Check if a value is a datetime64.
        """"""The numpy package.""""""

        """"""Enables numpy/comtypes interop.""""""

# if __debug__:
#     from ctypeslib.dynamic_module import include
#     include(""""""\
#     #define UNICODE
#     #define NO_STRICT
#     #include <windows.h>
#     """""",
#             persist=True)

        (""cElements"", DWORD),
        (""lLbound"", LONG),
    ]



        (""cDims"", USHORT),
        (""fFeatures"", USHORT),
        (""cbElements"", DWORD),
        (""cLocks"", DWORD),
        (""pvData"", PVOID),
        (""rgsabound"", SAFEARRAYBOUND * 1),
    ]














from ctypes.wintypes import DWORD, LONG, UINT, VARIANT_BOOL, WCHAR, WORD
from typing import (
    Any,
    Callable,
    ClassVar,
    List,
    Optional,
    TYPE_CHECKING,
    Tuple,
    Union as _UnionT,

from comtypes import BSTR, COMError, COMMETHOD, GUID, IID, IUnknown, STDMETHOD

if TYPE_CHECKING:
    from comtypes import hints  # type: ignore


VARENUM = c_int  # enum


    _fields_ = [
        (""wReserved"", c_ushort),
        (""scale"", c_ubyte),
        (""sign"", c_ubyte),
        (""Hi32"", c_ulong),
        (""Lo64"", c_ulonglong),
    ]
        """"""Convert a tagDEC struct to Decimal.
            ""-"" if self.sign else """",
        vt: int
        _: ""U_VARIANT1.__tagVARIANT.U_VARIANT2""
        null: ClassVar[""VARIANT""]
        empty: ClassVar[""VARIANT""]
        missing: ClassVar[""VARIANT""]
                    _fields_ = [(""pvRecord"", c_void_p), (""pRecInfo"", POINTER(IUnknown))]

                ]

            _fields_ = [
                (""vt"", VARTYPE),
                (""wReserved1"", c_ushort),
                (""wReserved2"", c_ushort),
                (""wReserved3"", c_ushort),
                (""_"", U_VARIANT2),

        _fields_ = [(""__VARIANT_NAME_2"", __tagVARIANT), (""decVal"", DECIMAL)]

        elif (
            hasattr(value, ""__len__"") and len(value) == 0 and not isinstance(value, str)
        ):
        elif isinstance(value, int):
        elif isinstance(value, str):
            com_days = (
                delta.days + (delta.seconds + delta.microseconds * 1e-6) / 86400.0
            )
            com_days /= comtypes.npsupport.numpy.timedelta64(1, ""D"")

                return None  # XXX?
                return None  # XXX?

        if self.vt == VT_BYREF | VT_VARIANT:
    # these are missing:
    # getter[VT_ERROR]
    # getter[VT_ARRAY]
    # getter[VT_BYREF|VT_UI1]
    # getter[VT_BYREF|VT_I2]
    # getter[VT_BYREF|VT_I4]
    # getter[VT_BYREF|VT_R4]
    # getter[VT_BYREF|VT_R8]
    # getter[VT_BYREF|VT_BOOL]
    # getter[VT_BYREF|VT_ERROR]
    # getter[VT_BYREF|VT_CY]
    # getter[VT_BYREF|VT_DATE]
    # getter[VT_BYREF|VT_BSTR]
    # getter[VT_BYREF|VT_UNKNOWN]
    # getter[VT_BYREF|VT_DISPATCH]
    # getter[VT_BYREF|VT_ARRAY]
    # getter[VT_BYREF|VT_VARIANT]
    # getter[VT_BYREF]
    # getter[VT_BYREF|VT_DECIMAL]
    # getter[VT_BYREF|VT_I1]
    # getter[VT_BYREF|VT_UI2]
    # getter[VT_BYREF|VT_UI4]
    # getter[VT_BYREF|VT_INT]
    # getter[VT_BYREF|VT_UINT]
        _VariantChangeType(self, self, 0, typecode)



    _iid_ = GUID(""{00020404-0000-0000-C000-000000000046}"")
    _idlflags_ = [""hidden""]

    def __next__(self):
        item, fetched = self.Next(1)
        if fetched:
            return item
        raise StopIteration
        # if isinstance(index, slice):
        #     self.Skip(index.start or 0)
        #     return self.Next(index.stop or sys.maxint)
        result = [v._get_value(dynamic=self._dynamic) for v in array[: fetched.value]]

    COMMETHOD(
        [],
        HRESULT,
        ""Next"",
        ([""in""], c_ulong, ""celt""),
        ([""out""], POINTER(VARIANT), ""rgvar""),
        ([""out""], POINTER(c_ulong), ""pceltFetched""),
    ),
    COMMETHOD([], HRESULT, ""Skip"", ([""in""], c_ulong, ""celt"")),
    COMMETHOD([], HRESULT, ""Reset""),
    COMMETHOD(
        [], HRESULT, ""Clone"", ([""out""], POINTER(POINTER(IEnumVARIANT)), ""ppenum"")
    ),
        wCode: int
        wReserved: int
        bstrSource: str
        bstrDescription: str
        bstrHelpFile: str
        dwHelpContext: int
        pvReserved: Optional[int]
        pfnDeferredFillIn: Optional[int]
        scode: int
        return ""<EXCEPINFO %s>"" % (
            (
                self.wCode,
                self.bstrSource,
                self.bstrDescription,
                self.bstrHelpFile,
                self.dwHelpContext,
                self.pfnDeferredFillIn,
                self.scode,
            ),
        )


    (""wCode"", WORD),
    (""wReserved"", WORD),
    (""bstrSource"", BSTR),
    (""bstrDescription"", BSTR),
    (""bstrHelpFile"", BSTR),
    (""dwHelpContext"", DWORD),
    (""pvReserved"", c_void_p),
    # ('pfnDeferredFillIn', WINFUNCTYPE(HRESULT, POINTER(tagEXCEPINFO))),
    (""pfnDeferredFillIn"", c_void_p),
    (""scode"", SCODE),

        rgvarg: Array[VARIANT]
        rgdispidNamedArgs: _Pointer[DISPID]
        cArgs: int
        cNamedArgs: int
        (""rgvarg"", POINTER(VARIANTARG)),
        (""rgdispidNamedArgs"", POINTER(DISPID)),
        (""cArgs"", UINT),
        (""cNamedArgs"", UINT),



RawGetIDsOfNamesFunc = Callable[
    [_byref_type, ""Array[c_wchar_p]"", int, int, ""Array[DISPID]""], int
]
# fmt: off
RawInvokeFunc = Callable[
    [
        int, _byref_type, int, int,  # dispIdMember, riid, lcid, wFlags
        _UnionT[_byref_type, DISPPARAMS],  # *pDispParams
        _UnionT[_byref_type, VARIANT],  # pVarResult
        _UnionT[_byref_type, EXCEPINFO, None],  # pExcepInfo
        _UnionT[_byref_type, c_uint],  # puArgErr
    ],
    int,
]
# fmt: on

    _disp_methods_: ClassVar[List[comtypes._DispMemberSpec]]
    _GetTypeInfo: Callable[[int, int], IUnknown]
    __com_GetIDsOfNames: RawGetIDsOfNamesFunc
    __com_Invoke: RawInvokeFunc
        COMMETHOD([], HRESULT, ""GetTypeInfoCount"", ([""out""], POINTER(UINT))),
        COMMETHOD(
            [],
            HRESULT,
            ""GetTypeInfo"",
            ([""in""], UINT, ""index""),
            ([""in""], LCID, ""lcid"", 0),
            # Normally, we would declare this parameter in this way:
            # (['out'], POINTER(POINTER(ITypeInfo)) ) ),
            # but we cannot import comtypes.typeinfo at the top level (recursive imports!).
            ([""out""], POINTER(POINTER(IUnknown))),
        ),
        STDMETHOD(
            HRESULT,
            ""GetIDsOfNames"",
            [POINTER(IID), POINTER(c_wchar_p), UINT, LCID, POINTER(DISPID)],
        ),
        STDMETHOD(
            HRESULT,
            ""Invoke"",
            [
                DISPID,
                POINTER(IID),
                LCID,
                WORD,
                POINTER(DISPPARAMS),
                POINTER(VARIANT),
                POINTER(EXCEPINFO),
                POINTER(UINT),
            ],
        ),
    def GetTypeInfo(self, index: int, lcid: int = 0) -> ""hints.ITypeInfo"":

    def GetIDsOfNames(self, *names: str, **kw: Any) -> List[int]:
    def _invoke(self, memid: int, invkind: int, lcid: int, *args: Any) -> Any:
        self.__com_Invoke(memid, riid_null, lcid, invkind, dp, var, None, argerr)
    def __make_dp(self, _invkind: int, *args: Any) -> DISPPARAMS:
        array = (VARIANT * len(args))()
        for i, a in enumerate(args[::-1]):
            array[i].value = a
        dp = DISPPARAMS()
        dp.cArgs = len(args)
        dp.rgvarg = array
        if _invkind in (DISPATCH_PROPERTYPUT, DISPATCH_PROPERTYPUTREF):  # propput
            dp.cNamedArgs = 1
            dp.rgdispidNamedArgs = pointer(DISPID(DISPID_PROPERTYPUT))
        else:
            dp.cNamedArgs = 0
        return dp

    def Invoke(self, dispid: int, *args: Any, **kw: Any) -> Any:
        _invkind = kw.pop(""_invkind"", 1)  # DISPATCH_METHOD
        dp = self.__make_dp(_invkind, *args)
            self.__com_Invoke(
                dispid,
                riid_null,
                _lcid,
                _invkind,
                byref(dp),
                byref(result),
                byref(excepinfo),
                byref(argerr),
            )
                details = (
                    excepinfo.bstrDescription,
                    excepinfo.bstrSource,
                    excepinfo.bstrHelpFile,
                    excepinfo.dwHelpContext,
                    excepinfo.scode,
                )
                raise COMError(
                    hresult,
                    text,
                    (""TypeError: Parameter %s"" % (argerr.value + 1), args),
                )
}
    POINTER(VARIANT): VT_BYREF | VT_VARIANT,
    POINTER(BSTR): VT_BYREF | VT_BSTR,
    # POINTER(IUnknown): VT_UNKNOWN,
    # POINTER(IDispatch): VT_DISPATCH,
}
# fmt: off
    ""CURRENCY"", ""CY"", ""tagCY"", ""DECIMAL"", ""tagDEC"", ""DISPATCH_METHOD"",
    ""DISPATCH_PROPERTYGET"", ""DISPATCH_PROPERTYPUT"", ""DISPATCH_PROPERTYPUTREF"",
    ""DISPID"", ""DISPID_COLLECT"", ""DISPID_CONSTRUCTOR"", ""DISPID_DESTRUCTOR"",
    ""DISPID_EVALUATE"", ""DISPID_NEWENUM"", ""DISPID_PROPERTYPUT"",
    ""DISPID_UNKNOWN"", ""DISPID_VALUE"", ""DISPPARAMS"", ""tagDISPPARAMS"",
    ""EXCEPINFO"", ""tagEXCEPINFO"", ""IDispatch"", ""IEnumVARIANT"", ""IID_NULL"",
    ""INVOKE_FUNC"", ""INVOKE_PROPERTYGET"", ""INVOKE_PROPERTYPUT"",
    ""INVOKE_PROPERTYPUTREF"", ""INVOKEKIND"", ""tagINVOKEKIND"", ""_midlSAFEARRAY"",
    ""SCODE"", ""_SysAllocStringLen"", ""VARENUM"", ""VARIANT"", ""tagVARIANT"",
    ""VARIANTARG"", ""_VariantChangeType"", ""_VariantClear"", ""_VariantCopy"",
    ""_VariantCopyInd"", ""VARTYPE"", ""VT_ARRAY"", ""VT_BLOB"", ""VT_BLOB_OBJECT"",
    ""VT_BOOL"", ""VT_BSTR"", ""VT_BSTR_BLOB"", ""VT_BYREF"", ""VT_CARRAY"", ""VT_CF"",
    ""VT_CLSID"", ""VT_CY"", ""VT_DATE"", ""VT_DECIMAL"", ""VT_DISPATCH"", ""VT_EMPTY"",
    ""VT_ERROR"", ""VT_FILETIME"", ""VT_HRESULT"", ""VT_I1"", ""VT_I2"", ""VT_I4"",
    ""VT_I8"", ""VT_ILLEGAL"", ""VT_ILLEGALMASKED"", ""VT_INT"", ""VT_INT_PTR"",
    ""VT_LPSTR"", ""VT_LPWSTR"", ""VT_NULL"", ""VT_PTR"", ""VT_R4"", ""VT_R8"",
    ""VT_RECORD"", ""VT_RESERVED"", ""VT_SAFEARRAY"", ""VT_STORAGE"",
    ""VT_STORED_OBJECT"", ""VT_STREAM"", ""VT_STREAMED_OBJECT"", ""VT_TYPEMASK"",
    ""VT_UI1"", ""VT_UI2"", ""VT_UI4"", ""VT_UI8"", ""VT_UINT"", ""VT_UINT_PTR"",
    ""VT_UNKNOWN"", ""VT_USERDEFINED"", ""VT_VARIANT"", ""VT_VECTOR"",
    ""VT_VERSIONED_STREAM"", ""VT_VOID"",
# fmt: on
""""""comtypes.client - High level client level COM support package.""""""
from typing import (
    Any,
    Optional,
    overload,
    Type,
    TYPE_CHECKING,
    TypeVar,
    Union as _UnionT,
)
from comtypes import automation, CoClass, GUID, IUnknown, typeinfo
if TYPE_CHECKING:
    from comtypes import hints  # type: ignore


_T_IUnknown = TypeVar(""_T_IUnknown"", bound=IUnknown)
def wrap_outparam(punk: Any) -> Any:
def GetBestInterface(punk: Any) -> Any:
    if not punk:  # NULL COM pointer
        return punk  # or should we return None?
            logger.debug(
                ""Does NOT implement IProvideClassInfo, trying IProvideClassInfo2""
            )
        tinfo = pci.GetClassInfo()  # TypeInfo for the CoClass
    itf_name = tinfo.GetDocumentation(-1)[0]  # interface name
    tlib = tinfo.GetContainingTypeLib()[0]  # typelib


@overload
def GetActiveObject(progid: _UnionT[str, CoClass, GUID]) -> Any:
    ...


@overload
def GetActiveObject(
    progid: _UnionT[str, CoClass, GUID], interface: Type[_T_IUnknown]
) -> _T_IUnknown:
    ...


def GetActiveObject(
    progid: _UnionT[str, CoClass, GUID],
    interface: Optional[Type[IUnknown]] = None,
    dynamic: bool = False,
) -> Any:
def _manage(
    obj: Any, clsid: Optional[GUID], interface: Optional[Type[IUnknown]]
) -> Any:
    obj.__dict__[""__clsid""] = str(clsid)




def GetClassObject(progid, clsctx=None, pServerInfo=None, interface=None):
@overload
def CreateObject(progid: _UnionT[str, Type[CoClass], GUID]) -> Any:
    ...


@overload
def CreateObject(
    progid: _UnionT[str, Type[CoClass], GUID],
    clsctx: Optional[int] = None,
    machine: Optional[str] = None,
    interface: Optional[Type[_T_IUnknown]] = None,
    dynamic: bool = ...,
    pServerInfo: Optional[comtypes.COSERVERINFO] = None,
) -> _T_IUnknown:
    ...


def CreateObject(
    progid: _UnionT[str, Type[CoClass], GUID],  # which object to create
    clsctx: Optional[int] = None,  # how to create the object
    machine: Optional[str] = None,  # where to create the object
    interface: Optional[Type[IUnknown]] = None,  # the interface we want
    dynamic: bool = False,  # use dynamic dispatch
    pServerInfo: Optional[
        comtypes.COSERVERINFO
    ] = None,  # server info struct for remoting
) -> Any:
        logger.debug(
            ""CoCreateInstance(%s, clsctx=%s, interface=%s)"", clsid, clsctx, interface
        )
        logger.debug(
            ""CoCreateInstanceEx(%s, clsctx=%s, interface=%s, machine=%s,\
            clsid,
            clsctx,
            interface,
            machine,
            pServerInfo,
        )
            msg = ""You cannot set both the machine name and server info.""
        obj = comtypes.CoCreateInstanceEx(
            clsid,
            clsctx=clsctx,
            interface=interface,
            machine=machine,
            pServerInfo=pServerInfo,
        )
@overload
def CoGetObject(displayname: str, interface: Type[_T_IUnknown]) -> _T_IUnknown:
    ...


@overload
def CoGetObject(displayname: str, interface: None = None, dynamic: bool = False) -> Any:
    ...


def CoGetObject(
    displayname: str,
    interface: Optional[Type[comtypes.IUnknown]] = None,
    dynamic: bool = False,
) -> Any:
    return _manage(punk, clsid=None, interface=interface)
# fmt: off
# fmt: on


        else:  # ftype in ('windows_exe', 'console_exe')

SHGetSpecialFolderPath.argtypes = [
    ctypes.c_ulong,
    ctypes.c_wchar_p,
    ctypes.c_int,
    ctypes.c_int,
]







        if isinstance(obj, str):



    clsid = source.__dict__.get(""__clsid"")
    # interface = find_single_connection_interface(source)
    # if interface:
    #     return interface


    if func.__code__.co_varnames[:2] == (""self"", ""this""):








            return comtypes.instancemethod(method, im_self, type(im_self))
def CreateEventReceiver(interface, handler):
    if issubclass(interface, comtypes.automation.IDispatch) and not hasattr(
        sink, ""_dispimpl_""
    ):







    # @ctypes.WINFUNCTYPE(ctypes.c_int, ctypes.c_uint)
        if dwCtrlType == 0:  # CTRL+C

            res = ctypes.oledll.ole32.CoWaitForMultipleHandles(
                0,
                int(timeout * 1000),
                len(handles),
                handles,
                ctypes.byref(ctypes.c_ulong()),
            )
            if details.winerror != RPC_S_CALLPENDING:  # timeout expired
from typing import Any, Tuple, List, Optional, Dict, Union as _UnionT
import winreg

from comtypes import GUID, typeinfo
def _my_import(fullname: str) -> types.ModuleType:

def _resolve_filename(tlib_string: str, dirpath: str) -> Tuple[str, bool]:
    assert isinstance(tlib_string, str)
def GetModule(tlib: _UnionT[Any, typeinfo.ITypeLib]) -> types.ModuleType:
    if isinstance(tlib, str):
        _file_: Optional[str] = frame.f_globals.get(""__file__"", None)
        pathname, is_abs = _resolve_filename(
            tlib_string, _file_ and os.path.dirname(_file_)  # type: ignore
        )
        assert not (os.path.isabs(pathname)) or os.path.exists(pathname)
    return ModuleGenerator().generate(tlib, pathname)


def _load_tlib(obj: Any) -> typeinfo.ITypeLib:
    if isinstance(obj, str):
        with winreg.OpenKey(
            winreg.HKEY_CLASSES_ROOT, r""CLSID\%s\TypeLib"" % clsid
        ) as key:
        with winreg.OpenKey(
            winreg.HKEY_CLASSES_ROOT, r""CLSID\%s\Version"" % clsid
        ) as key:
def _create_module_in_file(modulename: str, code: str) -> types.ModuleType:
def _create_module_in_memory(modulename: str, code: str) -> types.ModuleType:

class ModuleGenerator(object):
    def __init__(self) -> None:
        self.codegen = codegenerator.CodeGenerator(_get_known_symbols())

    def generate(
        self, tlib: typeinfo.ITypeLib, pathname: Optional[str]
    ) -> types.ModuleType:
        # create and import the real typelib wrapper module
        mod = self._create_wrapper_module(tlib, pathname)
        # try to get the friendly-name, if not, returns the real typelib wrapper module
        modulename = codegenerator.name_friendly_module(tlib)
        if modulename is None:
            return mod
        # create and import the friendly-named module
        return self._create_friendly_module(tlib, modulename)

    def _create_friendly_module(
        self, tlib: typeinfo.ITypeLib, modulename: str
    ) -> types.ModuleType:
        """"""helper which creates and imports the friendly-named module.""""""
        try:
            mod = _my_import(modulename)
        except Exception as details:
            logger.info(""Could not import %s: %s"", modulename, details)
        else:
            return mod
        # the module is always regenerated if the import fails
        logger.info(""# Generating %s"", modulename)
        # determine the Python module name
        modname = codegenerator.name_wrapper_module(tlib)
        code = self.codegen.generate_friendly_code(modname)
        if comtypes.client.gen_dir is None:
            return _create_module_in_memory(modulename, code)
        return _create_module_in_file(modulename, code)

    def _create_wrapper_module(
        self, tlib: typeinfo.ITypeLib, pathname: Optional[str]
    ) -> types.ModuleType:
        """"""helper which creates and imports the real typelib wrapper module.""""""
        modulename = codegenerator.name_wrapper_module(tlib)
        if modulename in sys.modules:
            return sys.modules[modulename]
        try:
            return _my_import(modulename)
        except Exception as details:
            logger.info(""Could not import %s: %s"", modulename, details)
        # generate the module since it doesn't exist or is out of date
        logger.info(""# Generating %s"", modulename)
        p = tlbparser.TypeLibParser(tlib)
        if pathname is None:
            pathname = tlbparser.get_tlib_filename(tlib)
        items = list(p.parse().values())
        code = self.codegen.generate_wrapper_code(items, filename=pathname)
        for ext_tlib in self.codegen.externals:  # generates dependency COM-lib modules
            GetModule(ext_tlib)
        if comtypes.client.gen_dir is None:
            return _create_module_in_memory(modulename, code)
        return _create_module_in_file(modulename, code)


def _get_known_symbols() -> Dict[str, str]:
    known_symbols: Dict[str, str] = {}
        ""ctypes"",
            names: List[str] = mod.__known_symbols__

from typing import Any, Dict, Optional, Set, Type, TypeVar
from comtypes import automation
from comtypes.client import lazybind
from comtypes import COMError, GUID, IUnknown, hresult as hres, _is_object

_T_IUnknown = TypeVar(""_T_IUnknown"", bound=IUnknown)

    """"""Wrap an object in a Dispatch instance, exposing methods and properties
    via fully dynamic dispatch.
    """"""
    if isinstance(obj, ctypes.POINTER(automation.IDispatch)):
        except (COMError, WindowsError):
        return lazybind.Dispatch(obj, tinfo)

    def __init__(self, _id: int, _obj: ""_Dispatch"") -> None:
    def __call__(self, *args: Any) -> Any:
    def __getitem__(self, *args: Any) -> Any:
        return self._obj._comobj.Invoke(
            self._id, *args, _invkind=automation.DISPATCH_PROPERTYGET
        )
    def __setitem__(self, *args: Any) -> None:
            self._obj._comobj.Invoke(
                self._id, *args, _invkind=automation.DISPATCH_PROPERTYPUTREF
            )
            self._obj._comobj.Invoke(
                self._id, *args, _invkind=automation.DISPATCH_PROPERTYPUT
            )

    """"""Expose methods and properties via fully dynamic dispatch.""""""

    _comobj: automation.IDispatch
    _ids: Dict[str, int]
    _methods: Set[str]

    def __init__(self, comobj: ""ctypes._Pointer[automation.IDispatch]""):
        # Tiny optimization: trying not to use GetIDsOfNames more than once
        self.__dict__[""_ids""] = {}
    def __enum(self) -> automation.IEnumVARIANT:
        e: IUnknown = self._comobj.Invoke(-4)  # DISPID_NEWENUM
        return e.QueryInterface(automation.IEnumVARIANT)
    def __hash__(self) -> int:
    def __getitem__(self, index: Any) -> Any:
    def QueryInterface(
        self, interface: Type[_T_IUnknown], iid: Optional[GUID] = None
    ) -> _T_IUnknown:
        """"""QueryInterface is forwarded to the real com object.""""""
        return self._comobj.QueryInterface(interface, iid)
    def _FlagAsMethod(self, *names: str) -> None:
    def __getattr__(self, name: str) -> Any:
        # tc = self._comobj.GetTypeInfo(0).QueryInterface(comtypes.typeinfo.ITypeComp)
        # dispid = tc.Bind(name)[1].memid
        flags = automation.DISPATCH_PROPERTYGET
            (hresult, _, _) = err.args
                raise err
    def __setattr__(self, name: str, value: Any) -> None:
    def __iter__(self) -> ""_Collection"":
    # def __setitem__(self, index, value):
    #     self._comobj.Invoke(
    #         -3,
    #         index,
    #         value,
    #         _invkind=automation.DISPATCH_PROPERTYPUT
    #         | automation.DISPATCH_PROPERTYPUTREF,
    #     )

    def __init__(self, enum: automation.IEnumVARIANT):
    def __next__(self) -> Any:
        item, fetched = self.enum.Next(1)
        if fetched:
            return item
        raise StopIteration



            return self.disp._comobj._invoke(self.get.memid, self.get.invkind, 0, *arg)
            return self.disp._comobj._invoke(self.get.memid, self.get.invkind, 0)
        return self.disp._comobj._invoke(self.get.memid, self.get.invkind, 0, *[arg])
        return self.disp._comobj._invoke(self.get.memid, self.get.invkind, 0, *args)
            self.disp._comobj._invoke(descr.memid, descr.invkind, 0, *(name + (value,)))
            self.disp._comobj._invoke(descr.memid, descr.invkind, 0, value)
            self.disp._comobj._invoke(descr.memid, descr.invkind, 0, name, value)
        """"""Explicitly disallow iteration.""""""


        # self.__dict__[""_iid""] = tinfo.GetTypeAttr().guid
                info = FuncDesc(
                    memid=descr.memid,
                    invkind=descr.invkind,
                    cParams=descr.cParams,
                    funckind=descr.funckind,
                )
        return isinstance(other, Dispatch) and self._comobj == other._comobj

        return self._comobj._invoke(
            DISPID_VALUE, DISPATCH_METHOD | DISPATCH_PROPERTYGET, 0, *args
        )
            return self._comobj._invoke(
                DISPID_VALUE, DISPATCH_METHOD | DISPATCH_PROPERTYGET, 0, *args
            )
        return self._comobj._invoke(DISPID_VALUE, invkind, 0, *args)
        punk = self._comobj._invoke(
            DISPID_NEWENUM, DISPATCH_METHOD | DISPATCH_PROPERTYGET, 0
        )


        (""pUnk"", POINTER(IUnknown)),
        (""dwCookie"", c_ulong),



    _iid_ = GUID(""{B196B284-BAB4-101A-B69C-00AA00341D07}"")

    _iid_ = GUID(""{B196B286-BAB4-101A-B69C-00AA00341D07}"")

    _iid_ = GUID(""{B196B287-BAB4-101A-B69C-00AA00341D07}"")
    def __next__(self):
        cp, fetched = self.Next(1)
        if fetched == 0:
            raise StopIteration
        return cp

    _iid_ = GUID(""{B196B285-BAB4-101A-B69C-00AA00341D07}"")
    def __next__(self):
        cp, fetched = self.Next(1)
        if fetched == 0:
            raise StopIteration
        return cp

    COMMETHOD(
        [],
        HRESULT,
        ""EnumConnectionPoints"",
        ([""out""], POINTER(POINTER(IEnumConnectionPoints)), ""ppEnum""),
    ),
    COMMETHOD(
        [],
        HRESULT,
        ""FindConnectionPoint"",
        ([""in""], POINTER(_GUID), ""riid""),
        ([""out""], POINTER(POINTER(IConnectionPoint)), ""ppCP""),
    ),
    COMMETHOD([], HRESULT, ""GetConnectionInterface"", ([""out""], POINTER(_GUID), ""pIID"")),
    COMMETHOD(
        [],
        HRESULT,
        ""GetConnectionPointContainer"",
        ([""out""], POINTER(POINTER(IConnectionPointContainer)), ""ppCPC""),
    ),
    COMMETHOD(
        [],
        HRESULT,
        ""Advise"",
        ([""in""], POINTER(IUnknown), ""pUnkSink""),
        ([""out""], POINTER(c_ulong), ""pdwCookie""),
    ),
    COMMETHOD([], HRESULT, ""Unadvise"", ([""in""], c_ulong, ""dwCookie"")),
    COMMETHOD(
        [],
        HRESULT,
        ""EnumConnections"",
        ([""out""], POINTER(POINTER(IEnumConnections)), ""ppEnum""),
    ),
    COMMETHOD(
        [],
        HRESULT,
        ""Next"",
        ([""in""], c_ulong, ""cConnections""),
        ([""out""], POINTER(tagCONNECTDATA), ""rgcd""),
        ([""out""], POINTER(c_ulong), ""pcFetched""),
    ),
    COMMETHOD([], HRESULT, ""Skip"", ([""in""], c_ulong, ""cConnections"")),
    COMMETHOD([], HRESULT, ""Reset""),
    COMMETHOD(
        [], HRESULT, ""Clone"", ([""out""], POINTER(POINTER(IEnumConnections)), ""ppEnum"")
    ),
    COMMETHOD(
        [],
        HRESULT,
        ""Next"",
        ([""in""], c_ulong, ""cConnections""),
        ([""out""], POINTER(POINTER(IConnectionPoint)), ""ppCP""),
        ([""out""], POINTER(c_ulong), ""pcFetched""),
    ),
    COMMETHOD([], HRESULT, ""Skip"", ([""in""], c_ulong, ""cConnections"")),
    COMMETHOD([], HRESULT, ""Reset""),
    COMMETHOD(
        [],
        HRESULT,
        ""Clone"",
        ([""out""], POINTER(POINTER(IEnumConnectionPoints)), ""ppEnum""),
    ),
        COMMETHOD([], HRESULT, ""SetGUID"", ([""in""], POINTER(GUID), ""rguid"")),
        COMMETHOD([], HRESULT, ""SetSource"", ([""in""], LPCOLESTR, ""szSource"")),
        COMMETHOD([], HRESULT, ""SetDescription"", ([""in""], LPCOLESTR, ""szDescription"")),
        COMMETHOD([], HRESULT, ""SetHelpFile"", ([""in""], LPCOLESTR, ""szHelpFile"")),
        COMMETHOD([], HRESULT, ""SetHelpContext"", ([""in""], DWORD, ""dwHelpContext"")),
    ]

        COMMETHOD([], HRESULT, ""GetGUID"", ([""out""], POINTER(GUID), ""pGUID"")),
        COMMETHOD([], HRESULT, ""GetSource"", ([""out""], POINTER(BSTR), ""pBstrSource"")),
        COMMETHOD(
            [], HRESULT, ""GetDescription"", ([""out""], POINTER(BSTR), ""pBstrDescription"")
        ),
        COMMETHOD(
            [], HRESULT, ""GetHelpFile"", ([""out""], POINTER(BSTR), ""pBstrHelpFile"")
        ),
        COMMETHOD(
            [], HRESULT, ""GetHelpContext"", ([""out""], POINTER(DWORD), ""pdwHelpContext"")
        ),
    ]

        COMMETHOD(
            [], HRESULT, ""InterfaceSupportsErrorInfo"", ([""in""], POINTER(GUID), ""riid"")
        )
    ]





def ReportError(
    text, iid, clsid=None, helpfile=None, helpcontext=0, hresult=DISP_E_EXCEPTION
):
        if isinstance(clsid, str):
            ei.SetSource(
                progid
            )  # progid for the class or application that created the error

def ReportException(
    hresult, iid, clsid=None, helpfile=None, helpcontext=None, stacklevel=None
):
    return ReportError(
        text,
        iid,
        clsid=clsid,
        helpfile=helpfile,
        helpcontext=helpcontext,
        hresult=hresult,
    )

# fmt: off
__all__ = [
    ""ICreateErrorInfo"", ""IErrorInfo"", ""ISupportErrorInfo"", ""ReportError"",
    ""ReportException"", ""SetErrorInfo"", ""GetErrorInfo"", ""CreateErrorInfo"",
]
# fmt: on
from comtypes import (
    IUnknown,
    STDMETHOD,
    COMMETHOD,
    GUID,
    HRESULT,
    CoCreateInstance,
    CLSCTX_INPROC_SERVER,
)

        STDMETHOD(
            HRESULT,
            ""RegisterInterfaceInGlobal"",
            [POINTER(IUnknown), POINTER(GUID), POINTER(DWORD)],
        ),
        STDMETHOD(
            HRESULT,
            ""GetInterfaceFromGlobal"",
            [DWORD, POINTER(GUID), POINTER(POINTER(IUnknown))],
        ),
    ]
git = CoCreateInstance(
    CLSID_StdGlobalInterfaceTable,
    interface=IGlobalInterfaceTable,
    clsctx=CLSCTX_INPROC_SERVER,
)
# fmt: off
__all__ = [
    ""RegisterInterfaceInGlobal"", ""RevokeInterfaceFromGlobal"",
    ""GetInterfaceFromGlobal"",
]
# fmt: on

    tlib = CreateTypeLib(""foo.bar"")  # we don not save it later
E_UNEXPECTED = -2147418113  # 0x8000FFFFL
E_NOTIMPL = -2147467263  # 0x80004001L
E_NOINTERFACE = -2147467262  # 0x80004002L
E_POINTER = -2147467261  # 0x80004003L
E_FAIL = -2147467259  # 0x80004005L
E_INVALIDARG = -2147024809  # 0x80070057L
E_OUTOFMEMORY = -2147024882  # 0x8007000EL
CLASS_E_NOAGGREGATION = -2147221232  # 0x80040110L
CLASS_E_CLASSNOTAVAILABLE = -2147221231  # 0x80040111L
CO_E_CLASSSTRING = -2147221005  # 0x800401F3L
TYPE_E_ELEMENTNOTFOUND = -2147352077  # 0x8002802BL
TYPE_E_REGISTRYACCESS = -2147319780  # 0x8002801CL
TYPE_E_CANTLOADLIBRARY = -2147312566  # 0x80029C4AL
DISP_E_PARAMNOTOPTIONAL = -2147352561  # 0x8002000F
DISP_E_BADPARAMCOUNT = -2147352562  # 0x8002000E
DISP_E_ARRAYISLOCKED = -2147352563  # 0x8002000D
DISP_E_UNKNOWNLCID = -2147352564  # 0x8002000C
DISP_E_BADINDEX = -2147352565  # 0x8002000B
DISP_E_OVERFLOW = -2147352566  # 0x8002000A
DISP_E_EXCEPTION = -2147352567  # 0x80020009
DISP_E_BADVARTYPE = -2147352568  # 0x80020008
DISP_E_NONAMEDARGS = -2147352569  # 0x80020007
DISP_E_UNKNOWNNAME = -2147352570  # 0x80020006
DISP_E_TYPEMISMATCH = -2147352571  # 0800020005
DISP_E_PARAMNOTFOUND = -2147352572  # 0x80020004
DISP_E_MEMBERNOTFOUND = -2147352573  # 0x80020003
DISP_E_UNKNOWNINTERFACE = -2147352575  # 0x80020001

RPC_E_CHANGED_MODE = -2147417850  # 0x80010106
RPC_E_SERVERFAULT = -2147417851  # 0x80010105






    def emit(
        self,
        record,
        writeA=ctypes.windll.kernel32.OutputDebugStringA,
        writeW=ctypes.windll.kernel32.OutputDebugStringW,
    ):
            writeW(text + ""\n"")



    parser.optionxform = str  # use case sensitive option names!
    DEFAULTS = {
        ""handler"": ""StreamHandler()"",
        ""format"": ""%(levelname)s:%(name)s:%(message)s"",
        ""level"": ""WARNING"",
    }

                return  # got WM_QUIT

            no_replace = getattr(value, ""__no_replace"", False)



    _iid_ = GUID(""{3127CA40-446E-11CE-8135-00AA004BB851}"")
        COMMETHOD(
            [],
            HRESULT,
            ""AddError"",
            ([""in""], WSTRING, ""pszPropName""),
            ([""in""], POINTER(tagEXCEPINFO), ""pExcepInfo""),
        ),
    ]

    _iid_ = GUID(""{55272A00-42CB-11CE-8135-00AA004BB851}"")
        COMMETHOD(
            [],
            HRESULT,
            ""Read"",
            ([""in""], WSTRING, ""pszPropName""),
            ([""in"", ""out""], POINTER(VARIANT), ""pVar""),
            ([""in""], POINTER(IErrorLog), ""pErrorLog""),
            # ( ['in', 'out'], POINTER(IErrorLog), 'pErrorLog' ),
        ),
        COMMETHOD(
            [],
            HRESULT,
            ""Write"",
            ([""in""], WSTRING, ""pszPropName""),
            ([""in""], POINTER(VARIANT), ""pVar""),
        ),
    ]

    _iid_ = GUID(""{37D84F60-42CB-11CE-8135-00AA004BB851}"")
        COMMETHOD([], HRESULT, ""InitNew""),
        COMMETHOD(
            [],
            HRESULT,
            ""Load"",
            ([""in""], POINTER(IPropertyBag), ""pPropBag""),
            ([""in""], POINTER(IErrorLog), ""pErrorLog""),
        ),
        COMMETHOD(
            [],
            HRESULT,
            ""Save"",
            ([""in""], POINTER(IPropertyBag), ""pPropBag""),
            ([""in""], c_int, ""fClearDirty""),
            ([""in""], c_int, ""fSaveAllProperties""),
        ),
    ]

        (""dwType"", c_ulong),
        (""vt"", c_ushort),
        (""cfType"", CLIPFORMAT),
        (""dwHint"", c_ulong),
        (""pstrName"", WSTRING),
        (""clsid"", GUID),
    ]

    _iid_ = GUID(""{22F55882-280B-11D0-A8A9-00A0C90C2004}"")
        COMMETHOD(
            [],
            HRESULT,
            ""Read"",
            ([""in""], c_ulong, ""cProperties""),
            ([""in""], POINTER(tagPROPBAG2), ""pPropBag""),
            ([""in""], POINTER(IErrorLog), ""pErrLog""),
            ([""out""], POINTER(VARIANT), ""pvarValue""),
            ([""out""], POINTER(HRESULT), ""phrError""),
        ),
        COMMETHOD(
            [],
            HRESULT,
            ""Write"",
            ([""in""], c_ulong, ""cProperties""),
            ([""in""], POINTER(tagPROPBAG2), ""pPropBag""),
            ([""in""], POINTER(VARIANT), ""pvarValue""),
        ),
        COMMETHOD(
            [], HRESULT, ""CountProperties"", ([""out""], POINTER(c_ulong), ""pcProperties"")
        ),
        COMMETHOD(
            [],
            HRESULT,
            ""GetPropertyInfo"",
            ([""in""], c_ulong, ""iProperty""),
            ([""in""], c_ulong, ""cProperties""),
            ([""out""], POINTER(tagPROPBAG2), ""pPropBag""),
            ([""out""], POINTER(c_ulong), ""pcProperties""),
        ),
        COMMETHOD(
            [],
            HRESULT,
            ""LoadObject"",
            ([""in""], WSTRING, ""pstrName""),
            ([""in""], c_ulong, ""dwHint""),
            ([""in""], POINTER(IUnknown), ""punkObject""),
            ([""in""], POINTER(IErrorLog), ""pErrLog""),
        ),
    ]

    _iid_ = GUID(""{22F55881-280B-11D0-A8A9-00A0C90C2004}"")
        COMMETHOD([], HRESULT, ""InitNew""),
        COMMETHOD(
            [],
            HRESULT,
            ""Load"",
            ([""in""], POINTER(IPropertyBag2), ""pPropBag""),
            ([""in""], POINTER(IErrorLog), ""pErrLog""),
        ),
        COMMETHOD(
            [],
            HRESULT,
            ""Save"",
            ([""in""], POINTER(IPropertyBag2), ""pPropBag""),
            ([""in""], c_int, ""fClearDirty""),
            ([""in""], c_int, ""fSaveAllProperties""),
        ),
        COMMETHOD([], HRESULT, ""IsDirty""),
    ]

    _iid_ = GUID(""{0000010B-0000-0000-C000-000000000046}"")
        COMMETHOD([], HRESULT, ""IsDirty""),
        COMMETHOD(
            [],
            HRESULT,
            ""Load"",
            ([""in""], LPCOLESTR, ""pszFileName""),
            ([""in""], DWORD, ""dwMode""),
        ),
        COMMETHOD(
            [],
            HRESULT,
            ""Save"",
            ([""in""], LPCOLESTR, ""pszFileName""),
            ([""in""], BOOL, ""fRemember""),
        ),
        COMMETHOD([], HRESULT, ""SaveCompleted"", ([""in""], LPCOLESTR, ""pszFileName"")),
        COMMETHOD(
            [], HRESULT, ""GetCurFile"", ([""out""], POINTER(LPOLESTR), ""ppszFileName"")
        ),
    ]



# fmt: off
    ""CLIPFORMAT"", ""DictPropertyBag"", ""IErrorLog"", ""IPersistFile"",
    ""IPersistPropertyBag"", ""IPersistPropertyBag2"", ""IPropertyBag"",
    ""IPropertyBag2"", ""tagPROPBAG2"", ""PROPBAG2_TYPE_DATA"",
    ""PROPBAG2_TYPE_MONIKER"", ""PROPBAG2_TYPE_OBJECT"", ""PROPBAG2_TYPE_STORAGE"",
    ""PROPBAG2_TYPE_STREAM"", ""PROPBAG2_TYPE_UNDEFINED"", ""PROPBAG2_TYPE_URL"",
    ""STGM_CONVERT"", ""STGM_CREATE"", ""STGM_DELETEONRELEASE"", ""STGM_DIRECT"",
    ""STGM_DIRECT_SWMR"", ""STGM_FAILIFTHERE"", ""STGM_NOSCRATCH"",
    ""STGM_NOSNAPSHOT"", ""STGM_PRIORITY"", ""STGM_READ"", ""STGM_READWRITE"",
    ""STGM_SHARE_DENY_NONE"", ""STGM_SHARE_DENY_READ"", ""STGM_SHARE_DENY_WRITE"",
    ""STGM_SHARE_EXCLUSIVE"", ""STGM_SIMPLE"", ""STGM_TRANSACTED"", ""STGM_WRITE"",
# fmt: on
from ctypes import POINTER, Structure, byref, cast, c_long, memmove, pointer, sizeof
    """"""Context manager allowing safe arrays to be extracted as ndarrays.
    """"""

        """"""True if context manager is currently entered on given thread.""""""
        return bool(getattr(self.thread_local, ""count"", 0))
    __nonzero__ = __bool__  # for Py2.7 compatibility
    from comtypes.automation import (
        _ctype_to_vartype,
        VT_RECORD,
        VT_UNKNOWN,
        IDispatch,
        VT_DISPATCH,
    )
    sa_type = meta.__new__(
        meta, ""SAFEARRAY_%s"" % itemtype.__name__, (_safearray.tagSAFEARRAY,), {}
    )

            pa = _safearray.SafeArrayCreateVectorEx(cls._vartype_, 0, len(value), extra)
                    raise TypeError(
                        ""Cannot create SAFEARRAY type VT_RECORD without IRecordInfo.""
                    )

            pa = _safearray.SafeArrayCreateEx(
                cls._vartype_, value.ndim, rgsa, extra  # cDims  # rgsaBound
            )  # pvExtra
                    raise TypeError(
                        ""Cannot create SAFEARRAY type VT_RECORD without IRecordInfo.""
                    )
            # print ""__setitem__"", index, value
                    return (
                        comtypes.npsupport.numpy.asarray(result).reshape((cols, rows)).T
                    )
                lowerbounds = [
                    _safearray.SafeArrayGetLBound(self, d) for d in range(1, dim + 1)
                ]
                upperbounds = [
                    _safearray.SafeArrayGetUBound(self, d) for d in range(1, dim + 1)
                ]

                        if safearray_as_ndarray and self._itemtype_ in list(
                            comtypes.npsupport.typecodes.keys()
                        ):
                            arr = comtypes.npsupport.numpy.ctypeslib.as_array(
                                ptr, (num_elements,)
                            )

            if dim + 1 == len(indices):
                for i in range(indices[dim], upperbounds[dim] + 1):
                for i in range(indices[dim], upperbounds[dim] + 1):
                    result.append(
                        self._get_row(dim + 1, indices, lowerbounds, upperbounds)
                    )
            return tuple(result)  # for compatibility with pywin32.
    """"""Convert an ndarray to VARIANT_dtype array""""""

    varr = numpy.zeros(value.shape, comtypes.npsupport.interop.VARIANT_dtype, order=""F"")
    """"""Convert an ndarray of datetime64 to VARIANT_dtype array""""""

    value = value / numpy.timedelta64(1, ""D"")
    varr = numpy.zeros(value.shape, comtypes.npsupport.interop.VARIANT_dtype, order=""F"")
    varr[""vt""] = VT_DATE
    varr[""_""][""VT_R8""].flat = value.flat
        comtypes.STDMETHOD(
            comtypes.HRESULT,
            ""CreateInstance"",
            [
                ctypes.POINTER(comtypes.IUnknown),
                ctypes.POINTER(comtypes.GUID),
                ctypes.POINTER(ctypes.c_void_p),
            ],
        ),
        comtypes.STDMETHOD(comtypes.HRESULT, ""LockServer"", [ctypes.c_int]),
    ]

# class IExternalConnection(IUnknown):
#     _iid_ = GUID(""{00000019-0000-0000-C000-000000000046}"")
#     _methods_ = [
#         STDMETHOD(HRESULT, ""AddConnection"", [c_ulong, c_ulong]),
#         STDMETHOD(HRESULT, ""ReleaseConnection"", [c_ulong, c_ulong, c_ulong])]
ACTIVEOBJECT_WEAK = 0x1

    oleaut32.RegisterActiveObject(
        punk, ctypes.byref(clsid), flags, ctypes.byref(handle)
    )


        self.items = (
            items  # keep, so that we can restore our iterator (in Reset, and Clone).
        )
        if not rgVar:
            return E_POINTER
        if not pCeltFetched:
            pCeltFetched = [None]
        # except:
        #     # ReportException? return E_FAIL?
        #     import traceback
        #     traceback.print_exc()



        return item.IUnknown_QueryInterface(None, pointer(pitem[0]._iid_), pitem)
        return enum.IUnknown_QueryInterface(None, pointer(IUnknown._iid_), penum)



                        logger.warning(
                            ""_call_sinks(%s, %s, *%s, **%s) failed; removing connection"",
                            self,
                            name,
                            args,
                            kw,
                            exc_info=True,
                        )
                            pass  # connection already gone
                        logger.warning(
                            ""_call_sinks(%s, %s, *%s, **%s)"",
                            self,
             ",bug-free
"            ""grpc >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""gRPC >= %s must be installed; however, """,buggy
"            ""grpcio >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""grpcio >= %s must be installed; however, """,bug-free
"            ""grpc >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""gRPC >= %s must be installed; however, """,buggy
"            ""grpcio >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""grpcio >= %s must be installed; however, """,bug-free
"            ""grpc >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""gRPC >= %s must be installed; however, """,buggy
"            ""grpcio >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""grpcio >= %s must be installed; however, """,bug-free
"            ""grpc >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""gRPC >= %s must be installed; however, """,buggy
"            ""grpcio >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""grpcio >= %s must be installed; however, """,bug-free
"            ""grpc >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""gRPC >= %s must be installed; however, """,buggy
"            ""grpcio >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""grpcio >= %s must be installed; however, """,bug-free
"            ""grpc >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""gRPC >= %s must be installed; however, """,buggy
"            ""grpcio >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""grpcio >= %s must be installed; however, """,bug-free
"            ""grpc >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""gRPC >= %s must be installed; however, """,buggy
"            ""grpcio >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""grpcio >= %s must be installed; however, """,bug-free
"            ""grpc >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""gRPC >= %s must be installed; however, """,buggy
"            ""grpcio >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""grpcio >= %s must be installed; however, """,bug-free
"            ""grpc >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""gRPC >= %s must be installed; however, """,buggy
"            ""grpcio >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""grpcio >= %s must be installed; however, """,bug-free
"            ""grpc >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""gRPC >= %s must be installed; however, """,buggy
"            ""grpcio >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""grpcio >= %s must be installed; however, """,bug-free
"            ""grpc >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""gRPC >= %s must be installed; however, """,buggy
"            ""grpcio >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""grpcio >= %s must be installed; however, """,bug-free
"            ""grpc >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""gRPC >= %s must be installed; however, """,buggy
"            ""grpcio >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""grpcio >= %s must be installed; however, """,bug-free
"            ""grpc >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""gRPC >= %s must be installed; however, """,buggy
"            ""grpcio >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""grpcio >= %s must be installed; however, """,bug-free
"            ""grpc >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""gRPC >= %s must be installed; however, """,buggy
"            ""grpcio >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""grpcio >= %s must be installed; however, """,bug-free
"            ""grpc >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""gRPC >= %s must be installed; however, """,buggy
"            ""grpcio >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""grpcio >= %s must be installed; however, """,bug-free
"            ""grpc >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""gRPC >= %s must be installed; however, """,buggy
"            ""grpcio >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""grpcio >= %s must be installed; however, """,bug-free
"            ""grpc >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""gRPC >= %s must be installed; however, """,buggy
"            ""grpcio >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""grpcio >= %s must be installed; however, """,bug-free
"            ""grpc >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""gRPC >= %s must be installed; however, """,buggy
"            ""grpcio >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""grpcio >= %s must be installed; however, """,bug-free
"            ""grpc >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""gRPC >= %s must be installed; however, """,buggy
"            ""grpcio >= %s must be installed; however, "" ""it was not found."" % minimum_grpc_version
            ""grpcio >= %s must be installed; however, """,bug-free
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
            ""sample_batch_size"": 1,
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
            ""sample_batch_size"": 50,
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
from ray.tests.utils import run_string_as_driver
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
ray.init(redis_address=""{}"")
"""""".format(cluster.redis_address, num_nodes)
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
    return 1
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
    command = [""git"", ""diff"", ""--name-only"", commit_range]
    RAY_CI_RLLIB_AFFECTED = 0
    if os.environ[""TRAVIS_EVENT_TYPE""] == ""pull_request"":
        files = list_changed_files(os.environ[""TRAVIS_COMMIT_RANGE""].replace(
            ""..."", ""..""))
            if changed_file.startswith(""python/ray/tune/""):
            elif changed_file.startswith(""python/ray/rllib/""):
    print(""export RAY_CI_TUNE_AFFECTED={}"".format(RAY_CI_TUNE_AFFECTED))
    print(""export RAY_CI_RLLIB_AFFECTED={}"".format(RAY_CI_RLLIB_AFFECTED))
    print(""export RAY_CI_JAVA_AFFECTED={}"".format(RAY_CI_JAVA_AFFECTED))
    print(""export RAY_CI_PYTHON_AFFECTED={}"".format(RAY_CI_PYTHON_AFFECTED))
    print(""export RAY_CI_LINUX_WHEELS_AFFECTED={}""
          .format(RAY_CI_LINUX_WHEELS_AFFECTED))
    print(""export RAY_CI_MACOS_WHEELS_AFFECTED={}""
          .format(RAY_CI_MACOS_WHEELS_AFFECTED))
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

    mat = np.array([[[2.0, 2.0], [2.0, 2.0]], [[2.0, 2.0], [2.0, 2.0]]],
                   dtype=np.float32)
    run_func(cyth.compute_kernel_matrix,
             ""L"",
             ""T"",
             2,
             2,
             1.0,
             mat,
             0,
             2,
             1.0,
             result,
             2
             )",buggy
"from ray.cluster_utils import Cluster
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
from ray.cluster_utils import Cluster
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
            ""rollout_fragment_length"": 1,
from ray.cluster_utils import Cluster
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
            ""rollout_fragment_length"": 50,
import numpy as np

from ray.cluster_utils import Cluster
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
        return np.zeros(1024, dtype=np.uint8)
from ray.cluster_utils import Cluster
from ray.test_utils import run_string_as_driver
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
ray.init(address=""{}"")
"""""".format(cluster.address, num_nodes)
import numpy as np

from ray.cluster_utils import Cluster
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
    return np.zeros(1024, dtype=np.uint8)
from ray.cluster_utils import Cluster
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
from ray.cluster_utils import Cluster
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
import json
import re
import sys
from pprint import pformat
    command = [""git"", ""diff"", ""--name-only"", commit_range, ""--""]
    RAY_CI_ONLY_RLLIB_AFFECTED = 0  # Whether only RLlib is affected.
    RAY_CI_RLLIB_AFFECTED = 0  # Whether RLlib minimal tests should be run.
    RAY_CI_RLLIB_FULL_AFFECTED = 0  # Whether full RLlib tests should be run.
    RAY_CI_SERVE_AFFECTED = 0
    RAY_CI_STREAMING_CPP_AFFECTED = 0
    RAY_CI_STREAMING_PYTHON_AFFECTED = 0
    RAY_CI_STREAMING_JAVA_AFFECTED = 0
    event_type = None
    for key in [""GITHUB_EVENT_NAME"", ""TRAVIS_EVENT_TYPE""]:
        event_type = os.getenv(key, event_type)
    if event_type == ""pull_request"":

        commit_range = os.getenv(""TRAVIS_COMMIT_RANGE"")
        if commit_range is None:
            with open(os.environ[""GITHUB_EVENT_PATH""], ""rb"") as f:
                event = json.loads(f.read())
            base = event[""pull_request""][""base""][""sha""]
            commit_range = ""{}...{}"".format(base, event.get(""after"", """"))
        files = list_changed_files(commit_range)

        print(pformat(files), file=sys.stderr)
            if changed_file.startswith(""python/ray/tune""):
                RAY_CI_RLLIB_FULL_AFFECTED = 1
            elif re.match(""^(python/ray/)?rllib/"", changed_file):
                RAY_CI_RLLIB_FULL_AFFECTED = 1
                RAY_CI_LINUX_WHEELS_AFFECTED = 1
                RAY_CI_MACOS_WHEELS_AFFECTED = 1
            elif changed_file.startswith(""python/ray/serve""):
                RAY_CI_SERVE_AFFECTED = 1
                RAY_CI_SERVE_AFFECTED = 1
                RAY_CI_STREAMING_PYTHON_AFFECTED = 1
                RAY_CI_STREAMING_JAVA_AFFECTED = 1
                RAY_CI_SERVE_AFFECTED = 1
                RAY_CI_STREAMING_CPP_AFFECTED = 1
                RAY_CI_STREAMING_PYTHON_AFFECTED = 1
                RAY_CI_STREAMING_JAVA_AFFECTED = 1
            elif changed_file.startswith(""streaming/src""):
                RAY_CI_STREAMING_CPP_AFFECTED = 1
                RAY_CI_STREAMING_PYTHON_AFFECTED = 1
                RAY_CI_STREAMING_JAVA_AFFECTED = 1
            elif changed_file.startswith(""streaming/python""):
                RAY_CI_STREAMING_PYTHON_AFFECTED = 1
            elif changed_file.startswith(""streaming/java""):
                RAY_CI_STREAMING_JAVA_AFFECTED = 1
                RAY_CI_SERVE_AFFECTED = 1
                RAY_CI_STREAMING_CPP_AFFECTED = 1
                RAY_CI_STREAMING_PYTHON_AFFECTED = 1
                RAY_CI_STREAMING_JAVA_AFFECTED = 1
        RAY_CI_RLLIB_FULL_AFFECTED = 1
        RAY_CI_SERVE_AFFECTED = 1
        RAY_CI_STREAMING_CPP_AFFECTED = 1
        RAY_CI_STREAMING_PYTHON_AFFECTED = 1
        RAY_CI_STREAMING_JAVA_AFFECTED = 1

    if not RAY_CI_TUNE_AFFECTED and not RAY_CI_SERVE_AFFECTED and \
            not RAY_CI_JAVA_AFFECTED and not RAY_CI_PYTHON_AFFECTED and not \
            RAY_CI_STREAMING_CPP_AFFECTED and \
            not RAY_CI_STREAMING_PYTHON_AFFECTED and \
            not RAY_CI_STREAMING_JAVA_AFFECTED:
        RAY_CI_ONLY_RLLIB_AFFECTED = 1
    # Log the modified environment variables visible in console.
    print("" "".join([
        ""RAY_CI_TUNE_AFFECTED={}"".format(RAY_CI_TUNE_AFFECTED),
        ""RAY_CI_ONLY_RLLIB_AFFECTED={}"".format(RAY_CI_ONLY_RLLIB_AFFECTED),
        ""RAY_CI_RLLIB_AFFECTED={}"".format(RAY_CI_RLLIB_AFFECTED),
        ""RAY_CI_RLLIB_FULL_AFFECTED={}"".format(RAY_CI_RLLIB_FULL_AFFECTED),
        ""RAY_CI_SERVE_AFFECTED={}"".format(RAY_CI_SERVE_AFFECTED),
        ""RAY_CI_JAVA_AFFECTED={}"".format(RAY_CI_JAVA_AFFECTED),
        ""RAY_CI_PYTHON_AFFECTED={}"".format(RAY_CI_PYTHON_AFFECTED),
        ""RAY_CI_LINUX_WHEELS_AFFECTED={}"".format(RAY_CI_LINUX_WHEELS_AFFECTED),
        ""RAY_CI_MACOS_WHEELS_AFFECTED={}"".format(RAY_CI_MACOS_WHEELS_AFFECTED),
        ""RAY_CI_STREAMING_CPP_AFFECTED={}"".format(
            RAY_CI_STREAMING_CPP_AFFECTED),
        ""RAY_CI_STREAMING_PYTHON_AFFECTED={}"".format(
            RAY_CI_STREAMING_PYTHON_AFFECTED),
        ""RAY_CI_STREAMING_JAVA_AFFECTED={}"".format(
            RAY_CI_STREAMING_JAVA_AFFECTED),
    ]))
    mat = np.array(
        [[[2.0, 2.0], [2.0, 2.0]], [[2.0, 2.0], [2.0, 2.0]]], dtype=np.float32)
    run_func(cyth.compute_kernel_matrix, ""L"", ""T"", 2, 2, 1.0, mat, 0, 2, 1.0,
             result, 2)",bug-free
"        self.handle = self.interface.id
        gpib.close(self.handle)",buggy
"
    # patch Gpib to avoid double closing of handles
    def _patch_Gpib():
        if not hasattr(Gpib, ""close""):
            _old_del = Gpib.__del__
            def _inner(self):
                _old_del(self)
                self._own = False
            Gpib.__del__ = _inner
            Gpib.close = _inner
    _patch_Gpib()
        self.interface.close()
        self.controller.close()",bug-free
from reviewboard.extensions.hooks import IntegrationHook,buggy
"from django.conf.urls import include, url
from reviewboard.extensions.hooks import IntegrationHook, URLHook
from rbintegrations.travisci.integration import TravisCIIntegration
        TravisCIIntegration,
    css_bundles = {
        'travis-ci-integration-config': {
            'source_filenames': ['css/travisci/integration-config.less'],
        },
    }

    js_bundles = {
        'travis-ci-integration-config': {
            'source_filenames': ['js/travisci/integrationConfig.es6.js'],
        },
    }


        URLHook(self, [
            url(r'^rbintegrations/travis-ci/',
                include('rbintegrations.travisci.urls'))
        ])",bug-free
"        skipped_tokens = list()
                orig_byweekday = tuple()
                orig_bynweekday = tuple()
                self._byhour = set((dtstart.hour,))
                self._byminute = set((dtstart.minute,))

try:
    import unittest2 as unittest
except ImportError:
    import unittest

try:
    import unittest2 as unittest
except ImportError:
    import unittest
from ._common import unittest
from ._common import unittest, WarningTestMixin, NotAValue
from ._common import WarningTestMixin, unittest
from ._common import unittest, PicklableMixin
from ._common import total_seconds
            
        # wall times are equal, even if they have different absolute times. 
            
        # wall times are equal, even if they have different absolute times. 
            
        tzos = tz.tzoffset('LST', total_seconds(tzl._std_offset))
        tzod = tz.tzoffset('LDT', total_seconds(tzl._std_offset))
        return tuple()
from ._common import tzname_in_python2, _tzinfo, _total_seconds
            offset = _total_seconds(offset)
                               int(_total_seconds(self._offset)))
        return idx - 1        
            stdoffset = _total_seconds(stdoffset)
            dstoffset = _total_seconds(dstoffset)
    return _total_seconds((dt.replace(tzinfo=None) - EPOCH))
# python2.6 compatability. Note that TarFile.__exit__ != TarFile.close, but
# it's close enough for python2.6
tar_open = TarFile.open
if not hasattr(TarFile, '__exit__'):
    def tar_open(*args, **kwargs):
        return closing(TarFile.open(*args, **kwargs))

            with tar_open(fileobj=zonefile_stream, mode='r') as tf:
                # dict comprehension does not work on python2.6
                # TODO: get back to the nicer syntax when we ditch python2.6
                # self.zones = {zf.name: tzfile(tf.extractfile(zf),
                #               filename = zf.name)
                #              for zf in tf.getmembers() if zf.isfile()}
                self.zones = dict((zf.name, tzfile(tf.extractfile(zf),
                                                   filename=zf.name))
                                  for zf in tf.getmembers()
                                  if zf.isfile() and zf.name != METADATA_FN)
                # links = {zl.name: self.zones[zl.linkname]
                #        for zl in tf.getmembers() if zl.islnk() or zl.issym()}
                links = dict((zl.name, self.zones[zl.linkname])
                             for zl in tf.getmembers() if
                             zl.islnk() or zl.issym())
            self.zones = dict()
_CLASS_ZONE_INSTANCE = list()
from dateutil.zoneinfo import tar_open, METADATA_FN, ZONEFILENAME
        with tar_open(filename) as tf:
        with tar_open(target, ""w:%s"" % format) as tf:",buggy
"        skipped_tokens = []
                orig_byweekday = ()
                orig_bynweekday = ()
                self._byhour = {dtstart.hour}
                self._byminute = {dtstart.minute}
import unittest
import unittest
import unittest
from ._common import WarningTestMixin, NotAValue
import unittest
from ._common import WarningTestMixin
import unittest
from ._common import PicklableMixin
import unittest

        # wall times are equal, even if they have different absolute times.

        # wall times are equal, even if they have different absolute times.

        tzos = tz.tzoffset('LST', tzl._std_offset.total_seconds())
        tzod = tz.tzoffset('LDT', tzl._std_offset.total_seconds())
        return ()
from ._common import tzname_in_python2, _tzinfo
            offset = offset.total_seconds()
                               int(self._offset.total_seconds()))
        return idx - 1
            stdoffset = stdoffset.total_seconds()
            dstoffset = dstoffset.total_seconds()
    return (dt.replace(tzinfo=None) - EPOCH).total_seconds()
            with TarFile.open(fileobj=zonefile_stream) as tf:
                self.zones = {zf.name: tzfile(tf.extractfile(zf), filename=zf.name)
                              for zf in tf.getmembers()
                              if zf.isfile() and zf.name != METADATA_FN}
                links = {zl.name: self.zones[zl.linkname]
                         for zl in tf.getmembers() if
                         zl.islnk() or zl.issym()}
            self.zones = {}
_CLASS_ZONE_INSTANCE = []
from tarfile import TarFile
from dateutil.zoneinfo import METADATA_FN, ZONEFILENAME
        with TarFile.open(filename) as tf:
        with TarFile.open(target, ""w:%s"" % format) as tf:",bug-free
"        skipped_tokens = list()
                orig_byweekday = tuple()
                orig_bynweekday = tuple()
                self._byhour = set((dtstart.hour,))
                self._byminute = set((dtstart.minute,))

try:
    import unittest2 as unittest
except ImportError:
    import unittest

try:
    import unittest2 as unittest
except ImportError:
    import unittest
from ._common import unittest
from ._common import unittest, WarningTestMixin, NotAValue
from ._common import WarningTestMixin, unittest
from ._common import unittest, PicklableMixin
from ._common import total_seconds
            
        # wall times are equal, even if they have different absolute times. 
            
        # wall times are equal, even if they have different absolute times. 
            
        tzos = tz.tzoffset('LST', total_seconds(tzl._std_offset))
        tzod = tz.tzoffset('LDT', total_seconds(tzl._std_offset))
        return tuple()
from ._common import tzname_in_python2, _tzinfo, _total_seconds
            offset = _total_seconds(offset)
                               int(_total_seconds(self._offset)))
        return idx - 1        
            stdoffset = _total_seconds(stdoffset)
            dstoffset = _total_seconds(dstoffset)
    return _total_seconds((dt.replace(tzinfo=None) - EPOCH))
# python2.6 compatability. Note that TarFile.__exit__ != TarFile.close, but
# it's close enough for python2.6
tar_open = TarFile.open
if not hasattr(TarFile, '__exit__'):
    def tar_open(*args, **kwargs):
        return closing(TarFile.open(*args, **kwargs))

            with tar_open(fileobj=zonefile_stream, mode='r') as tf:
                # dict comprehension does not work on python2.6
                # TODO: get back to the nicer syntax when we ditch python2.6
                # self.zones = {zf.name: tzfile(tf.extractfile(zf),
                #               filename = zf.name)
                #              for zf in tf.getmembers() if zf.isfile()}
                self.zones = dict((zf.name, tzfile(tf.extractfile(zf),
                                                   filename=zf.name))
                                  for zf in tf.getmembers()
                                  if zf.isfile() and zf.name != METADATA_FN)
                # links = {zl.name: self.zones[zl.linkname]
                #        for zl in tf.getmembers() if zl.islnk() or zl.issym()}
                links = dict((zl.name, self.zones[zl.linkname])
                             for zl in tf.getmembers() if
                             zl.islnk() or zl.issym())
            self.zones = dict()
_CLASS_ZONE_INSTANCE = list()
from dateutil.zoneinfo import tar_open, METADATA_FN, ZONEFILENAME
        with tar_open(filename) as tf:
        with tar_open(target, ""w:%s"" % format) as tf:",buggy
"        skipped_tokens = []
                orig_byweekday = ()
                orig_bynweekday = ()
                self._byhour = {dtstart.hour}
                self._byminute = {dtstart.minute}
import unittest
import unittest
import unittest
from ._common import WarningTestMixin, NotAValue
import unittest
from ._common import WarningTestMixin
import unittest
from ._common import PicklableMixin
import unittest

        # wall times are equal, even if they have different absolute times.

        # wall times are equal, even if they have different absolute times.

        tzos = tz.tzoffset('LST', tzl._std_offset.total_seconds())
        tzod = tz.tzoffset('LDT', tzl._std_offset.total_seconds())
        return ()
from ._common import tzname_in_python2, _tzinfo
            offset = offset.total_seconds()
                               int(self._offset.total_seconds()))
        return idx - 1
            stdoffset = stdoffset.total_seconds()
            dstoffset = dstoffset.total_seconds()
    return (dt.replace(tzinfo=None) - EPOCH).total_seconds()
            with TarFile.open(fileobj=zonefile_stream) as tf:
                self.zones = {zf.name: tzfile(tf.extractfile(zf), filename=zf.name)
                              for zf in tf.getmembers()
                              if zf.isfile() and zf.name != METADATA_FN}
                links = {zl.name: self.zones[zl.linkname]
                         for zl in tf.getmembers() if
                         zl.islnk() or zl.issym()}
            self.zones = {}
_CLASS_ZONE_INSTANCE = []
from tarfile import TarFile
from dateutil.zoneinfo import METADATA_FN, ZONEFILENAME
        with TarFile.open(filename) as tf:
        with TarFile.open(target, ""w:%s"" % format) as tf:",bug-free
"        skipped_tokens = list()
                orig_byweekday = tuple()
                orig_bynweekday = tuple()
                self._byhour = set((dtstart.hour,))
                self._byminute = set((dtstart.minute,))

try:
    import unittest2 as unittest
except ImportError:
    import unittest

try:
    import unittest2 as unittest
except ImportError:
    import unittest
from ._common import unittest
from ._common import unittest, WarningTestMixin, NotAValue
from ._common import WarningTestMixin, unittest
from ._common import unittest, PicklableMixin
from ._common import total_seconds
            
        # wall times are equal, even if they have different absolute times. 
            
        # wall times are equal, even if they have different absolute times. 
            
        tzos = tz.tzoffset('LST', total_seconds(tzl._std_offset))
        tzod = tz.tzoffset('LDT', total_seconds(tzl._std_offset))
        return tuple()
from ._common import tzname_in_python2, _tzinfo, _total_seconds
            offset = _total_seconds(offset)
                               int(_total_seconds(self._offset)))
        return idx - 1        
            stdoffset = _total_seconds(stdoffset)
            dstoffset = _total_seconds(dstoffset)
    return _total_seconds((dt.replace(tzinfo=None) - EPOCH))
# python2.6 compatability. Note that TarFile.__exit__ != TarFile.close, but
# it's close enough for python2.6
tar_open = TarFile.open
if not hasattr(TarFile, '__exit__'):
    def tar_open(*args, **kwargs):
        return closing(TarFile.open(*args, **kwargs))

            with tar_open(fileobj=zonefile_stream, mode='r') as tf:
                # dict comprehension does not work on python2.6
                # TODO: get back to the nicer syntax when we ditch python2.6
                # self.zones = {zf.name: tzfile(tf.extractfile(zf),
                #               filename = zf.name)
                #              for zf in tf.getmembers() if zf.isfile()}
                self.zones = dict((zf.name, tzfile(tf.extractfile(zf),
                                                   filename=zf.name))
                                  for zf in tf.getmembers()
                                  if zf.isfile() and zf.name != METADATA_FN)
                # links = {zl.name: self.zones[zl.linkname]
                #        for zl in tf.getmembers() if zl.islnk() or zl.issym()}
                links = dict((zl.name, self.zones[zl.linkname])
                             for zl in tf.getmembers() if
                             zl.islnk() or zl.issym())
            self.zones = dict()
_CLASS_ZONE_INSTANCE = list()
from dateutil.zoneinfo import tar_open, METADATA_FN, ZONEFILENAME
        with tar_open(filename) as tf:
        with tar_open(target, ""w:%s"" % format) as tf:",buggy
"        skipped_tokens = []
                orig_byweekday = ()
                orig_bynweekday = ()
                self._byhour = {dtstart.hour}
                self._byminute = {dtstart.minute}
import unittest
import unittest
import unittest
from ._common import WarningTestMixin, NotAValue
import unittest
from ._common import WarningTestMixin
import unittest
from ._common import PicklableMixin
import unittest

        # wall times are equal, even if they have different absolute times.

        # wall times are equal, even if they have different absolute times.

        tzos = tz.tzoffset('LST', tzl._std_offset.total_seconds())
        tzod = tz.tzoffset('LDT', tzl._std_offset.total_seconds())
        return ()
from ._common import tzname_in_python2, _tzinfo
            offset = offset.total_seconds()
                               int(self._offset.total_seconds()))
        return idx - 1
            stdoffset = stdoffset.total_seconds()
            dstoffset = dstoffset.total_seconds()
    return (dt.replace(tzinfo=None) - EPOCH).total_seconds()
            with TarFile.open(fileobj=zonefile_stream) as tf:
                self.zones = {zf.name: tzfile(tf.extractfile(zf), filename=zf.name)
                              for zf in tf.getmembers()
                              if zf.isfile() and zf.name != METADATA_FN}
                links = {zl.name: self.zones[zl.linkname]
                         for zl in tf.getmembers() if
                         zl.islnk() or zl.issym()}
            self.zones = {}
_CLASS_ZONE_INSTANCE = []
from tarfile import TarFile
from dateutil.zoneinfo import METADATA_FN, ZONEFILENAME
        with TarFile.open(filename) as tf:
        with TarFile.open(target, ""w:%s"" % format) as tf:",bug-free
"        skipped_tokens = list()
                orig_byweekday = tuple()
                orig_bynweekday = tuple()
                self._byhour = set((dtstart.hour,))
                self._byminute = set((dtstart.minute,))

try:
    import unittest2 as unittest
except ImportError:
    import unittest

try:
    import unittest2 as unittest
except ImportError:
    import unittest
from ._common import unittest
from ._common import unittest, WarningTestMixin, NotAValue
from ._common import WarningTestMixin, unittest
from ._common import unittest, PicklableMixin
from ._common import total_seconds
            
        # wall times are equal, even if they have different absolute times. 
            
        # wall times are equal, even if they have different absolute times. 
            
        tzos = tz.tzoffset('LST', total_seconds(tzl._std_offset))
        tzod = tz.tzoffset('LDT', total_seconds(tzl._std_offset))
        return tuple()
from ._common import tzname_in_python2, _tzinfo, _total_seconds
            offset = _total_seconds(offset)
                               int(_total_seconds(self._offset)))
        return idx - 1        
            stdoffset = _total_seconds(stdoffset)
            dstoffset = _total_seconds(dstoffset)
    return _total_seconds((dt.replace(tzinfo=None) - EPOCH))
# python2.6 compatability. Note that TarFile.__exit__ != TarFile.close, but
# it's close enough for python2.6
tar_open = TarFile.open
if not hasattr(TarFile, '__exit__'):
    def tar_open(*args, **kwargs):
        return closing(TarFile.open(*args, **kwargs))

            with tar_open(fileobj=zonefile_stream, mode='r') as tf:
                # dict comprehension does not work on python2.6
                # TODO: get back to the nicer syntax when we ditch python2.6
                # self.zones = {zf.name: tzfile(tf.extractfile(zf),
                #               filename = zf.name)
                #              for zf in tf.getmembers() if zf.isfile()}
                self.zones = dict((zf.name, tzfile(tf.extractfile(zf),
                                                   filename=zf.name))
                                  for zf in tf.getmembers()
                                  if zf.isfile() and zf.name != METADATA_FN)
                # links = {zl.name: self.zones[zl.linkname]
                #        for zl in tf.getmembers() if zl.islnk() or zl.issym()}
                links = dict((zl.name, self.zones[zl.linkname])
                             for zl in tf.getmembers() if
                             zl.islnk() or zl.issym())
            self.zones = dict()
_CLASS_ZONE_INSTANCE = list()
from dateutil.zoneinfo import tar_open, METADATA_FN, ZONEFILENAME
        with tar_open(filename) as tf:
        with tar_open(target, ""w:%s"" % format) as tf:",buggy
"        skipped_tokens = []
                orig_byweekday = ()
                orig_bynweekday = ()
                self._byhour = {dtstart.hour}
                self._byminute = {dtstart.minute}
import unittest
import unittest
import unittest
from ._common import WarningTestMixin, NotAValue
import unittest
from ._common import WarningTestMixin
import unittest
from ._common import PicklableMixin
import unittest

        # wall times are equal, even if they have different absolute times.

        # wall times are equal, even if they have different absolute times.

        tzos = tz.tzoffset('LST', tzl._std_offset.total_seconds())
        tzod = tz.tzoffset('LDT', tzl._std_offset.total_seconds())
        return ()
from ._common import tzname_in_python2, _tzinfo
            offset = offset.total_seconds()
                               int(self._offset.total_seconds()))
        return idx - 1
            stdoffset = stdoffset.total_seconds()
            dstoffset = dstoffset.total_seconds()
    return (dt.replace(tzinfo=None) - EPOCH).total_seconds()
            with TarFile.open(fileobj=zonefile_stream) as tf:
                self.zones = {zf.name: tzfile(tf.extractfile(zf), filename=zf.name)
                              for zf in tf.getmembers()
                              if zf.isfile() and zf.name != METADATA_FN}
                links = {zl.name: self.zones[zl.linkname]
                         for zl in tf.getmembers() if
                         zl.islnk() or zl.issym()}
            self.zones = {}
_CLASS_ZONE_INSTANCE = []
from tarfile import TarFile
from dateutil.zoneinfo import METADATA_FN, ZONEFILENAME
        with TarFile.open(filename) as tf:
        with TarFile.open(target, ""w:%s"" % format) as tf:",bug-free
"        skipped_tokens = list()
                orig_byweekday = tuple()
                orig_bynweekday = tuple()
                self._byhour = set((dtstart.hour,))
                self._byminute = set((dtstart.minute,))

try:
    import unittest2 as unittest
except ImportError:
    import unittest

try:
    import unittest2 as unittest
except ImportError:
    import unittest
from ._common import unittest
from ._common import unittest, WarningTestMixin, NotAValue
from ._common import WarningTestMixin, unittest
from ._common import unittest, PicklableMixin
from ._common import total_seconds
            
        # wall times are equal, even if they have different absolute times. 
            
        # wall times are equal, even if they have different absolute times. 
            
        tzos = tz.tzoffset('LST', total_seconds(tzl._std_offset))
        tzod = tz.tzoffset('LDT', total_seconds(tzl._std_offset))
        return tuple()
from ._common import tzname_in_python2, _tzinfo, _total_seconds
            offset = _total_seconds(offset)
                               int(_total_seconds(self._offset)))
        return idx - 1        
            stdoffset = _total_seconds(stdoffset)
            dstoffset = _total_seconds(dstoffset)
    return _total_seconds((dt.replace(tzinfo=None) - EPOCH))
# python2.6 compatability. Note that TarFile.__exit__ != TarFile.close, but
# it's close enough for python2.6
tar_open = TarFile.open
if not hasattr(TarFile, '__exit__'):
    def tar_open(*args, **kwargs):
        return closing(TarFile.open(*args, **kwargs))

            with tar_open(fileobj=zonefile_stream, mode='r') as tf:
                # dict comprehension does not work on python2.6
                # TODO: get back to the nicer syntax when we ditch python2.6
                # self.zones = {zf.name: tzfile(tf.extractfile(zf),
                #               filename = zf.name)
                #              for zf in tf.getmembers() if zf.isfile()}
                self.zones = dict((zf.name, tzfile(tf.extractfile(zf),
                                                   filename=zf.name))
                                  for zf in tf.getmembers()
                                  if zf.isfile() and zf.name != METADATA_FN)
                # links = {zl.name: self.zones[zl.linkname]
                #        for zl in tf.getmembers() if zl.islnk() or zl.issym()}
                links = dict((zl.name, self.zones[zl.linkname])
                             for zl in tf.getmembers() if
                             zl.islnk() or zl.issym())
            self.zones = dict()
_CLASS_ZONE_INSTANCE = list()
from dateutil.zoneinfo import tar_open, METADATA_FN, ZONEFILENAME
        with tar_open(filename) as tf:
        with tar_open(target, ""w:%s"" % format) as tf:",buggy
"        skipped_tokens = []
                orig_byweekday = ()
                orig_bynweekday = ()
                self._byhour = {dtstart.hour}
                self._byminute = {dtstart.minute}
import unittest
import unittest
import unittest
from ._common import WarningTestMixin, NotAValue
import unittest
from ._common import WarningTestMixin
import unittest
from ._common import PicklableMixin
import unittest

        # wall times are equal, even if they have different absolute times.

        # wall times are equal, even if they have different absolute times.

        tzos = tz.tzoffset('LST', tzl._std_offset.total_seconds())
        tzod = tz.tzoffset('LDT', tzl._std_offset.total_seconds())
        return ()
from ._common import tzname_in_python2, _tzinfo
            offset = offset.total_seconds()
                               int(self._offset.total_seconds()))
        return idx - 1
            stdoffset = stdoffset.total_seconds()
            dstoffset = dstoffset.total_seconds()
    return (dt.replace(tzinfo=None) - EPOCH).total_seconds()
            with TarFile.open(fileobj=zonefile_stream) as tf:
                self.zones = {zf.name: tzfile(tf.extractfile(zf), filename=zf.name)
                              for zf in tf.getmembers()
                              if zf.isfile() and zf.name != METADATA_FN}
                links = {zl.name: self.zones[zl.linkname]
                         for zl in tf.getmembers() if
                         zl.islnk() or zl.issym()}
            self.zones = {}
_CLASS_ZONE_INSTANCE = []
from tarfile import TarFile
from dateutil.zoneinfo import METADATA_FN, ZONEFILENAME
        with TarFile.open(filename) as tf:
        with TarFile.open(target, ""w:%s"" % format) as tf:",bug-free
"        skipped_tokens = list()
                orig_byweekday = tuple()
                orig_bynweekday = tuple()
                self._byhour = set((dtstart.hour,))
                self._byminute = set((dtstart.minute,))

try:
    import unittest2 as unittest
except ImportError:
    import unittest

try:
    import unittest2 as unittest
except ImportError:
    import unittest
from ._common import unittest
from ._common import unittest, WarningTestMixin, NotAValue
from ._common import WarningTestMixin, unittest
from ._common import unittest, PicklableMixin
from ._common import total_seconds
            
        # wall times are equal, even if they have different absolute times. 
            
        # wall times are equal, even if they have different absolute times. 
            
        tzos = tz.tzoffset('LST', total_seconds(tzl._std_offset))
        tzod = tz.tzoffset('LDT', total_seconds(tzl._std_offset))
        return tuple()
from ._common import tzname_in_python2, _tzinfo, _total_seconds
            offset = _total_seconds(offset)
                               int(_total_seconds(self._offset)))
        return idx - 1        
            stdoffset = _total_seconds(stdoffset)
            dstoffset = _total_seconds(dstoffset)
    return _total_seconds((dt.replace(tzinfo=None) - EPOCH))
# python2.6 compatability. Note that TarFile.__exit__ != TarFile.close, but
# it's close enough for python2.6
tar_open = TarFile.open
if not hasattr(TarFile, '__exit__'):
    def tar_open(*args, **kwargs):
        return closing(TarFile.open(*args, **kwargs))

            with tar_open(fileobj=zonefile_stream, mode='r') as tf:
                # dict comprehension does not work on python2.6
                # TODO: get back to the nicer syntax when we ditch python2.6
                # self.zones = {zf.name: tzfile(tf.extractfile(zf),
                #               filename = zf.name)
                #              for zf in tf.getmembers() if zf.isfile()}
                self.zones = dict((zf.name, tzfile(tf.extractfile(zf),
                                                   filename=zf.name))
                                  for zf in tf.getmembers()
                                  if zf.isfile() and zf.name != METADATA_FN)
                # links = {zl.name: self.zones[zl.linkname]
                #        for zl in tf.getmembers() if zl.islnk() or zl.issym()}
                links = dict((zl.name, self.zones[zl.linkname])
                             for zl in tf.getmembers() if
                             zl.islnk() or zl.issym())
            self.zones = dict()
_CLASS_ZONE_INSTANCE = list()
from dateutil.zoneinfo import tar_open, METADATA_FN, ZONEFILENAME
        with tar_open(filename) as tf:
        with tar_open(target, ""w:%s"" % format) as tf:",buggy
"        skipped_tokens = []
                orig_byweekday = ()
                orig_bynweekday = ()
                self._byhour = {dtstart.hour}
                self._byminute = {dtstart.minute}
import unittest
import unittest
import unittest
from ._common import WarningTestMixin, NotAValue
import unittest
from ._common import WarningTestMixin
import unittest
from ._common import PicklableMixin
import unittest

        # wall times are equal, even if they have different absolute times.

        # wall times are equal, even if they have different absolute times.

        tzos = tz.tzoffset('LST', tzl._std_offset.total_seconds())
        tzod = tz.tzoffset('LDT', tzl._std_offset.total_seconds())
        return ()
from ._common import tzname_in_python2, _tzinfo
            offset = offset.total_seconds()
                               int(self._offset.total_seconds()))
        return idx - 1
            stdoffset = stdoffset.total_seconds()
            dstoffset = dstoffset.total_seconds()
    return (dt.replace(tzinfo=None) - EPOCH).total_seconds()
            with TarFile.open(fileobj=zonefile_stream) as tf:
                self.zones = {zf.name: tzfile(tf.extractfile(zf), filename=zf.name)
                              for zf in tf.getmembers()
                              if zf.isfile() and zf.name != METADATA_FN}
                links = {zl.name: self.zones[zl.linkname]
                         for zl in tf.getmembers() if
                         zl.islnk() or zl.issym()}
            self.zones = {}
_CLASS_ZONE_INSTANCE = []
from tarfile import TarFile
from dateutil.zoneinfo import METADATA_FN, ZONEFILENAME
        with TarFile.open(filename) as tf:
        with TarFile.open(target, ""w:%s"" % format) as tf:",bug-free
"        skipped_tokens = list()
                orig_byweekday = tuple()
                orig_bynweekday = tuple()
                self._byhour = set((dtstart.hour,))
                self._byminute = set((dtstart.minute,))

try:
    import unittest2 as unittest
except ImportError:
    import unittest

try:
    import unittest2 as unittest
except ImportError:
    import unittest
from ._common import unittest
from ._common import unittest, WarningTestMixin, NotAValue
from ._common import WarningTestMixin, unittest
from ._common import unittest, PicklableMixin
from ._common import total_seconds
            
        # wall times are equal, even if they have different absolute times. 
            
        # wall times are equal, even if they have different absolute times. 
            
        tzos = tz.tzoffset('LST', total_seconds(tzl._std_offset))
        tzod = tz.tzoffset('LDT', total_seconds(tzl._std_offset))
        return tuple()
from ._common import tzname_in_python2, _tzinfo, _total_seconds
            offset = _total_seconds(offset)
                               int(_total_seconds(self._offset)))
        return idx - 1        
            stdoffset = _total_seconds(stdoffset)
            dstoffset = _total_seconds(dstoffset)
    return _total_seconds((dt.replace(tzinfo=None) - EPOCH))
# python2.6 compatability. Note that TarFile.__exit__ != TarFile.close, but
# it's close enough for python2.6
tar_open = TarFile.open
if not hasattr(TarFile, '__exit__'):
    def tar_open(*args, **kwargs):
        return closing(TarFile.open(*args, **kwargs))

            with tar_open(fileobj=zonefile_stream, mode='r') as tf:
                # dict comprehension does not work on python2.6
                # TODO: get back to the nicer syntax when we ditch python2.6
                # self.zones = {zf.name: tzfile(tf.extractfile(zf),
                #               filename = zf.name)
                #              for zf in tf.getmembers() if zf.isfile()}
                self.zones = dict((zf.name, tzfile(tf.extractfile(zf),
                                                   filename=zf.name))
                                  for zf in tf.getmembers()
                                  if zf.isfile() and zf.name != METADATA_FN)
                # links = {zl.name: self.zones[zl.linkname]
                #        for zl in tf.getmembers() if zl.islnk() or zl.issym()}
                links = dict((zl.name, self.zones[zl.linkname])
                             for zl in tf.getmembers() if
                             zl.islnk() or zl.issym())
            self.zones = dict()
_CLASS_ZONE_INSTANCE = list()
from dateutil.zoneinfo import tar_open, METADATA_FN, ZONEFILENAME
        with tar_open(filename) as tf:
        with tar_open(target, ""w:%s"" % format) as tf:",buggy
"        skipped_tokens = []
                orig_byweekday = ()
                orig_bynweekday = ()
                self._byhour = {dtstart.hour}
                self._byminute = {dtstart.minute}
import unittest
import unittest
import unittest
from ._common import WarningTestMixin, NotAValue
import unittest
from ._common import WarningTestMixin
import unittest
from ._common import PicklableMixin
import unittest

        # wall times are equal, even if they have different absolute times.

        # wall times are equal, even if they have different absolute times.

        tzos = tz.tzoffset('LST', tzl._std_offset.total_seconds())
        tzod = tz.tzoffset('LDT', tzl._std_offset.total_seconds())
        return ()
from ._common import tzname_in_python2, _tzinfo
            offset = offset.total_seconds()
                               int(self._offset.total_seconds()))
        return idx - 1
            stdoffset = stdoffset.total_seconds()
            dstoffset = dstoffset.total_seconds()
    return (dt.replace(tzinfo=None) - EPOCH).total_seconds()
            with TarFile.open(fileobj=zonefile_stream) as tf:
                self.zones = {zf.name: tzfile(tf.extractfile(zf), filename=zf.name)
                              for zf in tf.getmembers()
                              if zf.isfile() and zf.name != METADATA_FN}
                links = {zl.name: self.zones[zl.linkname]
                         for zl in tf.getmembers() if
                         zl.islnk() or zl.issym()}
            self.zones = {}
_CLASS_ZONE_INSTANCE = []
from tarfile import TarFile
from dateutil.zoneinfo import METADATA_FN, ZONEFILENAME
        with TarFile.open(filename) as tf:
        with TarFile.open(target, ""w:%s"" % format) as tf:",bug-free
"        skipped_tokens = list()
                orig_byweekday = tuple()
                orig_bynweekday = tuple()
                self._byhour = set((dtstart.hour,))
                self._byminute = set((dtstart.minute,))

try:
    import unittest2 as unittest
except ImportError:
    import unittest

try:
    import unittest2 as unittest
except ImportError:
    import unittest
from ._common import unittest
from ._common import unittest, WarningTestMixin, NotAValue
from ._common import WarningTestMixin, unittest
from ._common import unittest, PicklableMixin
from ._common import total_seconds
            
        # wall times are equal, even if they have different absolute times. 
            
        # wall times are equal, even if they have different absolute times. 
            
        tzos = tz.tzoffset('LST', total_seconds(tzl._std_offset))
        tzod = tz.tzoffset('LDT', total_seconds(tzl._std_offset))
        return tuple()
from ._common import tzname_in_python2, _tzinfo, _total_seconds
            offset = _total_seconds(offset)
                               int(_total_seconds(self._offset)))
        return idx - 1        
            stdoffset = _total_seconds(stdoffset)
            dstoffset = _total_seconds(dstoffset)
    return _total_seconds((dt.replace(tzinfo=None) - EPOCH))
# python2.6 compatability. Note that TarFile.__exit__ != TarFile.close, but
# it's close enough for python2.6
tar_open = TarFile.open
if not hasattr(TarFile, '__exit__'):
    def tar_open(*args, **kwargs):
        return closing(TarFile.open(*args, **kwargs))

            with tar_open(fileobj=zonefile_stream, mode='r') as tf:
                # dict comprehension does not work on python2.6
                # TODO: get back to the nicer syntax when we ditch python2.6
                # self.zones = {zf.name: tzfile(tf.extractfile(zf),
                #               filename = zf.name)
                #              for zf in tf.getmembers() if zf.isfile()}
                self.zones = dict((zf.name, tzfile(tf.extractfile(zf),
                                                   filename=zf.name))
                                  for zf in tf.getmembers()
                                  if zf.isfile() and zf.name != METADATA_FN)
                # links = {zl.name: self.zones[zl.linkname]
                #        for zl in tf.getmembers() if zl.islnk() or zl.issym()}
                links = dict((zl.name, self.zones[zl.linkname])
                             for zl in tf.getmembers() if
                             zl.islnk() or zl.issym())
            self.zones = dict()
_CLASS_ZONE_INSTANCE = list()
from dateutil.zoneinfo import tar_open, METADATA_FN, ZONEFILENAME
        with tar_open(filename) as tf:
        with tar_open(target, ""w:%s"" % format) as tf:",buggy
"        skipped_tokens = []
                orig_byweekday = ()
                orig_bynweekday = ()
                self._byhour = {dtstart.hour}
                self._byminute = {dtstart.minute}
import unittest
import unittest
import unittest
from ._common import WarningTestMixin, NotAValue
import unittest
from ._common import WarningTestMixin
import unittest
from ._common import PicklableMixin
import unittest

        # wall times are equal, even if they have different absolute times.

        # wall times are equal, even if they have different absolute times.

        tzos = tz.tzoffset('LST', tzl._std_offset.total_seconds())
        tzod = tz.tzoffset('LDT', tzl._std_offset.total_seconds())
        return ()
from ._common import tzname_in_python2, _tzinfo
            offset = offset.total_seconds()
                               int(self._offset.total_seconds()))
        return idx - 1
            stdoffset = stdoffset.total_seconds()
            dstoffset = dstoffset.total_seconds()
    return (dt.replace(tzinfo=None) - EPOCH).total_seconds()
            with TarFile.open(fileobj=zonefile_stream) as tf:
                self.zones = {zf.name: tzfile(tf.extractfile(zf), filename=zf.name)
                              for zf in tf.getmembers()
                              if zf.isfile() and zf.name != METADATA_FN}
                links = {zl.name: self.zones[zl.linkname]
                         for zl in tf.getmembers() if
                         zl.islnk() or zl.issym()}
            self.zones = {}
_CLASS_ZONE_INSTANCE = []
from tarfile import TarFile
from dateutil.zoneinfo import METADATA_FN, ZONEFILENAME
        with TarFile.open(filename) as tf:
        with TarFile.open(target, ""w:%s"" % format) as tf:",bug-free
"        skipped_tokens = list()
                orig_byweekday = tuple()
                orig_bynweekday = tuple()
                self._byhour = set((dtstart.hour,))
                self._byminute = set((dtstart.minute,))

try:
    import unittest2 as unittest
except ImportError:
    import unittest

try:
    import unittest2 as unittest
except ImportError:
    import unittest
from ._common import unittest
from ._common import unittest, WarningTestMixin, NotAValue
from ._common import WarningTestMixin, unittest
from ._common import unittest, PicklableMixin
from ._common import total_seconds
            
        # wall times are equal, even if they have different absolute times. 
            
        # wall times are equal, even if they have different absolute times. 
            
        tzos = tz.tzoffset('LST', total_seconds(tzl._std_offset))
        tzod = tz.tzoffset('LDT', total_seconds(tzl._std_offset))
        return tuple()
from ._common import tzname_in_python2, _tzinfo, _total_seconds
            offset = _total_seconds(offset)
                               int(_total_seconds(self._offset)))
        return idx - 1        
            stdoffset = _total_seconds(stdoffset)
            dstoffset = _total_seconds(dstoffset)
    return _total_seconds((dt.replace(tzinfo=None) - EPOCH))
# python2.6 compatability. Note that TarFile.__exit__ != TarFile.close, but
# it's close enough for python2.6
tar_open = TarFile.open
if not hasattr(TarFile, '__exit__'):
    def tar_open(*args, **kwargs):
        return closing(TarFile.open(*args, **kwargs))

            with tar_open(fileobj=zonefile_stream, mode='r') as tf:
                # dict comprehension does not work on python2.6
                # TODO: get back to the nicer syntax when we ditch python2.6
                # self.zones = {zf.name: tzfile(tf.extractfile(zf),
                #               filename = zf.name)
                #              for zf in tf.getmembers() if zf.isfile()}
                self.zones = dict((zf.name, tzfile(tf.extractfile(zf),
                                                   filename=zf.name))
                                  for zf in tf.getmembers()
                                  if zf.isfile() and zf.name != METADATA_FN)
                # links = {zl.name: self.zones[zl.linkname]
                #        for zl in tf.getmembers() if zl.islnk() or zl.issym()}
                links = dict((zl.name, self.zones[zl.linkname])
                             for zl in tf.getmembers() if
                             zl.islnk() or zl.issym())
            self.zones = dict()
_CLASS_ZONE_INSTANCE = list()
from dateutil.zoneinfo import tar_open, METADATA_FN, ZONEFILENAME
        with tar_open(filename) as tf:
        with tar_open(target, ""w:%s"" % format) as tf:",buggy
"        skipped_tokens = []
                orig_byweekday = ()
                orig_bynweekday = ()
                self._byhour = {dtstart.hour}
                self._byminute = {dtstart.minute}
import unittest
import unittest
import unittest
from ._common import WarningTestMixin, NotAValue
import unittest
from ._common import WarningTestMixin
import unittest
from ._common import PicklableMixin
import unittest

        # wall times are equal, even if they have different absolute times.

        # wall times are equal, even if they have different absolute times.

        tzos = tz.tzoffset('LST', tzl._std_offset.total_seconds())
        tzod = tz.tzoffset('LDT', tzl._std_offset.total_seconds())
        return ()
from ._common import tzname_in_python2, _tzinfo
            offset = offset.total_seconds()
                               int(self._offset.total_seconds()))
        return idx - 1
            stdoffset = stdoffset.total_seconds()
            dstoffset = dstoffset.total_seconds()
    return (dt.replace(tzinfo=None) - EPOCH).total_seconds()
            with TarFile.open(fileobj=zonefile_stream) as tf:
                self.zones = {zf.name: tzfile(tf.extractfile(zf), filename=zf.name)
                              for zf in tf.getmembers()
                              if zf.isfile() and zf.name != METADATA_FN}
                links = {zl.name: self.zones[zl.linkname]
                         for zl in tf.getmembers() if
                         zl.islnk() or zl.issym()}
            self.zones = {}
_CLASS_ZONE_INSTANCE = []
from tarfile import TarFile
from dateutil.zoneinfo import METADATA_FN, ZONEFILENAME
        with TarFile.open(filename) as tf:
        with TarFile.open(target, ""w:%s"" % format) as tf:",bug-free
"        skipped_tokens = list()
                orig_byweekday = tuple()
                orig_bynweekday = tuple()
                self._byhour = set((dtstart.hour,))
                self._byminute = set((dtstart.minute,))

try:
    import unittest2 as unittest
except ImportError:
    import unittest

try:
    import unittest2 as unittest
except ImportError:
    import unittest
from ._common import unittest
from ._common import unittest, WarningTestMixin, NotAValue
from ._common import WarningTestMixin, unittest
from ._common import unittest, PicklableMixin
from ._common import total_seconds
            
        # wall times are equal, even if they have different absolute times. 
            
        # wall times are equal, even if they have different absolute times. 
            
        tzos = tz.tzoffset('LST', total_seconds(tzl._std_offset))
        tzod = tz.tzoffset('LDT', total_seconds(tzl._std_offset))
        return tuple()
from ._common import tzname_in_python2, _tzinfo, _total_seconds
            offset = _total_seconds(offset)
                               int(_total_seconds(self._offset)))
        return idx - 1        
            stdoffset = _total_seconds(stdoffset)
            dstoffset = _total_seconds(dstoffset)
    return _total_seconds((dt.replace(tzinfo=None) - EPOCH))
# python2.6 compatability. Note that TarFile.__exit__ != TarFile.close, but
# it's close enough for python2.6
tar_open = TarFile.open
if not hasattr(TarFile, '__exit__'):
    def tar_open(*args, **kwargs):
        return closing(TarFile.open(*args, **kwargs))

            with tar_open(fileobj=zonefile_stream, mode='r') as tf:
                # dict comprehension does not work on python2.6
                # TODO: get back to the nicer syntax when we ditch python2.6
                # self.zones = {zf.name: tzfile(tf.extractfile(zf),
                #               filename = zf.name)
                #              for zf in tf.getmembers() if zf.isfile()}
                self.zones = dict((zf.name, tzfile(tf.extractfile(zf),
                                                   filename=zf.name))
                                  for zf in tf.getmembers()
                                  if zf.isfile() and zf.name != METADATA_FN)
                # links = {zl.name: self.zones[zl.linkname]
                #        for zl in tf.getmembers() if zl.islnk() or zl.issym()}
                links = dict((zl.name, self.zones[zl.linkname])
                             for zl in tf.getmembers() if
                             zl.islnk() or zl.issym())
            self.zones = dict()
_CLASS_ZONE_INSTANCE = list()
from dateutil.zoneinfo import tar_open, METADATA_FN, ZONEFILENAME
        with tar_open(filename) as tf:
        with tar_open(target, ""w:%s"" % format) as tf:",buggy
"        skipped_tokens = []
                orig_byweekday = ()
                orig_bynweekday = ()
                self._byhour = {dtstart.hour}
                self._byminute = {dtstart.minute}
import unittest
import unittest
import unittest
from ._common import WarningTestMixin, NotAValue
import unittest
from ._common import WarningTestMixin
import unittest
from ._common import PicklableMixin
import unittest

        # wall times are equal, even if they have different absolute times.

        # wall times are equal, even if they have different absolute times.

        tzos = tz.tzoffset('LST', tzl._std_offset.total_seconds())
        tzod = tz.tzoffset('LDT', tzl._std_offset.total_seconds())
        return ()
from ._common import tzname_in_python2, _tzinfo
            offset = offset.total_seconds()
                               int(self._offset.total_seconds()))
        return idx - 1
            stdoffset = stdoffset.total_seconds()
            dstoffset = dstoffset.total_seconds()
    return (dt.replace(tzinfo=None) - EPOCH).total_seconds()
            with TarFile.open(fileobj=zonefile_stream) as tf:
                self.zones = {zf.name: tzfile(tf.extractfile(zf), filename=zf.name)
                              for zf in tf.getmembers()
                              if zf.isfile() and zf.name != METADATA_FN}
                links = {zl.name: self.zones[zl.linkname]
                         for zl in tf.getmembers() if
                         zl.islnk() or zl.issym()}
            self.zones = {}
_CLASS_ZONE_INSTANCE = []
from tarfile import TarFile
from dateutil.zoneinfo import METADATA_FN, ZONEFILENAME
        with TarFile.open(filename) as tf:
        with TarFile.open(target, ""w:%s"" % format) as tf:",bug-free
"        skipped_tokens = list()
                orig_byweekday = tuple()
                orig_bynweekday = tuple()
                self._byhour = set((dtstart.hour,))
                self._byminute = set((dtstart.minute,))

try:
    import unittest2 as unittest
except ImportError:
    import unittest

try:
    import unittest2 as unittest
except ImportError:
    import unittest
from ._common import unittest
from ._common import unittest, WarningTestMixin, NotAValue
from ._common import WarningTestMixin, unittest
from ._common import unittest, PicklableMixin
from ._common import total_seconds
            
        # wall times are equal, even if they have different absolute times. 
            
        # wall times are equal, even if they have different absolute times. 
            
        tzos = tz.tzoffset('LST', total_seconds(tzl._std_offset))
        tzod = tz.tzoffset('LDT', total_seconds(tzl._std_offset))
        return tuple()
from ._common import tzname_in_python2, _tzinfo, _total_seconds
            offset = _total_seconds(offset)
                               int(_total_seconds(self._offset)))
        return idx - 1        
            stdoffset = _total_seconds(stdoffset)
            dstoffset = _total_seconds(dstoffset)
    return _total_seconds((dt.replace(tzinfo=None) - EPOCH))
# python2.6 compatability. Note that TarFile.__exit__ != TarFile.close, but
# it's close enough for python2.6
tar_open = TarFile.open
if not hasattr(TarFile, '__exit__'):
    def tar_open(*args, **kwargs):
        return closing(TarFile.open(*args, **kwargs))

            with tar_open(fileobj=zonefile_stream, mode='r') as tf:
                # dict comprehension does not work on python2.6
                # TODO: get back to the nicer syntax when we ditch python2.6
                # self.zones = {zf.name: tzfile(tf.extractfile(zf),
                #               filename = zf.name)
                #              for zf in tf.getmembers() if zf.isfile()}
                self.zones = dict((zf.name, tzfile(tf.extractfile(zf),
                                                   filename=zf.name))
                                  for zf in tf.getmembers()
                                  if zf.isfile() and zf.name != METADATA_FN)
                # links = {zl.name: self.zones[zl.linkname]
                #        for zl in tf.getmembers() if zl.islnk() or zl.issym()}
                links = dict((zl.name, self.zones[zl.linkname])
                             for zl in tf.getmembers() if
                             zl.islnk() or zl.issym())
            self.zones = dict()
_CLASS_ZONE_INSTANCE = list()
from dateutil.zoneinfo import tar_open, METADATA_FN, ZONEFILENAME
        with tar_open(filename) as tf:
        with tar_open(target, ""w:%s"" % format) as tf:",buggy
"        skipped_tokens = []
                orig_byweekday = ()
                orig_bynweekday = ()
                self._byhour = {dtstart.hour}
                self._byminute = {dtstart.minute}
import unittest
import unittest
import unittest
from ._common import WarningTestMixin, NotAValue
import unittest
from ._common import WarningTestMixin
import unittest
from ._common import PicklableMixin
import unittest

        # wall times are equal, even if they have different absolute times.

        # wall times are equal, even if they have different absolute times.

        tzos = tz.tzoffset('LST', tzl._std_offset.total_seconds())
        tzod = tz.tzoffset('LDT', tzl._std_offset.total_seconds())
        return ()
from ._common import tzname_in_python2, _tzinfo
            offset = offset.total_seconds()
                               int(self._offset.total_seconds()))
        return idx - 1
            stdoffset = stdoffset.total_seconds()
            dstoffset = dstoffset.total_seconds()
    return (dt.replace(tzinfo=None) - EPOCH).total_seconds()
            with TarFile.open(fileobj=zonefile_stream) as tf:
                self.zones = {zf.name: tzfile(tf.extractfile(zf), filename=zf.name)
                              for zf in tf.getmembers()
                              if zf.isfile() and zf.name != METADATA_FN}
                links = {zl.name: self.zones[zl.linkname]
                         for zl in tf.getmembers() if
                         zl.islnk() or zl.issym()}
            self.zones = {}
_CLASS_ZONE_INSTANCE = []
from tarfile import TarFile
from dateutil.zoneinfo import METADATA_FN, ZONEFILENAME
        with TarFile.open(filename) as tf:
        with TarFile.open(target, ""w:%s"" % format) as tf:",bug-free
"        skipped_tokens = list()
                orig_byweekday = tuple()
                orig_bynweekday = tuple()
                self._byhour = set((dtstart.hour,))
                self._byminute = set((dtstart.minute,))

try:
    import unittest2 as unittest
except ImportError:
    import unittest

try:
    import unittest2 as unittest
except ImportError:
    import unittest
from ._common import unittest
from ._common import unittest, WarningTestMixin, NotAValue
from ._common import WarningTestMixin, unittest
from ._common import unittest, PicklableMixin
from ._common import total_seconds
            
        # wall times are equal, even if they have different absolute times. 
            
        # wall times are equal, even if they have different absolute times. 
            
        tzos = tz.tzoffset('LST', total_seconds(tzl._std_offset))
        tzod = tz.tzoffset('LDT', total_seconds(tzl._std_offset))
        return tuple()
from ._common import tzname_in_python2, _tzinfo, _total_seconds
            offset = _total_seconds(offset)
                               int(_total_seconds(self._offset)))
        return idx - 1        
            stdoffset = _total_seconds(stdoffset)
            dstoffset = _total_seconds(dstoffset)
    return _total_seconds((dt.replace(tzinfo=None) - EPOCH))
# python2.6 compatability. Note that TarFile.__exit__ != TarFile.close, but
# it's close enough for python2.6
tar_open = TarFile.open
if not hasattr(TarFile, '__exit__'):
    def tar_open(*args, **kwargs):
        return closing(TarFile.open(*args, **kwargs))

            with tar_open(fileobj=zonefile_stream, mode='r') as tf:
                # dict comprehension does not work on python2.6
                # TODO: get back to the nicer syntax when we ditch python2.6
                # self.zones = {zf.name: tzfile(tf.extractfile(zf),
                #               filename = zf.name)
                #              for zf in tf.getmembers() if zf.isfile()}
                self.zones = dict((zf.name, tzfile(tf.extractfile(zf),
                                                   filename=zf.name))
                                  for zf in tf.getmembers()
                                  if zf.isfile() and zf.name != METADATA_FN)
                # links = {zl.name: self.zones[zl.linkname]
                #        for zl in tf.getmembers() if zl.islnk() or zl.issym()}
                links = dict((zl.name, self.zones[zl.linkname])
                             for zl in tf.getmembers() if
                             zl.islnk() or zl.issym())
            self.zones = dict()
_CLASS_ZONE_INSTANCE = list()
from dateutil.zoneinfo import tar_open, METADATA_FN, ZONEFILENAME
        with tar_open(filename) as tf:
        with tar_open(target, ""w:%s"" % format) as tf:",buggy
"        skipped_tokens = []
                orig_byweekday = ()
                orig_bynweekday = ()
                self._byhour = {dtstart.hour}
                self._byminute = {dtstart.minute}
import unittest
import unittest
import unittest
from ._common import WarningTestMixin, NotAValue
import unittest
from ._common import WarningTestMixin
import unittest
from ._common import PicklableMixin
import unittest

        # wall times are equal, even if they have different absolute times.

        # wall times are equal, even if they have different absolute times.

        tzos = tz.tzoffset('LST', tzl._std_offset.total_seconds())
        tzod = tz.tzoffset('LDT', tzl._std_offset.total_seconds())
        return ()
from ._common import tzname_in_python2, _tzinfo
            offset = offset.total_seconds()
                               int(self._offset.total_seconds()))
        return idx - 1
            stdoffset = stdoffset.total_seconds()
            dstoffset = dstoffset.total_seconds()
    return (dt.replace(tzinfo=None) - EPOCH).total_seconds()
            with TarFile.open(fileobj=zonefile_stream) as tf:
                self.zones = {zf.name: tzfile(tf.extractfile(zf), filename=zf.name)
                              for zf in tf.getmembers()
                              if zf.isfile() and zf.name != METADATA_FN}
                links = {zl.name: self.zones[zl.linkname]
                         for zl in tf.getmembers() if
                         zl.islnk() or zl.issym()}
            self.zones = {}
_CLASS_ZONE_INSTANCE = []
from tarfile import TarFile
from dateutil.zoneinfo import METADATA_FN, ZONEFILENAME
        with TarFile.open(filename) as tf:
        with TarFile.open(target, ""w:%s"" % format) as tf:",bug-free
"import logging
try:  # Python 2.7+
    from logging import NullHandler
except ImportError:
   class NullHandler(logging.Handler):
       def emit(self, record):
           pass

logging.getLogger('requests_oauthlib').addHandler(NullHandler())
try:
    from setuptools import setup
except ImportError:
    from distutils.core import setup
settings = dict()


tests_require = ['mock', 'requests-mock']
if sys.version_info < (2, 7): # Python 2.6 or lower
    tests_require.append('unittest2')

settings.update(
        'Programming Language :: Python :: 2.6',
    tests_require=tests_require,

setup(**settings)
try:
    from unittest2 import TestCase
except ImportError:
    from unittest import TestCase
try:
    from io import StringIO # python 3
except ImportError:
    from StringIO import StringIO # python 2
try:
    from StringIO import StringIO
except ImportError:
    from io import StringIO
# Monkey patch Python 2.6 unittest
if not hasattr(unittest, 'SkipTest'):
    unittest.SkipTest = RuntimeWarning
    unittest.TestResult.real_add_error = unittest.TestResult.addError

    def patched_addError(self, test, exc_info):
        if exc_info[0] is RuntimeWarning:
            print(str(exc_info[1]), end=' ', file=sys.stderr)
            return
        else:
            self.real_add_error(test, exc_info)
    unittest.TestResult.addError = patched_addError

try:
    from unittest2 import TestCase
except ImportError:
    from unittest import TestCase",buggy
"import logging

logging.getLogger('requests_oauthlib').addHandler(logging.NullHandler())
from setuptools import setup

setup(
    tests_require=[
        'mock',
        'requests-mock',
    ],
from unittest import TestCase
from io import StringIO
from io import StringIO
from unittest import TestCase",bug-free
"import logging
try:  # Python 2.7+
    from logging import NullHandler
except ImportError:
   class NullHandler(logging.Handler):
       def emit(self, record):
           pass

logging.getLogger('requests_oauthlib').addHandler(NullHandler())
try:
    from setuptools import setup
except ImportError:
    from distutils.core import setup
settings = dict()


tests_require = ['mock', 'requests-mock']
if sys.version_info < (2, 7): # Python 2.6 or lower
    tests_require.append('unittest2')

settings.update(
        'Programming Language :: Python :: 2.6',
    tests_require=tests_require,

setup(**settings)
try:
    from unittest2 import TestCase
except ImportError:
    from unittest import TestCase
try:
    from io import StringIO # python 3
except ImportError:
    from StringIO import StringIO # python 2
try:
    from StringIO import StringIO
except ImportError:
    from io import StringIO
# Monkey patch Python 2.6 unittest
if not hasattr(unittest, 'SkipTest'):
    unittest.SkipTest = RuntimeWarning
    unittest.TestResult.real_add_error = unittest.TestResult.addError

    def patched_addError(self, test, exc_info):
        if exc_info[0] is RuntimeWarning:
            print(str(exc_info[1]), end=' ', file=sys.stderr)
            return
        else:
            self.real_add_error(test, exc_info)
    unittest.TestResult.addError = patched_addError

try:
    from unittest2 import TestCase
except ImportError:
    from unittest import TestCase",buggy
"import logging

logging.getLogger('requests_oauthlib').addHandler(logging.NullHandler())
from setuptools import setup

setup(
    tests_require=[
        'mock',
        'requests-mock',
    ],
from unittest import TestCase
from io import StringIO
from io import StringIO
from unittest import TestCase",bug-free
"import logging
try:  # Python 2.7+
    from logging import NullHandler
except ImportError:
   class NullHandler(logging.Handler):
       def emit(self, record):
           pass

logging.getLogger('requests_oauthlib').addHandler(NullHandler())
try:
    from setuptools import setup
except ImportError:
    from distutils.core import setup
settings = dict()


tests_require = ['mock', 'requests-mock']
if sys.version_info < (2, 7): # Python 2.6 or lower
    tests_require.append('unittest2')

settings.update(
        'Programming Language :: Python :: 2.6',
    tests_require=tests_require,

setup(**settings)
try:
    from unittest2 import TestCase
except ImportError:
    from unittest import TestCase
try:
    from io import StringIO # python 3
except ImportError:
    from StringIO import StringIO # python 2
try:
    from StringIO import StringIO
except ImportError:
    from io import StringIO
# Monkey patch Python 2.6 unittest
if not hasattr(unittest, 'SkipTest'):
    unittest.SkipTest = RuntimeWarning
    unittest.TestResult.real_add_error = unittest.TestResult.addError

    def patched_addError(self, test, exc_info):
        if exc_info[0] is RuntimeWarning:
            print(str(exc_info[1]), end=' ', file=sys.stderr)
            return
        else:
            self.real_add_error(test, exc_info)
    unittest.TestResult.addError = patched_addError

try:
    from unittest2 import TestCase
except ImportError:
    from unittest import TestCase",buggy
"import logging

logging.getLogger('requests_oauthlib').addHandler(logging.NullHandler())
from setuptools import setup

setup(
    tests_require=[
        'mock',
        'requests-mock',
    ],
from unittest import TestCase
from io import StringIO
from io import StringIO
from unittest import TestCase",bug-free
"if sys.version_info < (3, 7):  # noqa: UP036
    msg = ""pybind11 does not support Python < 3.7. v2.12 was the last release supporting Python 3.6.""
@lru_cache()
    if (3, 8) <= sys.version_info < (3, 10) and env.CPYTHON:
    hooked = False
    if hasattr(sys, ""unraisablehook""):  # Python 3.8+
        hooked = True
        # Don't take `sys.unraisablehook`, as that's overwritten by pytest
        default_hook = sys.__unraisablehook__
        def hook(unraisable_hook_args):
            exc_type, exc_value, exc_tb, err_msg, obj = unraisable_hook_args
            if obj == ""already_set demo"":
                nonlocal triggered
                triggered = True
            default_hook(unraisable_hook_args)
            return
        # Use monkeypatch so pytest can apply and remove the patch as appropriate
        monkeypatch.setattr(sys, ""unraisablehook"", hook)
    if hooked:
        assert triggered is True",buggy
"if sys.version_info < (3, 8):  # noqa: UP036
    msg = ""pybind11 does not support Python < 3.8. v2.13 was the last release supporting Python 3.7.""
@lru_cache
    if sys.version_info < (3, 10) and env.CPYTHON:
    # Don't take `sys.unraisablehook`, as that's overwritten by pytest
    default_hook = sys.__unraisablehook__
    def hook(unraisable_hook_args):
        exc_type, exc_value, exc_tb, err_msg, obj = unraisable_hook_args
        if obj == ""already_set demo"":
            nonlocal triggered
            triggered = True
        default_hook(unraisable_hook_args)
        return
    # Use monkeypatch so pytest can apply and remove the patch as appropriate
    monkeypatch.setattr(sys, ""unraisablehook"", hook)
    assert triggered is True",bug-free
"if sys.version_info < (3, 7):  # noqa: UP036
    msg = ""pybind11 does not support Python < 3.7. v2.12 was the last release supporting Python 3.6.""
@lru_cache()
    if (3, 8) <= sys.version_info < (3, 10) and env.CPYTHON:
    hooked = False
    if hasattr(sys, ""unraisablehook""):  # Python 3.8+
        hooked = True
        # Don't take `sys.unraisablehook`, as that's overwritten by pytest
        default_hook = sys.__unraisablehook__
        def hook(unraisable_hook_args):
            exc_type, exc_value, exc_tb, err_msg, obj = unraisable_hook_args
            if obj == ""already_set demo"":
                nonlocal triggered
                triggered = True
            default_hook(unraisable_hook_args)
            return
        # Use monkeypatch so pytest can apply and remove the patch as appropriate
        monkeypatch.setattr(sys, ""unraisablehook"", hook)
    if hooked:
        assert triggered is True",buggy
"if sys.version_info < (3, 8):  # noqa: UP036
    msg = ""pybind11 does not support Python < 3.8. v2.13 was the last release supporting Python 3.7.""
@lru_cache
    if sys.version_info < (3, 10) and env.CPYTHON:
    # Don't take `sys.unraisablehook`, as that's overwritten by pytest
    default_hook = sys.__unraisablehook__
    def hook(unraisable_hook_args):
        exc_type, exc_value, exc_tb, err_msg, obj = unraisable_hook_args
        if obj == ""already_set demo"":
            nonlocal triggered
            triggered = True
        default_hook(unraisable_hook_args)
        return
    # Use monkeypatch so pytest can apply and remove the patch as appropriate
    monkeypatch.setattr(sys, ""unraisablehook"", hook)
    assert triggered is True",bug-free
"if sys.version_info < (3, 7):  # noqa: UP036
    msg = ""pybind11 does not support Python < 3.7. v2.12 was the last release supporting Python 3.6.""
@lru_cache()
    if (3, 8) <= sys.version_info < (3, 10) and env.CPYTHON:
    hooked = False
    if hasattr(sys, ""unraisablehook""):  # Python 3.8+
        hooked = True
        # Don't take `sys.unraisablehook`, as that's overwritten by pytest
        default_hook = sys.__unraisablehook__
        def hook(unraisable_hook_args):
            exc_type, exc_value, exc_tb, err_msg, obj = unraisable_hook_args
            if obj == ""already_set demo"":
                nonlocal triggered
                triggered = True
            default_hook(unraisable_hook_args)
            return
        # Use monkeypatch so pytest can apply and remove the patch as appropriate
        monkeypatch.setattr(sys, ""unraisablehook"", hook)
    if hooked:
        assert triggered is True",buggy
"if sys.version_info < (3, 8):  # noqa: UP036
    msg = ""pybind11 does not support Python < 3.8. v2.13 was the last release supporting Python 3.7.""
@lru_cache
    if sys.version_info < (3, 10) and env.CPYTHON:
    # Don't take `sys.unraisablehook`, as that's overwritten by pytest
    default_hook = sys.__unraisablehook__
    def hook(unraisable_hook_args):
        exc_type, exc_value, exc_tb, err_msg, obj = unraisable_hook_args
        if obj == ""already_set demo"":
            nonlocal triggered
            triggered = True
        default_hook(unraisable_hook_args)
        return
    # Use monkeypatch so pytest can apply and remove the patch as appropriate
    monkeypatch.setattr(sys, ""unraisablehook"", hook)
    assert triggered is True",bug-free
"class ConfigPath:
    def resolve_config(self) -> Mapping[str, YamlTree]:
        """"""resolves if config arg is a registry entry, a url, or a file, folder, or loads from defaults if None""""""
        start_t = time.time()

            config = self._download_config()
            config = self._load_config_from_local_path()

        if config:
            logger.debug(f""loaded {len(config)} configs in {time.time() - start_t}"")
        return config
    def _download_config(self) -> Mapping[str, YamlTree]:
            config = parse_config_string(
                ""remote-url"",
                filename=f""{config_url[:20]}..."",
        except InvalidRuleSchemaError as e:
            notice = f""\nRules downloaded from {config_url} failed to parse.\nThis is likely because rules have been added that use functionality introduced in later versions of semgrep.\nPlease upgrade to latest version of semgrep (see https://semgrep.dev/docs/upgrading/) and try again.\n""
            notice_color = with_color(Colors.red, notice, bold=True)
            logger.error(notice_color)
            raise e
    def _load_config_from_local_path(self) -> Dict[str, YamlTree]:
                config = parse_config_at_path(loc)
                config = parse_config_folder(loc)
        return self._config_path
def parse_config_at_path(
    loc: Path, base_path: Optional[Path] = None
) -> Dict[str, YamlTree]:
    Assumes file at loc exists
    config_id = str(loc)
    if base_path:
        config_id = str(loc).replace(str(base_path), """")

    return parse_config_string(config_id, loc.read_text(), str(loc))
def parse_config_folder(loc: Path, relative: bool = False) -> Dict[str, YamlTree]:
    configs = {}
    for l in loc.rglob(""*""):
        # Allow manually specified paths with ""."", but don't auto-expand them
        correct_suffix = is_config_suffix(l)
        if not _is_hidden_config(l.relative_to(loc)) and correct_suffix:
            if l.is_file():
                configs.update(parse_config_at_path(l, loc if relative else None))
    return configs


        return parse_config_at_path(default_file)
        return parse_config_folder(default_folder, relative=True)
    else:
        return {}
from semgrep.config_resolver import ConfigPath
    mocker.patch.object(ConfigPath, ""_make_config_request"", return_value=file_content)
from semgrep.config_resolver import ConfigPath
    mocker.patch.object(ConfigPath, ""_make_config_request"", return_value=file_content)
        ""semgrep.config_resolver.ConfigPath._make_config_request"",",buggy
"from typing import NamedTuple
import _jsonnet  # type: ignore
import ruamel.yaml
class ConfigFile(NamedTuple):
    config_id: Optional[str]  # None for remote files
    contents: str
    config_path: str


class ConfigLoader:
    def load_config(self) -> List[ConfigFile]:
        """"""
        Loads a config based on self's state.
        A config path produces a list of ConfigFiles because
        it may be a path to a folders of configs, each of
        which produces a file
        """"""
            return [self._download_config()]
            return self._load_config_from_local_path()
    def _download_config(self) -> ConfigFile:
            config = ConfigFile(
                None,
                config_url,
    def _load_config_from_local_path(self) -> List[ConfigFile]:
                config = [read_config_at_path(loc)]
                config = read_config_folder(loc)

def read_config_at_path(loc: Path, base_path: Optional[Path] = None) -> ConfigFile:
    """"""
    Assumes file at loc exists
    """"""
    config_id = str(loc)
    if base_path:
        config_id = str(loc).replace(str(base_path), """")

    return ConfigFile(config_id, loc.read_text(), str(loc))


def read_config_folder(loc: Path, relative: bool = False) -> List[ConfigFile]:
    configs = []
    for l in loc.rglob(""*""):
        # Allow manually specified paths with ""."", but don't auto-expand them
        correct_suffix = is_config_suffix(l)
        if not _is_hidden_config(l.relative_to(loc)) and correct_suffix:
            if l.is_file():
                configs.append(read_config_at_path(l, loc if relative else None))
    return configs


def parse_config_files(
    loaded_config_infos: List[ConfigFile],
) -> Dict[str, YamlTree]:
    """"""
    Parse a list of config files into rules
    This assumes that config_id is set for local rules
    but is None for registry rules
    """"""
    config = {}
    for (config_id, contents, config_path) in loaded_config_infos:
        try:
            if not config_id:  # registry rules don't have config ids
                config_id = ""remote-url""
                filename = f""{config_path[:20]}...""
            else:
                filename = config_path
            config.update(parse_config_string(config_id, contents, filename))
        except InvalidRuleSchemaError as e:
            if config_id == ""remote-url"":
                notice = f""\nRules downloaded from {config_path} failed to parse.\nThis is likely because rules have been added that use functionality introduced in later versions of semgrep.\nPlease upgrade to latest version of semgrep (see https://semgrep.dev/docs/upgrading/) and try again.\n""
                notice_color = with_color(Colors.red, notice, bold=True)
                logger.error(notice_color)
                raise e
            else:
                raise e
    return config


class ConfigPath:
    def __init__(self, config_str: str, project_url: Optional[str] = None) -> None:
        self._config_str = config_str
        self._project_url = project_url

    def resolve_config(self) -> Dict[str, YamlTree]:
        """"""resolves if config arg is a registry entry, a url, or a file, folder, or loads from defaults if None""""""
        start_t = time.time()

        config = parse_config_files(
            ConfigLoader(self._config_str, self._project_url).load_config()
        )

        if config:
            logger.debug(f""loaded {len(config)} configs in {time.time() - start_t}"")
        return config

        # TODO return the resolved config_path
        return self._config_str
def import_callback(_base: str, path: str) -> Tuple[str, str]:
    Instructions to jsonnet for how to resolve
    import expressions (`local $NAME = $PATH`).
    The base is the directory of the file and the
    path is $PATH in the local expression. We will
    later pass this function to jsonnet, which will
    use it when resolving imports. By implementing
    this callback, we support yaml files (jsonnet
    can otherwise only build against json files)
    and config specifiers like `p/python`.
    logger.debug(f""import_callback for {path}"")

    # On the fly conversion from yaml to json.
    # Can now do 'local x = import ""foo.yml"";'
    # TODO: Make this check less jank
    if path and (path.split(""."")[-1] == ""yml"" or path.split(""."")[-1] == ""yaml""):
        yaml = ruamel.yaml.YAML(typ=""safe"")
        with open(path) as fpi:
            data = yaml.load(fpi)
        contents = json.dumps(data)
        filename = path
        return filename, contents

    # Registry-aware import!
    # Can now do 'local x = import ""p/python"";'!!
    config_infos = ConfigLoader(path, None).load_config()
    if len(config_infos) == 0:
        raise SemgrepError(f""No valid configs imported"")
    elif len(config_infos) > 1:
        raise SemgrepError(f""Currently configs cannot be imported from a directory"")
    else:
        (_config_id, contents, config_path) = config_infos[0]
        return config_path, contents

    # TODO: Make this check less jank
    if filename and filename.split(""."")[-1] == ""jsonnet"":
        logger.error(
            ""Support for Jsonnet rules is experimental and currently meant for internal use only. The syntax may change or be removed at any point.""
        )
        contents = _jsonnet.evaluate_snippet(
            filename, contents, import_callback=import_callback
        )

    # Should we guard this code and checks whether filename ends with .json?
    config_infos = []
        config_infos = [read_config_at_path(default_file)]
        config_infos = read_config_folder(default_folder, relative=True)
    return parse_config_files(config_infos)
from semgrep.config_resolver import ConfigLoader
    mocker.patch.object(ConfigLoader, ""_make_config_request"", return_value=file_content)
from semgrep.config_resolver import ConfigLoader
    mocker.patch.object(ConfigLoader, ""_make_config_request"", return_value=file_content)
        ""semgrep.config_resolver.ConfigLoader._make_config_request"",",bug-free
"class ConfigPath:
    def resolve_config(self) -> Mapping[str, YamlTree]:
        """"""resolves if config arg is a registry entry, a url, or a file, folder, or loads from defaults if None""""""
        start_t = time.time()

            config = self._download_config()
            config = self._load_config_from_local_path()

        if config:
            logger.debug(f""loaded {len(config)} configs in {time.time() - start_t}"")
        return config
    def _download_config(self) -> Mapping[str, YamlTree]:
            config = parse_config_string(
                ""remote-url"",
                filename=f""{config_url[:20]}..."",
        except InvalidRuleSchemaError as e:
            notice = f""\nRules downloaded from {config_url} failed to parse.\nThis is likely because rules have been added that use functionality introduced in later versions of semgrep.\nPlease upgrade to latest version of semgrep (see https://semgrep.dev/docs/upgrading/) and try again.\n""
            notice_color = with_color(Colors.red, notice, bold=True)
            logger.error(notice_color)
            raise e
    def _load_config_from_local_path(self) -> Dict[str, YamlTree]:
                config = parse_config_at_path(loc)
                config = parse_config_folder(loc)
        return self._config_path
def parse_config_at_path(
    loc: Path, base_path: Optional[Path] = None
) -> Dict[str, YamlTree]:
    Assumes file at loc exists
    config_id = str(loc)
    if base_path:
        config_id = str(loc).replace(str(base_path), """")

    return parse_config_string(config_id, loc.read_text(), str(loc))
def parse_config_folder(loc: Path, relative: bool = False) -> Dict[str, YamlTree]:
    configs = {}
    for l in loc.rglob(""*""):
        # Allow manually specified paths with ""."", but don't auto-expand them
        correct_suffix = is_config_suffix(l)
        if not _is_hidden_config(l.relative_to(loc)) and correct_suffix:
            if l.is_file():
                configs.update(parse_config_at_path(l, loc if relative else None))
    return configs


        return parse_config_at_path(default_file)
        return parse_config_folder(default_folder, relative=True)
    else:
        return {}
from semgrep.config_resolver import ConfigPath
    mocker.patch.object(ConfigPath, ""_make_config_request"", return_value=file_content)
from semgrep.config_resolver import ConfigPath
    mocker.patch.object(ConfigPath, ""_make_config_request"", return_value=file_content)
        ""semgrep.config_resolver.ConfigPath._make_config_request"",",buggy
"from typing import NamedTuple
import _jsonnet  # type: ignore
import ruamel.yaml
class ConfigFile(NamedTuple):
    config_id: Optional[str]  # None for remote files
    contents: str
    config_path: str


class ConfigLoader:
    def load_config(self) -> List[ConfigFile]:
        """"""
        Loads a config based on self's state.
        A config path produces a list of ConfigFiles because
        it may be a path to a folders of configs, each of
        which produces a file
        """"""
            return [self._download_config()]
            return self._load_config_from_local_path()
    def _download_config(self) -> ConfigFile:
            config = ConfigFile(
                None,
                config_url,
    def _load_config_from_local_path(self) -> List[ConfigFile]:
                config = [read_config_at_path(loc)]
                config = read_config_folder(loc)

def read_config_at_path(loc: Path, base_path: Optional[Path] = None) -> ConfigFile:
    """"""
    Assumes file at loc exists
    """"""
    config_id = str(loc)
    if base_path:
        config_id = str(loc).replace(str(base_path), """")

    return ConfigFile(config_id, loc.read_text(), str(loc))


def read_config_folder(loc: Path, relative: bool = False) -> List[ConfigFile]:
    configs = []
    for l in loc.rglob(""*""):
        # Allow manually specified paths with ""."", but don't auto-expand them
        correct_suffix = is_config_suffix(l)
        if not _is_hidden_config(l.relative_to(loc)) and correct_suffix:
            if l.is_file():
                configs.append(read_config_at_path(l, loc if relative else None))
    return configs


def parse_config_files(
    loaded_config_infos: List[ConfigFile],
) -> Dict[str, YamlTree]:
    """"""
    Parse a list of config files into rules
    This assumes that config_id is set for local rules
    but is None for registry rules
    """"""
    config = {}
    for (config_id, contents, config_path) in loaded_config_infos:
        try:
            if not config_id:  # registry rules don't have config ids
                config_id = ""remote-url""
                filename = f""{config_path[:20]}...""
            else:
                filename = config_path
            config.update(parse_config_string(config_id, contents, filename))
        except InvalidRuleSchemaError as e:
            if config_id == ""remote-url"":
                notice = f""\nRules downloaded from {config_path} failed to parse.\nThis is likely because rules have been added that use functionality introduced in later versions of semgrep.\nPlease upgrade to latest version of semgrep (see https://semgrep.dev/docs/upgrading/) and try again.\n""
                notice_color = with_color(Colors.red, notice, bold=True)
                logger.error(notice_color)
                raise e
            else:
                raise e
    return config


class ConfigPath:
    def __init__(self, config_str: str, project_url: Optional[str] = None) -> None:
        self._config_str = config_str
        self._project_url = project_url

    def resolve_config(self) -> Dict[str, YamlTree]:
        """"""resolves if config arg is a registry entry, a url, or a file, folder, or loads from defaults if None""""""
        start_t = time.time()

        config = parse_config_files(
            ConfigLoader(self._config_str, self._project_url).load_config()
        )

        if config:
            logger.debug(f""loaded {len(config)} configs in {time.time() - start_t}"")
        return config

        # TODO return the resolved config_path
        return self._config_str
def import_callback(_base: str, path: str) -> Tuple[str, str]:
    Instructions to jsonnet for how to resolve
    import expressions (`local $NAME = $PATH`).
    The base is the directory of the file and the
    path is $PATH in the local expression. We will
    later pass this function to jsonnet, which will
    use it when resolving imports. By implementing
    this callback, we support yaml files (jsonnet
    can otherwise only build against json files)
    and config specifiers like `p/python`.
    logger.debug(f""import_callback for {path}"")

    # On the fly conversion from yaml to json.
    # Can now do 'local x = import ""foo.yml"";'
    # TODO: Make this check less jank
    if path and (path.split(""."")[-1] == ""yml"" or path.split(""."")[-1] == ""yaml""):
        yaml = ruamel.yaml.YAML(typ=""safe"")
        with open(path) as fpi:
            data = yaml.load(fpi)
        contents = json.dumps(data)
        filename = path
        return filename, contents

    # Registry-aware import!
    # Can now do 'local x = import ""p/python"";'!!
    config_infos = ConfigLoader(path, None).load_config()
    if len(config_infos) == 0:
        raise SemgrepError(f""No valid configs imported"")
    elif len(config_infos) > 1:
        raise SemgrepError(f""Currently configs cannot be imported from a directory"")
    else:
        (_config_id, contents, config_path) = config_infos[0]
        return config_path, contents

    # TODO: Make this check less jank
    if filename and filename.split(""."")[-1] == ""jsonnet"":
        logger.error(
            ""Support for Jsonnet rules is experimental and currently meant for internal use only. The syntax may change or be removed at any point.""
        )
        contents = _jsonnet.evaluate_snippet(
            filename, contents, import_callback=import_callback
        )

    # Should we guard this code and checks whether filename ends with .json?
    config_infos = []
        config_infos = [read_config_at_path(default_file)]
        config_infos = read_config_folder(default_folder, relative=True)
    return parse_config_files(config_infos)
from semgrep.config_resolver import ConfigLoader
    mocker.patch.object(ConfigLoader, ""_make_config_request"", return_value=file_content)
from semgrep.config_resolver import ConfigLoader
    mocker.patch.object(ConfigLoader, ""_make_config_request"", return_value=file_content)
        ""semgrep.config_resolver.ConfigLoader._make_config_request"",",bug-free
"class ConfigPath:
    def resolve_config(self) -> Mapping[str, YamlTree]:
        """"""resolves if config arg is a registry entry, a url, or a file, folder, or loads from defaults if None""""""
        start_t = time.time()

            config = self._download_config()
            config = self._load_config_from_local_path()

        if config:
            logger.debug(f""loaded {len(config)} configs in {time.time() - start_t}"")
        return config
    def _download_config(self) -> Mapping[str, YamlTree]:
            config = parse_config_string(
                ""remote-url"",
                filename=f""{config_url[:20]}..."",
        except InvalidRuleSchemaError as e:
            notice = f""\nRules downloaded from {config_url} failed to parse.\nThis is likely because rules have been added that use functionality introduced in later versions of semgrep.\nPlease upgrade to latest version of semgrep (see https://semgrep.dev/docs/upgrading/) and try again.\n""
            notice_color = with_color(Colors.red, notice, bold=True)
            logger.error(notice_color)
            raise e
    def _load_config_from_local_path(self) -> Dict[str, YamlTree]:
                config = parse_config_at_path(loc)
                config = parse_config_folder(loc)
        return self._config_path
def parse_config_at_path(
    loc: Path, base_path: Optional[Path] = None
) -> Dict[str, YamlTree]:
    Assumes file at loc exists
    config_id = str(loc)
    if base_path:
        config_id = str(loc).replace(str(base_path), """")

    return parse_config_string(config_id, loc.read_text(), str(loc))
def parse_config_folder(loc: Path, relative: bool = False) -> Dict[str, YamlTree]:
    configs = {}
    for l in loc.rglob(""*""):
        # Allow manually specified paths with ""."", but don't auto-expand them
        correct_suffix = is_config_suffix(l)
        if not _is_hidden_config(l.relative_to(loc)) and correct_suffix:
            if l.is_file():
                configs.update(parse_config_at_path(l, loc if relative else None))
    return configs


        return parse_config_at_path(default_file)
        return parse_config_folder(default_folder, relative=True)
    else:
        return {}
from semgrep.config_resolver import ConfigPath
    mocker.patch.object(ConfigPath, ""_make_config_request"", return_value=file_content)
from semgrep.config_resolver import ConfigPath
    mocker.patch.object(ConfigPath, ""_make_config_request"", return_value=file_content)
        ""semgrep.config_resolver.ConfigPath._make_config_request"",",buggy
"from typing import NamedTuple
import _jsonnet  # type: ignore
import ruamel.yaml
class ConfigFile(NamedTuple):
    config_id: Optional[str]  # None for remote files
    contents: str
    config_path: str


class ConfigLoader:
    def load_config(self) -> List[ConfigFile]:
        """"""
        Loads a config based on self's state.
        A config path produces a list of ConfigFiles because
        it may be a path to a folders of configs, each of
        which produces a file
        """"""
            return [self._download_config()]
            return self._load_config_from_local_path()
    def _download_config(self) -> ConfigFile:
            config = ConfigFile(
                None,
                config_url,
    def _load_config_from_local_path(self) -> List[ConfigFile]:
                config = [read_config_at_path(loc)]
                config = read_config_folder(loc)

def read_config_at_path(loc: Path, base_path: Optional[Path] = None) -> ConfigFile:
    """"""
    Assumes file at loc exists
    """"""
    config_id = str(loc)
    if base_path:
        config_id = str(loc).replace(str(base_path), """")

    return ConfigFile(config_id, loc.read_text(), str(loc))


def read_config_folder(loc: Path, relative: bool = False) -> List[ConfigFile]:
    configs = []
    for l in loc.rglob(""*""):
        # Allow manually specified paths with ""."", but don't auto-expand them
        correct_suffix = is_config_suffix(l)
        if not _is_hidden_config(l.relative_to(loc)) and correct_suffix:
            if l.is_file():
                configs.append(read_config_at_path(l, loc if relative else None))
    return configs


def parse_config_files(
    loaded_config_infos: List[ConfigFile],
) -> Dict[str, YamlTree]:
    """"""
    Parse a list of config files into rules
    This assumes that config_id is set for local rules
    but is None for registry rules
    """"""
    config = {}
    for (config_id, contents, config_path) in loaded_config_infos:
        try:
            if not config_id:  # registry rules don't have config ids
                config_id = ""remote-url""
                filename = f""{config_path[:20]}...""
            else:
                filename = config_path
            config.update(parse_config_string(config_id, contents, filename))
        except InvalidRuleSchemaError as e:
            if config_id == ""remote-url"":
                notice = f""\nRules downloaded from {config_path} failed to parse.\nThis is likely because rules have been added that use functionality introduced in later versions of semgrep.\nPlease upgrade to latest version of semgrep (see https://semgrep.dev/docs/upgrading/) and try again.\n""
                notice_color = with_color(Colors.red, notice, bold=True)
                logger.error(notice_color)
                raise e
            else:
                raise e
    return config


class ConfigPath:
    def __init__(self, config_str: str, project_url: Optional[str] = None) -> None:
        self._config_str = config_str
        self._project_url = project_url

    def resolve_config(self) -> Dict[str, YamlTree]:
        """"""resolves if config arg is a registry entry, a url, or a file, folder, or loads from defaults if None""""""
        start_t = time.time()

        config = parse_config_files(
            ConfigLoader(self._config_str, self._project_url).load_config()
        )

        if config:
            logger.debug(f""loaded {len(config)} configs in {time.time() - start_t}"")
        return config

        # TODO return the resolved config_path
        return self._config_str
def import_callback(_base: str, path: str) -> Tuple[str, str]:
    Instructions to jsonnet for how to resolve
    import expressions (`local $NAME = $PATH`).
    The base is the directory of the file and the
    path is $PATH in the local expression. We will
    later pass this function to jsonnet, which will
    use it when resolving imports. By implementing
    this callback, we support yaml files (jsonnet
    can otherwise only build against json files)
    and config specifiers like `p/python`.
    logger.debug(f""import_callback for {path}"")

    # On the fly conversion from yaml to json.
    # Can now do 'local x = import ""foo.yml"";'
    # TODO: Make this check less jank
    if path and (path.split(""."")[-1] == ""yml"" or path.split(""."")[-1] == ""yaml""):
        yaml = ruamel.yaml.YAML(typ=""safe"")
        with open(path) as fpi:
            data = yaml.load(fpi)
        contents = json.dumps(data)
        filename = path
        return filename, contents

    # Registry-aware import!
    # Can now do 'local x = import ""p/python"";'!!
    config_infos = ConfigLoader(path, None).load_config()
    if len(config_infos) == 0:
        raise SemgrepError(f""No valid configs imported"")
    elif len(config_infos) > 1:
        raise SemgrepError(f""Currently configs cannot be imported from a directory"")
    else:
        (_config_id, contents, config_path) = config_infos[0]
        return config_path, contents

    # TODO: Make this check less jank
    if filename and filename.split(""."")[-1] == ""jsonnet"":
        logger.error(
            ""Support for Jsonnet rules is experimental and currently meant for internal use only. The syntax may change or be removed at any point.""
        )
        contents = _jsonnet.evaluate_snippet(
            filename, contents, import_callback=import_callback
        )

    # Should we guard this code and checks whether filename ends with .json?
    config_infos = []
        config_infos = [read_config_at_path(default_file)]
        config_infos = read_config_folder(default_folder, relative=True)
    return parse_config_files(config_infos)
from semgrep.config_resolver import ConfigLoader
    mocker.patch.object(ConfigLoader, ""_make_config_request"", return_value=file_content)
from semgrep.config_resolver import ConfigLoader
    mocker.patch.object(ConfigLoader, ""_make_config_request"", return_value=file_content)
        ""semgrep.config_resolver.ConfigLoader._make_config_request"",",bug-free
"class ConfigPath:
    def resolve_config(self) -> Mapping[str, YamlTree]:
        """"""resolves if config arg is a registry entry, a url, or a file, folder, or loads from defaults if None""""""
        start_t = time.time()

            config = self._download_config()
            config = self._load_config_from_local_path()

        if config:
            logger.debug(f""loaded {len(config)} configs in {time.time() - start_t}"")
        return config
    def _download_config(self) -> Mapping[str, YamlTree]:
            config = parse_config_string(
                ""remote-url"",
                filename=f""{config_url[:20]}..."",
        except InvalidRuleSchemaError as e:
            notice = f""\nRules downloaded from {config_url} failed to parse.\nThis is likely because rules have been added that use functionality introduced in later versions of semgrep.\nPlease upgrade to latest version of semgrep (see https://semgrep.dev/docs/upgrading/) and try again.\n""
            notice_color = with_color(Colors.red, notice, bold=True)
            logger.error(notice_color)
            raise e
    def _load_config_from_local_path(self) -> Dict[str, YamlTree]:
                config = parse_config_at_path(loc)
                config = parse_config_folder(loc)
        return self._config_path
def parse_config_at_path(
    loc: Path, base_path: Optional[Path] = None
) -> Dict[str, YamlTree]:
    Assumes file at loc exists
    config_id = str(loc)
    if base_path:
        config_id = str(loc).replace(str(base_path), """")

    return parse_config_string(config_id, loc.read_text(), str(loc))
def parse_config_folder(loc: Path, relative: bool = False) -> Dict[str, YamlTree]:
    configs = {}
    for l in loc.rglob(""*""):
        # Allow manually specified paths with ""."", but don't auto-expand them
        correct_suffix = is_config_suffix(l)
        if not _is_hidden_config(l.relative_to(loc)) and correct_suffix:
            if l.is_file():
                configs.update(parse_config_at_path(l, loc if relative else None))
    return configs


        return parse_config_at_path(default_file)
        return parse_config_folder(default_folder, relative=True)
    else:
        return {}
from semgrep.config_resolver import ConfigPath
    mocker.patch.object(ConfigPath, ""_make_config_request"", return_value=file_content)
from semgrep.config_resolver import ConfigPath
    mocker.patch.object(ConfigPath, ""_make_config_request"", return_value=file_content)
        ""semgrep.config_resolver.ConfigPath._make_config_request"",",buggy
"from typing import NamedTuple
import _jsonnet  # type: ignore
import ruamel.yaml
class ConfigFile(NamedTuple):
    config_id: Optional[str]  # None for remote files
    contents: str
    config_path: str


class ConfigLoader:
    def load_config(self) -> List[ConfigFile]:
        """"""
        Loads a config based on self's state.
        A config path produces a list of ConfigFiles because
        it may be a path to a folders of configs, each of
        which produces a file
        """"""
            return [self._download_config()]
            return self._load_config_from_local_path()
    def _download_config(self) -> ConfigFile:
            config = ConfigFile(
                None,
                config_url,
    def _load_config_from_local_path(self) -> List[ConfigFile]:
                config = [read_config_at_path(loc)]
                config = read_config_folder(loc)

def read_config_at_path(loc: Path, base_path: Optional[Path] = None) -> ConfigFile:
    """"""
    Assumes file at loc exists
    """"""
    config_id = str(loc)
    if base_path:
        config_id = str(loc).replace(str(base_path), """")

    return ConfigFile(config_id, loc.read_text(), str(loc))


def read_config_folder(loc: Path, relative: bool = False) -> List[ConfigFile]:
    configs = []
    for l in loc.rglob(""*""):
        # Allow manually specified paths with ""."", but don't auto-expand them
        correct_suffix = is_config_suffix(l)
        if not _is_hidden_config(l.relative_to(loc)) and correct_suffix:
            if l.is_file():
                configs.append(read_config_at_path(l, loc if relative else None))
    return configs


def parse_config_files(
    loaded_config_infos: List[ConfigFile],
) -> Dict[str, YamlTree]:
    """"""
    Parse a list of config files into rules
    This assumes that config_id is set for local rules
    but is None for registry rules
    """"""
    config = {}
    for (config_id, contents, config_path) in loaded_config_infos:
        try:
            if not config_id:  # registry rules don't have config ids
                config_id = ""remote-url""
                filename = f""{config_path[:20]}...""
            else:
                filename = config_path
            config.update(parse_config_string(config_id, contents, filename))
        except InvalidRuleSchemaError as e:
            if config_id == ""remote-url"":
                notice = f""\nRules downloaded from {config_path} failed to parse.\nThis is likely because rules have been added that use functionality introduced in later versions of semgrep.\nPlease upgrade to latest version of semgrep (see https://semgrep.dev/docs/upgrading/) and try again.\n""
                notice_color = with_color(Colors.red, notice, bold=True)
                logger.error(notice_color)
                raise e
            else:
                raise e
    return config


class ConfigPath:
    def __init__(self, config_str: str, project_url: Optional[str] = None) -> None:
        self._config_str = config_str
        self._project_url = project_url

    def resolve_config(self) -> Dict[str, YamlTree]:
        """"""resolves if config arg is a registry entry, a url, or a file, folder, or loads from defaults if None""""""
        start_t = time.time()

        config = parse_config_files(
            ConfigLoader(self._config_str, self._project_url).load_config()
        )

        if config:
            logger.debug(f""loaded {len(config)} configs in {time.time() - start_t}"")
        return config

        # TODO return the resolved config_path
        return self._config_str
def import_callback(_base: str, path: str) -> Tuple[str, str]:
    Instructions to jsonnet for how to resolve
    import expressions (`local $NAME = $PATH`).
    The base is the directory of the file and the
    path is $PATH in the local expression. We will
    later pass this function to jsonnet, which will
    use it when resolving imports. By implementing
    this callback, we support yaml files (jsonnet
    can otherwise only build against json files)
    and config specifiers like `p/python`.
    logger.debug(f""import_callback for {path}"")

    # On the fly conversion from yaml to json.
    # Can now do 'local x = import ""foo.yml"";'
    # TODO: Make this check less jank
    if path and (path.split(""."")[-1] == ""yml"" or path.split(""."")[-1] == ""yaml""):
        yaml = ruamel.yaml.YAML(typ=""safe"")
        with open(path) as fpi:
            data = yaml.load(fpi)
        contents = json.dumps(data)
        filename = path
        return filename, contents

    # Registry-aware import!
    # Can now do 'local x = import ""p/python"";'!!
    config_infos = ConfigLoader(path, None).load_config()
    if len(config_infos) == 0:
        raise SemgrepError(f""No valid configs imported"")
    elif len(config_infos) > 1:
        raise SemgrepError(f""Currently configs cannot be imported from a directory"")
    else:
        (_config_id, contents, config_path) = config_infos[0]
        return config_path, contents

    # TODO: Make this check less jank
    if filename and filename.split(""."")[-1] == ""jsonnet"":
        logger.error(
            ""Support for Jsonnet rules is experimental and currently meant for internal use only. The syntax may change or be removed at any point.""
        )
        contents = _jsonnet.evaluate_snippet(
            filename, contents, import_callback=import_callback
        )

    # Should we guard this code and checks whether filename ends with .json?
    config_infos = []
        config_infos = [read_config_at_path(default_file)]
        config_infos = read_config_folder(default_folder, relative=True)
    return parse_config_files(config_infos)
from semgrep.config_resolver import ConfigLoader
    mocker.patch.object(ConfigLoader, ""_make_config_request"", return_value=file_content)
from semgrep.config_resolver import ConfigLoader
    mocker.patch.object(ConfigLoader, ""_make_config_request"", return_value=file_content)
        ""semgrep.config_resolver.ConfigLoader._make_config_request"",",bug-free
"class ConfigPath:
    def resolve_config(self) -> Mapping[str, YamlTree]:
        """"""resolves if config arg is a registry entry, a url, or a file, folder, or loads from defaults if None""""""
        start_t = time.time()

            config = self._download_config()
            config = self._load_config_from_local_path()

        if config:
            logger.debug(f""loaded {len(config)} configs in {time.time() - start_t}"")
        return config
    def _download_config(self) -> Mapping[str, YamlTree]:
            config = parse_config_string(
                ""remote-url"",
                filename=f""{config_url[:20]}..."",
        except InvalidRuleSchemaError as e:
            notice = f""\nRules downloaded from {config_url} failed to parse.\nThis is likely because rules have been added that use functionality introduced in later versions of semgrep.\nPlease upgrade to latest version of semgrep (see https://semgrep.dev/docs/upgrading/) and try again.\n""
            notice_color = with_color(Colors.red, notice, bold=True)
            logger.error(notice_color)
            raise e
    def _load_config_from_local_path(self) -> Dict[str, YamlTree]:
                config = parse_config_at_path(loc)
                config = parse_config_folder(loc)
        return self._config_path
def parse_config_at_path(
    loc: Path, base_path: Optional[Path] = None
) -> Dict[str, YamlTree]:
    Assumes file at loc exists
    config_id = str(loc)
    if base_path:
        config_id = str(loc).replace(str(base_path), """")

    return parse_config_string(config_id, loc.read_text(), str(loc))
def parse_config_folder(loc: Path, relative: bool = False) -> Dict[str, YamlTree]:
    configs = {}
    for l in loc.rglob(""*""):
        # Allow manually specified paths with ""."", but don't auto-expand them
        correct_suffix = is_config_suffix(l)
        if not _is_hidden_config(l.relative_to(loc)) and correct_suffix:
            if l.is_file():
                configs.update(parse_config_at_path(l, loc if relative else None))
    return configs


        return parse_config_at_path(default_file)
        return parse_config_folder(default_folder, relative=True)
    else:
        return {}
from semgrep.config_resolver import ConfigPath
    mocker.patch.object(ConfigPath, ""_make_config_request"", return_value=file_content)
from semgrep.config_resolver import ConfigPath
    mocker.patch.object(ConfigPath, ""_make_config_request"", return_value=file_content)
        ""semgrep.config_resolver.ConfigPath._make_config_request"",",buggy
"from typing import NamedTuple
import _jsonnet  # type: ignore
import ruamel.yaml
class ConfigFile(NamedTuple):
    config_id: Optional[str]  # None for remote files
    contents: str
    config_path: str


class ConfigLoader:
    def load_config(self) -> List[ConfigFile]:
        """"""
        Loads a config based on self's state.
        A config path produces a list of ConfigFiles because
        it may be a path to a folders of configs, each of
        which produces a file
        """"""
            return [self._download_config()]
            return self._load_config_from_local_path()
    def _download_config(self) -> ConfigFile:
            config = ConfigFile(
                None,
                config_url,
    def _load_config_from_local_path(self) -> List[ConfigFile]:
                config = [read_config_at_path(loc)]
                config = read_config_folder(loc)

def read_config_at_path(loc: Path, base_path: Optional[Path] = None) -> ConfigFile:
    """"""
    Assumes file at loc exists
    """"""
    config_id = str(loc)
    if base_path:
        config_id = str(loc).replace(str(base_path), """")

    return ConfigFile(config_id, loc.read_text(), str(loc))


def read_config_folder(loc: Path, relative: bool = False) -> List[ConfigFile]:
    configs = []
    for l in loc.rglob(""*""):
        # Allow manually specified paths with ""."", but don't auto-expand them
        correct_suffix = is_config_suffix(l)
        if not _is_hidden_config(l.relative_to(loc)) and correct_suffix:
            if l.is_file():
                configs.append(read_config_at_path(l, loc if relative else None))
    return configs


def parse_config_files(
    loaded_config_infos: List[ConfigFile],
) -> Dict[str, YamlTree]:
    """"""
    Parse a list of config files into rules
    This assumes that config_id is set for local rules
    but is None for registry rules
    """"""
    config = {}
    for (config_id, contents, config_path) in loaded_config_infos:
        try:
            if not config_id:  # registry rules don't have config ids
                config_id = ""remote-url""
                filename = f""{config_path[:20]}...""
            else:
                filename = config_path
            config.update(parse_config_string(config_id, contents, filename))
        except InvalidRuleSchemaError as e:
            if config_id == ""remote-url"":
                notice = f""\nRules downloaded from {config_path} failed to parse.\nThis is likely because rules have been added that use functionality introduced in later versions of semgrep.\nPlease upgrade to latest version of semgrep (see https://semgrep.dev/docs/upgrading/) and try again.\n""
                notice_color = with_color(Colors.red, notice, bold=True)
                logger.error(notice_color)
                raise e
            else:
                raise e
    return config


class ConfigPath:
    def __init__(self, config_str: str, project_url: Optional[str] = None) -> None:
        self._config_str = config_str
        self._project_url = project_url

    def resolve_config(self) -> Dict[str, YamlTree]:
        """"""resolves if config arg is a registry entry, a url, or a file, folder, or loads from defaults if None""""""
        start_t = time.time()

        config = parse_config_files(
            ConfigLoader(self._config_str, self._project_url).load_config()
        )

        if config:
            logger.debug(f""loaded {len(config)} configs in {time.time() - start_t}"")
        return config

        # TODO return the resolved config_path
        return self._config_str
def import_callback(_base: str, path: str) -> Tuple[str, str]:
    Instructions to jsonnet for how to resolve
    import expressions (`local $NAME = $PATH`).
    The base is the directory of the file and the
    path is $PATH in the local expression. We will
    later pass this function to jsonnet, which will
    use it when resolving imports. By implementing
    this callback, we support yaml files (jsonnet
    can otherwise only build against json files)
    and config specifiers like `p/python`.
    logger.debug(f""import_callback for {path}"")

    # On the fly conversion from yaml to json.
    # Can now do 'local x = import ""foo.yml"";'
    # TODO: Make this check less jank
    if path and (path.split(""."")[-1] == ""yml"" or path.split(""."")[-1] == ""yaml""):
        yaml = ruamel.yaml.YAML(typ=""safe"")
        with open(path) as fpi:
            data = yaml.load(fpi)
        contents = json.dumps(data)
        filename = path
        return filename, contents

    # Registry-aware import!
    # Can now do 'local x = import ""p/python"";'!!
    config_infos = ConfigLoader(path, None).load_config()
    if len(config_infos) == 0:
        raise SemgrepError(f""No valid configs imported"")
    elif len(config_infos) > 1:
        raise SemgrepError(f""Currently configs cannot be imported from a directory"")
    else:
        (_config_id, contents, config_path) = config_infos[0]
        return config_path, contents

    # TODO: Make this check less jank
    if filename and filename.split(""."")[-1] == ""jsonnet"":
        logger.error(
            ""Support for Jsonnet rules is experimental and currently meant for internal use only. The syntax may change or be removed at any point.""
        )
        contents = _jsonnet.evaluate_snippet(
            filename, contents, import_callback=import_callback
        )

    # Should we guard this code and checks whether filename ends with .json?
    config_infos = []
        config_infos = [read_config_at_path(default_file)]
        config_infos = read_config_folder(default_folder, relative=True)
    return parse_config_files(config_infos)
from semgrep.config_resolver import ConfigLoader
    mocker.patch.object(ConfigLoader, ""_make_config_request"", return_value=file_content)
from semgrep.config_resolver import ConfigLoader
    mocker.patch.object(ConfigLoader, ""_make_config_request"", return_value=file_content)
        ""semgrep.config_resolver.ConfigLoader._make_config_request"",",bug-free
"        @put(""/user/repos"")
        def add_event(self, **event_data: FieldMap):
        @post(""/attachments"")
        def upload_attachments(self, **files: PartMap):
from collections import abc
# Standard library imports
from collections import abc

# Standard library imports
from collections import abc

class Executable(abc.Iterator):
from collections import abc
__all__ = [""reraise""]
# Standard library imports
from collections import abc

from collections import abc
from collections import abc",buggy
"        @put(""/user/repos"", args={""event_data"": FieldMap})
        def add_event(self, **event_data):
        @post(""/attachments"", args={""files"": PartMap})
        def upload_attachments(self, **files):
from uplink.compat import abc
from uplink.compat import abc
class Executable(compat.abc.Iterator):
from uplink.compat import abc
__all__ = [""abc"", ""reraise""]
abc = six.moves.collections_abc
from uplink.compat import abc
from uplink.compat import abc
from uplink.compat import abc",bug-free
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
            ""sample_batch_size"": 1,
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
            ""sample_batch_size"": 50,
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
from ray.tests.utils import run_string_as_driver
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
ray.init(redis_address=""{}"")
"""""".format(cluster.redis_address, num_nodes)
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
    return 1
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
    command = [""git"", ""diff"", ""--name-only"", commit_range]
    RAY_CI_RLLIB_AFFECTED = 0
    if os.environ[""TRAVIS_EVENT_TYPE""] == ""pull_request"":
        files = list_changed_files(os.environ[""TRAVIS_COMMIT_RANGE""].replace(
            ""..."", ""..""))
            if changed_file.startswith(""python/ray/tune/""):
            elif changed_file.startswith(""python/ray/rllib/""):
    print(""export RAY_CI_TUNE_AFFECTED={}"".format(RAY_CI_TUNE_AFFECTED))
    print(""export RAY_CI_RLLIB_AFFECTED={}"".format(RAY_CI_RLLIB_AFFECTED))
    print(""export RAY_CI_JAVA_AFFECTED={}"".format(RAY_CI_JAVA_AFFECTED))
    print(""export RAY_CI_PYTHON_AFFECTED={}"".format(RAY_CI_PYTHON_AFFECTED))
    print(""export RAY_CI_LINUX_WHEELS_AFFECTED={}""
          .format(RAY_CI_LINUX_WHEELS_AFFECTED))
    print(""export RAY_CI_MACOS_WHEELS_AFFECTED={}""
          .format(RAY_CI_MACOS_WHEELS_AFFECTED))
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

    mat = np.array([[[2.0, 2.0], [2.0, 2.0]], [[2.0, 2.0], [2.0, 2.0]]],
                   dtype=np.float32)
    run_func(cyth.compute_kernel_matrix,
             ""L"",
             ""T"",
             2,
             2,
             1.0,
             mat,
             0,
             2,
             1.0,
             result,
             2
             )",buggy
"from ray.cluster_utils import Cluster
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
from ray.cluster_utils import Cluster
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
            ""rollout_fragment_length"": 1,
from ray.cluster_utils import Cluster
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
            ""rollout_fragment_length"": 50,
import numpy as np

from ray.cluster_utils import Cluster
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
        return np.zeros(1024, dtype=np.uint8)
from ray.cluster_utils import Cluster
from ray.test_utils import run_string_as_driver
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
ray.init(address=""{}"")
"""""".format(cluster.address, num_nodes)
import numpy as np

from ray.cluster_utils import Cluster
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
    return np.zeros(1024, dtype=np.uint8)
from ray.cluster_utils import Cluster
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
from ray.cluster_utils import Cluster
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
import json
import re
import sys
from pprint import pformat
    command = [""git"", ""diff"", ""--name-only"", commit_range, ""--""]
    RAY_CI_ONLY_RLLIB_AFFECTED = 0  # Whether only RLlib is affected.
    RAY_CI_RLLIB_AFFECTED = 0  # Whether RLlib minimal tests should be run.
    RAY_CI_RLLIB_FULL_AFFECTED = 0  # Whether full RLlib tests should be run.
    RAY_CI_SERVE_AFFECTED = 0
    RAY_CI_STREAMING_CPP_AFFECTED = 0
    RAY_CI_STREAMING_PYTHON_AFFECTED = 0
    RAY_CI_STREAMING_JAVA_AFFECTED = 0
    event_type = None
    for key in [""GITHUB_EVENT_NAME"", ""TRAVIS_EVENT_TYPE""]:
        event_type = os.getenv(key, event_type)
    if event_type == ""pull_request"":

        commit_range = os.getenv(""TRAVIS_COMMIT_RANGE"")
        if commit_range is None:
            with open(os.environ[""GITHUB_EVENT_PATH""], ""rb"") as f:
                event = json.loads(f.read())
            base = event[""pull_request""][""base""][""sha""]
            commit_range = ""{}...{}"".format(base, event.get(""after"", """"))
        files = list_changed_files(commit_range)

        print(pformat(files), file=sys.stderr)
            if changed_file.startswith(""python/ray/tune""):
                RAY_CI_RLLIB_FULL_AFFECTED = 1
            elif re.match(""^(python/ray/)?rllib/"", changed_file):
                RAY_CI_RLLIB_FULL_AFFECTED = 1
                RAY_CI_LINUX_WHEELS_AFFECTED = 1
                RAY_CI_MACOS_WHEELS_AFFECTED = 1
            elif changed_file.startswith(""python/ray/serve""):
                RAY_CI_SERVE_AFFECTED = 1
                RAY_CI_SERVE_AFFECTED = 1
                RAY_CI_STREAMING_PYTHON_AFFECTED = 1
                RAY_CI_STREAMING_JAVA_AFFECTED = 1
                RAY_CI_SERVE_AFFECTED = 1
                RAY_CI_STREAMING_CPP_AFFECTED = 1
                RAY_CI_STREAMING_PYTHON_AFFECTED = 1
                RAY_CI_STREAMING_JAVA_AFFECTED = 1
            elif changed_file.startswith(""streaming/src""):
                RAY_CI_STREAMING_CPP_AFFECTED = 1
                RAY_CI_STREAMING_PYTHON_AFFECTED = 1
                RAY_CI_STREAMING_JAVA_AFFECTED = 1
            elif changed_file.startswith(""streaming/python""):
                RAY_CI_STREAMING_PYTHON_AFFECTED = 1
            elif changed_file.startswith(""streaming/java""):
                RAY_CI_STREAMING_JAVA_AFFECTED = 1
                RAY_CI_SERVE_AFFECTED = 1
                RAY_CI_STREAMING_CPP_AFFECTED = 1
                RAY_CI_STREAMING_PYTHON_AFFECTED = 1
                RAY_CI_STREAMING_JAVA_AFFECTED = 1
        RAY_CI_RLLIB_FULL_AFFECTED = 1
        RAY_CI_SERVE_AFFECTED = 1
        RAY_CI_STREAMING_CPP_AFFECTED = 1
        RAY_CI_STREAMING_PYTHON_AFFECTED = 1
        RAY_CI_STREAMING_JAVA_AFFECTED = 1

    if not RAY_CI_TUNE_AFFECTED and not RAY_CI_SERVE_AFFECTED and \
            not RAY_CI_JAVA_AFFECTED and not RAY_CI_PYTHON_AFFECTED and not \
            RAY_CI_STREAMING_CPP_AFFECTED and \
            not RAY_CI_STREAMING_PYTHON_AFFECTED and \
            not RAY_CI_STREAMING_JAVA_AFFECTED:
        RAY_CI_ONLY_RLLIB_AFFECTED = 1
    # Log the modified environment variables visible in console.
    print("" "".join([
        ""RAY_CI_TUNE_AFFECTED={}"".format(RAY_CI_TUNE_AFFECTED),
        ""RAY_CI_ONLY_RLLIB_AFFECTED={}"".format(RAY_CI_ONLY_RLLIB_AFFECTED),
        ""RAY_CI_RLLIB_AFFECTED={}"".format(RAY_CI_RLLIB_AFFECTED),
        ""RAY_CI_RLLIB_FULL_AFFECTED={}"".format(RAY_CI_RLLIB_FULL_AFFECTED),
        ""RAY_CI_SERVE_AFFECTED={}"".format(RAY_CI_SERVE_AFFECTED),
        ""RAY_CI_JAVA_AFFECTED={}"".format(RAY_CI_JAVA_AFFECTED),
        ""RAY_CI_PYTHON_AFFECTED={}"".format(RAY_CI_PYTHON_AFFECTED),
        ""RAY_CI_LINUX_WHEELS_AFFECTED={}"".format(RAY_CI_LINUX_WHEELS_AFFECTED),
        ""RAY_CI_MACOS_WHEELS_AFFECTED={}"".format(RAY_CI_MACOS_WHEELS_AFFECTED),
        ""RAY_CI_STREAMING_CPP_AFFECTED={}"".format(
            RAY_CI_STREAMING_CPP_AFFECTED),
        ""RAY_CI_STREAMING_PYTHON_AFFECTED={}"".format(
            RAY_CI_STREAMING_PYTHON_AFFECTED),
        ""RAY_CI_STREAMING_JAVA_AFFECTED={}"".format(
            RAY_CI_STREAMING_JAVA_AFFECTED),
    ]))
    mat = np.array(
        [[[2.0, 2.0], [2.0, 2.0]], [[2.0, 2.0], [2.0, 2.0]]], dtype=np.float32)
    run_func(cyth.compute_kernel_matrix, ""L"", ""T"", 2, 2, 1.0, mat, 0, 2, 1.0,
             result, 2)",bug-free
"    """"""
    Offers a mechanism for waiting until another process is finished interacting with a shared resource. This is
    specifically written to interact with a class of the same name in the .NET extensions library.
            # Attempt to delete the lockfile. In either of the failure cases enumerated below, it is likely that
            # another process has raced this one and ended up clearing or locking the file for itself.
        except PermissionError:
            pass
            if ex.errno != errno.ENOENT:",buggy
"""""""Provides a mechanism for not competing with other processes interacting with an MSAL cache.""""""
    """"""Offers a mechanism for waiting until another process is finished interacting with a shared
    resource. This is specifically written to interact with a class of the same name in the .NET
    extensions library.
        self._fh = None
            # Attempt to delete the lockfile. In either of the failure cases enumerated below, it is
            # likely that another process has raced this one and ended up clearing or locking the
            # file for itself.
            if ex.errno != errno.ENOENT and ex.errno != errno.EACCES:",bug-free
"    version=""0.0.82"",
@router.get(""/general/v0.0.82/general"", include_in_schema=False)
@router.post(""/general/v0.0.82/general"", include_in_schema=False)
        responses: Sequence[str | List[Dict[str, Any]] | PlainTextResponse]
        (""winter-sports.epub"", ""application/epub""),
        (""fake.odt"", ""application/vnd.oasis.opendocument.text""),
    test_file = Path(""sample-docs"") / example_filename
    response = client.post(
        MAIN_API_ROUTE, files=[(""files"", (str(test_file), open(test_file, ""rb""), content_type))]
    )
    response = client.post(
        MAIN_API_ROUTE,
        files=[
            (""files"", (str(test_file), open(test_file, ""rb""), content_type)),
            (""files"", (str(test_file), open(test_file, ""rb""), content_type)),
        ],
    )
    csv_response = client.post(
        MAIN_API_ROUTE,
        files=[
            (""files"", (str(test_file), open(test_file, ""rb""), content_type)),
            (""files"", (str(test_file), open(test_file, ""rb""), content_type)),
        ],
        data={""output_format"": ""text/csv""},
    )
        data={},
    parameters: dict[str, Any]",buggy
"    version=""0.0.83"",
@router.get(""/general/v0.0.83/general"", include_in_schema=False)
@router.post(""/general/v0.0.83/general"", include_in_schema=False)
        responses: Sequence[str | List[Dict[str, Any]] | PlainTextResponse],
        # After https://github.com/Unstructured-IO/unstructured-api/pull/487 updated Starlette
        # to resolve a vulnerability, these unit tests fail with:
        # AttributeError: 'SpooledTemporaryFile' object has no attribute 'seekable'
        # These files pass the smoke test that runs against Docker, so assume there's no regression.
        # (""winter-sports.epub"", ""application/epub""),
        # (""fake.odt"", ""application/vnd.oasis.opendocument.text""),
    # Ensure files are properly closed
    test_file_path = str(Path(""sample-docs"") / example_filename)
    with open(test_file_path, ""rb"") as f:
        response = client.post(MAIN_API_ROUTE, files=[(""files"", (test_file_path, f, content_type))])

    with open(test_file_path, ""rb"") as f, open(test_file_path, ""rb"") as g:
        response = client.post(
            MAIN_API_ROUTE,
            files=[
                (""files"", (str(test_file_path), f, content_type)),
                (""files"", (str(test_file_path), g, content_type)),
            ],
        )
    with open(test_file_path, ""rb"") as f, open(test_file_path, ""rb"") as g:
        csv_response = client.post(
            MAIN_API_ROUTE,
            files=[
                (""files"", (str(test_file_path), f, content_type)),
                (""files"", (str(test_file_path), g, content_type)),
            ],
            data={""output_format"": ""text/csv""},
        )
        data={""chunking_strategy"": ""by_title"", ""new_after_n_chars"": 1000},
    parameters: dict[str, Any],",bug-free
"def logexport(events: List[func.EventHubEvent]):
        logging.exception(""failed to process event"")
",buggy
"MAX_RETRY_COUNT: Final[str] = ""3""
MINIMUM_INTERVAL: Final[str] = ""00:00:01""
MAXIMUM_INTERVAL: Final[str] = ""00:00:10""

# Configures an exponential backoff retry strategy in the trigger from eventhub to the function.
# When eventuhb executes the function, it will not commit a checkpoint until all retries are exhausted,
# and then progress in that partition is restarted.
@app.retry(
    strategy=""exponential_backoff"",
    max_retry_count=MAX_RETRY_COUNT,
    minimum_interval=MINIMUM_INTERVAL,
    maximum_interval=MAXIMUM_INTERVAL,
)
def logexport(events: List[func.EventHubEvent], context: func.Context) -> None:
        if context.retry_context.retry_count == context.retry_context.max_retry_count:
            logging.exception(
                ""failed to process event %d times. Giving up."",
                context.retry_context.retry_count + 1,
            )
        else:
            logging.exception(
                ""failed to process event %d times. Retrying..."",
                context.retry_context.retry_count + 1,
            )
            raise
",bug-free
"from .utils import get_mac_address_and_interface, get_debug
    assert 'error' in response.json()
    assert 'error' in response.json()",buggy
"from .utils import get_mac_address_and_interface, get_debug, validate_serial
    assert 'detail' in response.json()
    assert 'detail' in response.json()
#    assert 'error' in response.json()",bug-free
"from klingon_serial.generate_serial import generate_serial
from datetime import datetime
    epoch = int(datetime.utcnow().timestamp() * 1000)
    print(""Epoch datetime (ms):     "",int(datetime.utcnow().timestamp() * 1000))

    """"""Convert a string representation of truth to true (1) or false (0).
    Args:
        val (str): The string representation of truth value.

    Returns:
        int: 1 if the value is true, 0 if the value is false.

    Raises:
        ValueError: If the value is not a valid truth value.
    val = val.lower()
    if val in ('y', 'yes', 't', 'true', 'on', '1'):
        return 1
    elif val in ('n', 'no', 'f', 'false', 'off', '0'):
        return 0
    else:
        raise ValueError(""Invalid truth value %r"" % (val,))

###
### klingon_serial setup.py
### 
    name='klingon_serial',
        'datetime',
        'pytest',
        'uuid',
        'setuptools'
    python_requires='>=3.6',
)
from klingon_serial.generate_serial import generate_serial, get_mac_address_hex, get_process_id, get_millisecond_epoch_hex
    assert get_debug() is True
    assert get_debug() is False",buggy
"from klingon_serial.generate import generate_serial
from datetime import datetime, timezone
    epoch = int(datetime.now(timezone.utc).timestamp() * 1000)
    print(""Epoch datetime (ms):     "",int(datetime.now(timezone.utc).timestamp() * 1000))
from distutils.util import strtobool as str2bool

    """"""Convert a string representation of truth to true (True) or false (False).
    This function is a wrapper around str2bool for compatibility.
    return str2bool(val)
""""""
This module provides utility functions for the klingon_serial package, including
retrieving the MAC address and network interface, and determining the debug mode.
""""""

    try:
        # Get primary network interface by looking at the default route
        primary_interface = None
        for interface, addrs in psutil.net_if_addrs().items():
            for addr in addrs:
                if addr.family == psutil.AF_LINK:
                    primary_interface = interface
                    mac_address = addr.address
                    return mac_address, primary_interface  # Return on first found interface
    except Exception as e:
        print(f""Error retrieving network interface: {e}"")
    name='klingon-serial',
        'pytest>=6.0',  # Specify the minimum version required
        'str2bool',
    license='MIT',  # Add the license field
    python_requires='>=3.9',
)
from klingon_serial.generate import generate_serial, get_mac_address_hex, get_process_id, get_millisecond_epoch_hex
    assert get_debug() == True
    assert get_debug() == False",bug-free
"if sys.version_info >= (2, 6):
    def binary(obj):
        return bytes(obj)
else:
    def binary(obj):
        return buffer(obj)

if sys.version_info >= (3, 0):
    text_type = str
    base_text_type = str
else:
    text_type = unicode
    base_text_type = basestring
    _fields_ = [(""Data1"", DWORD),
                (""Data2"", WORD),
                (""Data3"", WORD),
                (""Data4"", BYTE * 8)]
            _CLSIDFromString(text_type(name), byref(self))
        return 'GUID(""%s"")' % text_type(self)
        return isinstance(other, GUID) and \
               binary(self) == binary(other)
        return GUID(text_type(self))
        """"""Get guid from progid, ...
        """"""
        elif isinstance(progid, base_text_type):
            _CLSIDFromProgID(text_type(progid), byref(inst))
from ctypes import _SimpleCData
from _ctypes import COMError
################################################################

def add_metaclass(metaclass):
    """"""Class decorator from six.py for creating a class with a metaclass.

    Copyright (c) 2010-2020 Benjamin Peterson

    Permission is hereby granted, free of charge, to any person obtaining a copy of
    this software and associated documentation files (the ""Software""), to deal in
    the Software without restriction, including without limitation the rights to
    use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
    the Software, and to permit persons to whom the Software is furnished to do so,
    subject to the following conditions:

    The above copyright notice and this permission notice shall be included in all
    copies or substantial portions of the Software.

    THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
    FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
    COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
    IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
    CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
    """"""
    def wrapper(cls):
        orig_vars = cls.__dict__.copy()
        slots = orig_vars.get('__slots__')
        if slots is not None:
            if isinstance(slots, text_type):
                slots = [slots]
            for slots_var in slots:
                orig_vars.pop(slots_var)
        orig_vars.pop('__dict__', None)
        orig_vars.pop('__weakref__', None)
        if hasattr(cls, '__qualname__'):
            orig_vars['__qualname__'] = cls.__qualname__
        return metaclass(cls.__name__, cls.__bases__, orig_vars)
    return wrapper

################################################################

# type hinting symbols
#
# `if TYPE_CHECKING:` code block must not be executed because `TYPE_CHECKING`
# is always `False` in runtime.
# see https://peps.python.org/pep-0484/#runtime-or-type-checking
#
if sys.version_info >= (3, 5):
    from typing import TYPE_CHECKING
else:  # typehints in this package don't support Py<3.5 due to importing symbols.
    TYPE_CHECKING = False
#
# Annotations must be placed in a `# type:` comment in according to PEP484.
# see https://peps.python.org/pep-0484/#suggested-syntax-for-python-2-7-and-straddling-code
# - `NameError` never raises by using those symbols.
# - It is not able to use any runtime introspections, such as
#   `typing.get_type_hints` or `typing.get_origin`.
#
    # _CData = _SimpleCData.__mro__[:-1][-1]  # defining in runtime
    from ctypes import _Pointer
    from typing import Any, ClassVar, overload, TypeVar
    # XXX: symbols for backward compatibility.
    # instead of `builtins`. see PEP585.
    from typing import Dict, List, Tuple, Type
    # instead of `collections.abc`. see PEP585.
    from typing import Callable, Iterable, Iterator
    # instead of `A | B` and `None | A`. see PEP604.
    from typing import Union as _UnionT  #  avoiding confusion with `ctypes.Union`
    from typing import Optional
    # utilities or workarounds for annotations.
    from comtypes import hints as hints

################################################################
    ComMemberGenerator, _ComMemberSpec, DispMemberGenerator, _DispMemberSpec,
    _encode_idl, _resolve_argspec,
################################################################
if sys.version_info >= (3, 0):
    text_type = str
else:
    text_type = unicode
if sys.version_info >= (3, 0):
    pythonapi.PyInstanceMethod_New.argtypes = [py_object]
    pythonapi.PyInstanceMethod_New.restype = py_object
    PyInstanceMethod_Type = type(pythonapi.PyInstanceMethod_New(id))
    def instancemethod(func, inst, cls):
        mth = PyInstanceMethod_Type(func)
        if inst is None:
            return mth
        return mth.__get__(inst)
else:
    def instancemethod(func, inst, cls):
        return types.MethodType(func, inst, cls)
##class IDLWarning(UserWarning):
##    ""Warn about questionable type information""
tagCLSCTX = c_int # enum

_ole32_nohresult = windll.ole32 # use this for functions that don't return a HRESULT
COINIT_MULTITHREADED     = 0x0
COINIT_DISABLE_OLE1DDE   = 0x4
def _shutdown(func=_ole32_nohresult.CoUninitialize,
             _debug=logger.debug,
             _exc_clear=getattr(sys, ""exc_clear"", lambda: None)):
        try: func()
        except WindowsError: pass
    if TYPE_CHECKING:
        _case_insensitive_ = hints.AnnoField()  # type: bool
        _iid_ = hints.AnnoField()  # type: GUID
        _methods_ = hints.AnnoField()  # type: List[_ComMemberSpec]
        _disp_methods_ = hints.AnnoField()  # type: List[_DispMemberSpec]
        p = type(_compointer_base)(""POINTER(%s)"" % new_cls.__name__,
                                   _ptr_bases,
                                   {""__com_interface__"": new_cls,
                                    ""_needs_com_addref_"": None})
                    if fixed_name != name: # prevent unbounded recursion
                    object.__setattr__(self,
                                       self.__map_case__.get(name.lower(), name),
                                       value)
##            assert self.__dict__.get(""_methods_"", None) is None
    def _make_dispmethods(self, methods):
        # type: (List[_DispMemberSpec]) -> None
    def _make_methods(self, methods):
        # type: (List[_ComMemberSpec]) -> None
            com_interface_registry[text_type(iid)] = self
@add_metaclass(_compointer_meta)
class _compointer_base(c_void_p):
        return cmp(super(_compointer_base, self).value, super(_compointer_base, other).value)
        return super(_compointer_base, self).value == super(_compointer_base, other).value
        if self._b_base_ is None \
               or self._needsfree:
class helpstring(text_type):
def STDMETHOD(restype, name, argtypes=()):
def DISPMETHOD(idlflags, restype, name, *argspec):
def DISPPROPERTY(idlflags, proptype, name):
def COMMETHOD(idlflags, restype, methodname, *argspec):
    _T_IUnknown = TypeVar(""_T_IUnknown"", bound=""IUnknown"")
    class _IUnknown_Base(c_void_p):
        __com_QueryInterface = hints.AnnoField()  # type: Callable[[Any, Any], int]
        __com_AddRef = hints.AnnoField()  # type: Callable[[], int]
        __com_Release = hints.AnnoField()  # type: Callable[[], int]
@add_metaclass(_cominterface_meta)
class IUnknown(_IUnknown_Base):
    _case_insensitive_ = False  # type: ClassVar[bool]
    _iid_ = GUID(""{00000000-0000-0000-C000-000000000046}"")  # type: ClassVar[GUID]
    _methods_ = [
        STDMETHOD(HRESULT, ""QueryInterface"",
                  [POINTER(GUID), POINTER(c_void_p)]),
        STDMETHOD(c_ulong, ""Release"")
    ]  # type: ClassVar[List[_ComMemberSpec]]
    def QueryInterface(self, interface, iid=None):
        # type: (Type[_T_IUnknown], Optional[GUID]) -> _T_IUnknown
        clsid = self.__dict__.get('__clsid')
            p.__dict__['__clsid'] = clsid
    def AddRef(self):
        # type: () -> int
    def Release(self):
        # type: () -> int
    _iid_ = GUID('{0000010C-0000-0000-C000-000000000046}')
        COMMETHOD([], HRESULT, 'GetClassID',
                  ( ['out'], POINTER(GUID), 'pClassID' )),
        ]
        # Returns the CLSID that uniquely represents an object class that
        # defines the code that can manipulate the object's data.
        GetClassID = hints.AnnoField()  # type: Callable[[], GUID]
    _iid_ = GUID('{6D5140C1-7436-11CE-8034-00AA006009FA}')
    if TYPE_CHECKING:
        _QueryService = hints.AnnoField()  # type: Callable[[Any, Any, Any], int]
    def QueryService(self, serviceIID, interface):
        # type: (GUID, Type[_T_IUnknown]) -> _T_IUnknown
        COMMETHOD([], HRESULT, 'QueryService',
                  ( ['in'], POINTER(GUID), 'guidService' ),
                  ( ['in'], POINTER(GUID), 'riid' ),
                  ( ['in'], POINTER(c_void_p), 'ppvObject' ))
        ]
if TYPE_CHECKING:
    @overload
    def CoGetObject(displayname, interface):  # `interface` can't be missing
        # type: (str, None) -> IUnknown
        pass
    @overload
    def CoGetObject(displayname, interface):  # it should be called this way
        # type: (str, Type[_T_IUnknown]) -> _T_IUnknown
        pass
def CoGetObject(displayname, interface):
    # type: (str, Optional[Type[IUnknown]]) -> IUnknown
    _ole32.CoGetObject(text_type(displayname),
                       None,
                       byref(interface._iid_),
                       byref(punk))
if TYPE_CHECKING:
    pUnkOuter = Type[_Pointer[IUnknown]]
    @overload
    def CoCreateInstance(clsid, interface=None, clsctx=None, punkouter=None):
        # type: (GUID, None, Optional[int], Optional[pUnkOuter]) -> IUnknown
        pass
    @overload
    def CoCreateInstance(clsid, interface, clsctx=None, punkouter=None):
        # type: (GUID, Type[_T_IUnknown], Optional[int], Optional[pUnkOuter]) -> _T_IUnknown
        pass
def CoCreateInstance(clsid, interface=None, clsctx=None, punkouter=None):
    # type: (GUID, Optional[Type[IUnknown]], Optional[int], Optional[pUnkOuter]) -> IUnknown
    _CoGetClassObject(clsid,
                      clsctx,
                      pServerInfo,
                      interface._iid_,
                      byref(p))
if TYPE_CHECKING:
    @overload
    def GetActiveObject(clsid, interface=None):
        # type: (GUID, None) -> IUnknown
        pass
    @overload
    def GetActiveObject(clsid, interface):
        # type: (GUID, Type[_T_IUnknown]) -> _T_IUnknown
        pass
def GetActiveObject(clsid, interface=None):
    # type: (GUID, Optional[Type[IUnknown]]) -> IUnknown
    _fields_ = [(""pIID"", POINTER(GUID)),
                (""pItf"", POINTER(c_void_p)),
                (""hr"", HRESULT)]
        pIID = hints.AnnoField()  # type: GUID
        pItf = hints.AnnoField()  # type: _Pointer[c_void_p]
        hr = hints.AnnoField()  # type: HRESULT
        ('User', POINTER(c_ushort)),
        ('UserLength', c_ulong),
        ('Domain', POINTER(c_ushort)),
        ('DomainLength', c_ulong),
        ('Password', POINTER(c_ushort)),
        ('PasswordLength', c_ulong),
        ('Flags', c_ulong),
        ('dwAuthnSvc', c_ulong),
        ('dwAuthzSvc', c_ulong),
        ('pwszServerPrincName', c_wchar_p),
        ('dwAuthnLevel', c_ulong),
        ('dwImpersonationLevel', c_ulong),
        ('pAuthIdentityData', POINTER(_COAUTHIDENTITY)),
        ('dwCapabilities', c_ulong),
        ('dwReserved1', c_ulong),
        ('pwszName', c_wchar_p),
        ('pAuthInfo', POINTER(_COAUTHINFO)),
        ('dwReserved2', c_ulong),
        dwReserved1 = hints.AnnoField()  # type: int
        pwszName = hints.AnnoField()  # type: Optional[str]
        pAuthInfo = hints.AnnoField()  # type: _COAUTHINFO
        dwReserved2 = hints.AnnoField()  # type: int
_CoGetClassObject.argtypes = [POINTER(GUID), DWORD, POINTER(COSERVERINFO),
                              POINTER(GUID), POINTER(c_void_p)]
        ('cbStruct', c_ulong),
        ('grfFlags', c_ulong),
        ('grfMode', c_ulong),
        ('dwTickCountDeadline', c_ulong)
        ('cbStruct', c_ulong),
        ('grfFlags', c_ulong),
        ('grfMode', c_ulong),
        ('dwTickCountDeadline', c_ulong),
        ('dwTrackFlags', c_ulong),
        ('dwClassContext', c_ulong),
        ('locale', c_ulong),
        ('pServerInfo', POINTER(_COSERVERINFO)),
#Structures for security setups
        ('User', POINTER(c_ushort)),
        ('UserLength', c_ulong),
        ('Domain', POINTER(c_ushort)),
        ('DomainLength', c_ulong),
        ('Password', POINTER(c_ushort)),
        ('PasswordLength', c_ulong),
        ('Flags', c_ulong),
        ('dwAuthnSvc', c_ulong),
        ('dwAuthzSvc', c_ulong),
        ('pAuthInfo', POINTER(_SEC_WINNT_AUTH_IDENTITY)),
        ('cAuthInfo', c_ulong),
        ('pAuthInfo', POINTER(_SOLE_AUTHENTICATION_INFO)),
SOLE_AUTHENTICATION_LIST = _SOLE_AUTHENTICATION_LIST
if TYPE_CHECKING:
    @overload
    def CoCreateInstanceEx(
        clsid, interface=None, clsctx=None, machine=None, pServerInfo=None):
        # type: (GUID, None, Optional[int], Optional[str], Optional[COSERVERINFO]) -> IUnknown
        pass
    @overload
    def CoCreateInstanceEx(
        clsid, interface=None, clsctx=None, machine=None, pServerInfo=None):
        # type: (GUID, Type[_T_IUnknown], Optional[int], Optional[str], Optional[COSERVERINFO]) -> _T_IUnknown
        pass
def CoCreateInstanceEx(clsid, interface=None,
                       clsctx=None,
                       machine=None,
                       pServerInfo=None):
    # type: (GUID, Optional[Type[IUnknown]], Optional[int], Optional[str], Optional[COSERVERINFO]) -> IUnknown
        clsctx=CLSCTX_LOCAL_SERVER|CLSCTX_REMOTE_SERVER
    _ole32.CoCreateInstanceEx(byref(clsid),
                             None,
                             clsctx,
                             pServerInfo,
                             1,
                             byref(multiqi))
@add_metaclass(_coclass_meta)
class CoClass(COMObject):
    'BIND_OPTS', 'tagBIND_OPTS', 'BINDOPTS2', 'tagBIND_OPTS2', 'BSTR',
    '_check_version', 'CLSCTX', 'tagCLSCTX', 'CLSCTX_ALL',
    'CLSCTX_DISABLE_AAA', 'CLSCTX_ENABLE_AAA', 'CLSCTX_ENABLE_CODE_DOWNLOAD',
    'CLSCTX_FROM_DEFAULT_CONTEXT', 'CLSCTX_INPROC', 'CLSCTX_INPROC_HANDLER',
    'CLSCTX_INPROC_HANDLER16', 'CLSCTX_INPROC_SERVER',
    'CLSCTX_INPROC_SERVER16', 'CLSCTX_LOCAL_SERVER', 'CLSCTX_NO_CODE_DOWNLOAD',
    'CLSCTX_NO_CUSTOM_MARSHAL', 'CLSCTX_NO_FAILURE_LOG',
    'CLSCTX_REMOTE_SERVER', 'CLSCTX_RESERVED1', 'CLSCTX_RESERVED2',
    'CLSCTX_RESERVED3', 'CLSCTX_RESERVED4', 'CLSCTX_RESERVED5',
    'CLSCTX_SERVER', '_COAUTHIDENTITY', 'COAUTHIDENTITY', '_COAUTHINFO',
    'COAUTHINFO', 'CoClass', 'CoCreateInstance', 'CoCreateInstanceEx',
    '_CoGetClassObject', 'CoGetClassObject', 'CoGetObject',
    'COINIT_APARTMENTTHREADED', 'COINIT_DISABLE_OLE1DDE',
    'COINIT_MULTITHREADED', 'COINIT_SPEED_OVER_MEMORY', 'CoInitialize',
    'CoInitializeEx', 'COMError', 'COMMETHOD', 'COMObject', '_COSERVERINFO',
    'COSERVERINFO', 'CoUninitialize', 'dispid', 'DISPMETHOD', 'DISPPROPERTY',
    'DWORD', 'EOAC_NONE', 'GetActiveObject', '_GUID', 'GUID', 'helpstring',
    'IID', 'IPersist', 'IServiceProvider', 'IUnknown', 'MULTI_QI',
    'ReturnHRESULT', 'RPC_C_AUTHN_LEVEL_CONNECT', 'RPC_C_AUTHN_WINNT',
    'RPC_C_AUTHZ_NONE', 'RPC_C_IMP_LEVEL_IMPERSONATE',
    '_SEC_WINNT_AUTH_IDENTITY', 'SEC_WINNT_AUTH_IDENTITY',
    'SEC_WINNT_AUTH_IDENTITY_UNICODE', '_SOLE_AUTHENTICATION_INFO',
    'SOLE_AUTHENTICATION_INFO', '_SOLE_AUTHENTICATION_LIST',
    'SOLE_AUTHENTICATION_LIST', 'STDMETHOD', 'wireHWND',
    FormatError, POINTER, Structure, WINFUNCTYPE, byref, c_long, c_void_p,
    oledll, pointer, windll
    DISP_E_BADINDEX, DISP_E_MEMBERNOTFOUND, E_FAIL, E_NOINTERFACE,
    E_INVALIDARG, E_NOTIMPL, RPC_E_CHANGED_MODE, S_FALSE, S_OK
if sys.version_info >= (3, 0):
    int_types = (int, )
else:
    int_types = (int, long)

        if isinstance(code, int_types):
    raise TypeError(""Expected comtypes.COMERROR or WindowsError instance, got %s"" % type(exc).__name__)
        _debug(""unimplemented method %s_%s called"", interface_name,
               method_name)
            return ReportError(text, iid=interface._iid_, clsid=clsid,
                               hresult=hresult)
            _error(""Exception in %s.%s implementation:"", interface.__name__,
                   mthname, exc_info=True)
            _warning(""Unimplemented method %s.%s called"", interface.__name__,
                     mthname)
            _error(""Exception in %s.%s implementation:"", interface.__name__,
                   mthname, exc_info=True)
        has_outargs = bool([x[0] for x in paramflags
                            if x[0] & 2])
        if a&2:
        if a&1 or a==0:
##    if args_in != code.co_argcount - 1:
##        return catch_errors(inst, mth, interface, mthname)
##        for a in outargs:
##            if not a:
##                return E_POINTER
        #make argument list for handler by index array built above
            return ReportError(text, iid=interface._iid_, clsid=clsid,
                               hresult=hresult)
            _error(""Exception in %s.%s implementation:"", interface.__name__,
                   mthname, exc_info=True)
            return ReportError(msg, iid=interface._iid_, clsid=clsid,
                               hresult=hr)
            _error(""Exception in %s.%s implementation:"", interface.__name__,
                   mthname, exc_info=True)
            _warning(""Unimplemented method %s.%s called"", interface.__name__,
                     mthname)
            _error(""Exception in %s.%s implementation:"", interface.__name__,
                   mthname, exc_info=True)
        _debug(""%r: %s.%s not implemented"", self.inst, interface.__name__,
               mthname)
        if sys.version_info >= (3, 0):
            import queue
        else:
            import Queue as queue

                if hasattr(self, ""_outgoing_interfaces_"") and \
                   IProvideClassInfo2 not in interfaces:
                    if 'propget' in idlflags:
                    elif 'propput' in idlflags:
                    elif 'propputref' in idlflags:
                            argspec = argspec + ((['out'], restype, """"),)
                    self.__make_dispentry(finder, interface, mthname,
                                          idlflags, argspec, invkind)
                        argspec += ((['out'], restype, """"),)
                    self.__make_dispentry(finder, interface,
                                          ""_get_"" + mthname,
                                          idlflags, argspec,
                                          2  # DISPATCH_PROPERTYGET
                                          )
                    if not 'readonly' in idlflags:
                        self.__make_dispentry(finder, interface,
                                              ""_set_"" + mthname,
                                              idlflags, argspec,
                                              4)  # DISPATCH_PROPERTYPUT
    def __make_dispentry(self,
                         finder, interface, mthname,
                         idlflags, argspec, invkind):
        paramflags = [((_encode_idl(x[0]), x[1]) + tuple(x[3:]))
                      for x in argspec]
        _debug(""%d active COM objects: Added   %r"", len(COMObject._instances_),
               obj)
            _debug(""%d active COM objects: Removed %r"",
                   len(COMObject._instances_), obj)
    def IUnknown_AddRef(self, this,
                        __InterlockedIncrement=_InterlockedIncrement,
                        _debug=_debug):
    def IUnknown_Release(self, this,
                         __InterlockedDecrement=_InterlockedDecrement,
                         _debug=_debug):
            raise COMError(E_NOINTERFACE, FormatError(E_NOINTERFACE),
                           (None, None, 0, None, None))
    def IDispatch_GetIDsOfNames(self, this, riid, rgszNames, cNames, lcid,
                                rgDispId):
        return windll.oleaut32.DispGetIDsOfNames(tinfo,
                                                 rgszNames, cNames, rgDispId)

    def IDispatch_Invoke(self, this, dispIdMember, riid, lcid, wFlags,
                         pDispParams, pVarResult, pExcepInfo, puArgErr):
                ptr, tinfo, dispIdMember, wFlags, pDispParams, pVarResult,
                pExcepInfo, puArgErr
            args = [params.rgvarg[i].value
                    for i in reversed(list(range(params.cNamedArgs)))]
            named_indexes = [params.rgdispidNamedArgs[i]
                             for i in range(params.cNamedArgs)]

from comtypes import TYPE_CHECKING
if TYPE_CHECKING:
    from comtypes import _CData
    from typing import (
        Any, Callable, Dict, Iterator, List, Optional, Tuple, Type, Union as _UnionT
    )
    PositionalParamFlagType = Tuple[int, Optional[str]]
    OptionalParamFlagType = Tuple[int, Optional[str], Any]
    ParamFlagType = _UnionT[PositionalParamFlagType, OptionalParamFlagType]
    PositionalArgSpecElmType = Tuple[List[str], Type[_CData], str]
    OptionalArgSpecElmType = Tuple[List[str], Type[_CData], str, Any]
    ArgSpecElmType = _UnionT[PositionalArgSpecElmType, OptionalArgSpecElmType]
    }
def _unpack_argspec(idl, typ, name=None, defval=_NOTHING):
    # type: (List[str], Type[_CData], Optional[str], Any) -> Tuple[List[str], Type[_CData], Optional[str], Any]
def _resolve_argspec(items):
    # type: (Tuple[ArgSpecElmType, ...]) -> Tuple[Tuple[ParamFlagType, ...], Tuple[Type[_CData], ...]]
class _MemberSpec(object):
    """"""Specifier of a slot of method or property.""""""
    __slots__ = (""name"", ""idlflags"", ""restype"")
    def __init__(self, name, idlflags, restype):
        self.name = name  # type: str
        self.idlflags = idlflags  # type: Tuple[_UnionT[str, int], ...]
        self.restype = restype  # type: Optional[Type[_CData]]

    def is_prop(self):
        # type: () -> bool
        propflags = (""propget"", ""propput"", ""propputref"")
        return any(f in propflags for f in self.idlflags)


class _ComMemberSpec(_MemberSpec):
    __slots__ = (""argtypes"", ""paramflags"", ""doc"")
    def __init__(self, restype, name, argtypes, paramflags, idlflags, doc):
        self.argtypes = argtypes  # type: Tuple[Type[_CData], ...]
        self.paramflags = paramflags  # type: Optional[Tuple[ParamFlagType, ...]]
        self.doc = doc  # type: Optional[str]
        super(_ComMemberSpec, self).__init__(name, idlflags, restype)
    def __iter__(self):
        # for backward compatibility:
        # A function that returns this object used to return a `tuple`.
        # So it is implemented as unpackable as well.
        for item in (self.restype, self.name, self.argtypes, self.paramflags, self.idlflags, self.doc):
            yield item
class _DispMemberSpec(_MemberSpec):
    __slots__ = (""what"", ""argspec"")
    def __init__(self, what, name, idlflags, restype, argspec):
        self.what = what  # type: str
        self.argspec = argspec  # type: Tuple[ArgSpecElmType, ...]
        super(_DispMemberSpec, self).__init__(name, idlflags, restype)
    def memid(self):
        # type: () -> int
    def __iter__(self):
        # for backward compatibility:
        # A function that returns this object used to return a `tuple`.
        # So it is implemented as unpackable as well.
        for item in (self.what, self.name, self.idlflags, self.restype, self.argspec):
            yield item
def _fix_inout_args(func, argtypes, paramflags):
    # type: (Callable[..., Any], Tuple[Type[_CData], ...], Tuple[ParamFlagType, ...]) -> Callable[..., Any]
        outargs = {}
            if direction & 3 == 3:
                atyp = argtypes[i]._type_
                try:
                    try:
                        v = args[i]
                    except IndexError:
                        v = kw[name]
                except KeyError:
                    # no parameter was passed, make an empty one
                    # of the required type
                    v = atyp()
                else:
                    # parameter was passed, call .from_param() to
                    # convert it to a ctypes type.
                        # Array of or pointer to type 'atyp' was
                        # passed, pointer to 'atyp' expected.
                        # The from_param method of simple types
                        # (c_int, c_double, ...) returns a byref()
                        # object which we cannot use since later
                        # it will be wrapped in a pointer.  Simply
                        # call the constructor with the argument
                        # in that case.
                outargs[outnum] = v
                outnum += 1
                if len(args) > i:
                    args[i] = v
                else:
            elif direction & 2 == 2:
        self._data = {}  # type: Dict[Tuple[str, Optional[str], int], List[Optional[Callable[..., Any]]]]
    def add_propget(self, name, doc, nargs, func):
        # type: (str, Optional[str], int, Callable[..., Any]) -> None
    def add_propput(self, name, doc, nargs, func):
        # type: (str, Optional[str], int, Callable[..., Any]) -> None
    def add_propputref(self, name, doc, nargs, func):
        # type: (str, Optional[str], int, Callable[..., Any]) -> None
    def __iter__(self):
        # type: () -> Iterator[Tuple[str, Optional[str], int, Optional[Callable[..., Any]], Optional[Callable[..., Any]]]]
    def __init__(self, cls_name):
        # type: (str) -> None
    def add(self, m, func):
        # type: (_MemberSpec, Callable[..., Any]) -> None
    def __iter__(self):
        # type: () -> Iterator[Tuple[str, _UnionT[property, named_property]]]
    def to_propget_keys(self, m):
        # type: (_MemberSpec) -> Tuple[str, Optional[str], int]
    def to_propput_keys(self, m):
        # type: (_MemberSpec) -> Tuple[str, Optional[str], int]
    def to_propputref_keys(self, m):
        # type: (_MemberSpec) -> Tuple[str, Optional[str], int]
    def to_propget_keys(self, m):
        # type: (_ComMemberSpec) -> Tuple[str, Optional[str], int]
        return m.name[len(""_get_""):], m.doc, nargs
    def to_propput_keys(self, m):
        # type: (_ComMemberSpec) -> Tuple[str, Optional[str], int]
        return m.name[len(""_set_""):], m.doc, nargs
    def to_propputref_keys(self, m):
        # type: (_ComMemberSpec) -> Tuple[str, Optional[str], int]
        return m.name[len(""_setref_""):], m.doc, nargs
    def to_propget_keys(self, m):
        # type: (_DispMemberSpec) -> Tuple[str, Optional[str], int]
    def to_propput_keys(self, m):
        # type: (_DispMemberSpec) -> Tuple[str, Optional[str], int]
    def to_propputref_keys(self, m):
        # type: (_DispMemberSpec) -> Tuple[str, Optional[str], int]
    def __init__(self, cls_name, vtbl_offset, iid):
        # type: (str, int, comtypes.GUID) -> None
        self._mths = []  # type: List[Tuple[str, Callable[..., Any], Callable[..., Any], bool]]
    def add(self, m):
        # type: (_ComMemberSpec) -> None
    def _fix_args(self, m, func):
        # type: (_ComMemberSpec, Callable[..., Any]) -> Callable[..., Any]
            dirflags = [(p[0]&3) for p in m.paramflags]
    def __init__(self, cls_name):
        # type: (str) -> None
        self._items = []  # type: List[Tuple[str, _UnionT[Callable[..., Any], property], bool]]
    def add(self, m):
        # type: (_DispMemberSpec) -> None
            assert not m.argspec # XXX does not yet work for properties with parameters
    def _make_disp_property(self, m):
        # type: (_DispMemberSpec) -> property
            return obj.Invoke(memid, _invkind=2) # DISPATCH_PROPERTYGET
    def _make_disp_method(self, m):
        # type: (_DispMemberSpec) -> Callable[..., Any]
                return obj.Invoke(memid, _invkind=2, *args, **kw) # DISPATCH_PROPERTYGET
                return obj.Invoke(memid, _invkind=4, *args, **kw) # DISPATCH_PROPERTYPUT
                return obj.Invoke(memid, _invkind=8, *args, **kw) # DISPATCH_PROPERTYPUTREF
            return obj.Invoke(memid, _invkind=1, *args, **kw) # DISPATCH_METHOD
        """""" Explicitly disallow iteration. """"""
        PTR = _coclass_pointer_meta(""POINTER(%s)"" % klass.__name__,
                                    (klass, c_void_p),
                                    {""__ctypes_from_outparam__"": _wrap_coclass,
                                     ""from_param"": classmethod(_coclass_from_param),
                                     })
    """""" Class encapsulating all the functionality necessary to allow interop of
        """""" Create a dtype for VARIANT. This requires support for Unions, which
        ptr_typecode = '<u8' if is_64bits else '<u4'
            ('pvRecord', ptr_typecode),
            ('pRecInfo', ptr_typecode),
                'VT_BOOL', 'VT_I1', 'VT_I2', 'VT_I4', 'VT_I8', 'VT_INT',
                'VT_UI1', 'VT_UI2', 'VT_UI4', 'VT_UI8', 'VT_UINT', 'VT_R4',
                'VT_R8', 'VT_CY', 'c_wchar_p', 'c_void_p', 'pparray',
                'bstrVal', '_tagBRECORD',
                '<i2', '<i1', '<i2', '<i4', '<i8', '<i4', '<u1', '<u2', '<u4',
                '<u8', '<u4', '<f4', '<f8', '<i8', ptr_typecode, ptr_typecode,
                ptr_typecode, ptr_typecode, _tagBRECORD_format,
            offsets=[0] * 19  # This is what makes it a union
            (""vt"", '<u2'),
            (""wReserved1"", '<u2'),
            (""wReserved2"", '<u2'),
            (""wReserved3"", '<u2'),
        """""" Check if a value is an ndarray.
        """""" Check if a value is a datetime64.
        """""" The numpy package.
        """"""
        """""" Enables numpy/comtypes interop.
        """"""
##if __debug__:
##    from ctypeslib.dynamic_module import include
##    include(""""""\
##    #define UNICODE
##    #define NO_STRICT
##    #include <windows.h>
##    """""",
##            persist=True)
        ('cElements', DWORD),
        ('lLbound', LONG),
]
        ('cDims', USHORT),
        ('fFeatures', USHORT),
        ('cbElements', DWORD),
        ('cLocks', DWORD),
        ('pvData', PVOID),
        ('rgsabound', SAFEARRAYBOUND * 1),
        ]

from comtypes import (
    BSTR, COMError, COMMETHOD, GUID, IID, IUnknown, STDMETHOD, TYPE_CHECKING,
from ctypes.wintypes import DWORD, LONG, UINT, VARIANT_BOOL, WCHAR, WORD

if TYPE_CHECKING:
    from typing import (
        Any, Callable, ClassVar, List, Optional, Tuple, Union as _UnionT,
    )
    from comtypes import hints


if sys.version_info >= (3, 0):
    int_types = (int, )
    str_types = (str, )
    base_text_type = str
else:
    int_types = (int, long)
    str_types = (unicode, str)
    base_text_type = basestring
VARENUM = c_int # enum
    _fields_ = [(""wReserved"", c_ushort),
                (""scale"", c_ubyte),
                (""sign"", c_ubyte),
                (""Hi32"", c_ulong),
                (""Lo64"", c_ulonglong)]
        """""" Convert a tagDEC struct to Decimal.
            '-' if self.sign else '',
        vt = hints.AnnoField()  # type: int
        _ = hints.AnnoField()  # type: U_VARIANT1.__tagVARIANT.U_VARIANT2
        null = hints.AnnoField()  # type: ClassVar[VARIANT]
        empty = hints.AnnoField()  # type: ClassVar[VARIANT]
        missing = hints.AnnoField()  # type: ClassVar[VARIANT]
                    _fields_ = [(""pvRecord"", c_void_p),
                                (""pRecInfo"", POINTER(IUnknown))]

                    ]
            _fields_ = [(""vt"", VARTYPE),
                        (""wReserved1"", c_ushort),
                        (""wReserved2"", c_ushort),
                        (""wReserved3"", c_ushort),
                        (""_"", U_VARIANT2)
        _fields_ = [(""__VARIANT_NAME_2"", __tagVARIANT),
                    (""decVal"", DECIMAL)]
        elif (hasattr(value, '__len__') and len(value) == 0
                and not isinstance(value, base_text_type)):
        elif isinstance(value, int_types):
        elif isinstance(value, str_types):
            com_days = delta.days + (delta.seconds + delta.microseconds * 1e-6) / 86400.
            com_days /= comtypes.npsupport.numpy.timedelta64(1, 'D')
                return None # XXX?
                return None # XXX?
        if self.vt == VT_BYREF|VT_VARIANT:

# these are missing:
##    getter[VT_ERROR]
##    getter[VT_ARRAY]
##    getter[VT_BYREF|VT_UI1]
##    getter[VT_BYREF|VT_I2]
##    getter[VT_BYREF|VT_I4]
##    getter[VT_BYREF|VT_R4]
##    getter[VT_BYREF|VT_R8]
##    getter[VT_BYREF|VT_BOOL]
##    getter[VT_BYREF|VT_ERROR]
##    getter[VT_BYREF|VT_CY]
##    getter[VT_BYREF|VT_DATE]
##    getter[VT_BYREF|VT_BSTR]
##    getter[VT_BYREF|VT_UNKNOWN]
##    getter[VT_BYREF|VT_DISPATCH]
##    getter[VT_BYREF|VT_ARRAY]
##    getter[VT_BYREF|VT_VARIANT]
##    getter[VT_BYREF]
##    getter[VT_BYREF|VT_DECIMAL]
##    getter[VT_BYREF|VT_I1]
##    getter[VT_BYREF|VT_UI2]
##    getter[VT_BYREF|VT_UI4]
##    getter[VT_BYREF|VT_INT]
##    getter[VT_BYREF|VT_UINT]
        _VariantChangeType(self,
                           self,
                           0,
                           typecode)
    _iid_ = GUID('{00020404-0000-0000-C000-000000000046}')
    _idlflags_ = ['hidden']
    if sys.version_info >= (3, 0):
        def __next__(self):
            item, fetched = self.Next(1)
            if fetched:
                return item
            raise StopIteration
    else:
        def next(self):
            item, fetched = self.Next(1)
            if fetched:
                return item
            raise StopIteration
##        if isinstance(index, slice):
##            self.Skip(index.start or 0)
##            return self.Next(index.stop or sys.maxint)
        result = [v._get_value(dynamic=self._dynamic) for v in array[:fetched.value]]
    COMMETHOD([], HRESULT, 'Next',
              ( ['in'], c_ulong, 'celt' ),
              ( ['out'], POINTER(VARIANT), 'rgvar' ),
              ( ['out'], POINTER(c_ulong), 'pceltFetched' )),
    COMMETHOD([], HRESULT, 'Skip',
              ( ['in'], c_ulong, 'celt' )),
    COMMETHOD([], HRESULT, 'Reset'),
    COMMETHOD([], HRESULT, 'Clone',
              ( ['out'], POINTER(POINTER(IEnumVARIANT)), 'ppenum' )),
        wCode = hints.AnnoField()  # type: int
        wReserved = hints.AnnoField()  # type: int
        bstrSource = hints.AnnoField()  # type: str
        bstrDescription = hints.AnnoField()  # type: str
        bstrHelpFile = hints.AnnoField()  # type: str
        dwHelpContext = hints.AnnoField()  # type: int
        pvReserved = hints.AnnoField()  # type: Optional[int]
        pfnDeferredFillIn = hints.AnnoField()  # type: Optional[int]
        scode = hints.AnnoField()  # type: int
        return ""<EXCEPINFO %s>"" % \
               ((self.wCode, self.bstrSource, self.bstrDescription, self.bstrHelpFile, self.dwHelpContext,
                self.pfnDeferredFillIn, self.scode),)
    ('wCode', WORD),
    ('wReserved', WORD),
    ('bstrSource', BSTR),
    ('bstrDescription', BSTR),
    ('bstrHelpFile', BSTR),
    ('dwHelpContext', DWORD),
    ('pvReserved', c_void_p),
##    ('pfnDeferredFillIn', WINFUNCTYPE(HRESULT, POINTER(tagEXCEPINFO))),
    ('pfnDeferredFillIn', c_void_p),
    ('scode', SCODE),
        rgvarg = hints.AnnoField()  # type: Array[VARIANT]
        rgdispidNamedArgs = hints.AnnoField()  # type: _Pointer[DISPID]
        cArgs = hints.AnnoField()  # type: int
        cNamedArgs = hints.AnnoField()  # type: int
        ('rgvarg', POINTER(VARIANTARG)),
        ('rgdispidNamedArgs', POINTER(DISPID)),
        ('cArgs', UINT),
        ('cNamedArgs', UINT),
if TYPE_CHECKING:
    RawGetIDsOfNamesFunc = Callable[
        [_byref_type, Array[c_wchar_p], int, int, Array[DISPID]], int,
    ]
    RawInvokeFunc = Callable[
        [
            int, _byref_type, int, int,  # dispIdMember, riid, lcid, wFlags
            _UnionT[_byref_type, DISPPARAMS],  # *pDispParams
            _UnionT[_byref_type, VARIANT],  # pVarResult
            _UnionT[_byref_type, EXCEPINFO, None],  # pExcepInfo
            _UnionT[_byref_type, c_uint],  # puArgErr
        ],
        int
    ]
    if TYPE_CHECKING:
        _disp_methods_ = hints.AnnoField()  # type: ClassVar[List[comtypes._DispMemberSpec]]
        _GetTypeInfo = hints.AnnoField()  # type: Callable[[int, int], IUnknown]
        __com_GetIDsOfNames = hints.AnnoField()  # type: RawGetIDsOfNamesFunc
        __com_Invoke = hints.AnnoField()  # type: RawInvokeFunc
        COMMETHOD([], HRESULT, 'GetTypeInfoCount',
                  (['out'], POINTER(UINT) ) ),
        COMMETHOD([], HRESULT, 'GetTypeInfo',
                  (['in'], UINT, 'index'),
                  (['in'], LCID, 'lcid', 0),
                # Normally, we would declare this parameter in this way:
                # (['out'], POINTER(POINTER(ITypeInfo)) ) ),
                # but we cannot import comtypes.typeinfo at the top level (recursive imports!).
                  (['out'], POINTER(POINTER(IUnknown)) ) ),
        STDMETHOD(HRESULT, 'GetIDsOfNames', [POINTER(IID), POINTER(c_wchar_p),
                                             UINT, LCID, POINTER(DISPID)]),
        STDMETHOD(HRESULT, 'Invoke', [DISPID, POINTER(IID), LCID, WORD,
                                      POINTER(DISPPARAMS), POINTER(VARIANT),
                                      POINTER(EXCEPINFO), POINTER(UINT)]),
    def GetTypeInfo(self, index, lcid=0):
        # type: (int, int) -> hints.ITypeInfo
    def GetIDsOfNames(self, *names, **kw):
        # type: (str, Any) -> List[int]
    def _invoke(self, memid, invkind, lcid, *args):
        # type: (int, int, int, Any) -> Any
        self.__com_Invoke(memid, riid_null, lcid, invkind,
                          dp, var, None, argerr)
    def Invoke(self, dispid, *args, **kw):
        # type: (int, Any, Any) -> Any
        _invkind = kw.pop(""_invkind"", 1) # DISPATCH_METHOD


        if _invkind in (DISPATCH_PROPERTYPUT, DISPATCH_PROPERTYPUTREF): # propput
            array = (VARIANT * len(args))()

            for i, a in enumerate(args[::-1]):
                array[i].value = a

            dp = DISPPARAMS()
            dp.cArgs = len(args)
            dp.cNamedArgs = 1
            dp.rgvarg = array
            dp.rgdispidNamedArgs = pointer(DISPID(DISPID_PROPERTYPUT))
        else:
            array = (VARIANT * len(args))()

            for i, a in enumerate(args[::-1]):
                array[i].value = a

            dp = DISPPARAMS()
            dp.cArgs = len(args)
            dp.cNamedArgs = 0
            dp.rgvarg = array

            self.__com_Invoke(dispid, riid_null, _lcid, _invkind, byref(dp),
                              byref(result), byref(excepinfo), byref(argerr))
                details = (excepinfo.bstrDescription, excepinfo.bstrSource,
                           excepinfo.bstrHelpFile, excepinfo.dwHelpContext,
                           excepinfo.scode)
                raise COMError(hresult, text,
                               (""TypeError: Parameter %s"" % (argerr.value + 1),
                                args))
    }







    POINTER(VARIANT): VT_BYREF|VT_VARIANT,

    POINTER(BSTR): VT_BYREF|VT_BSTR,

##    POINTER(IUnknown): VT_UNKNOWN,
##    POINTER(IDispatch): VT_DISPATCH,
    }

    'CURRENCY', 'CY', 'tagCY', 'DECIMAL', 'tagDEC', 'DISPATCH_METHOD',
    'DISPATCH_PROPERTYGET', 'DISPATCH_PROPERTYPUT', 'DISPATCH_PROPERTYPUTREF',
    'DISPID', 'DISPID_COLLECT', 'DISPID_CONSTRUCTOR', 'DISPID_DESTRUCTOR',
    'DISPID_EVALUATE', 'DISPID_NEWENUM', 'DISPID_PROPERTYPUT',
    'DISPID_UNKNOWN', 'DISPID_VALUE', 'DISPPARAMS', 'tagDISPPARAMS',
    'EXCEPINFO', 'tagEXCEPINFO', 'IDispatch', 'IEnumVARIANT', 'IID_NULL',
    'INVOKE_FUNC', 'INVOKE_PROPERTYGET', 'INVOKE_PROPERTYPUT',
    'INVOKE_PROPERTYPUTREF', 'INVOKEKIND', 'tagINVOKEKIND', '_midlSAFEARRAY',
    'SCODE', '_SysAllocStringLen', 'VARENUM', 'VARIANT','tagVARIANT', 
    'VARIANTARG', '_VariantChangeType', '_VariantClear', '_VariantCopy',
    '_VariantCopyInd', 'VARTYPE', 'VT_ARRAY', 'VT_BLOB', 'VT_BLOB_OBJECT',
    'VT_BOOL', 'VT_BSTR', 'VT_BSTR_BLOB', 'VT_BYREF', 'VT_CARRAY', 'VT_CF',
    'VT_CLSID', 'VT_CY', 'VT_DATE', 'VT_DECIMAL', 'VT_DISPATCH', 'VT_EMPTY',
    'VT_ERROR', 'VT_FILETIME', 'VT_HRESULT', 'VT_I1', 'VT_I2', 'VT_I4',
    'VT_I8', 'VT_ILLEGAL', 'VT_ILLEGALMASKED', 'VT_INT', 'VT_INT_PTR',
    'VT_LPSTR', 'VT_LPWSTR', 'VT_NULL', 'VT_PTR', 'VT_R4', 'VT_R8',
    'VT_RECORD', 'VT_RESERVED', 'VT_SAFEARRAY', 'VT_STORAGE',
    'VT_STORED_OBJECT', 'VT_STREAM', 'VT_STREAMED_OBJECT', 'VT_TYPEMASK',
    'VT_UI1', 'VT_UI2', 'VT_UI4', 'VT_UI8', 'VT_UINT', 'VT_UINT_PTR',
    'VT_UNKNOWN', 'VT_USERDEFINED', 'VT_VARIANT', 'VT_VECTOR',
    'VT_VERSIONED_STREAM', 'VT_VOID',
'''comtypes.client - High level client level COM support package.
'''
from comtypes import (
    automation, CoClass, GUID, IUnknown, TYPE_CHECKING, typeinfo,
)
if TYPE_CHECKING:
    from typing import Any, Optional, overload, Type, TypeVar, Union as _UnionT
    from comtypes import hints
    _T_IUnknown = TypeVar(""_T_IUnknown"", bound=IUnknown)

def wrap_outparam(punk):
    # type: (Any) -> Any
def GetBestInterface(punk):
    # type: (Any) -> Any
    if not punk: # NULL COM pointer
        return punk # or should we return None?
            logger.debug(""Does NOT implement IProvideClassInfo, trying IProvideClassInfo2"")
        tinfo = pci.GetClassInfo() # TypeInfo for the CoClass
    itf_name = tinfo.GetDocumentation(-1)[0] # interface name
    tlib = tinfo.GetContainingTypeLib()[0] # typelib
if comtypes.TYPE_CHECKING:
    @overload
    def GetActiveObject(progid):
        # type: (_UnionT[str, CoClass, GUID]) -> Any
        pass
    @overload
    def GetActiveObject(progid, interface):
        # type: (_UnionT[str, CoClass, GUID], Type[_T_IUnknown]) -> _T_IUnknown
        pass
def GetActiveObject(progid, interface=None, dynamic=False):
    # type: (_UnionT[str, CoClass, GUID], Optional[Any], bool) -> Any
def _manage(obj, clsid, interface):
    # type: (Any, Optional[GUID], Optional[Type[IUnknown]]) -> Any
    obj.__dict__['__clsid'] = str(clsid)
def GetClassObject(progid,
                   clsctx=None,
                   pServerInfo=None,
                   interface=None):
if TYPE_CHECKING:
    @overload
    def CreateObject(progid):
        # type: (_UnionT[str, CoClass, GUID]) -> Any
        pass
    @overload
    def CreateObject(progid, clsctx=None, machine=None, interface=None, dynamic=False, pServerInfo=None):
        # type: (_UnionT[str, CoClass, GUID], Optional[int], Optional[str], Optional[Type[_T_IUnknown]], bool, Optional[comtypes.COSERVERINFO]) -> _T_IUnknown
        pass
def CreateObject(progid,                  # which object to create
                 clsctx=None,             # how to create the object
                 machine=None,            # where to create the object
                 interface=None,          # the interface we want
                 dynamic=False,           # use dynamic dispatch
                 pServerInfo=None):       # server info struct for remoting
    # type: (_UnionT[str, CoClass, GUID], Optional[int], Optional[str], Optional[Type[IUnknown]], bool, Optional[comtypes.COSERVERINFO]) -> Any
        logger.debug(""CoCreateInstance(%s, clsctx=%s, interface=%s)"",
                     clsid, clsctx, interface)
        logger.debug(""CoCreateInstanceEx(%s, clsctx=%s, interface=%s, machine=%s,\
                     clsid, clsctx, interface, machine, pServerInfo)
            msg = ""You can notset both the machine name and server info.""
        obj = comtypes.CoCreateInstanceEx(clsid, clsctx=clsctx,
                interface=interface, machine=machine, pServerInfo=pServerInfo)
if TYPE_CHECKING:
    @overload
    def CoGetObject(displayname, interface):
        # type: (str, Type[_T_IUnknown]) -> _T_IUnknown
        pass
    @overload
    def CoGetObject(displayname, interface=None, dynamic=False):
        # type: (str, None, bool) -> Any
        pass
def CoGetObject(displayname, interface=None, dynamic=False):
    # type: (str, Optional[Type[comtypes.IUnknown]], bool) -> Any
    return _manage(punk,
                   clsid=None,
                   interface=interface)
        else: # ftype in ('windows_exe', 'console_exe')
SHGetSpecialFolderPath.argtypes = [ctypes.c_ulong, ctypes.c_wchar_p,
                                   ctypes.c_int, ctypes.c_int]
if sys.version_info >= (3, 0):
    base_text_type = str
else:
    base_text_type = basestring

        if isinstance(obj, base_text_type):
    clsid = source.__dict__.get('__clsid')
##    interface = find_single_connection_interface(source)
##    if interface:
##        return interface
    if func.__code__.co_varnames[:2] == ('self', 'this'):
            return comtypes.instancemethod(method,
                                           im_self,
                                           type(im_self))
def CreateEventReceiver(interface, handler):
    if issubclass(interface, comtypes.automation.IDispatch) \
           and not hasattr(sink, ""_dispimpl_""):
##    @ctypes.WINFUNCTYPE(ctypes.c_int, ctypes.c_uint)
        if dwCtrlType == 0: # CTRL+C
            res = ctypes.oledll.ole32.CoWaitForMultipleHandles(0,
                                                               int(timeout * 1000),
                                                               len(handles), handles,
                                                               ctypes.byref(ctypes.c_ulong()))
            if details.winerror != RPC_S_CALLPENDING: # timeout expired
if sys.version_info >= (3, 0):
    base_text_type = str
    import winreg
else:
    base_text_type = basestring
    import _winreg as winreg

from comtypes import GUID, TYPE_CHECKING, typeinfo
if TYPE_CHECKING:
    from typing import Any, Tuple, List, Optional, Dict, Union as _UnionT

def _my_import(fullname):
    # type: (str) -> types.ModuleType
def _resolve_filename(tlib_string, dirpath):
    # type: (str, str) -> Tuple[str, bool]
    assert isinstance(tlib_string, base_text_type)
def GetModule(tlib):
    # type: (_UnionT[Any, typeinfo.ITypeLib]) -> types.ModuleType
    if isinstance(tlib, base_text_type):
        _file_ = frame.f_globals.get(""__file__"", None)  # type: str
        pathname, is_abs = _resolve_filename(tlib_string, _file_ and os.path.dirname(_file_))
        assert not(os.path.isabs(pathname)) or os.path.exists(pathname)
    # create and import the real typelib wrapper module
    mod = _create_wrapper_module(tlib, pathname)
    # try to get the friendly-name, if not, returns the real typelib wrapper module
    modulename = codegenerator.name_friendly_module(tlib)
    if modulename is None:
        return mod
    if sys.version_info < (3, 0):
        modulename = modulename.encode(""mbcs"")
    # create and import the friendly-named module
    return _create_friendly_module(tlib, modulename)


def _load_tlib(obj):
    # type: (Any) -> typeinfo.ITypeLib
    if isinstance(obj, base_text_type):
        with winreg.OpenKey(winreg.HKEY_CLASSES_ROOT, r""CLSID\%s\TypeLib"" % clsid) as key:
        with winreg.OpenKey(winreg.HKEY_CLASSES_ROOT, r""CLSID\%s\Version"" % clsid) as key:
def _create_module_in_file(modulename, code):
    # type: (str, str) -> types.ModuleType
def _create_module_in_memory(modulename, code):
    # type: (str, str) -> types.ModuleType
def _create_friendly_module(tlib, modulename):
    # type: (typeinfo.ITypeLib, str) -> types.ModuleType
    """"""helper which creates and imports the friendly-named module.""""""
    try:
        mod = _my_import(modulename)
    except Exception as details:
        logger.info(""Could not import %s: %s"", modulename, details)
    else:
        return mod
    # the module is always regenerated if the import fails
    logger.info(""# Generating %s"", modulename)
    # determine the Python module name
    modname = codegenerator.name_wrapper_module(tlib).split(""."")[-1]
    code = ""from comtypes.gen import %s\n"" % modname
    code += ""globals().update(%s.__dict__)\n"" % modname
    code += ""__name__ = '%s'"" % modulename
    if comtypes.client.gen_dir is None:
        return _create_module_in_memory(modulename, code)
    return _create_module_in_file(modulename, code)


def _create_wrapper_module(tlib, pathname):
    # type: (typeinfo.ITypeLib, Optional[str]) -> types.ModuleType
    """"""helper which creates and imports the real typelib wrapper module.""""""
    modulename = codegenerator.name_wrapper_module(tlib)
    if modulename in sys.modules:
        return sys.modules[modulename]
    try:
        return _my_import(modulename)
    except Exception as details:
        logger.info(""Could not import %s: %s"", modulename, details)
    # generate the module since it doesn't exist or is out of date
    logger.info(""# Generating %s"", modulename)
    p = tlbparser.TypeLibParser(tlib)
    if pathname is None:
        pathname = tlbparser.get_tlib_filename(tlib)
    items = list(p.parse().values())
    codegen = codegenerator.CodeGenerator(_get_known_symbols())
    code = codegen.generate_code(items, filename=pathname)
    for ext_tlib in codegen.externals:  # generates dependency COM-lib modules
        GetModule(ext_tlib)
    if comtypes.client.gen_dir is None:
        return _create_module_in_memory(modulename, code)
    return _create_module_in_file(modulename, code)


def _get_known_symbols():
    # type: () -> Dict[str, str]
    known_symbols = {}  # type: Dict[str, str]
        ""ctypes""
            names = mod.__known_symbols__  # type: List[str]
import sys
import comtypes.automation
import comtypes.typeinfo
import comtypes.client
import comtypes.client.lazybind
from comtypes import COMError, IUnknown, _is_object
import comtypes.hresult as hres
    # Wrap an object in a Dispatch instance, exposing methods and properties
    # via fully dynamic dispatch
    if isinstance(obj, ctypes.POINTER(comtypes.automation.IDispatch)):
        except (comtypes.COMError, WindowsError):
        return comtypes.client.lazybind.Dispatch(obj, tinfo)
    def __init__(self, _id, _obj):
    def __call__(self, *args):
    def __getitem__(self, *args):
        return self._obj._comobj.Invoke(self._id, *args,
                                        **dict(_invkind=comtypes.automation.DISPATCH_PROPERTYGET))
    def __setitem__(self, *args):
            self._obj._comobj.Invoke(self._id, *args,
                                        **dict(_invkind=comtypes.automation.DISPATCH_PROPERTYPUTREF))
            self._obj._comobj.Invoke(self._id, *args,
                                        **dict(_invkind=comtypes.automation.DISPATCH_PROPERTYPUT))
    # Expose methods and properties via fully dynamic dispatch
    def __init__(self, comobj):
        self.__dict__[""_ids""] = {} # Tiny optimization: trying not to use GetIDsOfNames more than once
    def __enum(self):
        e = self._comobj.Invoke(-4) # DISPID_NEWENUM
        return e.QueryInterface(comtypes.automation.IEnumVARIANT)

    def __cmp__(self, other):
        if not isinstance(other, _Dispatch):
            return 1
        return cmp(self._comobj, other._comobj)
    def __hash__(self):
    def __getitem__(self, index):
    def QueryInterface(self, *args):
        ""QueryInterface is forwarded to the real com object.""
        return self._comobj.QueryInterface(*args)
    def _FlagAsMethod(self, *names):
    def __getattr__(self, name):
##        tc = self._comobj.GetTypeInfo(0).QueryInterface(comtypes.typeinfo.ITypeComp)
##        dispid = tc.Bind(name)[1].memid
        flags = comtypes.automation.DISPATCH_PROPERTYGET
            (hresult, text, details) = err.args
                # The line break is important for 2to3 to work correctly
                raise
        except:
            # The line break is important for 2to3 to work correctly
            raise
    def __setattr__(self, name, value):
    def __iter__(self):
##    def __setitem__(self, index, value):
##        self._comobj.Invoke(-3, index, value,
##                            _invkind=comtypes.automation.DISPATCH_PROPERTYPUT|comtypes.automation.DISPATCH_PROPERTYPUTREF)
    def __init__(self, enum):
    if sys.version_info >= (3, 0):
        def __next__(self):
            item, fetched = self.enum.Next(1)
            if fetched:
                return item
            raise StopIteration
    else:
        def next(self):
            item, fetched = self.enum.Next(1)
            if fetched:
                return item
            raise StopIteration
            return self.disp._comobj._invoke(self.get.memid,
                                             self.get.invkind,
                                             0,
                                             *arg)
            return self.disp._comobj._invoke(self.get.memid,
                                             self.get.invkind,
                                             0)
        return self.disp._comobj._invoke(self.get.memid,
                                         self.get.invkind,
                                         0,
                                         *[arg])
        return self.disp._comobj._invoke(self.get.memid,
                                            self.get.invkind,
                                            0,
                                            *args)
            self.disp._comobj._invoke(descr.memid,
                                      descr.invkind,
                                      0,
                                      *(name + (value,)))
            self.disp._comobj._invoke(descr.memid,
                                      descr.invkind,
                                      0,
                                      value)
            self.disp._comobj._invoke(descr.memid,
                                      descr.invkind,
                                      0,
                                      name,
                                      value)
        """""" Explicitly disallow iteration. """"""
##        self.__dict__[""_iid""] = tinfo.GetTypeAttr().guid
                info = FuncDesc(memid=descr.memid,
                                invkind=descr.invkind,
                                cParams=descr.cParams,
                                funckind=descr.funckind)
        return isinstance(other, Dispatch) and \
               self._comobj == other._comobj
        return self._comobj._invoke(DISPID_VALUE,
                                    DISPATCH_METHOD | DISPATCH_PROPERTYGET,
                                    0,
                                    *args)
            return self._comobj._invoke(DISPID_VALUE,
                                        DISPATCH_METHOD | DISPATCH_PROPERTYGET,
                                        0,
                                        *args)
        return self._comobj._invoke(DISPID_VALUE,
                                    invkind,
                                    0,
                                    *args)
        punk = self._comobj._invoke(DISPID_NEWENUM,
                                    DISPATCH_METHOD | DISPATCH_PROPERTYGET,
                                    0)
        ('pUnk', POINTER(IUnknown)),
        ('dwCookie', c_ulong),
    _iid_ = GUID('{B196B284-BAB4-101A-B69C-00AA00341D07}')
    _iid_ = GUID('{B196B286-BAB4-101A-B69C-00AA00341D07}')
    _iid_ = GUID('{B196B287-BAB4-101A-B69C-00AA00341D07}')
    if sys.version_info >= (3, 0):
        def __next__(self):
            cp, fetched = self.Next(1)
            if fetched == 0:
                raise StopIteration
            return cp
    else:
        def next(self):
            cp, fetched = self.Next(1)
            if fetched == 0:
                raise StopIteration
            return cp
    _iid_ = GUID('{B196B285-BAB4-101A-B69C-00AA00341D07}')
    if sys.version_info >= (3, 0):
        def __next__(self):
            cp, fetched = self.Next(1)
            if fetched == 0:
                raise StopIteration
            return cp
    else:
        def next(self):
            cp, fetched = self.Next(1)
            if fetched == 0:
                raise StopIteration
            return cp
    COMMETHOD([], HRESULT, 'EnumConnectionPoints',
              ( ['out'], POINTER(POINTER(IEnumConnectionPoints)), 'ppEnum' )),
    COMMETHOD([], HRESULT, 'FindConnectionPoint',
              ( ['in'], POINTER(_GUID), 'riid' ),
              ( ['out'], POINTER(POINTER(IConnectionPoint)), 'ppCP' )),
    COMMETHOD([], HRESULT, 'GetConnectionInterface',
              ( ['out'], POINTER(_GUID), 'pIID' )),
    COMMETHOD([], HRESULT, 'GetConnectionPointContainer',
              ( ['out'], POINTER(POINTER(IConnectionPointContainer)), 'ppCPC' )),
    COMMETHOD([], HRESULT, 'Advise',
              ( ['in'], POINTER(IUnknown), 'pUnkSink' ),
              ( ['out'], POINTER(c_ulong), 'pdwCookie' )),
    COMMETHOD([], HRESULT, 'Unadvise',
              ( ['in'], c_ulong, 'dwCookie' )),
    COMMETHOD([], HRESULT, 'EnumConnections',
              ( ['out'], POINTER(POINTER(IEnumConnections)), 'ppEnum' )),
    COMMETHOD([], HRESULT, 'Next',
              ( ['in'], c_ulong, 'cConnections' ),
              ( ['out'], POINTER(tagCONNECTDATA), 'rgcd' ),
              ( ['out'], POINTER(c_ulong), 'pcFetched' )),
    COMMETHOD([], HRESULT, 'Skip',
              ( ['in'], c_ulong, 'cConnections' )),
    COMMETHOD([], HRESULT, 'Reset'),
    COMMETHOD([], HRESULT, 'Clone',
              ( ['out'], POINTER(POINTER(IEnumConnections)), 'ppEnum' )),
    COMMETHOD([], HRESULT, 'Next',
              ( ['in'], c_ulong, 'cConnections' ),
              ( ['out'], POINTER(POINTER(IConnectionPoint)), 'ppCP' ),
              ( ['out'], POINTER(c_ulong), 'pcFetched' )),
    COMMETHOD([], HRESULT, 'Skip',
              ( ['in'], c_ulong, 'cConnections' )),
    COMMETHOD([], HRESULT, 'Reset'),
    COMMETHOD([], HRESULT, 'Clone',
              ( ['out'], POINTER(POINTER(IEnumConnectionPoints)), 'ppEnum' )),
if sys.version_info >= (3, 0):
    base_text_type = str
else:
    base_text_type = basestring
        COMMETHOD([], HRESULT, 'SetGUID',
                  (['in'], POINTER(GUID), ""rguid"")),
        COMMETHOD([], HRESULT, 'SetSource',
                  (['in'], LPCOLESTR, ""szSource"")),
        COMMETHOD([], HRESULT, 'SetDescription',
                  (['in'], LPCOLESTR, ""szDescription"")),
        COMMETHOD([], HRESULT, 'SetHelpFile',
                  (['in'], LPCOLESTR, ""szHelpFile"")),
        COMMETHOD([], HRESULT, 'SetHelpContext',
                  (['in'], DWORD, ""dwHelpContext""))
        ]
        COMMETHOD([], HRESULT, 'GetGUID',
                  (['out'], POINTER(GUID), ""pGUID"")),
        COMMETHOD([], HRESULT, 'GetSource',
                  (['out'], POINTER(BSTR), ""pBstrSource"")),
        COMMETHOD([], HRESULT, 'GetDescription',
                  (['out'], POINTER(BSTR), ""pBstrDescription"")),
        COMMETHOD([], HRESULT, 'GetHelpFile',
                  (['out'], POINTER(BSTR), ""pBstrHelpFile"")),
        COMMETHOD([], HRESULT, 'GetHelpContext',
                  (['out'], POINTER(DWORD), ""pdwHelpContext"")),
        ]
        COMMETHOD([], HRESULT, 'InterfaceSupportsErrorInfo',
                  (['in'], POINTER(GUID), 'riid'))
        ]
def ReportError(text, iid,
                clsid=None, helpfile=None, helpcontext=0, hresult=DISP_E_EXCEPTION):
        if isinstance(clsid, base_text_type):
            ei.SetSource(progid) # progid for the class or application that created the error
def ReportException(hresult, iid, clsid=None, helpfile=None, helpcontext=None,
                    stacklevel=None):
    return ReportError(text, iid,
                       clsid=clsid, helpfile=helpfile, helpcontext=helpcontext,
                       hresult=hresult)
__all__ = [""ICreateErrorInfo"", ""IErrorInfo"", ""ISupportErrorInfo"",
           ""ReportError"", ""ReportException"",
           ""SetErrorInfo"", ""GetErrorInfo"", ""CreateErrorInfo""]
from comtypes import IUnknown, STDMETHOD, COMMETHOD, \
     GUID, HRESULT, CoCreateInstance, CLSCTX_INPROC_SERVER
        STDMETHOD(HRESULT, ""RegisterInterfaceInGlobal"",
                  [POINTER(IUnknown), POINTER(GUID), POINTER(DWORD)]),
        STDMETHOD(HRESULT, ""GetInterfaceFromGlobal"",
                  [DWORD, POINTER(GUID), POINTER(POINTER(IUnknown))]),
        ]
git = CoCreateInstance(CLSID_StdGlobalInterfaceTable,
                       interface=IGlobalInterfaceTable,
                       clsctx=CLSCTX_INPROC_SERVER)
__all__ = [""RegisterInterfaceInGlobal"", ""RevokeInterfaceFromGlobal"", ""GetInterfaceFromGlobal""]
    tlib = CreateTypeLib(""foo.bar"") # we don not save it later
E_UNEXPECTED = -2147418113 #0x8000FFFFL
E_NOTIMPL = -2147467263 #0x80004001L
E_NOINTERFACE = -2147467262 #0x80004002L
E_POINTER = -2147467261 #0x80004003L
E_FAIL = -2147467259 #0x80004005L
E_INVALIDARG = -2147024809 #0x80070057L
E_OUTOFMEMORY = -2147024882 # 0x8007000EL
CLASS_E_NOAGGREGATION = -2147221232 #0x80040110L
CLASS_E_CLASSNOTAVAILABLE = -2147221231 #0x80040111L
CO_E_CLASSSTRING = -2147221005 #0x800401F3L
TYPE_E_ELEMENTNOTFOUND = -2147352077 #0x8002802BL
TYPE_E_REGISTRYACCESS = -2147319780 #0x8002801CL
TYPE_E_CANTLOADLIBRARY = -2147312566 #0x80029C4AL
DISP_E_PARAMNOTOPTIONAL = -2147352561 #0x8002000F
DISP_E_BADPARAMCOUNT = -2147352562 #0x8002000E
DISP_E_ARRAYISLOCKED = -2147352563 #0x8002000D
DISP_E_UNKNOWNLCID = -2147352564 #0x8002000C
DISP_E_BADINDEX = -2147352565 #0x8002000B
DISP_E_OVERFLOW = -2147352566 #0x8002000A
DISP_E_EXCEPTION = -2147352567 #0x80020009
DISP_E_BADVARTYPE = -2147352568 #0x80020008
DISP_E_NONAMEDARGS = -2147352569 #0x80020007
DISP_E_UNKNOWNNAME = -2147352570 #0x80020006
DISP_E_TYPEMISMATCH = -2147352571 #0800020005
DISP_E_PARAMNOTFOUND = -2147352572 #0x80020004
DISP_E_MEMBERNOTFOUND = -2147352573 #0x80020003
DISP_E_UNKNOWNINTERFACE = -2147352575 #0x80020001

RPC_E_CHANGED_MODE = -2147417850 # 0x80010106
RPC_E_SERVERFAULT = -2147417851 # 0x80010105
    def emit(self, record,
             writeA=ctypes.windll.kernel32.OutputDebugStringA,
             writeW=ctypes.windll.kernel32.OutputDebugStringW):
            writeW(text + u""\n"")
    parser.optionxform = str # use case sensitive option names!
    DEFAULTS = {""handler"": ""StreamHandler()"",
                ""format"": ""%(levelname)s:%(name)s:%(message)s"",
                ""level"": ""WARNING""}

                return # got WM_QUIT

            no_replace = getattr(value, '__no_replace', False)
    _iid_ = GUID('{3127CA40-446E-11CE-8135-00AA004BB851}')
        COMMETHOD([], HRESULT, 'AddError',
                  ( ['in'], WSTRING, 'pszPropName' ),
                  ( ['in'], POINTER(tagEXCEPINFO), 'pExcepInfo' )),
        ]
    _iid_ = GUID('{55272A00-42CB-11CE-8135-00AA004BB851}')
        COMMETHOD([], HRESULT, 'Read',
                  ( ['in'], WSTRING, 'pszPropName' ),
                  ( ['in', 'out'], POINTER(VARIANT), 'pVar' ),
                  ( ['in'], POINTER(IErrorLog), 'pErrorLog' )),
##                  ( ['in', 'out'], POINTER(IErrorLog), 'pErrorLog' )),
        COMMETHOD([], HRESULT, 'Write',
                  ( ['in'], WSTRING, 'pszPropName' ),
                  ( ['in'], POINTER(VARIANT), 'pVar' )),
        ]
    _iid_ = GUID('{37D84F60-42CB-11CE-8135-00AA004BB851}')
        COMMETHOD([], HRESULT, 'InitNew'),
        COMMETHOD([], HRESULT, 'Load',
                  ( ['in'], POINTER(IPropertyBag), 'pPropBag' ),
                  ( ['in'], POINTER(IErrorLog), 'pErrorLog' )),
        COMMETHOD([], HRESULT, 'Save',
                  ( ['in'], POINTER(IPropertyBag), 'pPropBag' ),
                  ( ['in'], c_int, 'fClearDirty' ),
                  ( ['in'], c_int, 'fSaveAllProperties' )),
        ]
        ('dwType', c_ulong),
        ('vt', c_ushort),
        ('cfType', CLIPFORMAT),
        ('dwHint', c_ulong),
        ('pstrName', WSTRING),
        ('clsid', GUID),
        ]
    _iid_ = GUID('{22F55882-280B-11D0-A8A9-00A0C90C2004}')
        COMMETHOD([], HRESULT, 'Read',
                  ( ['in'], c_ulong, 'cProperties' ),
                  ( ['in'], POINTER(tagPROPBAG2), 'pPropBag' ),
                  ( ['in'], POINTER(IErrorLog), 'pErrLog' ),
                  ( ['out'], POINTER(VARIANT), 'pvarValue' ),
                  ( ['out'], POINTER(HRESULT), 'phrError' )),
        COMMETHOD([], HRESULT, 'Write',
                  ( ['in'], c_ulong, 'cProperties' ),
                  ( ['in'], POINTER(tagPROPBAG2), 'pPropBag' ),
                  ( ['in'], POINTER(VARIANT), 'pvarValue' )),
        COMMETHOD([], HRESULT, 'CountProperties',
                  ( ['out'], POINTER(c_ulong), 'pcProperties' )),
        COMMETHOD([], HRESULT, 'GetPropertyInfo',
                  ( ['in'], c_ulong, 'iProperty' ),
                  ( ['in'], c_ulong, 'cProperties' ),
                  ( ['out'], POINTER(tagPROPBAG2), 'pPropBag' ),
                  ( ['out'], POINTER(c_ulong), 'pcProperties' )),
        COMMETHOD([], HRESULT, 'LoadObject',
                  ( ['in'], WSTRING, 'pstrName' ),
                  ( ['in'], c_ulong, 'dwHint' ),
                  ( ['in'], POINTER(IUnknown), 'punkObject' ),
                  ( ['in'], POINTER(IErrorLog), 'pErrLog' )),
        ]
    _iid_ = GUID('{22F55881-280B-11D0-A8A9-00A0C90C2004}')
        COMMETHOD([], HRESULT, 'InitNew'),
        COMMETHOD([], HRESULT, 'Load',
                  ( ['in'], POINTER(IPropertyBag2), 'pPropBag' ),
                  ( ['in'], POINTER(IErrorLog), 'pErrLog' )),
        COMMETHOD([], HRESULT, 'Save',
                  ( ['in'], POINTER(IPropertyBag2), 'pPropBag' ),
                  ( ['in'], c_int, 'fClearDirty' ),
                  ( ['in",buggy
"
def binary(obj):
    return bytes(obj)


    _fields_ = [(""Data1"", DWORD), (""Data2"", WORD), (""Data3"", WORD), (""Data4"", BYTE * 8)]
            _CLSIDFromString(str(name), byref(self))
        return 'GUID(""%s"")' % str(self)

        return isinstance(other, GUID) and binary(self) == binary(other)
        return GUID(str(self))
        """"""Get guid from progid, ...""""""
        elif isinstance(progid, str):
            _CLSIDFromProgID(str(progid), byref(inst))
from ctypes import _Pointer, _SimpleCData

try:
    from _ctypes import COMError
except ImportError as e:
    msg = ""\n"".join(
        (
            ""COM technology not available (maybe it's the wrong platform)."",
            ""Note that COM is only supported on Windows."",
            ""For more details, please check: ""
            ""https://learn.microsoft.com/en-us/windows/win32/com"",
        )
    )
    raise ImportError(msg) from e
# fmt: off
from typing import (
    Any, ClassVar, overload, TYPE_CHECKING, TypeVar,
    # instead of `builtins`. see PEP585
    Dict, List, Tuple, Type,
    # instead of `collections.abc`. see PEP585
    Callable, Iterable, Iterator,
    # instead of `A | B` and `None | A`. see PEP604
    Optional, Union as _UnionT,  # avoiding confusion with `ctypes.Union`
)
# fmt: on
    from comtypes import hints as hints  # type: ignore
else:
    _CData = _SimpleCData.__mro__[:-1][-1]
    ComMemberGenerator,
    _ComMemberSpec,
    DispMemberGenerator,
    _DispMemberSpec,
    _encode_idl,
    _resolve_argspec,





pythonapi.PyInstanceMethod_New.argtypes = [py_object]
pythonapi.PyInstanceMethod_New.restype = py_object
PyInstanceMethod_Type = type(pythonapi.PyInstanceMethod_New(id))


def instancemethod(func, inst, cls):
    mth = PyInstanceMethod_Type(func)
    if inst is None:
        return mth
    return mth.__get__(inst)


# class IDLWarning(UserWarning):
#    ""Warn about questionable type information""
tagCLSCTX = c_int  # enum
_ole32_nohresult = windll.ole32  # use this for functions that don't return a HRESULT
COINIT_MULTITHREADED = 0x0
COINIT_DISABLE_OLE1DDE = 0x4



def _shutdown(
    func=_ole32_nohresult.CoUninitialize,
    _debug=logger.debug,
    _exc_clear=getattr(sys, ""exc_clear"", lambda: None),
):
        try:
            func()
        except WindowsError:
            pass






    _case_insensitive_: bool
    _iid_: GUID
    _methods_: List[_ComMemberSpec]
    _disp_methods_: List[_DispMemberSpec]
        p = type(_compointer_base)(
            ""POINTER(%s)"" % new_cls.__name__,
            _ptr_bases,
            {""__com_interface__"": new_cls, ""_needs_com_addref_"": None},
        )

                    if fixed_name != name:  # prevent unbounded recursion
                    object.__setattr__(
                        self, self.__map_case__.get(name.lower(), name), value
                    )

            # assert self.__dict__.get(""_methods_"", None) is None




    def _make_dispmethods(self, methods: List[_DispMemberSpec]) -> None:
    def _make_methods(self, methods: List[_ComMemberSpec]) -> None:
            com_interface_registry[str(iid)] = self



class _compointer_base(c_void_p, metaclass=_compointer_meta):

        return cmp(
            super(_compointer_base, self).value, super(_compointer_base, other).value
        )
        return (
            super(_compointer_base, self).value == super(_compointer_base, other).value
        )




        if self._b_base_ is None or self._needsfree:


class helpstring(str):





def STDMETHOD(restype, name, argtypes=()) -> _ComMemberSpec:

def DISPMETHOD(idlflags, restype, name, *argspec) -> _DispMemberSpec:

def DISPPROPERTY(idlflags, proptype, name) -> _DispMemberSpec:


def COMMETHOD(idlflags, restype, methodname, *argspec) -> _ComMemberSpec:
_T_IUnknown = TypeVar(""_T_IUnknown"", bound=""IUnknown"")

    class _IUnknown_Base(c_void_p, metaclass=_cominterface_meta):

        __com_QueryInterface: Callable[[Any, Any], int]
        __com_AddRef: Callable[[], int]
        __com_Release: Callable[[], int]


class IUnknown(_IUnknown_Base, metaclass=_cominterface_meta):
    _case_insensitive_: ClassVar[bool] = False
    _iid_: ClassVar[GUID] = GUID(""{00000000-0000-0000-C000-000000000046}"")
    _methods_: ClassVar[List[_ComMemberSpec]] = [
        STDMETHOD(HRESULT, ""QueryInterface"", [POINTER(GUID), POINTER(c_void_p)]),
        STDMETHOD(c_ulong, ""Release""),
    ]
    def QueryInterface(
        self, interface: Type[_T_IUnknown], iid: Optional[GUID] = None
    ) -> _T_IUnknown:
        clsid = self.__dict__.get(""__clsid"")
            p.__dict__[""__clsid""] = clsid
    def AddRef(self) -> int:
    def Release(self) -> int:
    _iid_ = GUID(""{0000010C-0000-0000-C000-000000000046}"")
        COMMETHOD([], HRESULT, ""GetClassID"", ([""out""], POINTER(GUID), ""pClassID"")),
    ]
        # Should this be ""normal"" method that calls `self._GetClassID`?
        def GetClassID(self) -> GUID:
            """"""Returns the CLSID that uniquely represents an object class that
            defines the code that can manipulate the object's data.
            """"""
            ...
    _iid_ = GUID(""{6D5140C1-7436-11CE-8034-00AA006009FA}"")
    _QueryService: Callable[[Any, Any, Any], int]
    def QueryService(
        self, serviceIID: GUID, interface: Type[_T_IUnknown]
    ) -> _T_IUnknown:
        COMMETHOD(
            [],
            HRESULT,
            ""QueryService"",
            ([""in""], POINTER(GUID), ""guidService""),
            ([""in""], POINTER(GUID), ""riid""),
            ([""in""], POINTER(c_void_p), ""ppvObject""),
        )
    ]

@overload
def CoGetObject(displayname: str, interface: None) -> IUnknown:
    ...


@overload
def CoGetObject(displayname: str, interface: Type[_T_IUnknown]) -> _T_IUnknown:
    ...


def CoGetObject(displayname: str, interface: Optional[Type[IUnknown]]) -> IUnknown:
    _ole32.CoGetObject(str(displayname), None, byref(interface._iid_), byref(punk))
_pUnkOuter = Type[""_Pointer[IUnknown]""]


@overload
def CoCreateInstance(
    clsid: GUID,
    interface: None = None,
    clsctx: Optional[int] = None,
    punkouter: Optional[_pUnkOuter] = None,
) -> IUnknown:
    ...
@overload
def CoCreateInstance(
    clsid: GUID,
    interface: Type[_T_IUnknown],
    clsctx: Optional[int] = None,
    punkouter: Optional[_pUnkOuter] = None,
) -> _T_IUnknown:
    ...


def CoCreateInstance(
    clsid: GUID,
    interface: Optional[Type[IUnknown]] = None,
    clsctx: Optional[int] = None,
    punkouter: Optional[_pUnkOuter] = None,
) -> IUnknown:




    _CoGetClassObject(clsid, clsctx, pServerInfo, interface._iid_, byref(p))
@overload
def GetActiveObject(clsid: GUID, interface: None = None) -> IUnknown:
    ...


@overload
def GetActiveObject(clsid: GUID, interface: Type[_T_IUnknown]) -> _T_IUnknown:
    ...

def GetActiveObject(
    clsid: GUID, interface: Optional[Type[IUnknown]] = None
) -> IUnknown:
    _fields_ = [(""pIID"", POINTER(GUID)), (""pItf"", POINTER(c_void_p)), (""hr"", HRESULT)]
        pIID: GUID
        pItf: _Pointer[c_void_p]
        hr: HRESULT

        (""User"", POINTER(c_ushort)),
        (""UserLength"", c_ulong),
        (""Domain"", POINTER(c_ushort)),
        (""DomainLength"", c_ulong),
        (""Password"", POINTER(c_ushort)),
        (""PasswordLength"", c_ulong),
        (""Flags"", c_ulong),



        (""dwAuthnSvc"", c_ulong),
        (""dwAuthzSvc"", c_ulong),
        (""pwszServerPrincName"", c_wchar_p),
        (""dwAuthnLevel"", c_ulong),
        (""dwImpersonationLevel"", c_ulong),
        (""pAuthIdentityData"", POINTER(_COAUTHIDENTITY)),
        (""dwCapabilities"", c_ulong),



        (""dwReserved1"", c_ulong),
        (""pwszName"", c_wchar_p),
        (""pAuthInfo"", POINTER(_COAUTHINFO)),
        (""dwReserved2"", c_ulong),
        dwReserved1: int
        pwszName: Optional[str]
        pAuthInfo: _COAUTHINFO
        dwReserved2: int


_CoGetClassObject.argtypes = [
    POINTER(GUID),
    DWORD,
    POINTER(COSERVERINFO),
    POINTER(GUID),
    POINTER(c_void_p),
]

        (""cbStruct"", c_ulong),
        (""grfFlags"", c_ulong),
        (""grfMode"", c_ulong),
        (""dwTickCountDeadline"", c_ulong),



        (""cbStruct"", c_ulong),
        (""grfFlags"", c_ulong),
        (""grfMode"", c_ulong),
        (""dwTickCountDeadline"", c_ulong),
        (""dwTrackFlags"", c_ulong),
        (""dwClassContext"", c_ulong),
        (""locale"", c_ulong),
        (""pServerInfo"", POINTER(_COSERVERINFO)),


# Structures for security setups
        (""User"", POINTER(c_ushort)),
        (""UserLength"", c_ulong),
        (""Domain"", POINTER(c_ushort)),
        (""DomainLength"", c_ulong),
        (""Password"", POINTER(c_ushort)),
        (""PasswordLength"", c_ulong),
        (""Flags"", c_ulong),



        (""dwAuthnSvc"", c_ulong),
        (""dwAuthzSvc"", c_ulong),
        (""pAuthInfo"", POINTER(_SEC_WINNT_AUTH_IDENTITY)),



        (""cAuthInfo"", c_ulong),
        (""pAuthInfo"", POINTER(_SOLE_AUTHENTICATION_INFO)),
SOLE_AUTHENTICATION_LIST = _SOLE_AUTHENTICATION_LIST

@overload
def CoCreateInstanceEx(
    clsid: GUID,
    interface: None = None,
    clsctx: Optional[int] = None,
    machine: Optional[str] = None,
    pServerInfo: Optional[COSERVERINFO] = None,
) -> IUnknown:
    ...


@overload
def CoCreateInstanceEx(
    clsid: GUID,
    interface: Type[_T_IUnknown],
    clsctx: Optional[int] = None,
    machine: Optional[str] = None,
    pServerInfo: Optional[COSERVERINFO] = None,
) -> _T_IUnknown:
    ...


def CoCreateInstanceEx(
    clsid: GUID,
    interface: Optional[Type[IUnknown]] = None,
    clsctx: Optional[int] = None,
    machine: Optional[str] = None,
    pServerInfo: Optional[COSERVERINFO] = None,
) -> IUnknown:
        clsctx = CLSCTX_LOCAL_SERVER | CLSCTX_REMOTE_SERVER
    _ole32.CoCreateInstanceEx(
        byref(clsid), None, clsctx, pServerInfo, 1, byref(multiqi)
    )

class CoClass(COMObject, metaclass=_coclass_meta):


# fmt: off
    ""BIND_OPTS"", ""tagBIND_OPTS"", ""BINDOPTS2"", ""tagBIND_OPTS2"", ""BSTR"",
    ""_check_version"", ""CLSCTX"", ""tagCLSCTX"", ""CLSCTX_ALL"",
    ""CLSCTX_DISABLE_AAA"", ""CLSCTX_ENABLE_AAA"", ""CLSCTX_ENABLE_CODE_DOWNLOAD"",
    ""CLSCTX_FROM_DEFAULT_CONTEXT"", ""CLSCTX_INPROC"", ""CLSCTX_INPROC_HANDLER"",
    ""CLSCTX_INPROC_HANDLER16"", ""CLSCTX_INPROC_SERVER"",
    ""CLSCTX_INPROC_SERVER16"", ""CLSCTX_LOCAL_SERVER"", ""CLSCTX_NO_CODE_DOWNLOAD"",
    ""CLSCTX_NO_CUSTOM_MARSHAL"", ""CLSCTX_NO_FAILURE_LOG"",
    ""CLSCTX_REMOTE_SERVER"", ""CLSCTX_RESERVED1"", ""CLSCTX_RESERVED2"",
    ""CLSCTX_RESERVED3"", ""CLSCTX_RESERVED4"", ""CLSCTX_RESERVED5"",
    ""CLSCTX_SERVER"", ""_COAUTHIDENTITY"", ""COAUTHIDENTITY"", ""_COAUTHINFO"",
    ""COAUTHINFO"", ""CoClass"", ""CoCreateInstance"", ""CoCreateInstanceEx"",
    ""_CoGetClassObject"", ""CoGetClassObject"", ""CoGetObject"",
    ""COINIT_APARTMENTTHREADED"", ""COINIT_DISABLE_OLE1DDE"",
    ""COINIT_MULTITHREADED"", ""COINIT_SPEED_OVER_MEMORY"", ""CoInitialize"",
    ""CoInitializeEx"", ""COMError"", ""COMMETHOD"", ""COMObject"", ""_COSERVERINFO"",
    ""COSERVERINFO"", ""CoUninitialize"", ""dispid"", ""DISPMETHOD"", ""DISPPROPERTY"",
    ""DWORD"", ""EOAC_NONE"", ""GetActiveObject"", ""_GUID"", ""GUID"", ""helpstring"",
    ""IID"", ""IPersist"", ""IServiceProvider"", ""IUnknown"", ""MULTI_QI"",
    ""ReturnHRESULT"", ""RPC_C_AUTHN_LEVEL_CONNECT"", ""RPC_C_AUTHN_WINNT"",
    ""RPC_C_AUTHZ_NONE"", ""RPC_C_IMP_LEVEL_IMPERSONATE"",
    ""_SEC_WINNT_AUTH_IDENTITY"", ""SEC_WINNT_AUTH_IDENTITY"",
    ""SEC_WINNT_AUTH_IDENTITY_UNICODE"", ""_SOLE_AUTHENTICATION_INFO"",
    ""SOLE_AUTHENTICATION_INFO"", ""_SOLE_AUTHENTICATION_LIST"",
    ""SOLE_AUTHENTICATION_LIST"", ""STDMETHOD"", ""wireHWND"",
# fmt: on
    FormatError,
    POINTER,
    Structure,
    WINFUNCTYPE,
    byref,
    c_long,
    c_void_p,
    oledll,
    pointer,
    windll,
import queue
    DISP_E_BADINDEX,
    DISP_E_MEMBERNOTFOUND,
    E_FAIL,
    E_NOINTERFACE,
    E_INVALIDARG,
    E_NOTIMPL,
    RPC_E_CHANGED_MODE,
    S_FALSE,
    S_OK,
        if isinstance(code, int):
    raise TypeError(
        ""Expected comtypes.COMERROR or WindowsError instance, got %s""
        % type(exc).__name__
    )
        _debug(""unimplemented method %s_%s called"", interface_name, method_name)

            return ReportError(text, iid=interface._iid_, clsid=clsid, hresult=hresult)
            _error(
                ""Exception in %s.%s implementation:"",
                interface.__name__,
                mthname,
                exc_info=True,
            )
            _warning(""Unimplemented method %s.%s called"", interface.__name__, mthname)
            _error(
                ""Exception in %s.%s implementation:"",
                interface.__name__,
                mthname,
                exc_info=True,
            )

        has_outargs = bool([x[0] for x in paramflags if x[0] & 2])

        if a & 2:
        if a & 1 or a == 0:
    # if args_in != code.co_argcount - 1:
    #     return catch_errors(inst, mth, interface, mthname)
        # for a in outargs:
        #     if not a:
        #         return E_POINTER
        # make argument list for handler by index array built above
            return ReportError(text, iid=interface._iid_, clsid=clsid, hresult=hresult)
            _error(
                ""Exception in %s.%s implementation:"",
                interface.__name__,
                mthname,
                exc_info=True,
            )
            return ReportError(msg, iid=interface._iid_, clsid=clsid, hresult=hr)
            _error(
                ""Exception in %s.%s implementation:"",
                interface.__name__,
                mthname,
                exc_info=True,
            )
            _warning(""Unimplemented method %s.%s called"", interface.__name__, mthname)
            _error(
                ""Exception in %s.%s implementation:"",
                interface.__name__,
                mthname,
                exc_info=True,
            )

        _debug(""%r: %s.%s not implemented"", self.inst, interface.__name__, mthname)









                if (
                    hasattr(self, ""_outgoing_interfaces_"")
                    and IProvideClassInfo2 not in interfaces
                ):
                    if ""propget"" in idlflags:
                    elif ""propput"" in idlflags:
                    elif ""propputref"" in idlflags:
                            argspec = argspec + (([""out""], restype, """"),)
                    self.__make_dispentry(
                        finder, interface, mthname, idlflags, argspec, invkind
                    )
                        argspec += (([""out""], restype, """"),)
                    self.__make_dispentry(
                        finder,
                        interface,
                        ""_get_"" + mthname,
                        idlflags,
                        argspec,
                        2,  # DISPATCH_PROPERTYGET
                    )
                    if not ""readonly"" in idlflags:
                        self.__make_dispentry(
                            finder, interface, ""_set_"" + mthname, idlflags, argspec, 4
                        )  # DISPATCH_PROPERTYPUT
    def __make_dispentry(self, finder, interface, mthname, idlflags, argspec, invkind):
        paramflags = [((_encode_idl(x[0]), x[1]) + tuple(x[3:])) for x in argspec]
        _debug(""%d active COM objects: Added   %r"", len(COMObject._instances_), obj)
            _debug(""%d active COM objects: Removed %r"", len(COMObject._instances_), obj)

    def IUnknown_AddRef(
        self, this, __InterlockedIncrement=_InterlockedIncrement, _debug=_debug
    ):
    def IUnknown_Release(
        self, this, __InterlockedDecrement=_InterlockedDecrement, _debug=_debug
    ):
            raise COMError(
                E_NOINTERFACE, FormatError(E_NOINTERFACE), (None, None, 0, None, None)
            )
    def IDispatch_GetIDsOfNames(self, this, riid, rgszNames, cNames, lcid, rgDispId):
        return windll.oleaut32.DispGetIDsOfNames(tinfo, rgszNames, cNames, rgDispId)

    def IDispatch_Invoke(
        self,
        this,
        dispIdMember,
        riid,
        lcid,
        wFlags,
        pDispParams,
        pVarResult,
        pExcepInfo,
        puArgErr,
    ):
                ptr,
                tinfo,
                dispIdMember,
                wFlags,
                pDispParams,
                pVarResult,
                pExcepInfo,
                puArgErr,
            args = [
                params.rgvarg[i].value for i in reversed(list(range(params.cNamedArgs)))
            ]
            named_indexes = [
                params.rgdispidNamedArgs[i] for i in range(params.cNamedArgs)
            ]

from typing import (
    Any,
    Callable,
    Dict,
    Iterator,
    List,
    NamedTuple,
    Optional,
    Tuple,
    Type,
    Union as _UnionT,
)

from comtypes import _CData

_PositionalParamFlagType = Tuple[int, Optional[str]]
_OptionalParamFlagType = Tuple[int, Optional[str], Any]
_ParamFlagType = _UnionT[_PositionalParamFlagType, _OptionalParamFlagType]
_PositionalArgSpecElmType = Tuple[List[str], Type[_CData], str]
_OptionalArgSpecElmType = Tuple[List[str], Type[_CData], str, Any]
_ArgSpecElmType = _UnionT[_PositionalArgSpecElmType, _OptionalArgSpecElmType]
}
def _unpack_argspec(
    idl: List[str],
    typ: Type[_CData],
    name: Optional[str] = None,
    defval: Any = _NOTHING,
) -> Tuple[List[str], Type[_CData], Optional[str], Any]:
def _resolve_argspec(
    items: Tuple[_ArgSpecElmType, ...]
) -> Tuple[Tuple[_ParamFlagType, ...], Tuple[Type[_CData], ...]]:
class _ComMemberSpec(NamedTuple):
    restype: Optional[Type[_CData]]
    name: str
    argtypes: Tuple[Type[_CData], ...]
    paramflags: Optional[Tuple[_ParamFlagType, ...]]
    idlflags: Tuple[_UnionT[str, int], ...]
    doc: Optional[str]
    def is_prop(self) -> bool:
        return _is_spec_prop(self)
class _DispMemberSpec(NamedTuple):
    what: str
    name: str
    idlflags: Tuple[_UnionT[str, int], ...]
    restype: Optional[Type[_CData]]
    argspec: Tuple[_ArgSpecElmType, ...]
    def memid(self) -> int:
    def is_prop(self) -> bool:
        return _is_spec_prop(self)


# Specifier of a slot of method or property.
# This should be `typing.Protocol` if supporting Py3.8+ only.
_MemberSpec = _UnionT[_ComMemberSpec, _DispMemberSpec]


def _is_spec_prop(m: _MemberSpec):
    return any(f in (""propget"", ""propput"", ""propputref"") for f in m.idlflags)

_PropFunc = Optional[Callable[..., Any]]
_DocType = Optional[str]

def _fix_inout_args(
    func: Callable[..., Any],
    argtypes: Tuple[Type[_CData], ...],
    paramflags: Tuple[_ParamFlagType, ...],
) -> Callable[..., Any]:

        outargs: Dict[int, _UnionT[_CData, ""ctypes._CArgObject""]] = {}
        param_index = 0
        # Go through all expected arguments and match them to the provided arguments.
        # `param_index` first counts through the positional and then
        # through the keyword arguments.
            dir_in = direction & 1 == 1
            dir_out = direction & 2 == 2
            is_positional = param_index < len(args)
            if not (dir_in or dir_out):
                # The original code here did not check for this special case and
                # effectively treated `(dir_in, dir_out) == (False, False)` and
                # `(dir_in, dir_out) == (True, False)` the same.
                # In order not to break legacy code we do the same.
                # One example of a function that has neither `dir_in` nor `dir_out`
                # set is `IMFAttributes.GetString`.
                dir_in = True
            if dir_in and dir_out:
                atyp: Type[_CData] = getattr(argtypes[i], ""_type_"")

                def prepare_parameter(v):
                    # parameter was passed, call `from_param()` to
                    # convert it to a `ctypes` type.
                        # Array of or pointer to type `atyp` was passed,
                        # pointer to `atyp` expected.
                        # The `from_param` method of simple types
                        # (`c_int`, `c_double`, ...) returns a `byref` object which
                        # we cannot use since later it will be wrapped in a pointer.
                        # Simply call the constructor with the argument in that case.
                    return v

                if is_positional:
                    v = prepare_parameter(args[param_index])
                    args[param_index] = v
                elif name in kw:
                    v = prepare_parameter(kw[name])
                else:
                    # no parameter was passed, make an empty one of the required type
                    # and pass it as a keyword argument
                    v = atyp()
                    if name is not None:
                        kw[name] = v
                    else:
                        raise TypeError(""Unnamed inout parameters cannot be omitted"")
                outargs[outnum] = v
            if dir_out:
            if dir_in:
                param_index += 1


        # Our interpretation of this code
        # (jonschz, junkmd, see https://github.com/enthought/comtypes/pull/473):
        # - `outnum` counts the total number of 'out' and 'inout' arguments.
        # - `outargs` is a dict consisting of the supplied 'inout' arguments.
        # - The call to `func()` returns the 'out' and 'inout' arguments.
        #   Furthermore, it changes the variables in 'outargs' as a ""side effect""
        # - In a perfect world, it should be fine to just return `rescode`.
        #   But we assume there is a reason why the original authors did not do that.
        #   Instead, they replace the 'inout' variables in `rescode` by those in
        #   'outargs', and call `__ctypes_from_outparam__()` on them.

            # In this case, it is little faster than creating list with
            # `rescode = [rescode]` and getting item with index from the list.

        self._data: Dict[Tuple[str, _DocType, int], List[_PropFunc]] = {}
    def add_propget(
        self, name: str, doc: _DocType, nargs: int, func: Callable[..., Any]
    ) -> None:
    def add_propput(
        self, name: str, doc: _DocType, nargs: int, func: Callable[..., Any]
    ) -> None:
    def add_propputref(
        self, name: str, doc: _DocType, nargs: int, func: Callable[..., Any]
    ) -> None:
    def __iter__(self) -> Iterator[Tuple[str, _DocType, int, _PropFunc, _PropFunc]]:


    def __init__(self, cls_name: str) -> None:
    def add(self, m: _MemberSpec, func: Callable[..., Any]) -> None:
    def __iter__(self) -> Iterator[Tuple[str, _UnionT[property, ""named_property""]]]:
    def to_propget_keys(self, m: _MemberSpec) -> Tuple[str, _DocType, int]:
    def to_propput_keys(self, m: _MemberSpec) -> Tuple[str, _DocType, int]:
    def to_propputref_keys(self, m: _MemberSpec) -> Tuple[str, _DocType, int]:
    def to_propget_keys(self, m: _ComMemberSpec) -> Tuple[str, _DocType, int]:
        return m.name[len(""_get_"") :], m.doc, nargs
    def to_propput_keys(self, m: _ComMemberSpec) -> Tuple[str, _DocType, int]:
        return m.name[len(""_set_"") :], m.doc, nargs
    def to_propputref_keys(self, m: _ComMemberSpec) -> Tuple[str, _DocType, int]:
        return m.name[len(""_setref_"") :], m.doc, nargs
    def to_propget_keys(self, m: _DispMemberSpec) -> Tuple[str, _DocType, int]:
    def to_propput_keys(self, m: _DispMemberSpec) -> Tuple[str, _DocType, int]:
    def to_propputref_keys(self, m: _DispMemberSpec) -> Tuple[str, _DocType, int]:
    def __init__(self, cls_name: str, vtbl_offset: int, iid: comtypes.GUID) -> None:
        self._mths: List[Tuple[str, Callable[..., Any], Callable[..., Any], bool]] = []
    def add(self, m: _ComMemberSpec) -> None:
    def _fix_args(
        self, m: _ComMemberSpec, func: Callable[..., Any]
    ) -> Callable[..., Any]:
            dirflags = [(p[0] & 3) for p in m.paramflags]
    def __init__(self, cls_name: str) -> None:
        self._items: List[Tuple[str, _UnionT[Callable[..., Any], property], bool]] = []
    def add(self, m: _DispMemberSpec) -> None:
            assert not m.argspec  # XXX does not yet work for properties with parameters
    def _make_disp_property(self, m: _DispMemberSpec) -> property:

            return obj.Invoke(memid, _invkind=2)  # DISPATCH_PROPERTYGET



    def _make_disp_method(self, m: _DispMemberSpec) -> Callable[..., Any]:

                return obj.Invoke(
                    memid, _invkind=2, *args, **kw
                )  # DISPATCH_PROPERTYGET


                return obj.Invoke(
                    memid, _invkind=4, *args, **kw
                )  # DISPATCH_PROPERTYPUT


                return obj.Invoke(
                    memid, _invkind=8, *args, **kw
                )  # DISPATCH_PROPERTYPUTREF




            return obj.Invoke(memid, _invkind=1, *args, **kw)  # DISPATCH_METHOD


        """"""Explicitly disallow iteration.""""""




        PTR = _coclass_pointer_meta(
            ""POINTER(%s)"" % klass.__name__,
            (klass, c_void_p),
            {
                ""__ctypes_from_outparam__"": _wrap_coclass,
                ""from_param"": classmethod(_coclass_from_param),
            },
        )


    """"""Class encapsulating all the functionality necessary to allow interop of

        """"""Create a dtype for VARIANT. This requires support for Unions, which
        ptr_typecode = ""<u8"" if is_64bits else ""<u4""
            (""pvRecord"", ptr_typecode),
            (""pRecInfo"", ptr_typecode),
                ""VT_BOOL"",
                ""VT_I1"",
                ""VT_I2"",
                ""VT_I4"",
                ""VT_I8"",
                ""VT_INT"",
                ""VT_UI1"",
                ""VT_UI2"",
                ""VT_UI4"",
                ""VT_UI8"",
                ""VT_UINT"",
                ""VT_R4"",
                ""VT_R8"",
                ""VT_CY"",
                ""c_wchar_p"",
                ""c_void_p"",
                ""pparray"",
                ""bstrVal"",
                ""_tagBRECORD"",
                ""<i2"",
                ""<i1"",
                ""<i2"",
                ""<i4"",
                ""<i8"",
                ""<i4"",
                ""<u1"",
                ""<u2"",
                ""<u4"",
                ""<u8"",
                ""<u4"",
                ""<f4"",
                ""<f8"",
                ""<i8"",
                ptr_typecode,
                ptr_typecode,
                ptr_typecode,
                ptr_typecode,
                _tagBRECORD_format,
            offsets=[0] * 19,  # This is what makes it a union
            (""vt"", ""<u2""),
            (""wReserved1"", ""<u2""),
            (""wReserved2"", ""<u2""),
            (""wReserved3"", ""<u2""),

        """"""Check if a value is an ndarray.
        """"""Check if a value is a datetime64.
        """"""The numpy package.""""""

        """"""Enables numpy/comtypes interop.""""""

# if __debug__:
#     from ctypeslib.dynamic_module import include
#     include(""""""\
#     #define UNICODE
#     #define NO_STRICT
#     #include <windows.h>
#     """""",
#             persist=True)

        (""cElements"", DWORD),
        (""lLbound"", LONG),
    ]



        (""cDims"", USHORT),
        (""fFeatures"", USHORT),
        (""cbElements"", DWORD),
        (""cLocks"", DWORD),
        (""pvData"", PVOID),
        (""rgsabound"", SAFEARRAYBOUND * 1),
    ]














from ctypes.wintypes import DWORD, LONG, UINT, VARIANT_BOOL, WCHAR, WORD
from typing import (
    Any,
    Callable,
    ClassVar,
    List,
    Optional,
    TYPE_CHECKING,
    Tuple,
    Union as _UnionT,

from comtypes import BSTR, COMError, COMMETHOD, GUID, IID, IUnknown, STDMETHOD

if TYPE_CHECKING:
    from comtypes import hints  # type: ignore


VARENUM = c_int  # enum


    _fields_ = [
        (""wReserved"", c_ushort),
        (""scale"", c_ubyte),
        (""sign"", c_ubyte),
        (""Hi32"", c_ulong),
        (""Lo64"", c_ulonglong),
    ]
        """"""Convert a tagDEC struct to Decimal.
            ""-"" if self.sign else """",
        vt: int
        _: ""U_VARIANT1.__tagVARIANT.U_VARIANT2""
        null: ClassVar[""VARIANT""]
        empty: ClassVar[""VARIANT""]
        missing: ClassVar[""VARIANT""]
                    _fields_ = [(""pvRecord"", c_void_p), (""pRecInfo"", POINTER(IUnknown))]

                ]

            _fields_ = [
                (""vt"", VARTYPE),
                (""wReserved1"", c_ushort),
                (""wReserved2"", c_ushort),
                (""wReserved3"", c_ushort),
                (""_"", U_VARIANT2),

        _fields_ = [(""__VARIANT_NAME_2"", __tagVARIANT), (""decVal"", DECIMAL)]

        elif (
            hasattr(value, ""__len__"") and len(value) == 0 and not isinstance(value, str)
        ):
        elif isinstance(value, int):
        elif isinstance(value, str):
            com_days = (
                delta.days + (delta.seconds + delta.microseconds * 1e-6) / 86400.0
            )
            com_days /= comtypes.npsupport.numpy.timedelta64(1, ""D"")

                return None  # XXX?
                return None  # XXX?

        if self.vt == VT_BYREF | VT_VARIANT:
    # these are missing:
    # getter[VT_ERROR]
    # getter[VT_ARRAY]
    # getter[VT_BYREF|VT_UI1]
    # getter[VT_BYREF|VT_I2]
    # getter[VT_BYREF|VT_I4]
    # getter[VT_BYREF|VT_R4]
    # getter[VT_BYREF|VT_R8]
    # getter[VT_BYREF|VT_BOOL]
    # getter[VT_BYREF|VT_ERROR]
    # getter[VT_BYREF|VT_CY]
    # getter[VT_BYREF|VT_DATE]
    # getter[VT_BYREF|VT_BSTR]
    # getter[VT_BYREF|VT_UNKNOWN]
    # getter[VT_BYREF|VT_DISPATCH]
    # getter[VT_BYREF|VT_ARRAY]
    # getter[VT_BYREF|VT_VARIANT]
    # getter[VT_BYREF]
    # getter[VT_BYREF|VT_DECIMAL]
    # getter[VT_BYREF|VT_I1]
    # getter[VT_BYREF|VT_UI2]
    # getter[VT_BYREF|VT_UI4]
    # getter[VT_BYREF|VT_INT]
    # getter[VT_BYREF|VT_UINT]
        _VariantChangeType(self, self, 0, typecode)



    _iid_ = GUID(""{00020404-0000-0000-C000-000000000046}"")
    _idlflags_ = [""hidden""]

    def __next__(self):
        item, fetched = self.Next(1)
        if fetched:
            return item
        raise StopIteration
        # if isinstance(index, slice):
        #     self.Skip(index.start or 0)
        #     return self.Next(index.stop or sys.maxint)
        result = [v._get_value(dynamic=self._dynamic) for v in array[: fetched.value]]

    COMMETHOD(
        [],
        HRESULT,
        ""Next"",
        ([""in""], c_ulong, ""celt""),
        ([""out""], POINTER(VARIANT), ""rgvar""),
        ([""out""], POINTER(c_ulong), ""pceltFetched""),
    ),
    COMMETHOD([], HRESULT, ""Skip"", ([""in""], c_ulong, ""celt"")),
    COMMETHOD([], HRESULT, ""Reset""),
    COMMETHOD(
        [], HRESULT, ""Clone"", ([""out""], POINTER(POINTER(IEnumVARIANT)), ""ppenum"")
    ),
        wCode: int
        wReserved: int
        bstrSource: str
        bstrDescription: str
        bstrHelpFile: str
        dwHelpContext: int
        pvReserved: Optional[int]
        pfnDeferredFillIn: Optional[int]
        scode: int
        return ""<EXCEPINFO %s>"" % (
            (
                self.wCode,
                self.bstrSource,
                self.bstrDescription,
                self.bstrHelpFile,
                self.dwHelpContext,
                self.pfnDeferredFillIn,
                self.scode,
            ),
        )


    (""wCode"", WORD),
    (""wReserved"", WORD),
    (""bstrSource"", BSTR),
    (""bstrDescription"", BSTR),
    (""bstrHelpFile"", BSTR),
    (""dwHelpContext"", DWORD),
    (""pvReserved"", c_void_p),
    # ('pfnDeferredFillIn', WINFUNCTYPE(HRESULT, POINTER(tagEXCEPINFO))),
    (""pfnDeferredFillIn"", c_void_p),
    (""scode"", SCODE),

        rgvarg: Array[VARIANT]
        rgdispidNamedArgs: _Pointer[DISPID]
        cArgs: int
        cNamedArgs: int
        (""rgvarg"", POINTER(VARIANTARG)),
        (""rgdispidNamedArgs"", POINTER(DISPID)),
        (""cArgs"", UINT),
        (""cNamedArgs"", UINT),



RawGetIDsOfNamesFunc = Callable[
    [_byref_type, ""Array[c_wchar_p]"", int, int, ""Array[DISPID]""], int
]
# fmt: off
RawInvokeFunc = Callable[
    [
        int, _byref_type, int, int,  # dispIdMember, riid, lcid, wFlags
        _UnionT[_byref_type, DISPPARAMS],  # *pDispParams
        _UnionT[_byref_type, VARIANT],  # pVarResult
        _UnionT[_byref_type, EXCEPINFO, None],  # pExcepInfo
        _UnionT[_byref_type, c_uint],  # puArgErr
    ],
    int,
]
# fmt: on

    _disp_methods_: ClassVar[List[comtypes._DispMemberSpec]]
    _GetTypeInfo: Callable[[int, int], IUnknown]
    __com_GetIDsOfNames: RawGetIDsOfNamesFunc
    __com_Invoke: RawInvokeFunc
        COMMETHOD([], HRESULT, ""GetTypeInfoCount"", ([""out""], POINTER(UINT))),
        COMMETHOD(
            [],
            HRESULT,
            ""GetTypeInfo"",
            ([""in""], UINT, ""index""),
            ([""in""], LCID, ""lcid"", 0),
            # Normally, we would declare this parameter in this way:
            # (['out'], POINTER(POINTER(ITypeInfo)) ) ),
            # but we cannot import comtypes.typeinfo at the top level (recursive imports!).
            ([""out""], POINTER(POINTER(IUnknown))),
        ),
        STDMETHOD(
            HRESULT,
            ""GetIDsOfNames"",
            [POINTER(IID), POINTER(c_wchar_p), UINT, LCID, POINTER(DISPID)],
        ),
        STDMETHOD(
            HRESULT,
            ""Invoke"",
            [
                DISPID,
                POINTER(IID),
                LCID,
                WORD,
                POINTER(DISPPARAMS),
                POINTER(VARIANT),
                POINTER(EXCEPINFO),
                POINTER(UINT),
            ],
        ),
    def GetTypeInfo(self, index: int, lcid: int = 0) -> ""hints.ITypeInfo"":

    def GetIDsOfNames(self, *names: str, **kw: Any) -> List[int]:
    def _invoke(self, memid: int, invkind: int, lcid: int, *args: Any) -> Any:
        self.__com_Invoke(memid, riid_null, lcid, invkind, dp, var, None, argerr)
    def __make_dp(self, _invkind: int, *args: Any) -> DISPPARAMS:
        array = (VARIANT * len(args))()
        for i, a in enumerate(args[::-1]):
            array[i].value = a
        dp = DISPPARAMS()
        dp.cArgs = len(args)
        dp.rgvarg = array
        if _invkind in (DISPATCH_PROPERTYPUT, DISPATCH_PROPERTYPUTREF):  # propput
            dp.cNamedArgs = 1
            dp.rgdispidNamedArgs = pointer(DISPID(DISPID_PROPERTYPUT))
        else:
            dp.cNamedArgs = 0
        return dp

    def Invoke(self, dispid: int, *args: Any, **kw: Any) -> Any:
        _invkind = kw.pop(""_invkind"", 1)  # DISPATCH_METHOD
        dp = self.__make_dp(_invkind, *args)
            self.__com_Invoke(
                dispid,
                riid_null,
                _lcid,
                _invkind,
                byref(dp),
                byref(result),
                byref(excepinfo),
                byref(argerr),
            )
                details = (
                    excepinfo.bstrDescription,
                    excepinfo.bstrSource,
                    excepinfo.bstrHelpFile,
                    excepinfo.dwHelpContext,
                    excepinfo.scode,
                )
                raise COMError(
                    hresult,
                    text,
                    (""TypeError: Parameter %s"" % (argerr.value + 1), args),
                )
}
    POINTER(VARIANT): VT_BYREF | VT_VARIANT,
    POINTER(BSTR): VT_BYREF | VT_BSTR,
    # POINTER(IUnknown): VT_UNKNOWN,
    # POINTER(IDispatch): VT_DISPATCH,
}
# fmt: off
    ""CURRENCY"", ""CY"", ""tagCY"", ""DECIMAL"", ""tagDEC"", ""DISPATCH_METHOD"",
    ""DISPATCH_PROPERTYGET"", ""DISPATCH_PROPERTYPUT"", ""DISPATCH_PROPERTYPUTREF"",
    ""DISPID"", ""DISPID_COLLECT"", ""DISPID_CONSTRUCTOR"", ""DISPID_DESTRUCTOR"",
    ""DISPID_EVALUATE"", ""DISPID_NEWENUM"", ""DISPID_PROPERTYPUT"",
    ""DISPID_UNKNOWN"", ""DISPID_VALUE"", ""DISPPARAMS"", ""tagDISPPARAMS"",
    ""EXCEPINFO"", ""tagEXCEPINFO"", ""IDispatch"", ""IEnumVARIANT"", ""IID_NULL"",
    ""INVOKE_FUNC"", ""INVOKE_PROPERTYGET"", ""INVOKE_PROPERTYPUT"",
    ""INVOKE_PROPERTYPUTREF"", ""INVOKEKIND"", ""tagINVOKEKIND"", ""_midlSAFEARRAY"",
    ""SCODE"", ""_SysAllocStringLen"", ""VARENUM"", ""VARIANT"", ""tagVARIANT"",
    ""VARIANTARG"", ""_VariantChangeType"", ""_VariantClear"", ""_VariantCopy"",
    ""_VariantCopyInd"", ""VARTYPE"", ""VT_ARRAY"", ""VT_BLOB"", ""VT_BLOB_OBJECT"",
    ""VT_BOOL"", ""VT_BSTR"", ""VT_BSTR_BLOB"", ""VT_BYREF"", ""VT_CARRAY"", ""VT_CF"",
    ""VT_CLSID"", ""VT_CY"", ""VT_DATE"", ""VT_DECIMAL"", ""VT_DISPATCH"", ""VT_EMPTY"",
    ""VT_ERROR"", ""VT_FILETIME"", ""VT_HRESULT"", ""VT_I1"", ""VT_I2"", ""VT_I4"",
    ""VT_I8"", ""VT_ILLEGAL"", ""VT_ILLEGALMASKED"", ""VT_INT"", ""VT_INT_PTR"",
    ""VT_LPSTR"", ""VT_LPWSTR"", ""VT_NULL"", ""VT_PTR"", ""VT_R4"", ""VT_R8"",
    ""VT_RECORD"", ""VT_RESERVED"", ""VT_SAFEARRAY"", ""VT_STORAGE"",
    ""VT_STORED_OBJECT"", ""VT_STREAM"", ""VT_STREAMED_OBJECT"", ""VT_TYPEMASK"",
    ""VT_UI1"", ""VT_UI2"", ""VT_UI4"", ""VT_UI8"", ""VT_UINT"", ""VT_UINT_PTR"",
    ""VT_UNKNOWN"", ""VT_USERDEFINED"", ""VT_VARIANT"", ""VT_VECTOR"",
    ""VT_VERSIONED_STREAM"", ""VT_VOID"",
# fmt: on
""""""comtypes.client - High level client level COM support package.""""""
from typing import (
    Any,
    Optional,
    overload,
    Type,
    TYPE_CHECKING,
    TypeVar,
    Union as _UnionT,
)
from comtypes import automation, CoClass, GUID, IUnknown, typeinfo
if TYPE_CHECKING:
    from comtypes import hints  # type: ignore


_T_IUnknown = TypeVar(""_T_IUnknown"", bound=IUnknown)
def wrap_outparam(punk: Any) -> Any:
def GetBestInterface(punk: Any) -> Any:
    if not punk:  # NULL COM pointer
        return punk  # or should we return None?
            logger.debug(
                ""Does NOT implement IProvideClassInfo, trying IProvideClassInfo2""
            )
        tinfo = pci.GetClassInfo()  # TypeInfo for the CoClass
    itf_name = tinfo.GetDocumentation(-1)[0]  # interface name
    tlib = tinfo.GetContainingTypeLib()[0]  # typelib


@overload
def GetActiveObject(progid: _UnionT[str, CoClass, GUID]) -> Any:
    ...


@overload
def GetActiveObject(
    progid: _UnionT[str, CoClass, GUID], interface: Type[_T_IUnknown]
) -> _T_IUnknown:
    ...


def GetActiveObject(
    progid: _UnionT[str, CoClass, GUID],
    interface: Optional[Type[IUnknown]] = None,
    dynamic: bool = False,
) -> Any:
def _manage(
    obj: Any, clsid: Optional[GUID], interface: Optional[Type[IUnknown]]
) -> Any:
    obj.__dict__[""__clsid""] = str(clsid)




def GetClassObject(progid, clsctx=None, pServerInfo=None, interface=None):
@overload
def CreateObject(progid: _UnionT[str, Type[CoClass], GUID]) -> Any:
    ...


@overload
def CreateObject(
    progid: _UnionT[str, Type[CoClass], GUID],
    clsctx: Optional[int] = None,
    machine: Optional[str] = None,
    interface: Optional[Type[_T_IUnknown]] = None,
    dynamic: bool = ...,
    pServerInfo: Optional[comtypes.COSERVERINFO] = None,
) -> _T_IUnknown:
    ...


def CreateObject(
    progid: _UnionT[str, Type[CoClass], GUID],  # which object to create
    clsctx: Optional[int] = None,  # how to create the object
    machine: Optional[str] = None,  # where to create the object
    interface: Optional[Type[IUnknown]] = None,  # the interface we want
    dynamic: bool = False,  # use dynamic dispatch
    pServerInfo: Optional[
        comtypes.COSERVERINFO
    ] = None,  # server info struct for remoting
) -> Any:
        logger.debug(
            ""CoCreateInstance(%s, clsctx=%s, interface=%s)"", clsid, clsctx, interface
        )
        logger.debug(
            ""CoCreateInstanceEx(%s, clsctx=%s, interface=%s, machine=%s,\
            clsid,
            clsctx,
            interface,
            machine,
            pServerInfo,
        )
            msg = ""You cannot set both the machine name and server info.""
        obj = comtypes.CoCreateInstanceEx(
            clsid,
            clsctx=clsctx,
            interface=interface,
            machine=machine,
            pServerInfo=pServerInfo,
        )
@overload
def CoGetObject(displayname: str, interface: Type[_T_IUnknown]) -> _T_IUnknown:
    ...


@overload
def CoGetObject(displayname: str, interface: None = None, dynamic: bool = False) -> Any:
    ...


def CoGetObject(
    displayname: str,
    interface: Optional[Type[comtypes.IUnknown]] = None,
    dynamic: bool = False,
) -> Any:
    return _manage(punk, clsid=None, interface=interface)
# fmt: off
# fmt: on


        else:  # ftype in ('windows_exe', 'console_exe')

SHGetSpecialFolderPath.argtypes = [
    ctypes.c_ulong,
    ctypes.c_wchar_p,
    ctypes.c_int,
    ctypes.c_int,
]







        if isinstance(obj, str):



    clsid = source.__dict__.get(""__clsid"")
    # interface = find_single_connection_interface(source)
    # if interface:
    #     return interface


    if func.__code__.co_varnames[:2] == (""self"", ""this""):








            return comtypes.instancemethod(method, im_self, type(im_self))
def CreateEventReceiver(interface, handler):
    if issubclass(interface, comtypes.automation.IDispatch) and not hasattr(
        sink, ""_dispimpl_""
    ):







    # @ctypes.WINFUNCTYPE(ctypes.c_int, ctypes.c_uint)
        if dwCtrlType == 0:  # CTRL+C

            res = ctypes.oledll.ole32.CoWaitForMultipleHandles(
                0,
                int(timeout * 1000),
                len(handles),
                handles,
                ctypes.byref(ctypes.c_ulong()),
            )
            if details.winerror != RPC_S_CALLPENDING:  # timeout expired
from typing import Any, Tuple, List, Optional, Dict, Union as _UnionT
import winreg

from comtypes import GUID, typeinfo
def _my_import(fullname: str) -> types.ModuleType:

def _resolve_filename(tlib_string: str, dirpath: str) -> Tuple[str, bool]:
    assert isinstance(tlib_string, str)
def GetModule(tlib: _UnionT[Any, typeinfo.ITypeLib]) -> types.ModuleType:
    if isinstance(tlib, str):
        _file_: Optional[str] = frame.f_globals.get(""__file__"", None)
        pathname, is_abs = _resolve_filename(
            tlib_string, _file_ and os.path.dirname(_file_)  # type: ignore
        )
        assert not (os.path.isabs(pathname)) or os.path.exists(pathname)
    return ModuleGenerator().generate(tlib, pathname)


def _load_tlib(obj: Any) -> typeinfo.ITypeLib:
    if isinstance(obj, str):
        with winreg.OpenKey(
            winreg.HKEY_CLASSES_ROOT, r""CLSID\%s\TypeLib"" % clsid
        ) as key:
        with winreg.OpenKey(
            winreg.HKEY_CLASSES_ROOT, r""CLSID\%s\Version"" % clsid
        ) as key:
def _create_module_in_file(modulename: str, code: str) -> types.ModuleType:
def _create_module_in_memory(modulename: str, code: str) -> types.ModuleType:

class ModuleGenerator(object):
    def __init__(self) -> None:
        self.codegen = codegenerator.CodeGenerator(_get_known_symbols())

    def generate(
        self, tlib: typeinfo.ITypeLib, pathname: Optional[str]
    ) -> types.ModuleType:
        # create and import the real typelib wrapper module
        mod = self._create_wrapper_module(tlib, pathname)
        # try to get the friendly-name, if not, returns the real typelib wrapper module
        modulename = codegenerator.name_friendly_module(tlib)
        if modulename is None:
            return mod
        # create and import the friendly-named module
        return self._create_friendly_module(tlib, modulename)

    def _create_friendly_module(
        self, tlib: typeinfo.ITypeLib, modulename: str
    ) -> types.ModuleType:
        """"""helper which creates and imports the friendly-named module.""""""
        try:
            mod = _my_import(modulename)
        except Exception as details:
            logger.info(""Could not import %s: %s"", modulename, details)
        else:
            return mod
        # the module is always regenerated if the import fails
        logger.info(""# Generating %s"", modulename)
        # determine the Python module name
        modname = codegenerator.name_wrapper_module(tlib)
        code = self.codegen.generate_friendly_code(modname)
        if comtypes.client.gen_dir is None:
            return _create_module_in_memory(modulename, code)
        return _create_module_in_file(modulename, code)

    def _create_wrapper_module(
        self, tlib: typeinfo.ITypeLib, pathname: Optional[str]
    ) -> types.ModuleType:
        """"""helper which creates and imports the real typelib wrapper module.""""""
        modulename = codegenerator.name_wrapper_module(tlib)
        if modulename in sys.modules:
            return sys.modules[modulename]
        try:
            return _my_import(modulename)
        except Exception as details:
            logger.info(""Could not import %s: %s"", modulename, details)
        # generate the module since it doesn't exist or is out of date
        logger.info(""# Generating %s"", modulename)
        p = tlbparser.TypeLibParser(tlib)
        if pathname is None:
            pathname = tlbparser.get_tlib_filename(tlib)
        items = list(p.parse().values())
        code = self.codegen.generate_wrapper_code(items, filename=pathname)
        for ext_tlib in self.codegen.externals:  # generates dependency COM-lib modules
            GetModule(ext_tlib)
        if comtypes.client.gen_dir is None:
            return _create_module_in_memory(modulename, code)
        return _create_module_in_file(modulename, code)


def _get_known_symbols() -> Dict[str, str]:
    known_symbols: Dict[str, str] = {}
        ""ctypes"",
            names: List[str] = mod.__known_symbols__

from typing import Any, Dict, Optional, Set, Type, TypeVar
from comtypes import automation
from comtypes.client import lazybind
from comtypes import COMError, GUID, IUnknown, hresult as hres, _is_object

_T_IUnknown = TypeVar(""_T_IUnknown"", bound=IUnknown)

    """"""Wrap an object in a Dispatch instance, exposing methods and properties
    via fully dynamic dispatch.
    """"""
    if isinstance(obj, ctypes.POINTER(automation.IDispatch)):
        except (COMError, WindowsError):
        return lazybind.Dispatch(obj, tinfo)

    def __init__(self, _id: int, _obj: ""_Dispatch"") -> None:
    def __call__(self, *args: Any) -> Any:
    def __getitem__(self, *args: Any) -> Any:
        return self._obj._comobj.Invoke(
            self._id, *args, _invkind=automation.DISPATCH_PROPERTYGET
        )
    def __setitem__(self, *args: Any) -> None:
            self._obj._comobj.Invoke(
                self._id, *args, _invkind=automation.DISPATCH_PROPERTYPUTREF
            )
            self._obj._comobj.Invoke(
                self._id, *args, _invkind=automation.DISPATCH_PROPERTYPUT
            )

    """"""Expose methods and properties via fully dynamic dispatch.""""""

    _comobj: automation.IDispatch
    _ids: Dict[str, int]
    _methods: Set[str]

    def __init__(self, comobj: ""ctypes._Pointer[automation.IDispatch]""):
        # Tiny optimization: trying not to use GetIDsOfNames more than once
        self.__dict__[""_ids""] = {}
    def __enum(self) -> automation.IEnumVARIANT:
        e: IUnknown = self._comobj.Invoke(-4)  # DISPID_NEWENUM
        return e.QueryInterface(automation.IEnumVARIANT)
    def __hash__(self) -> int:
    def __getitem__(self, index: Any) -> Any:
    def QueryInterface(
        self, interface: Type[_T_IUnknown], iid: Optional[GUID] = None
    ) -> _T_IUnknown:
        """"""QueryInterface is forwarded to the real com object.""""""
        return self._comobj.QueryInterface(interface, iid)
    def _FlagAsMethod(self, *names: str) -> None:
    def __getattr__(self, name: str) -> Any:
        # tc = self._comobj.GetTypeInfo(0).QueryInterface(comtypes.typeinfo.ITypeComp)
        # dispid = tc.Bind(name)[1].memid
        flags = automation.DISPATCH_PROPERTYGET
            (hresult, _, _) = err.args
                raise err
    def __setattr__(self, name: str, value: Any) -> None:
    def __iter__(self) -> ""_Collection"":
    # def __setitem__(self, index, value):
    #     self._comobj.Invoke(
    #         -3,
    #         index,
    #         value,
    #         _invkind=automation.DISPATCH_PROPERTYPUT
    #         | automation.DISPATCH_PROPERTYPUTREF,
    #     )

    def __init__(self, enum: automation.IEnumVARIANT):
    def __next__(self) -> Any:
        item, fetched = self.enum.Next(1)
        if fetched:
            return item
        raise StopIteration



            return self.disp._comobj._invoke(self.get.memid, self.get.invkind, 0, *arg)
            return self.disp._comobj._invoke(self.get.memid, self.get.invkind, 0)
        return self.disp._comobj._invoke(self.get.memid, self.get.invkind, 0, *[arg])
        return self.disp._comobj._invoke(self.get.memid, self.get.invkind, 0, *args)
            self.disp._comobj._invoke(descr.memid, descr.invkind, 0, *(name + (value,)))
            self.disp._comobj._invoke(descr.memid, descr.invkind, 0, value)
            self.disp._comobj._invoke(descr.memid, descr.invkind, 0, name, value)
        """"""Explicitly disallow iteration.""""""


        # self.__dict__[""_iid""] = tinfo.GetTypeAttr().guid
                info = FuncDesc(
                    memid=descr.memid,
                    invkind=descr.invkind,
                    cParams=descr.cParams,
                    funckind=descr.funckind,
                )
        return isinstance(other, Dispatch) and self._comobj == other._comobj

        return self._comobj._invoke(
            DISPID_VALUE, DISPATCH_METHOD | DISPATCH_PROPERTYGET, 0, *args
        )
            return self._comobj._invoke(
                DISPID_VALUE, DISPATCH_METHOD | DISPATCH_PROPERTYGET, 0, *args
            )
        return self._comobj._invoke(DISPID_VALUE, invkind, 0, *args)
        punk = self._comobj._invoke(
            DISPID_NEWENUM, DISPATCH_METHOD | DISPATCH_PROPERTYGET, 0
        )


        (""pUnk"", POINTER(IUnknown)),
        (""dwCookie"", c_ulong),



    _iid_ = GUID(""{B196B284-BAB4-101A-B69C-00AA00341D07}"")

    _iid_ = GUID(""{B196B286-BAB4-101A-B69C-00AA00341D07}"")

    _iid_ = GUID(""{B196B287-BAB4-101A-B69C-00AA00341D07}"")
    def __next__(self):
        cp, fetched = self.Next(1)
        if fetched == 0:
            raise StopIteration
        return cp

    _iid_ = GUID(""{B196B285-BAB4-101A-B69C-00AA00341D07}"")
    def __next__(self):
        cp, fetched = self.Next(1)
        if fetched == 0:
            raise StopIteration
        return cp

    COMMETHOD(
        [],
        HRESULT,
        ""EnumConnectionPoints"",
        ([""out""], POINTER(POINTER(IEnumConnectionPoints)), ""ppEnum""),
    ),
    COMMETHOD(
        [],
        HRESULT,
        ""FindConnectionPoint"",
        ([""in""], POINTER(_GUID), ""riid""),
        ([""out""], POINTER(POINTER(IConnectionPoint)), ""ppCP""),
    ),
    COMMETHOD([], HRESULT, ""GetConnectionInterface"", ([""out""], POINTER(_GUID), ""pIID"")),
    COMMETHOD(
        [],
        HRESULT,
        ""GetConnectionPointContainer"",
        ([""out""], POINTER(POINTER(IConnectionPointContainer)), ""ppCPC""),
    ),
    COMMETHOD(
        [],
        HRESULT,
        ""Advise"",
        ([""in""], POINTER(IUnknown), ""pUnkSink""),
        ([""out""], POINTER(c_ulong), ""pdwCookie""),
    ),
    COMMETHOD([], HRESULT, ""Unadvise"", ([""in""], c_ulong, ""dwCookie"")),
    COMMETHOD(
        [],
        HRESULT,
        ""EnumConnections"",
        ([""out""], POINTER(POINTER(IEnumConnections)), ""ppEnum""),
    ),
    COMMETHOD(
        [],
        HRESULT,
        ""Next"",
        ([""in""], c_ulong, ""cConnections""),
        ([""out""], POINTER(tagCONNECTDATA), ""rgcd""),
        ([""out""], POINTER(c_ulong), ""pcFetched""),
    ),
    COMMETHOD([], HRESULT, ""Skip"", ([""in""], c_ulong, ""cConnections"")),
    COMMETHOD([], HRESULT, ""Reset""),
    COMMETHOD(
        [], HRESULT, ""Clone"", ([""out""], POINTER(POINTER(IEnumConnections)), ""ppEnum"")
    ),
    COMMETHOD(
        [],
        HRESULT,
        ""Next"",
        ([""in""], c_ulong, ""cConnections""),
        ([""out""], POINTER(POINTER(IConnectionPoint)), ""ppCP""),
        ([""out""], POINTER(c_ulong), ""pcFetched""),
    ),
    COMMETHOD([], HRESULT, ""Skip"", ([""in""], c_ulong, ""cConnections"")),
    COMMETHOD([], HRESULT, ""Reset""),
    COMMETHOD(
        [],
        HRESULT,
        ""Clone"",
        ([""out""], POINTER(POINTER(IEnumConnectionPoints)), ""ppEnum""),
    ),
        COMMETHOD([], HRESULT, ""SetGUID"", ([""in""], POINTER(GUID), ""rguid"")),
        COMMETHOD([], HRESULT, ""SetSource"", ([""in""], LPCOLESTR, ""szSource"")),
        COMMETHOD([], HRESULT, ""SetDescription"", ([""in""], LPCOLESTR, ""szDescription"")),
        COMMETHOD([], HRESULT, ""SetHelpFile"", ([""in""], LPCOLESTR, ""szHelpFile"")),
        COMMETHOD([], HRESULT, ""SetHelpContext"", ([""in""], DWORD, ""dwHelpContext"")),
    ]

        COMMETHOD([], HRESULT, ""GetGUID"", ([""out""], POINTER(GUID), ""pGUID"")),
        COMMETHOD([], HRESULT, ""GetSource"", ([""out""], POINTER(BSTR), ""pBstrSource"")),
        COMMETHOD(
            [], HRESULT, ""GetDescription"", ([""out""], POINTER(BSTR), ""pBstrDescription"")
        ),
        COMMETHOD(
            [], HRESULT, ""GetHelpFile"", ([""out""], POINTER(BSTR), ""pBstrHelpFile"")
        ),
        COMMETHOD(
            [], HRESULT, ""GetHelpContext"", ([""out""], POINTER(DWORD), ""pdwHelpContext"")
        ),
    ]

        COMMETHOD(
            [], HRESULT, ""InterfaceSupportsErrorInfo"", ([""in""], POINTER(GUID), ""riid"")
        )
    ]





def ReportError(
    text, iid, clsid=None, helpfile=None, helpcontext=0, hresult=DISP_E_EXCEPTION
):
        if isinstance(clsid, str):
            ei.SetSource(
                progid
            )  # progid for the class or application that created the error

def ReportException(
    hresult, iid, clsid=None, helpfile=None, helpcontext=None, stacklevel=None
):
    return ReportError(
        text,
        iid,
        clsid=clsid,
        helpfile=helpfile,
        helpcontext=helpcontext,
        hresult=hresult,
    )

# fmt: off
__all__ = [
    ""ICreateErrorInfo"", ""IErrorInfo"", ""ISupportErrorInfo"", ""ReportError"",
    ""ReportException"", ""SetErrorInfo"", ""GetErrorInfo"", ""CreateErrorInfo"",
]
# fmt: on
from comtypes import (
    IUnknown,
    STDMETHOD,
    COMMETHOD,
    GUID,
    HRESULT,
    CoCreateInstance,
    CLSCTX_INPROC_SERVER,
)

        STDMETHOD(
            HRESULT,
            ""RegisterInterfaceInGlobal"",
            [POINTER(IUnknown), POINTER(GUID), POINTER(DWORD)],
        ),
        STDMETHOD(
            HRESULT,
            ""GetInterfaceFromGlobal"",
            [DWORD, POINTER(GUID), POINTER(POINTER(IUnknown))],
        ),
    ]
git = CoCreateInstance(
    CLSID_StdGlobalInterfaceTable,
    interface=IGlobalInterfaceTable,
    clsctx=CLSCTX_INPROC_SERVER,
)
# fmt: off
__all__ = [
    ""RegisterInterfaceInGlobal"", ""RevokeInterfaceFromGlobal"",
    ""GetInterfaceFromGlobal"",
]
# fmt: on

    tlib = CreateTypeLib(""foo.bar"")  # we don not save it later
E_UNEXPECTED = -2147418113  # 0x8000FFFFL
E_NOTIMPL = -2147467263  # 0x80004001L
E_NOINTERFACE = -2147467262  # 0x80004002L
E_POINTER = -2147467261  # 0x80004003L
E_FAIL = -2147467259  # 0x80004005L
E_INVALIDARG = -2147024809  # 0x80070057L
E_OUTOFMEMORY = -2147024882  # 0x8007000EL
CLASS_E_NOAGGREGATION = -2147221232  # 0x80040110L
CLASS_E_CLASSNOTAVAILABLE = -2147221231  # 0x80040111L
CO_E_CLASSSTRING = -2147221005  # 0x800401F3L
TYPE_E_ELEMENTNOTFOUND = -2147352077  # 0x8002802BL
TYPE_E_REGISTRYACCESS = -2147319780  # 0x8002801CL
TYPE_E_CANTLOADLIBRARY = -2147312566  # 0x80029C4AL
DISP_E_PARAMNOTOPTIONAL = -2147352561  # 0x8002000F
DISP_E_BADPARAMCOUNT = -2147352562  # 0x8002000E
DISP_E_ARRAYISLOCKED = -2147352563  # 0x8002000D
DISP_E_UNKNOWNLCID = -2147352564  # 0x8002000C
DISP_E_BADINDEX = -2147352565  # 0x8002000B
DISP_E_OVERFLOW = -2147352566  # 0x8002000A
DISP_E_EXCEPTION = -2147352567  # 0x80020009
DISP_E_BADVARTYPE = -2147352568  # 0x80020008
DISP_E_NONAMEDARGS = -2147352569  # 0x80020007
DISP_E_UNKNOWNNAME = -2147352570  # 0x80020006
DISP_E_TYPEMISMATCH = -2147352571  # 0800020005
DISP_E_PARAMNOTFOUND = -2147352572  # 0x80020004
DISP_E_MEMBERNOTFOUND = -2147352573  # 0x80020003
DISP_E_UNKNOWNINTERFACE = -2147352575  # 0x80020001

RPC_E_CHANGED_MODE = -2147417850  # 0x80010106
RPC_E_SERVERFAULT = -2147417851  # 0x80010105






    def emit(
        self,
        record,
        writeA=ctypes.windll.kernel32.OutputDebugStringA,
        writeW=ctypes.windll.kernel32.OutputDebugStringW,
    ):
            writeW(text + ""\n"")



    parser.optionxform = str  # use case sensitive option names!
    DEFAULTS = {
        ""handler"": ""StreamHandler()"",
        ""format"": ""%(levelname)s:%(name)s:%(message)s"",
        ""level"": ""WARNING"",
    }

                return  # got WM_QUIT

            no_replace = getattr(value, ""__no_replace"", False)



    _iid_ = GUID(""{3127CA40-446E-11CE-8135-00AA004BB851}"")
        COMMETHOD(
            [],
            HRESULT,
            ""AddError"",
            ([""in""], WSTRING, ""pszPropName""),
            ([""in""], POINTER(tagEXCEPINFO), ""pExcepInfo""),
        ),
    ]

    _iid_ = GUID(""{55272A00-42CB-11CE-8135-00AA004BB851}"")
        COMMETHOD(
            [],
            HRESULT,
            ""Read"",
            ([""in""], WSTRING, ""pszPropName""),
            ([""in"", ""out""], POINTER(VARIANT), ""pVar""),
            ([""in""], POINTER(IErrorLog), ""pErrorLog""),
            # ( ['in', 'out'], POINTER(IErrorLog), 'pErrorLog' ),
        ),
        COMMETHOD(
            [],
            HRESULT,
            ""Write"",
            ([""in""], WSTRING, ""pszPropName""),
            ([""in""], POINTER(VARIANT), ""pVar""),
        ),
    ]

    _iid_ = GUID(""{37D84F60-42CB-11CE-8135-00AA004BB851}"")
        COMMETHOD([], HRESULT, ""InitNew""),
        COMMETHOD(
            [],
            HRESULT,
            ""Load"",
            ([""in""], POINTER(IPropertyBag), ""pPropBag""),
            ([""in""], POINTER(IErrorLog), ""pErrorLog""),
        ),
        COMMETHOD(
            [],
            HRESULT,
            ""Save"",
            ([""in""], POINTER(IPropertyBag), ""pPropBag""),
            ([""in""], c_int, ""fClearDirty""),
            ([""in""], c_int, ""fSaveAllProperties""),
        ),
    ]

        (""dwType"", c_ulong),
        (""vt"", c_ushort),
        (""cfType"", CLIPFORMAT),
        (""dwHint"", c_ulong),
        (""pstrName"", WSTRING),
        (""clsid"", GUID),
    ]

    _iid_ = GUID(""{22F55882-280B-11D0-A8A9-00A0C90C2004}"")
        COMMETHOD(
            [],
            HRESULT,
            ""Read"",
            ([""in""], c_ulong, ""cProperties""),
            ([""in""], POINTER(tagPROPBAG2), ""pPropBag""),
            ([""in""], POINTER(IErrorLog), ""pErrLog""),
            ([""out""], POINTER(VARIANT), ""pvarValue""),
            ([""out""], POINTER(HRESULT), ""phrError""),
        ),
        COMMETHOD(
            [],
            HRESULT,
            ""Write"",
            ([""in""], c_ulong, ""cProperties""),
            ([""in""], POINTER(tagPROPBAG2), ""pPropBag""),
            ([""in""], POINTER(VARIANT), ""pvarValue""),
        ),
        COMMETHOD(
            [], HRESULT, ""CountProperties"", ([""out""], POINTER(c_ulong), ""pcProperties"")
        ),
        COMMETHOD(
            [],
            HRESULT,
            ""GetPropertyInfo"",
            ([""in""], c_ulong, ""iProperty""),
            ([""in""], c_ulong, ""cProperties""),
            ([""out""], POINTER(tagPROPBAG2), ""pPropBag""),
            ([""out""], POINTER(c_ulong), ""pcProperties""),
        ),
        COMMETHOD(
            [],
            HRESULT,
            ""LoadObject"",
            ([""in""], WSTRING, ""pstrName""),
            ([""in""], c_ulong, ""dwHint""),
            ([""in""], POINTER(IUnknown), ""punkObject""),
            ([""in""], POINTER(IErrorLog), ""pErrLog""),
        ),
    ]

    _iid_ = GUID(""{22F55881-280B-11D0-A8A9-00A0C90C2004}"")
        COMMETHOD([], HRESULT, ""InitNew""),
        COMMETHOD(
            [],
            HRESULT,
            ""Load"",
            ([""in""], POINTER(IPropertyBag2), ""pPropBag""),
            ([""in""], POINTER(IErrorLog), ""pErrLog""),
        ),
        COMMETHOD(
            [],
            HRESULT,
            ""Save"",
            ([""in""], POINTER(IPropertyBag2), ""pPropBag""),
            ([""in""], c_int, ""fClearDirty""),
            ([""in""], c_int, ""fSaveAllProperties""),
        ),
        COMMETHOD([], HRESULT, ""IsDirty""),
    ]

    _iid_ = GUID(""{0000010B-0000-0000-C000-000000000046}"")
        COMMETHOD([], HRESULT, ""IsDirty""),
        COMMETHOD(
            [],
            HRESULT,
            ""Load"",
            ([""in""], LPCOLESTR, ""pszFileName""),
            ([""in""], DWORD, ""dwMode""),
        ),
        COMMETHOD(
            [],
            HRESULT,
            ""Save"",
            ([""in""], LPCOLESTR, ""pszFileName""),
            ([""in""], BOOL, ""fRemember""),
        ),
        COMMETHOD([], HRESULT, ""SaveCompleted"", ([""in""], LPCOLESTR, ""pszFileName"")),
        COMMETHOD(
            [], HRESULT, ""GetCurFile"", ([""out""], POINTER(LPOLESTR), ""ppszFileName"")
        ),
    ]



# fmt: off
    ""CLIPFORMAT"", ""DictPropertyBag"", ""IErrorLog"", ""IPersistFile"",
    ""IPersistPropertyBag"", ""IPersistPropertyBag2"", ""IPropertyBag"",
    ""IPropertyBag2"", ""tagPROPBAG2"", ""PROPBAG2_TYPE_DATA"",
    ""PROPBAG2_TYPE_MONIKER"", ""PROPBAG2_TYPE_OBJECT"", ""PROPBAG2_TYPE_STORAGE"",
    ""PROPBAG2_TYPE_STREAM"", ""PROPBAG2_TYPE_UNDEFINED"", ""PROPBAG2_TYPE_URL"",
    ""STGM_CONVERT"", ""STGM_CREATE"", ""STGM_DELETEONRELEASE"", ""STGM_DIRECT"",
    ""STGM_DIRECT_SWMR"", ""STGM_FAILIFTHERE"", ""STGM_NOSCRATCH"",
    ""STGM_NOSNAPSHOT"", ""STGM_PRIORITY"", ""STGM_READ"", ""STGM_READWRITE"",
    ""STGM_SHARE_DENY_NONE"", ""STGM_SHARE_DENY_READ"", ""STGM_SHARE_DENY_WRITE"",
    ""STGM_SHARE_EXCLUSIVE"", ""STGM_SIMPLE"", ""STGM_TRANSACTED"", ""STGM_WRITE"",
# fmt: on
from ctypes import POINTER, Structure, byref, cast, c_long, memmove, pointer, sizeof
    """"""Context manager allowing safe arrays to be extracted as ndarrays.
    """"""

        """"""True if context manager is currently entered on given thread.""""""
        return bool(getattr(self.thread_local, ""count"", 0))
    __nonzero__ = __bool__  # for Py2.7 compatibility
    from comtypes.automation import (
        _ctype_to_vartype,
        VT_RECORD,
        VT_UNKNOWN,
        IDispatch,
        VT_DISPATCH,
    )
    sa_type = meta.__new__(
        meta, ""SAFEARRAY_%s"" % itemtype.__name__, (_safearray.tagSAFEARRAY,), {}
    )

            pa = _safearray.SafeArrayCreateVectorEx(cls._vartype_, 0, len(value), extra)
                    raise TypeError(
                        ""Cannot create SAFEARRAY type VT_RECORD without IRecordInfo.""
                    )

            pa = _safearray.SafeArrayCreateEx(
                cls._vartype_, value.ndim, rgsa, extra  # cDims  # rgsaBound
            )  # pvExtra
                    raise TypeError(
                        ""Cannot create SAFEARRAY type VT_RECORD without IRecordInfo.""
                    )
            # print ""__setitem__"", index, value
                    return (
                        comtypes.npsupport.numpy.asarray(result).reshape((cols, rows)).T
                    )
                lowerbounds = [
                    _safearray.SafeArrayGetLBound(self, d) for d in range(1, dim + 1)
                ]
                upperbounds = [
                    _safearray.SafeArrayGetUBound(self, d) for d in range(1, dim + 1)
                ]

                        if safearray_as_ndarray and self._itemtype_ in list(
                            comtypes.npsupport.typecodes.keys()
                        ):
                            arr = comtypes.npsupport.numpy.ctypeslib.as_array(
                                ptr, (num_elements,)
                            )

            if dim + 1 == len(indices):
                for i in range(indices[dim], upperbounds[dim] + 1):
                for i in range(indices[dim], upperbounds[dim] + 1):
                    result.append(
                        self._get_row(dim + 1, indices, lowerbounds, upperbounds)
                    )
            return tuple(result)  # for compatibility with pywin32.
    """"""Convert an ndarray to VARIANT_dtype array""""""

    varr = numpy.zeros(value.shape, comtypes.npsupport.interop.VARIANT_dtype, order=""F"")
    """"""Convert an ndarray of datetime64 to VARIANT_dtype array""""""

    value = value / numpy.timedelta64(1, ""D"")
    varr = numpy.zeros(value.shape, comtypes.npsupport.interop.VARIANT_dtype, order=""F"")
    varr[""vt""] = VT_DATE
    varr[""_""][""VT_R8""].flat = value.flat
        comtypes.STDMETHOD(
            comtypes.HRESULT,
            ""CreateInstance"",
            [
                ctypes.POINTER(comtypes.IUnknown),
                ctypes.POINTER(comtypes.GUID),
                ctypes.POINTER(ctypes.c_void_p),
            ],
        ),
        comtypes.STDMETHOD(comtypes.HRESULT, ""LockServer"", [ctypes.c_int]),
    ]

# class IExternalConnection(IUnknown):
#     _iid_ = GUID(""{00000019-0000-0000-C000-000000000046}"")
#     _methods_ = [
#         STDMETHOD(HRESULT, ""AddConnection"", [c_ulong, c_ulong]),
#         STDMETHOD(HRESULT, ""ReleaseConnection"", [c_ulong, c_ulong, c_ulong])]
ACTIVEOBJECT_WEAK = 0x1

    oleaut32.RegisterActiveObject(
        punk, ctypes.byref(clsid), flags, ctypes.byref(handle)
    )


        self.items = (
            items  # keep, so that we can restore our iterator (in Reset, and Clone).
        )
        if not rgVar:
            return E_POINTER
        if not pCeltFetched:
            pCeltFetched = [None]
        # except:
        #     # ReportException? return E_FAIL?
        #     import traceback
        #     traceback.print_exc()



        return item.IUnknown_QueryInterface(None, pointer(pitem[0]._iid_), pitem)
        return enum.IUnknown_QueryInterface(None, pointer(IUnknown._iid_), penum)



                        logger.warning(
                            ""_call_sinks(%s, %s, *%s, **%s) failed; removing connection"",
                            self,
                            name,
                            args,
                            kw,
                            exc_info=True,
                        )
                            pass  # connection already gone
                        logger.warning(
                            ""_call_sinks(%s, %s, *%s, **%s)"",
                            self,
             ",bug-free
"    self.maxDiff = 100000  # pylint: disable=invalid-name
    self.maxDiff = 100000  # pylint: disable=invalid-name
    self.maxDiff = 100000  # pylint: disable=invalid-name",buggy
"    self.maxDiff = 100000
    self.maxDiff = 100000
    self.maxDiff = 100000",bug-free
"    self.maxDiff = 100000  # pylint: disable=invalid-name
    self.maxDiff = 100000  # pylint: disable=invalid-name
    self.maxDiff = 100000  # pylint: disable=invalid-name",buggy
"    self.maxDiff = 100000
    self.maxDiff = 100000
    self.maxDiff = 100000",bug-free
"        @put(""/user/repos"")
        def add_event(self, **event_data: FieldMap):
        @post(""/attachments"")
        def upload_attachments(self, **files: PartMap):
from collections import abc
# Standard library imports
from collections import abc

# Standard library imports
from collections import abc

class Executable(abc.Iterator):
from collections import abc
__all__ = [""reraise""]
# Standard library imports
from collections import abc

from collections import abc
from collections import abc",buggy
"        @put(""/user/repos"", args={""event_data"": FieldMap})
        def add_event(self, **event_data):
        @post(""/attachments"", args={""files"": PartMap})
        def upload_attachments(self, **files):
from uplink.compat import abc
from uplink.compat import abc
class Executable(compat.abc.Iterator):
from uplink.compat import abc
__all__ = [""abc"", ""reraise""]
abc = six.moves.collections_abc
from uplink.compat import abc
from uplink.compat import abc
from uplink.compat import abc",bug-free
"    ""tests"": [""pytest==4.6.5"", ""pytest-mock"", ""pytest-cov"", ""pytest-twisted""],",buggy
"    ""tests"": [""pytest"", ""pytest-mock"", ""pytest-cov"", ""pytest-twisted""],",bug-free
"from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
            ""sample_batch_size"": 1,
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
            ""sample_batch_size"": 50,
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
from ray.tests.utils import run_string_as_driver
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
ray.init(redis_address=""{}"")
"""""".format(cluster.redis_address, num_nodes)
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
    return 1
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

from ray.tests.cluster_utils import Cluster
        redis_max_memory=redis_max_memory)
ray.init(redis_address=cluster.redis_address)
    command = [""git"", ""diff"", ""--name-only"", commit_range]
    RAY_CI_RLLIB_AFFECTED = 0
    if os.environ[""TRAVIS_EVENT_TYPE""] == ""pull_request"":
        files = list_changed_files(os.environ[""TRAVIS_COMMIT_RANGE""].replace(
            ""..."", ""..""))
            if changed_file.startswith(""python/ray/tune/""):
            elif changed_file.startswith(""python/ray/rllib/""):
    print(""export RAY_CI_TUNE_AFFECTED={}"".format(RAY_CI_TUNE_AFFECTED))
    print(""export RAY_CI_RLLIB_AFFECTED={}"".format(RAY_CI_RLLIB_AFFECTED))
    print(""export RAY_CI_JAVA_AFFECTED={}"".format(RAY_CI_JAVA_AFFECTED))
    print(""export RAY_CI_PYTHON_AFFECTED={}"".format(RAY_CI_PYTHON_AFFECTED))
    print(""export RAY_CI_LINUX_WHEELS_AFFECTED={}""
          .format(RAY_CI_LINUX_WHEELS_AFFECTED))
    print(""export RAY_CI_MACOS_WHEELS_AFFECTED={}""
          .format(RAY_CI_MACOS_WHEELS_AFFECTED))
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function

    mat = np.array([[[2.0, 2.0], [2.0, 2.0]], [[2.0, 2.0], [2.0, 2.0]]],
                   dtype=np.float32)
    run_func(cyth.compute_kernel_matrix,
             ""L"",
             ""T"",
             2,
             2,
             1.0,
             mat,
             0,
             2,
             1.0,
             result,
             2
             )",buggy
"from ray.cluster_utils import Cluster
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
from ray.cluster_utils import Cluster
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
            ""rollout_fragment_length"": 1,
from ray.cluster_utils import Cluster
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
            ""rollout_fragment_length"": 50,
import numpy as np

from ray.cluster_utils import Cluster
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
        return np.zeros(1024, dtype=np.uint8)
from ray.cluster_utils import Cluster
from ray.test_utils import run_string_as_driver
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
ray.init(address=""{}"")
"""""".format(cluster.address, num_nodes)
import numpy as np

from ray.cluster_utils import Cluster
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
    return np.zeros(1024, dtype=np.uint8)
from ray.cluster_utils import Cluster
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
from ray.cluster_utils import Cluster
        redis_max_memory=redis_max_memory,
        webui_host=""0.0.0.0"")
ray.init(address=cluster.address)
import json
import re
import sys
from pprint import pformat
    command = [""git"", ""diff"", ""--name-only"", commit_range, ""--""]
    RAY_CI_ONLY_RLLIB_AFFECTED = 0  # Whether only RLlib is affected.
    RAY_CI_RLLIB_AFFECTED = 0  # Whether RLlib minimal tests should be run.
    RAY_CI_RLLIB_FULL_AFFECTED = 0  # Whether full RLlib tests should be run.
    RAY_CI_SERVE_AFFECTED = 0
    RAY_CI_STREAMING_CPP_AFFECTED = 0
    RAY_CI_STREAMING_PYTHON_AFFECTED = 0
    RAY_CI_STREAMING_JAVA_AFFECTED = 0
    event_type = None
    for key in [""GITHUB_EVENT_NAME"", ""TRAVIS_EVENT_TYPE""]:
        event_type = os.getenv(key, event_type)
    if event_type == ""pull_request"":

        commit_range = os.getenv(""TRAVIS_COMMIT_RANGE"")
        if commit_range is None:
            with open(os.environ[""GITHUB_EVENT_PATH""], ""rb"") as f:
                event = json.loads(f.read())
            base = event[""pull_request""][""base""][""sha""]
            commit_range = ""{}...{}"".format(base, event.get(""after"", """"))
        files = list_changed_files(commit_range)

        print(pformat(files), file=sys.stderr)
            if changed_file.startswith(""python/ray/tune""):
                RAY_CI_RLLIB_FULL_AFFECTED = 1
            elif re.match(""^(python/ray/)?rllib/"", changed_file):
                RAY_CI_RLLIB_FULL_AFFECTED = 1
                RAY_CI_LINUX_WHEELS_AFFECTED = 1
                RAY_CI_MACOS_WHEELS_AFFECTED = 1
            elif changed_file.startswith(""python/ray/serve""):
                RAY_CI_SERVE_AFFECTED = 1
                RAY_CI_SERVE_AFFECTED = 1
                RAY_CI_STREAMING_PYTHON_AFFECTED = 1
                RAY_CI_STREAMING_JAVA_AFFECTED = 1
                RAY_CI_SERVE_AFFECTED = 1
                RAY_CI_STREAMING_CPP_AFFECTED = 1
                RAY_CI_STREAMING_PYTHON_AFFECTED = 1
                RAY_CI_STREAMING_JAVA_AFFECTED = 1
            elif changed_file.startswith(""streaming/src""):
                RAY_CI_STREAMING_CPP_AFFECTED = 1
                RAY_CI_STREAMING_PYTHON_AFFECTED = 1
                RAY_CI_STREAMING_JAVA_AFFECTED = 1
            elif changed_file.startswith(""streaming/python""):
                RAY_CI_STREAMING_PYTHON_AFFECTED = 1
            elif changed_file.startswith(""streaming/java""):
                RAY_CI_STREAMING_JAVA_AFFECTED = 1
                RAY_CI_SERVE_AFFECTED = 1
                RAY_CI_STREAMING_CPP_AFFECTED = 1
                RAY_CI_STREAMING_PYTHON_AFFECTED = 1
                RAY_CI_STREAMING_JAVA_AFFECTED = 1
        RAY_CI_RLLIB_FULL_AFFECTED = 1
        RAY_CI_SERVE_AFFECTED = 1
        RAY_CI_STREAMING_CPP_AFFECTED = 1
        RAY_CI_STREAMING_PYTHON_AFFECTED = 1
        RAY_CI_STREAMING_JAVA_AFFECTED = 1

    if not RAY_CI_TUNE_AFFECTED and not RAY_CI_SERVE_AFFECTED and \
            not RAY_CI_JAVA_AFFECTED and not RAY_CI_PYTHON_AFFECTED and not \
            RAY_CI_STREAMING_CPP_AFFECTED and \
            not RAY_CI_STREAMING_PYTHON_AFFECTED and \
            not RAY_CI_STREAMING_JAVA_AFFECTED:
        RAY_CI_ONLY_RLLIB_AFFECTED = 1
    # Log the modified environment variables visible in console.
    print("" "".join([
        ""RAY_CI_TUNE_AFFECTED={}"".format(RAY_CI_TUNE_AFFECTED),
        ""RAY_CI_ONLY_RLLIB_AFFECTED={}"".format(RAY_CI_ONLY_RLLIB_AFFECTED),
        ""RAY_CI_RLLIB_AFFECTED={}"".format(RAY_CI_RLLIB_AFFECTED),
        ""RAY_CI_RLLIB_FULL_AFFECTED={}"".format(RAY_CI_RLLIB_FULL_AFFECTED),
        ""RAY_CI_SERVE_AFFECTED={}"".format(RAY_CI_SERVE_AFFECTED),
        ""RAY_CI_JAVA_AFFECTED={}"".format(RAY_CI_JAVA_AFFECTED),
        ""RAY_CI_PYTHON_AFFECTED={}"".format(RAY_CI_PYTHON_AFFECTED),
        ""RAY_CI_LINUX_WHEELS_AFFECTED={}"".format(RAY_CI_LINUX_WHEELS_AFFECTED),
        ""RAY_CI_MACOS_WHEELS_AFFECTED={}"".format(RAY_CI_MACOS_WHEELS_AFFECTED),
        ""RAY_CI_STREAMING_CPP_AFFECTED={}"".format(
            RAY_CI_STREAMING_CPP_AFFECTED),
        ""RAY_CI_STREAMING_PYTHON_AFFECTED={}"".format(
            RAY_CI_STREAMING_PYTHON_AFFECTED),
        ""RAY_CI_STREAMING_JAVA_AFFECTED={}"".format(
            RAY_CI_STREAMING_JAVA_AFFECTED),
    ]))
    mat = np.array(
        [[[2.0, 2.0], [2.0, 2.0]], [[2.0, 2.0], [2.0, 2.0]]], dtype=np.float32)
    run_func(cyth.compute_kernel_matrix, ""L"", ""T"", 2, 2, 1.0, mat, 0, 2, 1.0,
             result, 2)",bug-free
"        u'EN-English': u'en-US',
        u'FR-Français': u'fr-FR',
        u'DE-Deutsch': u'de-DE'
    prompt = _(""What is your email password?"") + "": ""
    if(get_profile_var(profile, [""email"", ""password""])):
        prompt += default_text(
            _(""(just press enter to keep current password)"")
        ) + default_prompt()
    temp = getpass(
        format_prompt(
            ""?"",
            prompt
    )
    if(temp):
        set_profile_var(profile, ['email', 'password'], temp)
    if(get_profile_var(profile, ['active_stt', 'engine']) == 'watson-stt'):
    if(
    if(get_profile_var(profile, ['active_stt', 'engine']) == 'julius-stt'):",buggy
"        u'EN-English': 'en-US',
        u'FR-Français': 'fr-FR',
        u'DE-Deutsch': 'de-DE'
    if(get_profile_var(profile, [""email"", ""address""])):
        prompt = _(""What is your email password?"") + "": ""
        if(get_profile_var(profile, [""email"", ""password""])):
            prompt += default_text(
                _(""(just press enter to keep current password)"")
            ) + default_prompt()
        temp = getpass(
            format_prompt(
                ""?"",
                prompt
            )
        if(temp):
            set_profile_var(profile, ['email', 'password'], temp)
    elif(get_profile_var(profile, ['active_stt', 'engine']) == 'watson-stt'):
    elif(
    elif(get_profile_var(profile, ['active_stt', 'engine']) == 'julius-stt'):
    elif(get_profile_var(profile, ['active_stt', 'engine']) == 'witai-stt'):
        witai_token = simple_input(
            format_prompt(
                ""!"",
                _(""Please enter your Wit.AI token"")
            ),
            get_profile_var(profile,[""witai-stt"", ""access_token""])
        )
        set_profile_var(profile, [""witai-stt"", ""access_token""], witai_token)        ",bug-free
"        if lines and lines[0].startswith("">>> ""):
            return '\n'.join(line[4:] for line in lines)

        return snippet",buggy
"        parser.add_flag(""py-remove-empty-lines"", help=""enable the deletion of empty lines (enabled by default)."")
        if lines and lines[0].startswith("">>>""):
            # all the lines starts with a prompt
            ok = all(l.startswith("">>>"") or l.startswith(""..."") for l in lines)
            if not ok:
                raise ValueError(""Incorrect prompts"")

            # a space follows a prompt except when the line is just a prompt
            ok = all(l[3] == ' ' for l in lines if len(l) >= 4)
            if not ok:
                raise ValueError(""Missing space after the prompt"")

            # remove the prompts
            lines = (l[4:] for l in lines)

        if self.options.get('py_remove_empty_lines', True):
            # remove the empty lines if they are followed by indented lines
            # if they are followed by non-indented lines, the empty lines means
            # ""end the block"" of code and they should not be removed or we will
            # have SyntaxError
            filtered = []
            lines = list(lines)
            for i, line in enumerate(lines[:-1]):
                if line or (not lines[i+1].startswith("" "") and lines[i+1]):
                    filtered.append(line)

            filtered.append(lines[-1])
            lines = filtered

        out = '\n'.join(lines)
        return out",bug-free
"            print('Replaced {} with {}'.format(old, new), file=sys.stderr)",buggy
"            print('Replaced {} with {}'.format(old, new), file=sys.stderr)  # noqa",bug-free
"a=1;b=2
c=a+b
BROKEN_VAR=BROKEN_VAR",buggy
"import pandas
import numpy as np

c = 1 + 2",bug-free
"from .whiteutils import commonPrefix, reindentBlock, whitePrefix
    def parseMarker(self, line):
    def parseLine(self, line):
    def getCode(self):
        prefIn = commonPrefix(self.markers + self.lines)
        if prefIn:
            self.markers = [line.replace(prefIn, """", 1) for line in self.markers]
            self.lines = [line.replace(prefIn, """", 1) for line in self.lines]
        return reindentBlock(self.lines, """")
        prefOut = whitePrefix(self.markers)
        intext = self.getCode()
        if self.options.printOutput:
        if self.options.printOutput:
        return reindentBlock(self.outstring, prefOut)
            sOut = reindentBlock(sOut)
        self.includePath = []
        self.showVersion = False
        self.makeWritableCmd = None
        self.noGenerate = False
        self.outputName = None
        self.warnEmpty = False
        self.hashOutput = False
        self.deleteCode = False
        self.eofCanBeEnd = False
        self.beginSpec = ""[[[cog""
        self.endSpec = ""]]]""
        self.endOutput = ""[[[end]]]""
        self.printOutput = False
    def addToIncludePath(self, dirs):
        self.includePath.extend(dirs)
    def parseArgs(self, argv):
                self.hashOutput = True
                self.deleteCode = True
                self.warnEmpty = True
                self.addToIncludePath(os.path.abspath(a))
                self.outputName = a
                self.printOutput = True
                self.showVersion = True
                self.makeWritableCmd = a
                self.noGenerate = True
                self.eofCanBeEnd = True
            self.beginSpec, self.endSpec, self.endOutput = val.split("" "")
        if self.replace and self.deleteCode:
        if self.replace and self.outputName:
        self._fixEndOutputPatterns()
        self.createCogModule()
        self.checkFailed = False
    def _fixEndOutputPatterns(self):
        end_output = re.escape(self.options.endOutput)
        self.reEndOutput = re.compile(
        self.endFormat = self.options.endOutput + "" (checksum: %s)""
    def showWarning(self, msg):
    def isBeginSpecLine(self, s):
        return self.options.beginSpec in s
    def isEndSpecLine(self, s):
        return self.options.endSpec in s and not self.isEndOutputLine(s)
    def isEndOutputLine(self, s):
        return self.options.endOutput in s
    def createCogModule(self):
    def openOutputFile(self, fname):
    def openInputFile(self, fname):
    def processFile(self, fileIn, fileOut, fname=None, globals=None):
        fileNameIn = fname or """"
        fileNameOut = fname or """"
        fileInToClose = fileOutToClose = None
        if isinstance(fileIn, (bytes, str)):
            fileNameIn = fileIn
            fileIn = fileInToClose = self.openInputFile(fileIn)
        if isinstance(fileOut, (bytes, str)):
            fileNameOut = fileOut
            fileOut = fileOutToClose = self.openOutputFile(fileOut)
            fileIn = NumberedFileReader(fileIn)
            sawCog = False
            self.cogmodule.inFile = fileNameIn
            self.cogmodule.outFile = fileNameOut
            self.cogmodulename = ""cog_"" + md5(fileNameOut.encode()).hexdigest()
            line = fileIn.readline()
                while line and not self.isBeginSpecLine(line):
                    if self.isEndSpecLine(line):
                            f""Unexpected {self.options.endSpec!r}"",
                            file=fileNameIn,
                            line=fileIn.linenumber(),
                    if self.isEndOutputLine(line):
                            f""Unexpected {self.options.endOutput!r}"",
                            file=fileNameIn,
                            line=fileIn.linenumber(),
                    fileOut.write(line)
                    line = fileIn.readline()
                if not self.options.deleteCode:
                    fileOut.write(line)
                gen.setOutput(stdout=self.stdout)
                gen.parseMarker(line)
                firstLineNum = fileIn.linenumber()
                self.cogmodule.firstLineNum = firstLineNum
                if self.isEndSpecLine(line):
                    beg = line.find(self.options.beginSpec)
                    end = line.find(self.options.endSpec)
                            file=fileNameIn,
                            line=firstLineNum,
                        code = line[beg + len(self.options.beginSpec) : end].strip()
                        gen.parseLine(code)
                    line = fileIn.readline()
                    while line and not self.isEndSpecLine(line):
                        if self.isBeginSpecLine(line):
                                f""Unexpected {self.options.beginSpec!r}"",
                                file=fileNameIn,
                                line=fileIn.linenumber(),
                        if self.isEndOutputLine(line):
                                f""Unexpected {self.options.endOutput!r}"",
                                file=fileNameIn,
                                line=fileIn.linenumber(),
                        if not self.options.deleteCode:
                            fileOut.write(line)
                        gen.parseLine(line)
                        line = fileIn.readline()
                            file=fileNameIn,
                            line=firstLineNum,
                    if not self.options.deleteCode:
                        fileOut.write(line)
                    gen.parseMarker(line)
                line = fileIn.readline()
                while line and not self.isEndOutputLine(line):
                    if self.isBeginSpecLine(line):
                            f""Unexpected {self.options.beginSpec!r}"",
                            file=fileNameIn,
                            line=fileIn.linenumber(),
                    if self.isEndSpecLine(line):
                            f""Unexpected {self.options.endSpec!r}"",
                            file=fileNameIn,
                            line=fileIn.linenumber(),
                    line = fileIn.readline()
                curHash = hasher.hexdigest()
                if not line and not self.options.eofCanBeEnd:
                        f""Missing {self.options.endOutput!r} before end of file."",
                        file=fileNameIn,
                        line=fileIn.linenumber(),
                if not self.options.noGenerate:
                    fname = f""<cog {fileNameIn}:{firstLineNum}>""
                    gen = self.suffixLines(gen)
                    fileOut.write(gen)
                newHash = hasher.hexdigest()
                sawCog = True
                hashMatch = self.reEndOutput.search(line)
                if self.options.hashOutput:
                    if hashMatch:
                        oldHash = hashMatch[""hash""]
                        if oldHash != curHash:
                                file=fileNameIn,
                                line=fileIn.linenumber(),
                        endpieces = line.split(hashMatch.group(0), 1)
                        endpieces = line.split(self.options.endOutput, 1)
                    line = (self.endFormat % newHash).join(endpieces)
                    if hashMatch:
                        line = line.replace(hashMatch[""hashsect""], """", 1)
                if not self.options.deleteCode:
                    fileOut.write(line)
                line = fileIn.readline()
            if not sawCog and self.options.warnEmpty:
                self.showWarning(f""no cog code found in {fileNameIn}"")
            if fileInToClose:
                fileInToClose.close()
            if fileOutToClose:
                fileOutToClose.close()
    reNonEmptyLines = re.compile(r""^\s*\S+.*$"", re.MULTILINE)
    def suffixLines(self, text):
            text = self.reNonEmptyLines.sub(repl, text)
    def processString(self, input, fname=None):
        fileOld = io.StringIO(input)
        fileNew = io.StringIO()
        self.processFile(fileOld, fileNew, fname=fname)
        return fileNew.getvalue()
    def replaceFile(self, oldPath, newText):
        if not os.access(oldPath, os.W_OK):
            if self.options.makeWritableCmd:
                cmd = self.options.makeWritableCmd.replace(""%s"", oldPath)
                if not os.access(oldPath, os.W_OK):
                    raise CogError(f""Couldn't make {oldPath} writable"")
                raise CogError(f""Can't overwrite {oldPath}"")
        f = self.openOutputFile(oldPath)
        f.write(newText)
    def saveIncludePath(self):
        self.savedInclude = self.options.includePath[:]
        self.savedSysPath = sys.path[:]
    def restoreIncludePath(self):
        self.options.includePath = self.savedInclude
        self.cogmodule.path = self.options.includePath
        sys.path = self.savedSysPath
    def addToIncludePath(self, includePath):
        self.cogmodule.path.extend(includePath)
        sys.path.extend(includePath)
    def processOneFile(self, fname):
        self.saveIncludePath()
        needNewline = False
            self.addToIncludePath(self.options.includePath)
            self.addToIncludePath([os.path.dirname(fname)])
            if self.options.outputName:
                self.processFile(fname, self.options.outputName, fname)
                    needNewline = True
                    fileOldFile = self.openInputFile(fname)
                    oldText = fileOldFile.read()
                    fileOldFile.close()
                    newText = self.processString(oldText, fname=fname)
                    if oldText != newText:
                            needNewline = False
                            self.replaceFile(fname, newText)
                            self.checkFailed = True
                    if needNewline:
                self.processFile(fname, self.stdout, fname)
            self.restoreIncludePath()
    def processWildcards(self, fname):
            for matchingFile in files:
                self.processOneFile(matchingFile)
            self.processOneFile(fname)
    def processFileList(self, fileNameList):
        flist = self.openInputFile(fileNameList)
                self.processArguments(args)
    def processArguments(self, args):
        self.options.parseArgs(args[1:])
            if self.options.outputName:
            self.processFileList(args[0][1:])
            if self.options.outputName:
                self.processFileList(os.path.basename(file_list))
            self.processWildcards(args[0])
    def callableMain(self, argv):
        self.options.parseArgs(argv)
        self._fixEndOutputPatterns()
        if self.options.showVersion:
                self.processArguments([a])
        if self.checkFailed:
            self.callableMain(argv)
from .whiteutils import reindentBlock
def makeFiles(d, basedir="".""):
                f.write(reindentBlock(contents))
            makeFiles(contents, child)
def removeFiles(d, basedir="".""):
            removeFiles(contents, child)
from .makefiles import makeFiles
from .whiteutils import reindentBlock
    def testNoCog(self):
            self.assertEqual(Cog().processString(s), s)
    def testSimple(self):
        self.assertEqual(Cog().processString(infile), outfile)
    def testEmptyCog(self):
        infile = reindentBlock(infile)
        self.assertEqual(Cog().processString(infile), infile)
    def testMultipleCogs(self):
        infile = reindentBlock(infile)
        self.assertEqual(Cog().processString(infile), infile)
    def testTrimBlankLines(self):
        infile = reindentBlock(infile)
        self.assertEqual(Cog().processString(infile), infile)
    def testTrimEmptyBlankLines(self):
        infile = reindentBlock(infile)
        self.assertEqual(Cog().processString(infile), infile)
    def testTrimBlankLinesWithLastPartial(self):
        infile = reindentBlock(infile)
        self.assertEqual(Cog().processString(infile), infile)
    def testCogOutDedent(self):
        infile = reindentBlock(infile)
        self.assertEqual(Cog().processString(infile), infile)
    def test22EndOfLine(self):
        infile = reindentBlock(infile)
        self.assertEqual(Cog().processString(infile), infile)
    def testIndentedCode(self):
        infile = reindentBlock(infile)
        self.assertEqual(Cog().processString(infile), infile)
    def testPrefixedCode(self):
        infile = reindentBlock(infile)
        self.assertEqual(Cog().processString(infile), infile)
    def testPrefixedIndentedCode(self):
        infile = reindentBlock(infile)
        self.assertEqual(Cog().processString(infile), infile)
    def testBogusPrefixMatch(self):
        infile = reindentBlock(infile)
        self.assertEqual(Cog().processString(infile), infile)
    def testNoFinalNewline(self):
        infile = reindentBlock(infile)
        self.assertEqual(Cog().processString(infile), infile)
    def testNoOutputAtAll(self):
        infile = reindentBlock(infile)
        self.assertEqual(Cog().processString(infile), infile)
    def testPurelyBlankLine(self):
        infile = reindentBlock(infile.replace(""$"", """"))
        self.assertEqual(Cog().processString(infile), infile)
    def testEmptyOutl(self):
        infile = reindentBlock(infile)
        self.assertEqual(Cog().processString(infile), infile)
    def testFirstLineNum(self):
        infile = reindentBlock(infile)
        self.assertEqual(Cog().processString(infile), infile)
    def testCompactOneLineCode(self):
        infile = reindentBlock(infile)
        self.assertEqual(Cog().processString(infile), reindentBlock(outfile))
    def testInsideOutCompact(self):
            Cog().processString(reindentBlock(infile), ""infile.txt"")
    def testSharingGlobals(self):
        infile = reindentBlock(infile)
        self.assertEqual(Cog().processString(infile), reindentBlock(outfile))
    def testAssertInCogCode(self):
        infile = reindentBlock(infile)
            Cog().processString(infile)
    def testCogPrevious(self):
        infile = reindentBlock(infile)
        self.assertEqual(Cog().processString(infile), reindentBlock(outfile))
    def testEquality(self):
        o.parseArgs([""-r""])
        p.parseArgs([""-r""])
    def testCloning(self):
        o.parseArgs([""-I"", ""fooey"", ""-I"", ""booey"", ""-s"", "" /*x*/""])
        p.parseArgs([""-I"", ""huey"", ""-D"", ""foo=quux""])
        q.parseArgs(
    def testCombiningFlags(self):
        o.parseArgs([""-e"", ""-r"", ""-z""])
        p.parseArgs([""-erz""])
    def testMarkers(self):
        self.assertEqual(""a"", o.beginSpec)
        self.assertEqual(""b"", o.endSpec)
        self.assertEqual(""c"", o.endOutput)
    def testMarkersSwitch(self):
        o.parseArgs([""--markers"", ""a b c""])
        self.assertEqual(""a"", o.beginSpec)
        self.assertEqual(""b"", o.endSpec)
        self.assertEqual(""c"", o.endOutput)
    def isBad(self, infile, msg=None):
        infile = reindentBlock(infile)
            Cog().processString(infile, ""infile.txt"")
    def testBeginNoEnd(self):
        self.isBad(infile, ""infile.txt(2): Cog block begun but never ended."")
    def testNoEoo(self):
        self.isBad(infile, ""infile.txt(4): Missing '[[[end]]]' before end of file."")
        self.isBad(infile2, ""infile.txt(5): Unexpected '[[[cog'"")
    def testStartWithEnd(self):
        self.isBad(infile, ""infile.txt(1): Unexpected ']]]'"")
        self.isBad(infile2, ""infile.txt(5): Unexpected ']]]'"")
    def testStartWithEoo(self):
        self.isBad(infile, ""infile.txt(1): Unexpected '[[[end]]]'"")
        self.isBad(infile2, ""infile.txt(5): Unexpected '[[[end]]]'"")
    def testNoEnd(self):
        self.isBad(infile, ""infile.txt(3): Unexpected '[[[end]]]'"")
        self.isBad(infile2, ""infile.txt(7): Unexpected '[[[end]]]'"")
    def testTwoBegins(self):
        self.isBad(infile, ""infile.txt(2): Unexpected '[[[cog'"")
        self.isBad(infile2, ""infile.txt(6): Unexpected '[[[cog'"")
    def testTwoEnds(self):
        self.isBad(infile, ""infile.txt(4): Unexpected ']]]'"")
        self.isBad(infile2, ""infile.txt(8): Unexpected ']]]'"")
    def testErrorMsg(self):
        infile = reindentBlock(infile)
            Cog().processString(infile)
    def testErrorNoMsg(self):
        infile = reindentBlock(infile)
            Cog().processString(infile)
    def testNoErrorIfErrorNotCalled(self):
        infile = reindentBlock(infile)
        self.assertEqual(Cog().processString(infile), infile)
        self.m = self.gen.parseMarker
        self.parseLine = self.gen.parseLine
    def testEmpty(self):
        self.assertEqual(self.gen.getCode(), """")
    def testSimple(self):
        self.parseLine('  print ""hello""')
        self.parseLine('  print ""bye""')
        self.assertEqual(self.gen.getCode(), 'print ""hello""\nprint ""bye""')
    def testCompressed1(self):
        self.parseLine(""// hello"")
        self.parseLine(""// bye"")
        self.assertEqual(self.gen.getCode(), ""hello\nbye"")
    def testCompressed2(self):
        self.parseLine(""hello"")
        self.parseLine(""bye"")
        self.assertEqual(self.gen.getCode(), ""hello\nbye"")
    def testCompressed3(self):
        self.parseLine('print """"""hello')
        self.parseLine(""bye"")
        self.assertEqual(self.gen.getCode(), 'print """"""hello\nbye')
    def testCompressed4(self):
        self.parseLine(""hello"")
        self.parseLine('bye"""""")')
        self.assertEqual(self.gen.getCode(), 'hello\nbye"""""")')
    def testNoCommonPrefixForMarkers(self):
        self.parseLine(""\timport cog, sys"")
        self.parseLine("""")
        self.parseLine(""\tprint sys.argv"")
        self.assertEqual(self.gen.getCode(), ""import cog, sys\n\nprint sys.argv"")
    def newCog(self):
        self.cog.setOutput(stdout=self.output, stderr=self.output)
        self.newCog()
    def assertFilesSame(self, fileName1, fileName2):
        with open(os.path.join(self.tempdir, fileName1), ""rb"") as f1:
        with open(os.path.join(self.tempdir, fileName2), ""rb"") as f2:
    def testArgumentFailure(self):
            self.cog.callableMain([""argv0""])
            self.cog.callableMain([""argv0"", ""-j""])
    def testNoDashOAndAtFile(self):
        makeFiles({""cogfiles.txt"": ""# Please run cog""})
            self.cog.callableMain([""argv0"", ""-o"", ""foo"", ""@cogfiles.txt""])
    def testNoDashOAndAmpFile(self):
        makeFiles({""cogfiles.txt"": ""# Please run cog""})
            self.cog.callableMain([""argv0"", ""-o"", ""foo"", ""&cogfiles.txt""])
    def testDashV(self):
    def producesHelp(self, args):
        self.newCog()
    def testDashH(self):
        self.producesHelp(""-h"")
        self.producesHelp(""-?"")
        self.producesHelp(""fooey.txt -h"")
        self.producesHelp(""-o -r @fooey.txt -? @booey.txt"")
    def testDashOAndDashR(self):
        makeFiles(d)
            self.cog.callableMain([""argv0"", ""-o"", ""foo"", ""-r"", ""cogfile.txt""])
    def testDashZ(self):
        makeFiles(d)
            self.cog.callableMain([""argv0"", ""-r"", ""test.cog""])
        self.newCog()
        self.cog.callableMain([""argv0"", ""-r"", ""-z"", ""test.cog""])
    def testBadDashD(self):
            self.cog.callableMain([""argv0"", ""-Dfooey"", ""cog.txt""])
            self.cog.callableMain([""argv0"", ""-D"", ""fooey"", ""cog.txt""])
    def testBadMarkers(self):
            self.cog.callableMain([""argv0"", ""--markers=X""])
            self.cog.callableMain([""argv0"", ""--markers=A B C D""])
        makeFiles(self.files)
        expected = reindentBlock(""""""\
        makeFiles(self.files)
        expected = reindentBlock(""""""\
    def testSimple(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-r"", ""test.cog""])
    def testPrintOutput(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-rP"", ""test.cog""])
    def testWildcards(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-r"", ""t*.cog""])
    def testOutputFile(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-o"", ""in/a/dir/test.cogged"", ""test.cog""])
    def testAtFile(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-r"", ""@cogfiles.txt""])
    def testNestedAtFile(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-r"", ""@cogfiles.txt""])
    def testAtFileWithArgs(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""@cogfiles.txt""])
    def testAtFileWithBadArgCombo(self):
        makeFiles(d)
            self.cog.callableMain([""argv0"", ""-r"", ""@cogfiles.txt""])
    def testAtFileWithTrickyFilenames(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-z"", ""-r"", ""@cogfiles.txt""])
    def testAmpFile(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-r"", ""&code/files_to_cog""])
        makeFiles(d)
        self.cog.callableMain(
    def testOutputNativeEol(self):
        makeFiles({""infile"": ""\n"".join(self.lines_in)})
        self.cog.callableMain([""argv0"", ""-o"", ""outfile"", ""infile""])
    def testOutputLfEol(self):
        makeFiles({""infile"": ""\n"".join(self.lines_in)})
        self.cog.callableMain([""argv0"", ""-U"", ""-o"", ""outfile"", ""infile""])
    def testReplaceNativeEol(self):
        makeFiles({""test.cog"": ""\n"".join(self.lines_in)})
        self.cog.callableMain([""argv0"", ""-r"", ""test.cog""])
    def testReplaceLfEol(self):
        makeFiles({""test.cog"": ""\n"".join(self.lines_in)})
        self.cog.callableMain([""argv0"", ""-U"", ""-r"", ""test.cog""])
    def testSimple(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-r"", ""test.cog""])
    def testFileEncodingOption(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-n"", ""cp1251"", ""-r"", ""test.cog""])
    def testNeedIncludePath(self):
        makeFiles(self.dincludes)
            self.cog.callableMain([""argv0"", ""-r"", ""test.cog""])
    def testIncludePath(self):
        makeFiles(self.dincludes)
        self.cog.callableMain([""argv0"", ""-r"", ""-I"", ""include"", ""test.cog""])
    def testTwoIncludePaths(self):
        makeFiles(self.dincludes)
        self.cog.callableMain(
    def testTwoIncludePaths2(self):
        makeFiles(self.dincludes)
        self.cog.callableMain(
    def testUselessIncludePath(self):
        makeFiles(self.dincludes)
        self.cog.callableMain(
    def testSysPathIsUnchanged(self):
        makeFiles(d)
        self.newCog()
        self.newCog()
        self.cog.callableMain([""argv0"", ""-r"", ""good.cog""])
        self.newCog()
        self.cog.callableMain([""argv0"", ""-r"", ""-I"", ""xyzzy"", ""good.cog""])
        self.newCog()
        self.cog.callableMain([""argv0"", ""-r"", ""-I"", ""xyzzy"", ""-I"", ""quux"", ""good.cog""])
        self.newCog()
            self.cog.callableMain([""argv0"", ""-r"", ""bad.cog""])
        self.newCog()
            self.cog.callableMain([""argv0"", ""-r"", ""-I"", ""xyzzy"", ""bad.cog""])
        self.newCog()
            self.cog.callableMain(
    def testSubDirectories(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-r"", ""code/test.cog""])
    def testWarnIfNoCogCode(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-e"", ""with.cog""])
        self.newCog()
        self.cog.callableMain([""argv0"", ""-e"", ""without.cog""])
        self.newCog()
        self.cog.callableMain([""argv0"", ""without.cog""])
    def testFileNameProps(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-r"", ""cog1.txt""])
        self.newCog()
        self.cog.callableMain([""argv0"", ""-o"", ""cog1out.txt"", ""cog1.txt""])
    def testGlobalsDontCrossFiles(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-r"", ""@cogfiles.txt""])
    def testRemoveGeneratedOutput(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-r"", ""-x"", ""cog1.txt""])
        self.newCog()
        self.cog.callableMain([""argv0"", ""-r"", ""cog1.txt""])
        self.newCog()
        self.cog.callableMain([""argv0"", ""-r"", ""-x"", ""cog1.txt""])
    def testMsgCall(self):
        infile = reindentBlock(infile)
        self.assertEqual(self.cog.processString(infile), infile)
    def testErrorMessageHasNoTraceback(self):
        makeFiles(d)
        self.cog.setOutput(stderr=stderr)
    def testDashD(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-r"", ""-D"", ""fooey=kablooey"", ""test.cog""])
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-r"", ""-Dfooey=kablooey"", ""test.cog""])
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-r"", ""-Dfooey=e=mc2"", ""test.cog""])
        makeFiles(d)
        self.cog.callableMain(
        makeFiles(d)
        self.cog.callableMain(
        makeFiles(d)
        self.cog.callableMain(
    def testOutputToStdout(self):
        makeFiles(d)
        self.cog.setOutput(stderr=stderr)
        self.cog.callableMain([""argv0"", ""test.cog""])
    def testReadFromStdin(self):
        self.cog.setOutput(stderr=stderr)
        self.cog.callableMain([""argv0"", ""-""])
    def testSuffixOutputLines(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-r"", ""-s"", "" (foo)"", ""test.cog""])
    def testEmptySuffix(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-r"", ""-s"", """", ""test.cog""])
    def testHellishSuffix(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-z"", ""-r"", ""-s"", r"" /\n*+([)]><"", ""test.cog""])
    def testPrologue(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-r"", ""-p"", ""import math"", ""test.cog""])
    def testThreads(self):
        makeFiles(d)
            content = reindentBlock(content)
        makeFiles(d)
        makeFiles(d)
        makeFiles(d)
        makeFiles(d)
            self.newCog()
        makeFiles(d)
        makeFiles(d)
        makeFiles(self.d)
    def testReadonlyNoCommand(self):
            self.cog.callableMain([""argv0"", ""-r"", ""test.cog""])
    def testReadonlyWithCommand(self):
        self.cog.callableMain([""argv0"", ""-r"", ""-w"", self.cmd_w_args, ""test.cog""])
    def testReadonlyWithCommandWithNoSlot(self):
        self.cog.callableMain([""argv0"", ""-r"", ""-w"", self.cmd_w_asterisk, ""test.cog""])
    def testReadonlyWithIneffectualCommand(self):
            self.cog.callableMain([""argv0"", ""-r"", ""-w"", ""echo %s"", ""test.cog""])
    def testCreateChecksumOutput(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-r"", ""-c"", ""cog1.txt""])
    def testCheckChecksumOutput(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-r"", ""-c"", ""cog1.txt""])
    def testRemoveChecksumOutput(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-r"", ""cog1.txt""])
    def testTamperedChecksumOutput(self):
        makeFiles(d)
            self.cog.callableMain([""argv0"", ""-c"", ""cog1.txt""])
            self.cog.callableMain([""argv0"", ""-c"", ""cog2.txt""])
            self.cog.callableMain([""argv0"", ""-c"", ""cog3.txt""])
            self.cog.callableMain([""argv0"", ""-c"", ""cog4.txt""])
            self.cog.callableMain([""argv0"", ""-c"", ""cog5.txt""])
            self.cog.callableMain([""argv0"", ""-c"", ""cog6.txt""])
    def testArgvIsntModified(self):
        self.cog.callableMain(argv)
    def testCustomerMarkers(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-r"", ""--markers={{ }} {{end}}"", ""test.cog""])
    def testTrulyWackyMarkers(self):
        makeFiles(d)
        self.cog.callableMain(
    def testChangeJustOneMarker(self):
        makeFiles(d)
        self.cog.callableMain(
    def testDeleteCode(self):
        makeFiles(d)
        self.cog.callableMain([""argv0"", ""-d"", ""-o"", ""test.cogged"", ""test.cog""])
    def testDeleteCodeWithDashRFails(self):
        makeFiles(d)
            self.cog.callableMain([""argv0"", ""-r"", ""-d"", ""test.cog""])
    def testSettingGlobals(self):
        makeFiles(d)
        self.cog.options.deleteCode = True
        self.cog.processFile(""test.cog"", ""test.cogged"", globals=globals)
    def testErrorCallHasNoTraceback(self):
        makeFiles(d)
    def testRealErrorHasTraceback(self):
        makeFiles(d)
    def checkFilesExist(self, d, dname):
                self.checkFilesExist(d[fname], os.path.join(dname, fname))
    def checkFilesDontExist(self, d, dname):
    def testOneFile(self):
        makefiles.makeFiles(d, self.tempdir)
        makefiles.removeFiles(d, self.tempdir)
    def testManyFiles(self):
        self.checkFilesDontExist(d, self.tempdir)
        makefiles.makeFiles(d, self.tempdir)
        self.checkFilesExist(d, self.tempdir)
        makefiles.removeFiles(d, self.tempdir)
        self.checkFilesDontExist(d, self.tempdir)
    def testOverlapping(self):
        self.checkFilesDontExist(d1, self.tempdir)
        self.checkFilesDontExist(d2, self.tempdir)
        makefiles.makeFiles(d1, self.tempdir)
        makefiles.makeFiles(d2, self.tempdir)
        self.checkFilesExist(d1, self.tempdir)
        self.checkFilesExist(d2, self.tempdir)
        makefiles.removeFiles(d1, self.tempdir)
        makefiles.removeFiles(d2, self.tempdir)
        self.checkFilesDontExist(d1, self.tempdir)
        self.checkFilesDontExist(d2, self.tempdir)

    def testContents(self):
        makefiles.makeFiles(d, self.tempdir)
    def testDedent(self):
        makefiles.makeFiles(d, self.tempdir)
from .whiteutils import commonPrefix, reindentBlock, whitePrefix
    def testSingleLine(self):
        self.assertEqual(whitePrefix([""""]), """")
        self.assertEqual(whitePrefix(["" ""]), """")
        self.assertEqual(whitePrefix([""x""]), """")
        self.assertEqual(whitePrefix(["" x""]), "" "")
        self.assertEqual(whitePrefix([""\tx""]), ""\t"")
        self.assertEqual(whitePrefix([""  x""]), ""  "")
        self.assertEqual(whitePrefix(["" \t \tx   ""]), "" \t \t"")
    def testMultiLine(self):
        self.assertEqual(whitePrefix([""  x"", ""  x"", ""  x""]), ""  "")
        self.assertEqual(whitePrefix([""   y"", ""  y"", "" y""]), "" "")
        self.assertEqual(whitePrefix(["" y"", ""  y"", ""   y""]), "" "")
    def testBlankLinesAreIgnored(self):
        self.assertEqual(whitePrefix([""  x"", ""  x"", """", ""  x""]), ""  "")
        self.assertEqual(whitePrefix(["""", ""  x"", ""  x"", ""  x""]), ""  "")
        self.assertEqual(whitePrefix([""  x"", ""  x"", ""  x"", """"]), ""  "")
        self.assertEqual(whitePrefix([""  x"", ""  x"", ""          "", ""  x""]), ""  "")
    def testTabCharacters(self):
        self.assertEqual(whitePrefix([""\timport sys"", """", ""\tprint sys.argv""]), ""\t"")
    def testDecreasingLengths(self):
        self.assertEqual(whitePrefix([""   x"", ""  x"", "" x""]), "" "")
        self.assertEqual(whitePrefix([""     x"", "" x"", "" x""]), "" "")
    def testNonTermLine(self):
        self.assertEqual(reindentBlock(""""), """")
        self.assertEqual(reindentBlock(""x""), ""x"")
        self.assertEqual(reindentBlock("" x""), ""x"")
        self.assertEqual(reindentBlock(""  x""), ""x"")
        self.assertEqual(reindentBlock(""\tx""), ""x"")
        self.assertEqual(reindentBlock(""x"", "" ""), "" x"")
        self.assertEqual(reindentBlock(""x"", ""\t""), ""\tx"")
        self.assertEqual(reindentBlock("" x"", "" ""), "" x"")
        self.assertEqual(reindentBlock("" x"", ""\t""), ""\tx"")
        self.assertEqual(reindentBlock("" x"", ""  ""), ""  x"")

    def testSingleLine(self):
        self.assertEqual(reindentBlock(""\n""), ""\n"")
        self.assertEqual(reindentBlock(""x\n""), ""x\n"")
        self.assertEqual(reindentBlock("" x\n""), ""x\n"")
        self.assertEqual(reindentBlock(""  x\n""), ""x\n"")
        self.assertEqual(reindentBlock(""\tx\n""), ""x\n"")
        self.assertEqual(reindentBlock(""x\n"", "" ""), "" x\n"")
        self.assertEqual(reindentBlock(""x\n"", ""\t""), ""\tx\n"")
        self.assertEqual(reindentBlock("" x\n"", "" ""), "" x\n"")
        self.assertEqual(reindentBlock("" x\n"", ""\t""), ""\tx\n"")
        self.assertEqual(reindentBlock("" x\n"", ""  ""), ""  x\n"")

    def testRealBlock(self):
            reindentBlock(""\timport sys\n\n\tprint sys.argv\n""),
    def testDegenerateCases(self):
        self.assertEqual(commonPrefix([]), """")
        self.assertEqual(commonPrefix([""""]), """")
        self.assertEqual(commonPrefix(["""", """", """", """", """"]), """")
        self.assertEqual(commonPrefix([""cat in the hat""]), ""cat in the hat"")
    def testNoCommonPrefix(self):
        self.assertEqual(commonPrefix([""a"", ""b""]), """")
        self.assertEqual(commonPrefix([""a"", ""b"", ""c"", ""d"", ""e"", ""f""]), """")
        self.assertEqual(commonPrefix([""a"", ""a"", ""a"", ""a"", ""a"", ""x""]), """")
    def testUsualCases(self):
        self.assertEqual(commonPrefix([""ab"", ""ac""]), ""a"")
        self.assertEqual(commonPrefix([""aab"", ""aac""]), ""aa"")
        self.assertEqual(commonPrefix([""aab"", ""aab"", ""aab"", ""aac""]), ""aa"")
    def testBlankLine(self):
        self.assertEqual(commonPrefix([""abc"", ""abx"", """", ""aby""]), """")
    def testDecreasingLengths(self):
        self.assertEqual(commonPrefix([""abcd"", ""abc"", ""ab""]), ""ab"")
    def setOutput(self, stdout=None, stderr=None):
def whitePrefix(strings):
def reindentBlock(lines, newIndent=""""):
    oldIndent = whitePrefix(lines)
    outLines = []
        if oldIndent:
            line = line.replace(oldIndent, nothing, 1)
        if line and newIndent:
            line = newIndent + line
        outLines.append(line)
    return sep.join(outLines)
def commonPrefix(strings):",buggy
"from .whiteutils import common_prefix, reindent_block, white_prefix
    def parse_marker(self, line):
    def parse_line(self, line):
    def get_code(self):
        pref_in = common_prefix(self.markers + self.lines)
        if pref_in:
            self.markers = [line.replace(pref_in, """", 1) for line in self.markers]
            self.lines = [line.replace(pref_in, """", 1) for line in self.lines]
        return reindent_block(self.lines, """")
        pref_out = white_prefix(self.markers)
        intext = self.get_code()
        if self.options.print_output:
        if self.options.print_output:
        return reindent_block(self.outstring, pref_out)
            sOut = reindent_block(sOut)
        self.include_path = []
        self.show_version = False
        self.make_writable_cmd = None
        self.no_generate = False
        self.output_name = None
        self.warn_empty = False
        self.hash_output = False
        self.delete_code = False
        self.eof_can_be_end = False
        self.begin_spec = ""[[[cog""
        self.end_spec = ""]]]""
        self.end_output = ""[[[end]]]""
        self.print_output = False
    def add_to_include_path(self, dirs):
        self.include_path.extend(dirs)
    def parse_args(self, argv):
                self.hash_output = True
                self.delete_code = True
                self.warn_empty = True
                self.add_to_include_path(os.path.abspath(a))
                self.output_name = a
                self.print_output = True
                self.show_version = True
                self.make_writable_cmd = a
                self.no_generate = True
                self.eof_can_be_end = True
            self.begin_spec, self.end_spec, self.end_output = val.split("" "")
        if self.replace and self.delete_code:
        if self.replace and self.output_name:
        self._fix_end_output_patterns()
        self.create_cog_module()
        self.check_failed = False
    def _fix_end_output_patterns(self):
        end_output = re.escape(self.options.end_output)
        self.re_end_output = re.compile(
        self.end_format = self.options.end_output + "" (checksum: %s)""
    def show_warning(self, msg):
    def is_begin_spec_line(self, s):
        return self.options.begin_spec in s
    def is_end_spec_line(self, s):
        return self.options.end_spec in s and not self.is_end_output_line(s)
    def is_end_output_line(self, s):
        return self.options.end_output in s
    def create_cog_module(self):
    def open_output_file(self, fname):
    def open_input_file(self, fname):
    def process_file(self, file_in, file_out, fname=None, globals=None):
        file_name_in = fname or """"
        file_name_out = fname or """"
        file_in_to_close = file_out_to_close = None
        if isinstance(file_in, (bytes, str)):
            file_name_in = file_in
            file_in = file_in_to_close = self.open_input_file(file_in)
        if isinstance(file_out, (bytes, str)):
            file_name_out = file_out
            file_out = file_out_to_close = self.open_output_file(file_out)
            file_in = NumberedFileReader(file_in)
            saw_cog = False
            self.cogmodule.inFile = file_name_in
            self.cogmodule.outFile = file_name_out
            self.cogmodulename = ""cog_"" + md5(file_name_out.encode()).hexdigest()
            line = file_in.readline()
                while line and not self.is_begin_spec_line(line):
                    if self.is_end_spec_line(line):
                            f""Unexpected {self.options.end_spec!r}"",
                            file=file_name_in,
                            line=file_in.linenumber(),
                    if self.is_end_output_line(line):
                            f""Unexpected {self.options.end_output!r}"",
                            file=file_name_in,
                            line=file_in.linenumber(),
                    file_out.write(line)
                    line = file_in.readline()
                if not self.options.delete_code:
                    file_out.write(line)
                gen.set_output(stdout=self.stdout)
                gen.parse_marker(line)
                first_line_num = file_in.linenumber()
                self.cogmodule.firstLineNum = first_line_num
                if self.is_end_spec_line(line):
                    beg = line.find(self.options.begin_spec)
                    end = line.find(self.options.end_spec)
                            file=file_name_in,
                            line=first_line_num,
                        code = line[beg + len(self.options.begin_spec) : end].strip()
                        gen.parse_line(code)
                    line = file_in.readline()
                    while line and not self.is_end_spec_line(line):
                        if self.is_begin_spec_line(line):
                                f""Unexpected {self.options.begin_spec!r}"",
                                file=file_name_in,
                                line=file_in.linenumber(),
                        if self.is_end_output_line(line):
                                f""Unexpected {self.options.end_output!r}"",
                                file=file_name_in,
                                line=file_in.linenumber(),
                        if not self.options.delete_code:
                            file_out.write(line)
                        gen.parse_line(line)
                        line = file_in.readline()
                            file=file_name_in,
                            line=first_line_num,
                    if not self.options.delete_code:
                        file_out.write(line)
                    gen.parse_marker(line)
                line = file_in.readline()
                while line and not self.is_end_output_line(line):
                    if self.is_begin_spec_line(line):
                            f""Unexpected {self.options.begin_spec!r}"",
                            file=file_name_in,
                            line=file_in.linenumber(),
                    if self.is_end_spec_line(line):
                            f""Unexpected {self.options.end_spec!r}"",
                            file=file_name_in,
                            line=file_in.linenumber(),
                    line = file_in.readline()
                cur_hash = hasher.hexdigest()
                if not line and not self.options.eof_can_be_end:
                        f""Missing {self.options.end_output!r} before end of file."",
                        file=file_name_in,
                        line=file_in.linenumber(),
                if not self.options.no_generate:
                    fname = f""<cog {file_name_in}:{first_line_num}>""
                    gen = self.suffix_lines(gen)
                    file_out.write(gen)
                new_hash = hasher.hexdigest()
                saw_cog = True
                hash_match = self.re_end_output.search(line)
                if self.options.hash_output:
                    if hash_match:
                        old_hash = hash_match[""hash""]
                        if old_hash != cur_hash:
                                file=file_name_in,
                                line=file_in.linenumber(),
                        endpieces = line.split(hash_match.group(0), 1)
                        endpieces = line.split(self.options.end_output, 1)
                    line = (self.end_format % new_hash).join(endpieces)
                    if hash_match:
                        line = line.replace(hash_match[""hashsect""], """", 1)
                if not self.options.delete_code:
                    file_out.write(line)
                line = file_in.readline()
            if not saw_cog and self.options.warn_empty:
                self.show_warning(f""no cog code found in {file_name_in}"")
            if file_in_to_close:
                file_in_to_close.close()
            if file_out_to_close:
                file_out_to_close.close()
    re_non_empty_lines = re.compile(r""^\s*\S+.*$"", re.MULTILINE)
    def suffix_lines(self, text):
            text = self.re_non_empty_lines.sub(repl, text)
    def process_string(self, input, fname=None):
        file_old = io.StringIO(input)
        file_new = io.StringIO()
        self.process_file(file_old, file_new, fname=fname)
        return file_new.getvalue()
    def replace_file(self, old_path, new_text):
        if not os.access(old_path, os.W_OK):
            if self.options.make_writable_cmd:
                cmd = self.options.make_writable_cmd.replace(""%s"", old_path)
                if not os.access(old_path, os.W_OK):
                    raise CogError(f""Couldn't make {old_path} writable"")
                raise CogError(f""Can't overwrite {old_path}"")
        f = self.open_output_file(old_path)
        f.write(new_text)
    def save_include_path(self):
        self.saved_include = self.options.include_path[:]
        self.saved_sys_path = sys.path[:]
    def restore_include_path(self):
        self.options.include_path = self.saved_include
        self.cogmodule.path = self.options.include_path
        sys.path = self.saved_sys_path
    def add_to_include_path(self, include_path):
        self.cogmodule.path.extend(include_path)
        sys.path.extend(include_path)
    def process_one_file(self, fname):
        self.save_include_path()
        need_newline = False
            self.add_to_include_path(self.options.include_path)
            self.add_to_include_path([os.path.dirname(fname)])
            if self.options.output_name:
                self.process_file(fname, self.options.output_name, fname)
                    need_newline = True
                    file_old_file = self.open_input_file(fname)
                    old_text = file_old_file.read()
                    file_old_file.close()
                    new_text = self.process_string(old_text, fname=fname)
                    if old_text != new_text:
                            need_newline = False
                            self.replace_file(fname, new_text)
                            self.check_failed = True
                    if need_newline:
                self.process_file(fname, self.stdout, fname)
            self.restore_include_path()
    def process_wildcards(self, fname):
            for matching_file in files:
                self.process_one_file(matching_file)
            self.process_one_file(fname)
    def process_file_list(self, file_name_list):
        flist = self.open_input_file(file_name_list)
                self.process_arguments(args)
    def process_arguments(self, args):
        self.options.parse_args(args[1:])
            if self.options.output_name:
            self.process_file_list(args[0][1:])
            if self.options.output_name:
                self.process_file_list(os.path.basename(file_list))
            self.process_wildcards(args[0])
    def callable_main(self, argv):
        self.options.parse_args(argv)
        self._fix_end_output_patterns()
        if self.options.show_version:
                self.process_arguments([a])
        if self.check_failed:
            self.callable_main(argv)
from .whiteutils import reindent_block
def make_files(d, basedir="".""):
                f.write(reindent_block(contents))
            make_files(contents, child)
def remove_files(d, basedir="".""):
            remove_files(contents, child)
from .makefiles import make_files
from .whiteutils import reindent_block
    def test_no_cog(self):
            self.assertEqual(Cog().process_string(s), s)
    def test_simple(self):
        self.assertEqual(Cog().process_string(infile), outfile)
    def test_empty_cog(self):
        infile = reindent_block(infile)
        self.assertEqual(Cog().process_string(infile), infile)
    def test_multiple_cogs(self):
        infile = reindent_block(infile)
        self.assertEqual(Cog().process_string(infile), infile)
    def test_trim_blank_lines(self):
        infile = reindent_block(infile)
        self.assertEqual(Cog().process_string(infile), infile)
    def test_trim_empty_blank_lines(self):
        infile = reindent_block(infile)
        self.assertEqual(Cog().process_string(infile), infile)
    def test_trim_blank_lines_with_last_partial(self):
        infile = reindent_block(infile)
        self.assertEqual(Cog().process_string(infile), infile)
    def test_cog_out_dedent(self):
        infile = reindent_block(infile)
        self.assertEqual(Cog().process_string(infile), infile)
    def test22_end_of_line(self):
        infile = reindent_block(infile)
        self.assertEqual(Cog().process_string(infile), infile)
    def test_indented_code(self):
        infile = reindent_block(infile)
        self.assertEqual(Cog().process_string(infile), infile)
    def test_prefixed_code(self):
        infile = reindent_block(infile)
        self.assertEqual(Cog().process_string(infile), infile)
    def test_prefixed_indented_code(self):
        infile = reindent_block(infile)
        self.assertEqual(Cog().process_string(infile), infile)
    def test_bogus_prefix_match(self):
        infile = reindent_block(infile)
        self.assertEqual(Cog().process_string(infile), infile)
    def test_no_final_newline(self):
        infile = reindent_block(infile)
        self.assertEqual(Cog().process_string(infile), infile)
    def test_no_output_at_all(self):
        infile = reindent_block(infile)
        self.assertEqual(Cog().process_string(infile), infile)
    def test_purely_blank_line(self):
        infile = reindent_block(infile.replace(""$"", """"))
        self.assertEqual(Cog().process_string(infile), infile)
    def test_empty_outl(self):
        infile = reindent_block(infile)
        self.assertEqual(Cog().process_string(infile), infile)
    def test_first_line_num(self):
        infile = reindent_block(infile)
        self.assertEqual(Cog().process_string(infile), infile)
    def test_compact_one_line_code(self):
        infile = reindent_block(infile)
        self.assertEqual(Cog().process_string(infile), reindent_block(outfile))
    def test_inside_out_compact(self):
            Cog().process_string(reindent_block(infile), ""infile.txt"")
    def test_sharing_globals(self):
        infile = reindent_block(infile)
        self.assertEqual(Cog().process_string(infile), reindent_block(outfile))
    def test_assert_in_cog_code(self):
        infile = reindent_block(infile)
            Cog().process_string(infile)
    def test_cog_previous(self):
        infile = reindent_block(infile)
        self.assertEqual(Cog().process_string(infile), reindent_block(outfile))
    def test_equality(self):
        o.parse_args([""-r""])
        p.parse_args([""-r""])
    def test_cloning(self):
        o.parse_args([""-I"", ""fooey"", ""-I"", ""booey"", ""-s"", "" /*x*/""])
        p.parse_args([""-I"", ""huey"", ""-D"", ""foo=quux""])
        q.parse_args(
    def test_combining_flags(self):
        o.parse_args([""-e"", ""-r"", ""-z""])
        p.parse_args([""-erz""])
    def test_markers(self):
        self.assertEqual(""a"", o.begin_spec)
        self.assertEqual(""b"", o.end_spec)
        self.assertEqual(""c"", o.end_output)
    def test_markers_switch(self):
        o.parse_args([""--markers"", ""a b c""])
        self.assertEqual(""a"", o.begin_spec)
        self.assertEqual(""b"", o.end_spec)
        self.assertEqual(""c"", o.end_output)
    def is_bad(self, infile, msg=None):
        infile = reindent_block(infile)
            Cog().process_string(infile, ""infile.txt"")
    def test_begin_no_end(self):
        self.is_bad(infile, ""infile.txt(2): Cog block begun but never ended."")
    def test_no_eoo(self):
        self.is_bad(infile, ""infile.txt(4): Missing '[[[end]]]' before end of file."")
        self.is_bad(infile2, ""infile.txt(5): Unexpected '[[[cog'"")
    def test_start_with_end(self):
        self.is_bad(infile, ""infile.txt(1): Unexpected ']]]'"")
        self.is_bad(infile2, ""infile.txt(5): Unexpected ']]]'"")
    def test_start_with_eoo(self):
        self.is_bad(infile, ""infile.txt(1): Unexpected '[[[end]]]'"")
        self.is_bad(infile2, ""infile.txt(5): Unexpected '[[[end]]]'"")
    def test_no_end(self):
        self.is_bad(infile, ""infile.txt(3): Unexpected '[[[end]]]'"")
        self.is_bad(infile2, ""infile.txt(7): Unexpected '[[[end]]]'"")
    def test_two_begins(self):
        self.is_bad(infile, ""infile.txt(2): Unexpected '[[[cog'"")
        self.is_bad(infile2, ""infile.txt(6): Unexpected '[[[cog'"")
    def test_two_ends(self):
        self.is_bad(infile, ""infile.txt(4): Unexpected ']]]'"")
        self.is_bad(infile2, ""infile.txt(8): Unexpected ']]]'"")
    def test_error_msg(self):
        infile = reindent_block(infile)
            Cog().process_string(infile)
    def test_error_no_msg(self):
        infile = reindent_block(infile)
            Cog().process_string(infile)
    def test_no_error_if_error_not_called(self):
        infile = reindent_block(infile)
        self.assertEqual(Cog().process_string(infile), infile)
        self.m = self.gen.parse_marker
        self.parse_line = self.gen.parse_line
    def test_empty(self):
        self.assertEqual(self.gen.get_code(), """")
    def test_simple(self):
        self.parse_line('  print ""hello""')
        self.parse_line('  print ""bye""')
        self.assertEqual(self.gen.get_code(), 'print ""hello""\nprint ""bye""')
    def test_compressed1(self):
        self.parse_line(""// hello"")
        self.parse_line(""// bye"")
        self.assertEqual(self.gen.get_code(), ""hello\nbye"")
    def test_compressed2(self):
        self.parse_line(""hello"")
        self.parse_line(""bye"")
        self.assertEqual(self.gen.get_code(), ""hello\nbye"")
    def test_compressed3(self):
        self.parse_line('print """"""hello')
        self.parse_line(""bye"")
        self.assertEqual(self.gen.get_code(), 'print """"""hello\nbye')
    def test_compressed4(self):
        self.parse_line(""hello"")
        self.parse_line('bye"""""")')
        self.assertEqual(self.gen.get_code(), 'hello\nbye"""""")')
    def test_no_common_prefix_for_markers(self):
        self.parse_line(""\timport cog, sys"")
        self.parse_line("""")
        self.parse_line(""\tprint sys.argv"")
        self.assertEqual(self.gen.get_code(), ""import cog, sys\n\nprint sys.argv"")
    def new_cog(self):
        self.cog.set_output(stdout=self.output, stderr=self.output)
        self.new_cog()
    def assertFilesSame(self, file_name1, file_name2):
        with open(os.path.join(self.tempdir, file_name1), ""rb"") as f1:
        with open(os.path.join(self.tempdir, file_name2), ""rb"") as f2:
    def test_argument_failure(self):
            self.cog.callable_main([""argv0""])
            self.cog.callable_main([""argv0"", ""-j""])
    def test_no_dash_o_and_at_file(self):
        make_files({""cogfiles.txt"": ""# Please run cog""})
            self.cog.callable_main([""argv0"", ""-o"", ""foo"", ""@cogfiles.txt""])
    def test_no_dash_o_and_amp_file(self):
        make_files({""cogfiles.txt"": ""# Please run cog""})
            self.cog.callable_main([""argv0"", ""-o"", ""foo"", ""&cogfiles.txt""])
    def test_dash_v(self):
    def produces_help(self, args):
        self.new_cog()
    def test_dash_h(self):
        self.produces_help(""-h"")
        self.produces_help(""-?"")
        self.produces_help(""fooey.txt -h"")
        self.produces_help(""-o -r @fooey.txt -? @booey.txt"")
    def test_dash_o_and_dash_r(self):
        make_files(d)
            self.cog.callable_main([""argv0"", ""-o"", ""foo"", ""-r"", ""cogfile.txt""])
    def test_dash_z(self):
        make_files(d)
            self.cog.callable_main([""argv0"", ""-r"", ""test.cog""])
        self.new_cog()
        self.cog.callable_main([""argv0"", ""-r"", ""-z"", ""test.cog""])
    def test_bad_dash_d(self):
            self.cog.callable_main([""argv0"", ""-Dfooey"", ""cog.txt""])
            self.cog.callable_main([""argv0"", ""-D"", ""fooey"", ""cog.txt""])
    def test_bad_markers(self):
            self.cog.callable_main([""argv0"", ""--markers=X""])
            self.cog.callable_main([""argv0"", ""--markers=A B C D""])
        make_files(self.files)
        expected = reindent_block(""""""\
        make_files(self.files)
        expected = reindent_block(""""""\
    def test_simple(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-r"", ""test.cog""])
    def test_print_output(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-rP"", ""test.cog""])
    def test_wildcards(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-r"", ""t*.cog""])
    def test_output_file(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-o"", ""in/a/dir/test.cogged"", ""test.cog""])
    def test_at_file(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-r"", ""@cogfiles.txt""])
    def test_nested_at_file(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-r"", ""@cogfiles.txt""])
    def test_at_file_with_args(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""@cogfiles.txt""])
    def test_at_file_with_bad_arg_combo(self):
        make_files(d)
            self.cog.callable_main([""argv0"", ""-r"", ""@cogfiles.txt""])
    def test_at_file_with_tricky_filenames(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-z"", ""-r"", ""@cogfiles.txt""])
    def test_amp_file(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-r"", ""&code/files_to_cog""])
        make_files(d)
        self.cog.callable_main(
    def test_output_native_eol(self):
        make_files({""infile"": ""\n"".join(self.lines_in)})
        self.cog.callable_main([""argv0"", ""-o"", ""outfile"", ""infile""])
    def test_output_lf_eol(self):
        make_files({""infile"": ""\n"".join(self.lines_in)})
        self.cog.callable_main([""argv0"", ""-U"", ""-o"", ""outfile"", ""infile""])
    def test_replace_native_eol(self):
        make_files({""test.cog"": ""\n"".join(self.lines_in)})
        self.cog.callable_main([""argv0"", ""-r"", ""test.cog""])
    def test_replace_lf_eol(self):
        make_files({""test.cog"": ""\n"".join(self.lines_in)})
        self.cog.callable_main([""argv0"", ""-U"", ""-r"", ""test.cog""])
    def test_simple(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-r"", ""test.cog""])
    def test_file_encoding_option(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-n"", ""cp1251"", ""-r"", ""test.cog""])
    def test_need_include_path(self):
        make_files(self.dincludes)
            self.cog.callable_main([""argv0"", ""-r"", ""test.cog""])
    def test_include_path(self):
        make_files(self.dincludes)
        self.cog.callable_main([""argv0"", ""-r"", ""-I"", ""include"", ""test.cog""])
    def test_two_include_paths(self):
        make_files(self.dincludes)
        self.cog.callable_main(
    def test_two_include_paths2(self):
        make_files(self.dincludes)
        self.cog.callable_main(
    def test_useless_include_path(self):
        make_files(self.dincludes)
        self.cog.callable_main(
    def test_sys_path_is_unchanged(self):
        make_files(d)
        self.new_cog()
        self.new_cog()
        self.cog.callable_main([""argv0"", ""-r"", ""good.cog""])
        self.new_cog()
        self.cog.callable_main([""argv0"", ""-r"", ""-I"", ""xyzzy"", ""good.cog""])
        self.new_cog()
        self.cog.callable_main([""argv0"", ""-r"", ""-I"", ""xyzzy"", ""-I"", ""quux"", ""good.cog""])
        self.new_cog()
            self.cog.callable_main([""argv0"", ""-r"", ""bad.cog""])
        self.new_cog()
            self.cog.callable_main([""argv0"", ""-r"", ""-I"", ""xyzzy"", ""bad.cog""])
        self.new_cog()
            self.cog.callable_main(
    def test_sub_directories(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-r"", ""code/test.cog""])
    def test_warn_if_no_cog_code(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-e"", ""with.cog""])
        self.new_cog()
        self.cog.callable_main([""argv0"", ""-e"", ""without.cog""])
        self.new_cog()
        self.cog.callable_main([""argv0"", ""without.cog""])
    def test_file_name_props(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-r"", ""cog1.txt""])
        self.new_cog()
        self.cog.callable_main([""argv0"", ""-o"", ""cog1out.txt"", ""cog1.txt""])
    def test_globals_dont_cross_files(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-r"", ""@cogfiles.txt""])
    def test_remove_generated_output(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-r"", ""-x"", ""cog1.txt""])
        self.new_cog()
        self.cog.callable_main([""argv0"", ""-r"", ""cog1.txt""])
        self.new_cog()
        self.cog.callable_main([""argv0"", ""-r"", ""-x"", ""cog1.txt""])
    def test_msg_call(self):
        infile = reindent_block(infile)
        self.assertEqual(self.cog.process_string(infile), infile)
    def test_error_message_has_no_traceback(self):
        make_files(d)
        self.cog.set_output(stderr=stderr)
    def test_dash_d(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-r"", ""-D"", ""fooey=kablooey"", ""test.cog""])
        make_files(d)
        self.cog.callable_main([""argv0"", ""-r"", ""-Dfooey=kablooey"", ""test.cog""])
        make_files(d)
        self.cog.callable_main([""argv0"", ""-r"", ""-Dfooey=e=mc2"", ""test.cog""])
        make_files(d)
        self.cog.callable_main(
        make_files(d)
        self.cog.callable_main(
        make_files(d)
        self.cog.callable_main(
    def test_output_to_stdout(self):
        make_files(d)
        self.cog.set_output(stderr=stderr)
        self.cog.callable_main([""argv0"", ""test.cog""])
    def test_read_from_stdin(self):
        self.cog.set_output(stderr=stderr)
        self.cog.callable_main([""argv0"", ""-""])
    def test_suffix_output_lines(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-r"", ""-s"", "" (foo)"", ""test.cog""])
    def test_empty_suffix(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-r"", ""-s"", """", ""test.cog""])
    def test_hellish_suffix(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-z"", ""-r"", ""-s"", r"" /\n*+([)]><"", ""test.cog""])
    def test_prologue(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-r"", ""-p"", ""import math"", ""test.cog""])
    def test_threads(self):
        make_files(d)
            content = reindent_block(content)
        make_files(d)
        make_files(d)
        make_files(d)
        make_files(d)
            self.new_cog()
        make_files(d)
        make_files(d)
        make_files(self.d)
    def test_readonly_no_command(self):
            self.cog.callable_main([""argv0"", ""-r"", ""test.cog""])
    def test_readonly_with_command(self):
        self.cog.callable_main([""argv0"", ""-r"", ""-w"", self.cmd_w_args, ""test.cog""])
    def test_readonly_with_command_with_no_slot(self):
        self.cog.callable_main([""argv0"", ""-r"", ""-w"", self.cmd_w_asterisk, ""test.cog""])
    def test_readonly_with_ineffectual_command(self):
            self.cog.callable_main([""argv0"", ""-r"", ""-w"", ""echo %s"", ""test.cog""])
    def test_create_checksum_output(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-r"", ""-c"", ""cog1.txt""])
    def test_check_checksum_output(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-r"", ""-c"", ""cog1.txt""])
    def test_remove_checksum_output(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-r"", ""cog1.txt""])
    def test_tampered_checksum_output(self):
        make_files(d)
            self.cog.callable_main([""argv0"", ""-c"", ""cog1.txt""])
            self.cog.callable_main([""argv0"", ""-c"", ""cog2.txt""])
            self.cog.callable_main([""argv0"", ""-c"", ""cog3.txt""])
            self.cog.callable_main([""argv0"", ""-c"", ""cog4.txt""])
            self.cog.callable_main([""argv0"", ""-c"", ""cog5.txt""])
            self.cog.callable_main([""argv0"", ""-c"", ""cog6.txt""])
    def test_argv_isnt_modified(self):
        self.cog.callable_main(argv)
    def test_customer_markers(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-r"", ""--markers={{ }} {{end}}"", ""test.cog""])
    def test_truly_wacky_markers(self):
        make_files(d)
        self.cog.callable_main(
    def test_change_just_one_marker(self):
        make_files(d)
        self.cog.callable_main(
    def test_delete_code(self):
        make_files(d)
        self.cog.callable_main([""argv0"", ""-d"", ""-o"", ""test.cogged"", ""test.cog""])
    def test_delete_code_with_dash_r_fails(self):
        make_files(d)
            self.cog.callable_main([""argv0"", ""-r"", ""-d"", ""test.cog""])
    def test_setting_globals(self):
        make_files(d)
        self.cog.options.delete_code = True
        self.cog.process_file(""test.cog"", ""test.cogged"", globals=globals)
    def test_error_call_has_no_traceback(self):
        make_files(d)
    def test_real_error_has_traceback(self):
        make_files(d)
    def check_files_exist(self, d, dname):
                self.check_files_exist(d[fname], os.path.join(dname, fname))
    def check_files_dont_exist(self, d, dname):
    def test_one_file(self):
        makefiles.make_files(d, self.tempdir)
        makefiles.remove_files(d, self.tempdir)
    def test_many_files(self):
        self.check_files_dont_exist(d, self.tempdir)
        makefiles.make_files(d, self.tempdir)
        self.check_files_exist(d, self.tempdir)
        makefiles.remove_files(d, self.tempdir)
        self.check_files_dont_exist(d, self.tempdir)
    def test_overlapping(self):
        self.check_files_dont_exist(d1, self.tempdir)
        self.check_files_dont_exist(d2, self.tempdir)
        makefiles.make_files(d1, self.tempdir)
        makefiles.make_files(d2, self.tempdir)
        self.check_files_exist(d1, self.tempdir)
        self.check_files_exist(d2, self.tempdir)
        makefiles.remove_files(d1, self.tempdir)
        makefiles.remove_files(d2, self.tempdir)
        self.check_files_dont_exist(d1, self.tempdir)
        self.check_files_dont_exist(d2, self.tempdir)

    def test_contents(self):
        makefiles.make_files(d, self.tempdir)
    def test_dedent(self):
        makefiles.make_files(d, self.tempdir)
from .whiteutils import common_prefix, reindent_block, white_prefix
    def test_single_line(self):
        self.assertEqual(white_prefix([""""]), """")
        self.assertEqual(white_prefix(["" ""]), """")
        self.assertEqual(white_prefix([""x""]), """")
        self.assertEqual(white_prefix(["" x""]), "" "")
        self.assertEqual(white_prefix([""\tx""]), ""\t"")
        self.assertEqual(white_prefix([""  x""]), ""  "")
        self.assertEqual(white_prefix(["" \t \tx   ""]), "" \t \t"")
    def test_multi_line(self):
        self.assertEqual(white_prefix([""  x"", ""  x"", ""  x""]), ""  "")
        self.assertEqual(white_prefix([""   y"", ""  y"", "" y""]), "" "")
        self.assertEqual(white_prefix(["" y"", ""  y"", ""   y""]), "" "")
    def test_blank_lines_are_ignored(self):
        self.assertEqual(white_prefix([""  x"", ""  x"", """", ""  x""]), ""  "")
        self.assertEqual(white_prefix(["""", ""  x"", ""  x"", ""  x""]), ""  "")
        self.assertEqual(white_prefix([""  x"", ""  x"", ""  x"", """"]), ""  "")
        self.assertEqual(white_prefix([""  x"", ""  x"", ""          "", ""  x""]), ""  "")
    def test_tab_characters(self):
        self.assertEqual(white_prefix([""\timport sys"", """", ""\tprint sys.argv""]), ""\t"")
    def test_decreasing_lengths(self):
        self.assertEqual(white_prefix([""   x"", ""  x"", "" x""]), "" "")
        self.assertEqual(white_prefix([""     x"", "" x"", "" x""]), "" "")
    def test_non_term_line(self):
        self.assertEqual(reindent_block(""""), """")
        self.assertEqual(reindent_block(""x""), ""x"")
        self.assertEqual(reindent_block("" x""), ""x"")
        self.assertEqual(reindent_block(""  x""), ""x"")
        self.assertEqual(reindent_block(""\tx""), ""x"")
        self.assertEqual(reindent_block(""x"", "" ""), "" x"")
        self.assertEqual(reindent_block(""x"", ""\t""), ""\tx"")
        self.assertEqual(reindent_block("" x"", "" ""), "" x"")
        self.assertEqual(reindent_block("" x"", ""\t""), ""\tx"")
        self.assertEqual(reindent_block("" x"", ""  ""), ""  x"")

    def test_single_line(self):
        self.assertEqual(reindent_block(""\n""), ""\n"")
        self.assertEqual(reindent_block(""x\n""), ""x\n"")
        self.assertEqual(reindent_block("" x\n""), ""x\n"")
        self.assertEqual(reindent_block(""  x\n""), ""x\n"")
        self.assertEqual(reindent_block(""\tx\n""), ""x\n"")
        self.assertEqual(reindent_block(""x\n"", "" ""), "" x\n"")
        self.assertEqual(reindent_block(""x\n"", ""\t""), ""\tx\n"")
        self.assertEqual(reindent_block("" x\n"", "" ""), "" x\n"")
        self.assertEqual(reindent_block("" x\n"", ""\t""), ""\tx\n"")
        self.assertEqual(reindent_block("" x\n"", ""  ""), ""  x\n"")

    def test_real_block(self):
            reindent_block(""\timport sys\n\n\tprint sys.argv\n""),
    def test_degenerate_cases(self):
        self.assertEqual(common_prefix([]), """")
        self.assertEqual(common_prefix([""""]), """")
        self.assertEqual(common_prefix(["""", """", """", """", """"]), """")
        self.assertEqual(common_prefix([""cat in the hat""]), ""cat in the hat"")
    def test_no_common_prefix(self):
        self.assertEqual(common_prefix([""a"", ""b""]), """")
        self.assertEqual(common_prefix([""a"", ""b"", ""c"", ""d"", ""e"", ""f""]), """")
        self.assertEqual(common_prefix([""a"", ""a"", ""a"", ""a"", ""a"", ""x""]), """")
    def test_usual_cases(self):
        self.assertEqual(common_prefix([""ab"", ""ac""]), ""a"")
        self.assertEqual(common_prefix([""aab"", ""aac""]), ""aa"")
        self.assertEqual(common_prefix([""aab"", ""aab"", ""aab"", ""aac""]), ""aa"")
    def test_blank_line(self):
        self.assertEqual(common_prefix([""abc"", ""abx"", """", ""aby""]), """")
    def test_decreasing_lengths(self):
        self.assertEqual(common_prefix([""abcd"", ""abc"", ""ab""]), ""ab"")
    def set_output(self, stdout=None, stderr=None):
def white_prefix(strings):
def reindent_block(lines, new_indent=""""):
    old_indent = white_prefix(lines)
    out_lines = []
        if old_indent:
            line = line.replace(old_indent, nothing, 1)
        if line and new_indent:
            line = new_indent + line
        out_lines.append(line)
    return sep.join(out_lines)
def common_prefix(strings):",bug-free
"from klingon_serial.generate_serial import generate_serial
from datetime import datetime
    epoch = int(datetime.utcnow().timestamp() * 1000)
    print(""Epoch datetime (ms):     "",int(datetime.utcnow().timestamp() * 1000))

    """"""Convert a string representation of truth to true (1) or false (0).
    Args:
        val (str): The string representation of truth value.

    Returns:
        int: 1 if the value is true, 0 if the value is false.

    Raises:
        ValueError: If the value is not a valid truth value.
    val = val.lower()
    if val in ('y', 'yes', 't', 'true', 'on', '1'):
        return 1
    elif val in ('n', 'no', 'f', 'false', 'off', '0'):
        return 0
    else:
        raise ValueError(""Invalid truth value %r"" % (val,))

###
### klingon_serial setup.py
### 
    name='klingon_serial',
        'datetime',
        'pytest',
        'uuid',
        'setuptools'
    python_requires='>=3.6',
)
from klingon_serial.generate_serial import generate_serial, get_mac_address_hex, get_process_id, get_millisecond_epoch_hex
    assert get_debug() is True
    assert get_debug() is False",buggy
"from klingon_serial.generate import generate_serial
from datetime import datetime, timezone
    epoch = int(datetime.now(timezone.utc).timestamp() * 1000)
    print(""Epoch datetime (ms):     "",int(datetime.now(timezone.utc).timestamp() * 1000))
from distutils.util import strtobool as str2bool

    """"""Convert a string representation of truth to true (True) or false (False).
    This function is a wrapper around str2bool for compatibility.
    return str2bool(val)
""""""
This module provides utility functions for the klingon_serial package, including
retrieving the MAC address and network interface, and determining the debug mode.
""""""

    try:
        # Get primary network interface by looking at the default route
        primary_interface = None
        for interface, addrs in psutil.net_if_addrs().items():
            for addr in addrs:
                if addr.family == psutil.AF_LINK:
                    primary_interface = interface
                    mac_address = addr.address
                    return mac_address, primary_interface  # Return on first found interface
    except Exception as e:
        print(f""Error retrieving network interface: {e}"")
    name='klingon-serial',
        'pytest>=6.0',  # Specify the minimum version required
        'str2bool',
    license='MIT',  # Add the license field
    python_requires='>=3.9',
)
from klingon_serial.generate import generate_serial, get_mac_address_hex, get_process_id, get_millisecond_epoch_hex
    assert get_debug() == True
    assert get_debug() == False",bug-free
"        'std_mean': None,
        'std_meanunbiased': None,
        'gradient', 'var', 'std', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm, var_mean as _var_mean
    _lib.impl(""var_mean.correction"", _var_mean, ""MPS"")",buggy
"        'gradient', 'var', 'std', 'std_mean', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm",bug-free
"        'std_mean': None,
        'std_meanunbiased': None,
        'gradient', 'var', 'std', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm, var_mean as _var_mean
    _lib.impl(""var_mean.correction"", _var_mean, ""MPS"")",buggy
"        'gradient', 'var', 'std', 'std_mean', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm",bug-free
"        'std_mean': None,
        'std_meanunbiased': None,
        'gradient', 'var', 'std', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm, var_mean as _var_mean
    _lib.impl(""var_mean.correction"", _var_mean, ""MPS"")",buggy
"        'gradient', 'var', 'std', 'std_mean', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm",bug-free
"        'std_mean': None,
        'std_meanunbiased': None,
        'gradient', 'var', 'std', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm, var_mean as _var_mean
    _lib.impl(""var_mean.correction"", _var_mean, ""MPS"")",buggy
"        'gradient', 'var', 'std', 'std_mean', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm",bug-free
"        'std_mean': None,
        'std_meanunbiased': None,
        'gradient', 'var', 'std', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm, var_mean as _var_mean
    _lib.impl(""var_mean.correction"", _var_mean, ""MPS"")",buggy
"        'gradient', 'var', 'std', 'std_mean', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm",bug-free
"        'std_mean': None,
        'std_meanunbiased': None,
        'gradient', 'var', 'std', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm, var_mean as _var_mean
    _lib.impl(""var_mean.correction"", _var_mean, ""MPS"")",buggy
"        'gradient', 'var', 'std', 'std_mean', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm",bug-free
"        'std_mean': None,
        'std_meanunbiased': None,
        'gradient', 'var', 'std', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm, var_mean as _var_mean
    _lib.impl(""var_mean.correction"", _var_mean, ""MPS"")",buggy
"        'gradient', 'var', 'std', 'std_mean', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm",bug-free
"        'std_mean': None,
        'std_meanunbiased': None,
        'gradient', 'var', 'std', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm, var_mean as _var_mean
    _lib.impl(""var_mean.correction"", _var_mean, ""MPS"")",buggy
"        'gradient', 'var', 'std', 'std_mean', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm",bug-free
"        'std_mean': None,
        'std_meanunbiased': None,
        'gradient', 'var', 'std', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm, var_mean as _var_mean
    _lib.impl(""var_mean.correction"", _var_mean, ""MPS"")",buggy
"        'gradient', 'var', 'std', 'std_mean', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm",bug-free
"        'std_mean': None,
        'std_meanunbiased': None,
        'gradient', 'var', 'std', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm, var_mean as _var_mean
    _lib.impl(""var_mean.correction"", _var_mean, ""MPS"")",buggy
"        'gradient', 'var', 'std', 'std_mean', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm",bug-free
"        'std_mean': None,
        'std_meanunbiased': None,
        'gradient', 'var', 'std', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm, var_mean as _var_mean
    _lib.impl(""var_mean.correction"", _var_mean, ""MPS"")",buggy
"        'gradient', 'var', 'std', 'std_mean', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm",bug-free
"        'std_mean': None,
        'std_meanunbiased': None,
        'gradient', 'var', 'std', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm, var_mean as _var_mean
    _lib.impl(""var_mean.correction"", _var_mean, ""MPS"")",buggy
"        'gradient', 'var', 'std', 'std_mean', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm",bug-free
"        'std_mean': None,
        'std_meanunbiased': None,
        'gradient', 'var', 'std', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm, var_mean as _var_mean
    _lib.impl(""var_mean.correction"", _var_mean, ""MPS"")",buggy
"        'gradient', 'var', 'std', 'std_mean', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm",bug-free
"        'std_mean': None,
        'std_meanunbiased': None,
        'gradient', 'var', 'std', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm, var_mean as _var_mean
    _lib.impl(""var_mean.correction"", _var_mean, ""MPS"")",buggy
"        'gradient', 'var', 'std', 'std_mean', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm",bug-free
"        'std_mean': None,
        'std_meanunbiased': None,
        'gradient', 'var', 'std', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm, var_mean as _var_mean
    _lib.impl(""var_mean.correction"", _var_mean, ""MPS"")",buggy
"        'gradient', 'var', 'std', 'std_mean', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm",bug-free
"        'std_mean': None,
        'std_meanunbiased': None,
        'gradient', 'var', 'std', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm, var_mean as _var_mean
    _lib.impl(""var_mean.correction"", _var_mean, ""MPS"")",buggy
"        'gradient', 'var', 'std', 'std_mean', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm",bug-free
"        'std_mean': None,
        'std_meanunbiased': None,
        'gradient', 'var', 'std', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm, var_mean as _var_mean
    _lib.impl(""var_mean.correction"", _var_mean, ""MPS"")",buggy
"        'gradient', 'var', 'std', 'std_mean', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm",bug-free
"        'std_mean': None,
        'std_meanunbiased': None,
        'gradient', 'var', 'std', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm, var_mean as _var_mean
    _lib.impl(""var_mean.correction"", _var_mean, ""MPS"")",buggy
"        'gradient', 'var', 'std', 'std_mean', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm",bug-free
"        'std_mean': None,
        'std_meanunbiased': None,
        'gradient', 'var', 'std', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm, var_mean as _var_mean
    _lib.impl(""var_mean.correction"", _var_mean, ""MPS"")",buggy
"        'gradient', 'var', 'std', 'std_mean', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm",bug-free
"        'std_mean': None,
        'std_meanunbiased': None,
        'gradient', 'var', 'std', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm, var_mean as _var_mean
    _lib.impl(""var_mean.correction"", _var_mean, ""MPS"")",buggy
"        'gradient', 'var', 'std', 'std_mean', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm",bug-free
"        'std_mean': None,
        'std_meanunbiased': None,
        'gradient', 'var', 'std', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm, var_mean as _var_mean
    _lib.impl(""var_mean.correction"", _var_mean, ""MPS"")",buggy
"        'gradient', 'var', 'std', 'std_mean', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm",bug-free
"        'std_mean': None,
        'std_meanunbiased': None,
        'gradient', 'var', 'std', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm, var_mean as _var_mean
    _lib.impl(""var_mean.correction"", _var_mean, ""MPS"")",buggy
"        'gradient', 'var', 'std', 'std_mean', 'ldexp',
    from ..._refs import native_group_norm as _native_group_norm",bug-free
"if sys.version_info >= (2, 6):
    def binary(obj):
        return bytes(obj)
else:
    def binary(obj):
        return buffer(obj)

if sys.version_info >= (3, 0):
    text_type = str
    base_text_type = str
else:
    text_type = unicode
    base_text_type = basestring
    _fields_ = [(""Data1"", DWORD),
                (""Data2"", WORD),
                (""Data3"", WORD),
                (""Data4"", BYTE * 8)]
            _CLSIDFromString(text_type(name), byref(self))
        return 'GUID(""%s"")' % text_type(self)
        return isinstance(other, GUID) and \
               binary(self) == binary(other)
        return GUID(text_type(self))
        """"""Get guid from progid, ...
        """"""
        elif isinstance(progid, base_text_type):
            _CLSIDFromProgID(text_type(progid), byref(inst))
from ctypes import _SimpleCData
from _ctypes import COMError
################################################################

def add_metaclass(metaclass):
    """"""Class decorator from six.py for creating a class with a metaclass.

    Copyright (c) 2010-2020 Benjamin Peterson

    Permission is hereby granted, free of charge, to any person obtaining a copy of
    this software and associated documentation files (the ""Software""), to deal in
    the Software without restriction, including without limitation the rights to
    use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of
    the Software, and to permit persons to whom the Software is furnished to do so,
    subject to the following conditions:

    The above copyright notice and this permission notice shall be included in all
    copies or substantial portions of the Software.

    THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
    FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
    COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
    IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
    CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
    """"""
    def wrapper(cls):
        orig_vars = cls.__dict__.copy()
        slots = orig_vars.get('__slots__')
        if slots is not None:
            if isinstance(slots, text_type):
                slots = [slots]
            for slots_var in slots:
                orig_vars.pop(slots_var)
        orig_vars.pop('__dict__', None)
        orig_vars.pop('__weakref__', None)
        if hasattr(cls, '__qualname__'):
            orig_vars['__qualname__'] = cls.__qualname__
        return metaclass(cls.__name__, cls.__bases__, orig_vars)
    return wrapper

################################################################

# type hinting symbols
#
# `if TYPE_CHECKING:` code block must not be executed because `TYPE_CHECKING`
# is always `False` in runtime.
# see https://peps.python.org/pep-0484/#runtime-or-type-checking
#
if sys.version_info >= (3, 5):
    from typing import TYPE_CHECKING
else:  # typehints in this package don't support Py<3.5 due to importing symbols.
    TYPE_CHECKING = False
#
# Annotations must be placed in a `# type:` comment in according to PEP484.
# see https://peps.python.org/pep-0484/#suggested-syntax-for-python-2-7-and-straddling-code
# - `NameError` never raises by using those symbols.
# - It is not able to use any runtime introspections, such as
#   `typing.get_type_hints` or `typing.get_origin`.
#
    # _CData = _SimpleCData.__mro__[:-1][-1]  # defining in runtime
    from ctypes import _Pointer
    from typing import Any, ClassVar, overload, TypeVar
    # XXX: symbols for backward compatibility.
    # instead of `builtins`. see PEP585.
    from typing import Dict, List, Tuple, Type
    # instead of `collections.abc`. see PEP585.
    from typing import Callable, Iterable, Iterator
    # instead of `A | B` and `None | A`. see PEP604.
    from typing import Union as _UnionT  #  avoiding confusion with `ctypes.Union`
    from typing import Optional
    # utilities or workarounds for annotations.
    from comtypes import hints as hints

################################################################
    ComMemberGenerator, _ComMemberSpec, DispMemberGenerator, _DispMemberSpec,
    _encode_idl, _resolve_argspec,
################################################################
if sys.version_info >= (3, 0):
    text_type = str
else:
    text_type = unicode
if sys.version_info >= (3, 0):
    pythonapi.PyInstanceMethod_New.argtypes = [py_object]
    pythonapi.PyInstanceMethod_New.restype = py_object
    PyInstanceMethod_Type = type(pythonapi.PyInstanceMethod_New(id))
    def instancemethod(func, inst, cls):
        mth = PyInstanceMethod_Type(func)
        if inst is None:
            return mth
        return mth.__get__(inst)
else:
    def instancemethod(func, inst, cls):
        return types.MethodType(func, inst, cls)
##class IDLWarning(UserWarning):
##    ""Warn about questionable type information""
tagCLSCTX = c_int # enum

_ole32_nohresult = windll.ole32 # use this for functions that don't return a HRESULT
COINIT_MULTITHREADED     = 0x0
COINIT_DISABLE_OLE1DDE   = 0x4
def _shutdown(func=_ole32_nohresult.CoUninitialize,
             _debug=logger.debug,
             _exc_clear=getattr(sys, ""exc_clear"", lambda: None)):
        try: func()
        except WindowsError: pass
    if TYPE_CHECKING:
        _case_insensitive_ = hints.AnnoField()  # type: bool
        _iid_ = hints.AnnoField()  # type: GUID
        _methods_ = hints.AnnoField()  # type: List[_ComMemberSpec]
        _disp_methods_ = hints.AnnoField()  # type: List[_DispMemberSpec]
        p = type(_compointer_base)(""POINTER(%s)"" % new_cls.__name__,
                                   _ptr_bases,
                                   {""__com_interface__"": new_cls,
                                    ""_needs_com_addref_"": None})
                    if fixed_name != name: # prevent unbounded recursion
                    object.__setattr__(self,
                                       self.__map_case__.get(name.lower(), name),
                                       value)
##            assert self.__dict__.get(""_methods_"", None) is None
    def _make_dispmethods(self, methods):
        # type: (List[_DispMemberSpec]) -> None
    def _make_methods(self, methods):
        # type: (List[_ComMemberSpec]) -> None
            com_interface_registry[text_type(iid)] = self
@add_metaclass(_compointer_meta)
class _compointer_base(c_void_p):
        return cmp(super(_compointer_base, self).value, super(_compointer_base, other).value)
        return super(_compointer_base, self).value == super(_compointer_base, other).value
        if self._b_base_ is None \
               or self._needsfree:
class helpstring(text_type):
def STDMETHOD(restype, name, argtypes=()):
def DISPMETHOD(idlflags, restype, name, *argspec):
def DISPPROPERTY(idlflags, proptype, name):
def COMMETHOD(idlflags, restype, methodname, *argspec):
    _T_IUnknown = TypeVar(""_T_IUnknown"", bound=""IUnknown"")
    class _IUnknown_Base(c_void_p):
        __com_QueryInterface = hints.AnnoField()  # type: Callable[[Any, Any], int]
        __com_AddRef = hints.AnnoField()  # type: Callable[[], int]
        __com_Release = hints.AnnoField()  # type: Callable[[], int]
@add_metaclass(_cominterface_meta)
class IUnknown(_IUnknown_Base):
    _case_insensitive_ = False  # type: ClassVar[bool]
    _iid_ = GUID(""{00000000-0000-0000-C000-000000000046}"")  # type: ClassVar[GUID]
    _methods_ = [
        STDMETHOD(HRESULT, ""QueryInterface"",
                  [POINTER(GUID), POINTER(c_void_p)]),
        STDMETHOD(c_ulong, ""Release"")
    ]  # type: ClassVar[List[_ComMemberSpec]]
    def QueryInterface(self, interface, iid=None):
        # type: (Type[_T_IUnknown], Optional[GUID]) -> _T_IUnknown
        clsid = self.__dict__.get('__clsid')
            p.__dict__['__clsid'] = clsid
    def AddRef(self):
        # type: () -> int
    def Release(self):
        # type: () -> int
    _iid_ = GUID('{0000010C-0000-0000-C000-000000000046}')
        COMMETHOD([], HRESULT, 'GetClassID',
                  ( ['out'], POINTER(GUID), 'pClassID' )),
        ]
        # Returns the CLSID that uniquely represents an object class that
        # defines the code that can manipulate the object's data.
        GetClassID = hints.AnnoField()  # type: Callable[[], GUID]
    _iid_ = GUID('{6D5140C1-7436-11CE-8034-00AA006009FA}')
    if TYPE_CHECKING:
        _QueryService = hints.AnnoField()  # type: Callable[[Any, Any, Any], int]
    def QueryService(self, serviceIID, interface):
        # type: (GUID, Type[_T_IUnknown]) -> _T_IUnknown
        COMMETHOD([], HRESULT, 'QueryService',
                  ( ['in'], POINTER(GUID), 'guidService' ),
                  ( ['in'], POINTER(GUID), 'riid' ),
                  ( ['in'], POINTER(c_void_p), 'ppvObject' ))
        ]
if TYPE_CHECKING:
    @overload
    def CoGetObject(displayname, interface):  # `interface` can't be missing
        # type: (str, None) -> IUnknown
        pass
    @overload
    def CoGetObject(displayname, interface):  # it should be called this way
        # type: (str, Type[_T_IUnknown]) -> _T_IUnknown
        pass
def CoGetObject(displayname, interface):
    # type: (str, Optional[Type[IUnknown]]) -> IUnknown
    _ole32.CoGetObject(text_type(displayname),
                       None,
                       byref(interface._iid_),
                       byref(punk))
if TYPE_CHECKING:
    pUnkOuter = Type[_Pointer[IUnknown]]
    @overload
    def CoCreateInstance(clsid, interface=None, clsctx=None, punkouter=None):
        # type: (GUID, None, Optional[int], Optional[pUnkOuter]) -> IUnknown
        pass
    @overload
    def CoCreateInstance(clsid, interface, clsctx=None, punkouter=None):
        # type: (GUID, Type[_T_IUnknown], Optional[int], Optional[pUnkOuter]) -> _T_IUnknown
        pass
def CoCreateInstance(clsid, interface=None, clsctx=None, punkouter=None):
    # type: (GUID, Optional[Type[IUnknown]], Optional[int], Optional[pUnkOuter]) -> IUnknown
    _CoGetClassObject(clsid,
                      clsctx,
                      pServerInfo,
                      interface._iid_,
                      byref(p))
if TYPE_CHECKING:
    @overload
    def GetActiveObject(clsid, interface=None):
        # type: (GUID, None) -> IUnknown
        pass
    @overload
    def GetActiveObject(clsid, interface):
        # type: (GUID, Type[_T_IUnknown]) -> _T_IUnknown
        pass
def GetActiveObject(clsid, interface=None):
    # type: (GUID, Optional[Type[IUnknown]]) -> IUnknown
    _fields_ = [(""pIID"", POINTER(GUID)),
                (""pItf"", POINTER(c_void_p)),
                (""hr"", HRESULT)]
        pIID = hints.AnnoField()  # type: GUID
        pItf = hints.AnnoField()  # type: _Pointer[c_void_p]
        hr = hints.AnnoField()  # type: HRESULT
        ('User', POINTER(c_ushort)),
        ('UserLength', c_ulong),
        ('Domain', POINTER(c_ushort)),
        ('DomainLength', c_ulong),
        ('Password', POINTER(c_ushort)),
        ('PasswordLength', c_ulong),
        ('Flags', c_ulong),
        ('dwAuthnSvc', c_ulong),
        ('dwAuthzSvc', c_ulong),
        ('pwszServerPrincName', c_wchar_p),
        ('dwAuthnLevel', c_ulong),
        ('dwImpersonationLevel', c_ulong),
        ('pAuthIdentityData', POINTER(_COAUTHIDENTITY)),
        ('dwCapabilities', c_ulong),
        ('dwReserved1', c_ulong),
        ('pwszName', c_wchar_p),
        ('pAuthInfo', POINTER(_COAUTHINFO)),
        ('dwReserved2', c_ulong),
        dwReserved1 = hints.AnnoField()  # type: int
        pwszName = hints.AnnoField()  # type: Optional[str]
        pAuthInfo = hints.AnnoField()  # type: _COAUTHINFO
        dwReserved2 = hints.AnnoField()  # type: int
_CoGetClassObject.argtypes = [POINTER(GUID), DWORD, POINTER(COSERVERINFO),
                              POINTER(GUID), POINTER(c_void_p)]
        ('cbStruct', c_ulong),
        ('grfFlags', c_ulong),
        ('grfMode', c_ulong),
        ('dwTickCountDeadline', c_ulong)
        ('cbStruct', c_ulong),
        ('grfFlags', c_ulong),
        ('grfMode', c_ulong),
        ('dwTickCountDeadline', c_ulong),
        ('dwTrackFlags', c_ulong),
        ('dwClassContext', c_ulong),
        ('locale', c_ulong),
        ('pServerInfo', POINTER(_COSERVERINFO)),
#Structures for security setups
        ('User', POINTER(c_ushort)),
        ('UserLength', c_ulong),
        ('Domain', POINTER(c_ushort)),
        ('DomainLength', c_ulong),
        ('Password', POINTER(c_ushort)),
        ('PasswordLength', c_ulong),
        ('Flags', c_ulong),
        ('dwAuthnSvc', c_ulong),
        ('dwAuthzSvc', c_ulong),
        ('pAuthInfo', POINTER(_SEC_WINNT_AUTH_IDENTITY)),
        ('cAuthInfo', c_ulong),
        ('pAuthInfo', POINTER(_SOLE_AUTHENTICATION_INFO)),
SOLE_AUTHENTICATION_LIST = _SOLE_AUTHENTICATION_LIST
if TYPE_CHECKING:
    @overload
    def CoCreateInstanceEx(
        clsid, interface=None, clsctx=None, machine=None, pServerInfo=None):
        # type: (GUID, None, Optional[int], Optional[str], Optional[COSERVERINFO]) -> IUnknown
        pass
    @overload
    def CoCreateInstanceEx(
        clsid, interface=None, clsctx=None, machine=None, pServerInfo=None):
        # type: (GUID, Type[_T_IUnknown], Optional[int], Optional[str], Optional[COSERVERINFO]) -> _T_IUnknown
        pass
def CoCreateInstanceEx(clsid, interface=None,
                       clsctx=None,
                       machine=None,
                       pServerInfo=None):
    # type: (GUID, Optional[Type[IUnknown]], Optional[int], Optional[str], Optional[COSERVERINFO]) -> IUnknown
        clsctx=CLSCTX_LOCAL_SERVER|CLSCTX_REMOTE_SERVER
    _ole32.CoCreateInstanceEx(byref(clsid),
                             None,
                             clsctx,
                             pServerInfo,
                             1,
                             byref(multiqi))
@add_metaclass(_coclass_meta)
class CoClass(COMObject):
    'BIND_OPTS', 'tagBIND_OPTS', 'BINDOPTS2', 'tagBIND_OPTS2', 'BSTR',
    '_check_version', 'CLSCTX', 'tagCLSCTX', 'CLSCTX_ALL',
    'CLSCTX_DISABLE_AAA', 'CLSCTX_ENABLE_AAA', 'CLSCTX_ENABLE_CODE_DOWNLOAD',
    'CLSCTX_FROM_DEFAULT_CONTEXT', 'CLSCTX_INPROC', 'CLSCTX_INPROC_HANDLER',
    'CLSCTX_INPROC_HANDLER16', 'CLSCTX_INPROC_SERVER',
    'CLSCTX_INPROC_SERVER16', 'CLSCTX_LOCAL_SERVER', 'CLSCTX_NO_CODE_DOWNLOAD',
    'CLSCTX_NO_CUSTOM_MARSHAL', 'CLSCTX_NO_FAILURE_LOG',
    'CLSCTX_REMOTE_SERVER', 'CLSCTX_RESERVED1', 'CLSCTX_RESERVED2',
    'CLSCTX_RESERVED3', 'CLSCTX_RESERVED4', 'CLSCTX_RESERVED5',
    'CLSCTX_SERVER', '_COAUTHIDENTITY', 'COAUTHIDENTITY', '_COAUTHINFO',
    'COAUTHINFO', 'CoClass', 'CoCreateInstance', 'CoCreateInstanceEx',
    '_CoGetClassObject', 'CoGetClassObject', 'CoGetObject',
    'COINIT_APARTMENTTHREADED', 'COINIT_DISABLE_OLE1DDE',
    'COINIT_MULTITHREADED', 'COINIT_SPEED_OVER_MEMORY', 'CoInitialize',
    'CoInitializeEx', 'COMError', 'COMMETHOD', 'COMObject', '_COSERVERINFO',
    'COSERVERINFO', 'CoUninitialize', 'dispid', 'DISPMETHOD', 'DISPPROPERTY',
    'DWORD', 'EOAC_NONE', 'GetActiveObject', '_GUID', 'GUID', 'helpstring',
    'IID', 'IPersist', 'IServiceProvider', 'IUnknown', 'MULTI_QI',
    'ReturnHRESULT', 'RPC_C_AUTHN_LEVEL_CONNECT', 'RPC_C_AUTHN_WINNT',
    'RPC_C_AUTHZ_NONE', 'RPC_C_IMP_LEVEL_IMPERSONATE',
    '_SEC_WINNT_AUTH_IDENTITY', 'SEC_WINNT_AUTH_IDENTITY',
    'SEC_WINNT_AUTH_IDENTITY_UNICODE', '_SOLE_AUTHENTICATION_INFO',
    'SOLE_AUTHENTICATION_INFO', '_SOLE_AUTHENTICATION_LIST',
    'SOLE_AUTHENTICATION_LIST', 'STDMETHOD', 'wireHWND',
    FormatError, POINTER, Structure, WINFUNCTYPE, byref, c_long, c_void_p,
    oledll, pointer, windll
    DISP_E_BADINDEX, DISP_E_MEMBERNOTFOUND, E_FAIL, E_NOINTERFACE,
    E_INVALIDARG, E_NOTIMPL, RPC_E_CHANGED_MODE, S_FALSE, S_OK
if sys.version_info >= (3, 0):
    int_types = (int, )
else:
    int_types = (int, long)

        if isinstance(code, int_types):
    raise TypeError(""Expected comtypes.COMERROR or WindowsError instance, got %s"" % type(exc).__name__)
        _debug(""unimplemented method %s_%s called"", interface_name,
               method_name)
            return ReportError(text, iid=interface._iid_, clsid=clsid,
                               hresult=hresult)
            _error(""Exception in %s.%s implementation:"", interface.__name__,
                   mthname, exc_info=True)
            _warning(""Unimplemented method %s.%s called"", interface.__name__,
                     mthname)
            _error(""Exception in %s.%s implementation:"", interface.__name__,
                   mthname, exc_info=True)
        has_outargs = bool([x[0] for x in paramflags
                            if x[0] & 2])
        if a&2:
        if a&1 or a==0:
##    if args_in != code.co_argcount - 1:
##        return catch_errors(inst, mth, interface, mthname)
##        for a in outargs:
##            if not a:
##                return E_POINTER
        #make argument list for handler by index array built above
            return ReportError(text, iid=interface._iid_, clsid=clsid,
                               hresult=hresult)
            _error(""Exception in %s.%s implementation:"", interface.__name__,
                   mthname, exc_info=True)
            return ReportError(msg, iid=interface._iid_, clsid=clsid,
                               hresult=hr)
            _error(""Exception in %s.%s implementation:"", interface.__name__,
                   mthname, exc_info=True)
            _warning(""Unimplemented method %s.%s called"", interface.__name__,
                     mthname)
            _error(""Exception in %s.%s implementation:"", interface.__name__,
                   mthname, exc_info=True)
        _debug(""%r: %s.%s not implemented"", self.inst, interface.__name__,
               mthname)
        if sys.version_info >= (3, 0):
            import queue
        else:
            import Queue as queue

                if hasattr(self, ""_outgoing_interfaces_"") and \
                   IProvideClassInfo2 not in interfaces:
                    if 'propget' in idlflags:
                    elif 'propput' in idlflags:
                    elif 'propputref' in idlflags:
                            argspec = argspec + ((['out'], restype, """"),)
                    self.__make_dispentry(finder, interface, mthname,
                                          idlflags, argspec, invkind)
                        argspec += ((['out'], restype, """"),)
                    self.__make_dispentry(finder, interface,
                                          ""_get_"" + mthname,
                                          idlflags, argspec,
                                          2  # DISPATCH_PROPERTYGET
                                          )
                    if not 'readonly' in idlflags:
                        self.__make_dispentry(finder, interface,
                                              ""_set_"" + mthname,
                                              idlflags, argspec,
                                              4)  # DISPATCH_PROPERTYPUT
    def __make_dispentry(self,
                         finder, interface, mthname,
                         idlflags, argspec, invkind):
        paramflags = [((_encode_idl(x[0]), x[1]) + tuple(x[3:]))
                      for x in argspec]
        _debug(""%d active COM objects: Added   %r"", len(COMObject._instances_),
               obj)
            _debug(""%d active COM objects: Removed %r"",
                   len(COMObject._instances_), obj)
    def IUnknown_AddRef(self, this,
                        __InterlockedIncrement=_InterlockedIncrement,
                        _debug=_debug):
    def IUnknown_Release(self, this,
                         __InterlockedDecrement=_InterlockedDecrement,
                         _debug=_debug):
            raise COMError(E_NOINTERFACE, FormatError(E_NOINTERFACE),
                           (None, None, 0, None, None))
    def IDispatch_GetIDsOfNames(self, this, riid, rgszNames, cNames, lcid,
                                rgDispId):
        return windll.oleaut32.DispGetIDsOfNames(tinfo,
                                                 rgszNames, cNames, rgDispId)

    def IDispatch_Invoke(self, this, dispIdMember, riid, lcid, wFlags,
                         pDispParams, pVarResult, pExcepInfo, puArgErr):
                ptr, tinfo, dispIdMember, wFlags, pDispParams, pVarResult,
                pExcepInfo, puArgErr
            args = [params.rgvarg[i].value
                    for i in reversed(list(range(params.cNamedArgs)))]
            named_indexes = [params.rgdispidNamedArgs[i]
                             for i in range(params.cNamedArgs)]

from comtypes import TYPE_CHECKING
if TYPE_CHECKING:
    from comtypes import _CData
    from typing import (
        Any, Callable, Dict, Iterator, List, Optional, Tuple, Type, Union as _UnionT
    )
    PositionalParamFlagType = Tuple[int, Optional[str]]
    OptionalParamFlagType = Tuple[int, Optional[str], Any]
    ParamFlagType = _UnionT[PositionalParamFlagType, OptionalParamFlagType]
    PositionalArgSpecElmType = Tuple[List[str], Type[_CData], str]
    OptionalArgSpecElmType = Tuple[List[str], Type[_CData], str, Any]
    ArgSpecElmType = _UnionT[PositionalArgSpecElmType, OptionalArgSpecElmType]
    }
def _unpack_argspec(idl, typ, name=None, defval=_NOTHING):
    # type: (List[str], Type[_CData], Optional[str], Any) -> Tuple[List[str], Type[_CData], Optional[str], Any]
def _resolve_argspec(items):
    # type: (Tuple[ArgSpecElmType, ...]) -> Tuple[Tuple[ParamFlagType, ...], Tuple[Type[_CData], ...]]
class _MemberSpec(object):
    """"""Specifier of a slot of method or property.""""""
    __slots__ = (""name"", ""idlflags"", ""restype"")
    def __init__(self, name, idlflags, restype):
        self.name = name  # type: str
        self.idlflags = idlflags  # type: Tuple[_UnionT[str, int], ...]
        self.restype = restype  # type: Optional[Type[_CData]]

    def is_prop(self):
        # type: () -> bool
        propflags = (""propget"", ""propput"", ""propputref"")
        return any(f in propflags for f in self.idlflags)


class _ComMemberSpec(_MemberSpec):
    __slots__ = (""argtypes"", ""paramflags"", ""doc"")
    def __init__(self, restype, name, argtypes, paramflags, idlflags, doc):
        self.argtypes = argtypes  # type: Tuple[Type[_CData], ...]
        self.paramflags = paramflags  # type: Optional[Tuple[ParamFlagType, ...]]
        self.doc = doc  # type: Optional[str]
        super(_ComMemberSpec, self).__init__(name, idlflags, restype)
    def __iter__(self):
        # for backward compatibility:
        # A function that returns this object used to return a `tuple`.
        # So it is implemented as unpackable as well.
        for item in (self.restype, self.name, self.argtypes, self.paramflags, self.idlflags, self.doc):
            yield item
class _DispMemberSpec(_MemberSpec):
    __slots__ = (""what"", ""argspec"")
    def __init__(self, what, name, idlflags, restype, argspec):
        self.what = what  # type: str
        self.argspec = argspec  # type: Tuple[ArgSpecElmType, ...]
        super(_DispMemberSpec, self).__init__(name, idlflags, restype)
    def memid(self):
        # type: () -> int
    def __iter__(self):
        # for backward compatibility:
        # A function that returns this object used to return a `tuple`.
        # So it is implemented as unpackable as well.
        for item in (self.what, self.name, self.idlflags, self.restype, self.argspec):
            yield item
def _fix_inout_args(func, argtypes, paramflags):
    # type: (Callable[..., Any], Tuple[Type[_CData], ...], Tuple[ParamFlagType, ...]) -> Callable[..., Any]
        outargs = {}
            if direction & 3 == 3:
                atyp = argtypes[i]._type_
                try:
                    try:
                        v = args[i]
                    except IndexError:
                        v = kw[name]
                except KeyError:
                    # no parameter was passed, make an empty one
                    # of the required type
                    v = atyp()
                else:
                    # parameter was passed, call .from_param() to
                    # convert it to a ctypes type.
                        # Array of or pointer to type 'atyp' was
                        # passed, pointer to 'atyp' expected.
                        # The from_param method of simple types
                        # (c_int, c_double, ...) returns a byref()
                        # object which we cannot use since later
                        # it will be wrapped in a pointer.  Simply
                        # call the constructor with the argument
                        # in that case.
                outargs[outnum] = v
                outnum += 1
                if len(args) > i:
                    args[i] = v
                else:
            elif direction & 2 == 2:
        self._data = {}  # type: Dict[Tuple[str, Optional[str], int], List[Optional[Callable[..., Any]]]]
    def add_propget(self, name, doc, nargs, func):
        # type: (str, Optional[str], int, Callable[..., Any]) -> None
    def add_propput(self, name, doc, nargs, func):
        # type: (str, Optional[str], int, Callable[..., Any]) -> None
    def add_propputref(self, name, doc, nargs, func):
        # type: (str, Optional[str], int, Callable[..., Any]) -> None
    def __iter__(self):
        # type: () -> Iterator[Tuple[str, Optional[str], int, Optional[Callable[..., Any]], Optional[Callable[..., Any]]]]
    def __init__(self, cls_name):
        # type: (str) -> None
    def add(self, m, func):
        # type: (_MemberSpec, Callable[..., Any]) -> None
    def __iter__(self):
        # type: () -> Iterator[Tuple[str, _UnionT[property, named_property]]]
    def to_propget_keys(self, m):
        # type: (_MemberSpec) -> Tuple[str, Optional[str], int]
    def to_propput_keys(self, m):
        # type: (_MemberSpec) -> Tuple[str, Optional[str], int]
    def to_propputref_keys(self, m):
        # type: (_MemberSpec) -> Tuple[str, Optional[str], int]
    def to_propget_keys(self, m):
        # type: (_ComMemberSpec) -> Tuple[str, Optional[str], int]
        return m.name[len(""_get_""):], m.doc, nargs
    def to_propput_keys(self, m):
        # type: (_ComMemberSpec) -> Tuple[str, Optional[str], int]
        return m.name[len(""_set_""):], m.doc, nargs
    def to_propputref_keys(self, m):
        # type: (_ComMemberSpec) -> Tuple[str, Optional[str], int]
        return m.name[len(""_setref_""):], m.doc, nargs
    def to_propget_keys(self, m):
        # type: (_DispMemberSpec) -> Tuple[str, Optional[str], int]
    def to_propput_keys(self, m):
        # type: (_DispMemberSpec) -> Tuple[str, Optional[str], int]
    def to_propputref_keys(self, m):
        # type: (_DispMemberSpec) -> Tuple[str, Optional[str], int]
    def __init__(self, cls_name, vtbl_offset, iid):
        # type: (str, int, comtypes.GUID) -> None
        self._mths = []  # type: List[Tuple[str, Callable[..., Any], Callable[..., Any], bool]]
    def add(self, m):
        # type: (_ComMemberSpec) -> None
    def _fix_args(self, m, func):
        # type: (_ComMemberSpec, Callable[..., Any]) -> Callable[..., Any]
            dirflags = [(p[0]&3) for p in m.paramflags]
    def __init__(self, cls_name):
        # type: (str) -> None
        self._items = []  # type: List[Tuple[str, _UnionT[Callable[..., Any], property], bool]]
    def add(self, m):
        # type: (_DispMemberSpec) -> None
            assert not m.argspec # XXX does not yet work for properties with parameters
    def _make_disp_property(self, m):
        # type: (_DispMemberSpec) -> property
            return obj.Invoke(memid, _invkind=2) # DISPATCH_PROPERTYGET
    def _make_disp_method(self, m):
        # type: (_DispMemberSpec) -> Callable[..., Any]
                return obj.Invoke(memid, _invkind=2, *args, **kw) # DISPATCH_PROPERTYGET
                return obj.Invoke(memid, _invkind=4, *args, **kw) # DISPATCH_PROPERTYPUT
                return obj.Invoke(memid, _invkind=8, *args, **kw) # DISPATCH_PROPERTYPUTREF
            return obj.Invoke(memid, _invkind=1, *args, **kw) # DISPATCH_METHOD
        """""" Explicitly disallow iteration. """"""
        PTR = _coclass_pointer_meta(""POINTER(%s)"" % klass.__name__,
                                    (klass, c_void_p),
                                    {""__ctypes_from_outparam__"": _wrap_coclass,
                                     ""from_param"": classmethod(_coclass_from_param),
                                     })
    """""" Class encapsulating all the functionality necessary to allow interop of
        """""" Create a dtype for VARIANT. This requires support for Unions, which
        ptr_typecode = '<u8' if is_64bits else '<u4'
            ('pvRecord', ptr_typecode),
            ('pRecInfo', ptr_typecode),
                'VT_BOOL', 'VT_I1', 'VT_I2', 'VT_I4', 'VT_I8', 'VT_INT',
                'VT_UI1', 'VT_UI2', 'VT_UI4', 'VT_UI8', 'VT_UINT', 'VT_R4',
                'VT_R8', 'VT_CY', 'c_wchar_p', 'c_void_p', 'pparray',
                'bstrVal', '_tagBRECORD',
                '<i2', '<i1', '<i2', '<i4', '<i8', '<i4', '<u1', '<u2', '<u4',
                '<u8', '<u4', '<f4', '<f8', '<i8', ptr_typecode, ptr_typecode,
                ptr_typecode, ptr_typecode, _tagBRECORD_format,
            offsets=[0] * 19  # This is what makes it a union
            (""vt"", '<u2'),
            (""wReserved1"", '<u2'),
            (""wReserved2"", '<u2'),
            (""wReserved3"", '<u2'),
        """""" Check if a value is an ndarray.
        """""" Check if a value is a datetime64.
        """""" The numpy package.
        """"""
        """""" Enables numpy/comtypes interop.
        """"""
##if __debug__:
##    from ctypeslib.dynamic_module import include
##    include(""""""\
##    #define UNICODE
##    #define NO_STRICT
##    #include <windows.h>
##    """""",
##            persist=True)
        ('cElements', DWORD),
        ('lLbound', LONG),
]
        ('cDims', USHORT),
        ('fFeatures', USHORT),
        ('cbElements', DWORD),
        ('cLocks', DWORD),
        ('pvData', PVOID),
        ('rgsabound', SAFEARRAYBOUND * 1),
        ]

from comtypes import (
    BSTR, COMError, COMMETHOD, GUID, IID, IUnknown, STDMETHOD, TYPE_CHECKING,
from ctypes.wintypes import DWORD, LONG, UINT, VARIANT_BOOL, WCHAR, WORD

if TYPE_CHECKING:
    from typing import (
        Any, Callable, ClassVar, List, Optional, Tuple, Union as _UnionT,
    )
    from comtypes import hints


if sys.version_info >= (3, 0):
    int_types = (int, )
    str_types = (str, )
    base_text_type = str
else:
    int_types = (int, long)
    str_types = (unicode, str)
    base_text_type = basestring
VARENUM = c_int # enum
    _fields_ = [(""wReserved"", c_ushort),
                (""scale"", c_ubyte),
                (""sign"", c_ubyte),
                (""Hi32"", c_ulong),
                (""Lo64"", c_ulonglong)]
        """""" Convert a tagDEC struct to Decimal.
            '-' if self.sign else '',
        vt = hints.AnnoField()  # type: int
        _ = hints.AnnoField()  # type: U_VARIANT1.__tagVARIANT.U_VARIANT2
        null = hints.AnnoField()  # type: ClassVar[VARIANT]
        empty = hints.AnnoField()  # type: ClassVar[VARIANT]
        missing = hints.AnnoField()  # type: ClassVar[VARIANT]
                    _fields_ = [(""pvRecord"", c_void_p),
                                (""pRecInfo"", POINTER(IUnknown))]

                    ]
            _fields_ = [(""vt"", VARTYPE),
                        (""wReserved1"", c_ushort),
                        (""wReserved2"", c_ushort),
                        (""wReserved3"", c_ushort),
                        (""_"", U_VARIANT2)
        _fields_ = [(""__VARIANT_NAME_2"", __tagVARIANT),
                    (""decVal"", DECIMAL)]
        elif (hasattr(value, '__len__') and len(value) == 0
                and not isinstance(value, base_text_type)):
        elif isinstance(value, int_types):
        elif isinstance(value, str_types):
            com_days = delta.days + (delta.seconds + delta.microseconds * 1e-6) / 86400.
            com_days /= comtypes.npsupport.numpy.timedelta64(1, 'D')
                return None # XXX?
                return None # XXX?
        if self.vt == VT_BYREF|VT_VARIANT:

# these are missing:
##    getter[VT_ERROR]
##    getter[VT_ARRAY]
##    getter[VT_BYREF|VT_UI1]
##    getter[VT_BYREF|VT_I2]
##    getter[VT_BYREF|VT_I4]
##    getter[VT_BYREF|VT_R4]
##    getter[VT_BYREF|VT_R8]
##    getter[VT_BYREF|VT_BOOL]
##    getter[VT_BYREF|VT_ERROR]
##    getter[VT_BYREF|VT_CY]
##    getter[VT_BYREF|VT_DATE]
##    getter[VT_BYREF|VT_BSTR]
##    getter[VT_BYREF|VT_UNKNOWN]
##    getter[VT_BYREF|VT_DISPATCH]
##    getter[VT_BYREF|VT_ARRAY]
##    getter[VT_BYREF|VT_VARIANT]
##    getter[VT_BYREF]
##    getter[VT_BYREF|VT_DECIMAL]
##    getter[VT_BYREF|VT_I1]
##    getter[VT_BYREF|VT_UI2]
##    getter[VT_BYREF|VT_UI4]
##    getter[VT_BYREF|VT_INT]
##    getter[VT_BYREF|VT_UINT]
        _VariantChangeType(self,
                           self,
                           0,
                           typecode)
    _iid_ = GUID('{00020404-0000-0000-C000-000000000046}')
    _idlflags_ = ['hidden']
    if sys.version_info >= (3, 0):
        def __next__(self):
            item, fetched = self.Next(1)
            if fetched:
                return item
            raise StopIteration
    else:
        def next(self):
            item, fetched = self.Next(1)
            if fetched:
                return item
            raise StopIteration
##        if isinstance(index, slice):
##            self.Skip(index.start or 0)
##            return self.Next(index.stop or sys.maxint)
        result = [v._get_value(dynamic=self._dynamic) for v in array[:fetched.value]]
    COMMETHOD([], HRESULT, 'Next',
              ( ['in'], c_ulong, 'celt' ),
              ( ['out'], POINTER(VARIANT), 'rgvar' ),
              ( ['out'], POINTER(c_ulong), 'pceltFetched' )),
    COMMETHOD([], HRESULT, 'Skip',
              ( ['in'], c_ulong, 'celt' )),
    COMMETHOD([], HRESULT, 'Reset'),
    COMMETHOD([], HRESULT, 'Clone',
              ( ['out'], POINTER(POINTER(IEnumVARIANT)), 'ppenum' )),
        wCode = hints.AnnoField()  # type: int
        wReserved = hints.AnnoField()  # type: int
        bstrSource = hints.AnnoField()  # type: str
        bstrDescription = hints.AnnoField()  # type: str
        bstrHelpFile = hints.AnnoField()  # type: str
        dwHelpContext = hints.AnnoField()  # type: int
        pvReserved = hints.AnnoField()  # type: Optional[int]
        pfnDeferredFillIn = hints.AnnoField()  # type: Optional[int]
        scode = hints.AnnoField()  # type: int
        return ""<EXCEPINFO %s>"" % \
               ((self.wCode, self.bstrSource, self.bstrDescription, self.bstrHelpFile, self.dwHelpContext,
                self.pfnDeferredFillIn, self.scode),)
    ('wCode', WORD),
    ('wReserved', WORD),
    ('bstrSource', BSTR),
    ('bstrDescription', BSTR),
    ('bstrHelpFile', BSTR),
    ('dwHelpContext', DWORD),
    ('pvReserved', c_void_p),
##    ('pfnDeferredFillIn', WINFUNCTYPE(HRESULT, POINTER(tagEXCEPINFO))),
    ('pfnDeferredFillIn', c_void_p),
    ('scode', SCODE),
        rgvarg = hints.AnnoField()  # type: Array[VARIANT]
        rgdispidNamedArgs = hints.AnnoField()  # type: _Pointer[DISPID]
        cArgs = hints.AnnoField()  # type: int
        cNamedArgs = hints.AnnoField()  # type: int
        ('rgvarg', POINTER(VARIANTARG)),
        ('rgdispidNamedArgs', POINTER(DISPID)),
        ('cArgs', UINT),
        ('cNamedArgs', UINT),
if TYPE_CHECKING:
    RawGetIDsOfNamesFunc = Callable[
        [_byref_type, Array[c_wchar_p], int, int, Array[DISPID]], int,
    ]
    RawInvokeFunc = Callable[
        [
            int, _byref_type, int, int,  # dispIdMember, riid, lcid, wFlags
            _UnionT[_byref_type, DISPPARAMS],  # *pDispParams
            _UnionT[_byref_type, VARIANT],  # pVarResult
            _UnionT[_byref_type, EXCEPINFO, None],  # pExcepInfo
            _UnionT[_byref_type, c_uint],  # puArgErr
        ],
        int
    ]
    if TYPE_CHECKING:
        _disp_methods_ = hints.AnnoField()  # type: ClassVar[List[comtypes._DispMemberSpec]]
        _GetTypeInfo = hints.AnnoField()  # type: Callable[[int, int], IUnknown]
        __com_GetIDsOfNames = hints.AnnoField()  # type: RawGetIDsOfNamesFunc
        __com_Invoke = hints.AnnoField()  # type: RawInvokeFunc
        COMMETHOD([], HRESULT, 'GetTypeInfoCount',
                  (['out'], POINTER(UINT) ) ),
        COMMETHOD([], HRESULT, 'GetTypeInfo',
                  (['in'], UINT, 'index'),
                  (['in'], LCID, 'lcid', 0),
                # Normally, we would declare this parameter in this way:
                # (['out'], POINTER(POINTER(ITypeInfo)) ) ),
                # but we cannot import comtypes.typeinfo at the top level (recursive imports!).
                  (['out'], POINTER(POINTER(IUnknown)) ) ),
        STDMETHOD(HRESULT, 'GetIDsOfNames', [POINTER(IID), POINTER(c_wchar_p),
                                             UINT, LCID, POINTER(DISPID)]),
        STDMETHOD(HRESULT, 'Invoke', [DISPID, POINTER(IID), LCID, WORD,
                                      POINTER(DISPPARAMS), POINTER(VARIANT),
                                      POINTER(EXCEPINFO), POINTER(UINT)]),
    def GetTypeInfo(self, index, lcid=0):
        # type: (int, int) -> hints.ITypeInfo
    def GetIDsOfNames(self, *names, **kw):
        # type: (str, Any) -> List[int]
    def _invoke(self, memid, invkind, lcid, *args):
        # type: (int, int, int, Any) -> Any
        self.__com_Invoke(memid, riid_null, lcid, invkind,
                          dp, var, None, argerr)
    def Invoke(self, dispid, *args, **kw):
        # type: (int, Any, Any) -> Any
        _invkind = kw.pop(""_invkind"", 1) # DISPATCH_METHOD


        if _invkind in (DISPATCH_PROPERTYPUT, DISPATCH_PROPERTYPUTREF): # propput
            array = (VARIANT * len(args))()

            for i, a in enumerate(args[::-1]):
                array[i].value = a

            dp = DISPPARAMS()
            dp.cArgs = len(args)
            dp.cNamedArgs = 1
            dp.rgvarg = array
            dp.rgdispidNamedArgs = pointer(DISPID(DISPID_PROPERTYPUT))
        else:
            array = (VARIANT * len(args))()

            for i, a in enumerate(args[::-1]):
                array[i].value = a

            dp = DISPPARAMS()
            dp.cArgs = len(args)
            dp.cNamedArgs = 0
            dp.rgvarg = array

            self.__com_Invoke(dispid, riid_null, _lcid, _invkind, byref(dp),
                              byref(result), byref(excepinfo), byref(argerr))
                details = (excepinfo.bstrDescription, excepinfo.bstrSource,
                           excepinfo.bstrHelpFile, excepinfo.dwHelpContext,
                           excepinfo.scode)
                raise COMError(hresult, text,
                               (""TypeError: Parameter %s"" % (argerr.value + 1),
                                args))
    }







    POINTER(VARIANT): VT_BYREF|VT_VARIANT,

    POINTER(BSTR): VT_BYREF|VT_BSTR,

##    POINTER(IUnknown): VT_UNKNOWN,
##    POINTER(IDispatch): VT_DISPATCH,
    }

    'CURRENCY', 'CY', 'tagCY', 'DECIMAL', 'tagDEC', 'DISPATCH_METHOD',
    'DISPATCH_PROPERTYGET', 'DISPATCH_PROPERTYPUT', 'DISPATCH_PROPERTYPUTREF',
    'DISPID', 'DISPID_COLLECT', 'DISPID_CONSTRUCTOR', 'DISPID_DESTRUCTOR',
    'DISPID_EVALUATE', 'DISPID_NEWENUM', 'DISPID_PROPERTYPUT',
    'DISPID_UNKNOWN', 'DISPID_VALUE', 'DISPPARAMS', 'tagDISPPARAMS',
    'EXCEPINFO', 'tagEXCEPINFO', 'IDispatch', 'IEnumVARIANT', 'IID_NULL',
    'INVOKE_FUNC', 'INVOKE_PROPERTYGET', 'INVOKE_PROPERTYPUT',
    'INVOKE_PROPERTYPUTREF', 'INVOKEKIND', 'tagINVOKEKIND', '_midlSAFEARRAY',
    'SCODE', '_SysAllocStringLen', 'VARENUM', 'VARIANT','tagVARIANT', 
    'VARIANTARG', '_VariantChangeType', '_VariantClear', '_VariantCopy',
    '_VariantCopyInd', 'VARTYPE', 'VT_ARRAY', 'VT_BLOB', 'VT_BLOB_OBJECT',
    'VT_BOOL', 'VT_BSTR', 'VT_BSTR_BLOB', 'VT_BYREF', 'VT_CARRAY', 'VT_CF',
    'VT_CLSID', 'VT_CY', 'VT_DATE', 'VT_DECIMAL', 'VT_DISPATCH', 'VT_EMPTY',
    'VT_ERROR', 'VT_FILETIME', 'VT_HRESULT', 'VT_I1', 'VT_I2', 'VT_I4',
    'VT_I8', 'VT_ILLEGAL', 'VT_ILLEGALMASKED', 'VT_INT', 'VT_INT_PTR',
    'VT_LPSTR', 'VT_LPWSTR', 'VT_NULL', 'VT_PTR', 'VT_R4', 'VT_R8',
    'VT_RECORD', 'VT_RESERVED', 'VT_SAFEARRAY', 'VT_STORAGE',
    'VT_STORED_OBJECT', 'VT_STREAM', 'VT_STREAMED_OBJECT', 'VT_TYPEMASK',
    'VT_UI1', 'VT_UI2', 'VT_UI4', 'VT_UI8', 'VT_UINT', 'VT_UINT_PTR',
    'VT_UNKNOWN', 'VT_USERDEFINED', 'VT_VARIANT', 'VT_VECTOR',
    'VT_VERSIONED_STREAM', 'VT_VOID',
'''comtypes.client - High level client level COM support package.
'''
from comtypes import (
    automation, CoClass, GUID, IUnknown, TYPE_CHECKING, typeinfo,
)
if TYPE_CHECKING:
    from typing import Any, Optional, overload, Type, TypeVar, Union as _UnionT
    from comtypes import hints
    _T_IUnknown = TypeVar(""_T_IUnknown"", bound=IUnknown)

def wrap_outparam(punk):
    # type: (Any) -> Any
def GetBestInterface(punk):
    # type: (Any) -> Any
    if not punk: # NULL COM pointer
        return punk # or should we return None?
            logger.debug(""Does NOT implement IProvideClassInfo, trying IProvideClassInfo2"")
        tinfo = pci.GetClassInfo() # TypeInfo for the CoClass
    itf_name = tinfo.GetDocumentation(-1)[0] # interface name
    tlib = tinfo.GetContainingTypeLib()[0] # typelib
if comtypes.TYPE_CHECKING:
    @overload
    def GetActiveObject(progid):
        # type: (_UnionT[str, CoClass, GUID]) -> Any
        pass
    @overload
    def GetActiveObject(progid, interface):
        # type: (_UnionT[str, CoClass, GUID], Type[_T_IUnknown]) -> _T_IUnknown
        pass
def GetActiveObject(progid, interface=None, dynamic=False):
    # type: (_UnionT[str, CoClass, GUID], Optional[Any], bool) -> Any
def _manage(obj, clsid, interface):
    # type: (Any, Optional[GUID], Optional[Type[IUnknown]]) -> Any
    obj.__dict__['__clsid'] = str(clsid)
def GetClassObject(progid,
                   clsctx=None,
                   pServerInfo=None,
                   interface=None):
if TYPE_CHECKING:
    @overload
    def CreateObject(progid):
        # type: (_UnionT[str, CoClass, GUID]) -> Any
        pass
    @overload
    def CreateObject(progid, clsctx=None, machine=None, interface=None, dynamic=False, pServerInfo=None):
        # type: (_UnionT[str, CoClass, GUID], Optional[int], Optional[str], Optional[Type[_T_IUnknown]], bool, Optional[comtypes.COSERVERINFO]) -> _T_IUnknown
        pass
def CreateObject(progid,                  # which object to create
                 clsctx=None,             # how to create the object
                 machine=None,            # where to create the object
                 interface=None,          # the interface we want
                 dynamic=False,           # use dynamic dispatch
                 pServerInfo=None):       # server info struct for remoting
    # type: (_UnionT[str, CoClass, GUID], Optional[int], Optional[str], Optional[Type[IUnknown]], bool, Optional[comtypes.COSERVERINFO]) -> Any
        logger.debug(""CoCreateInstance(%s, clsctx=%s, interface=%s)"",
                     clsid, clsctx, interface)
        logger.debug(""CoCreateInstanceEx(%s, clsctx=%s, interface=%s, machine=%s,\
                     clsid, clsctx, interface, machine, pServerInfo)
            msg = ""You can notset both the machine name and server info.""
        obj = comtypes.CoCreateInstanceEx(clsid, clsctx=clsctx,
                interface=interface, machine=machine, pServerInfo=pServerInfo)
if TYPE_CHECKING:
    @overload
    def CoGetObject(displayname, interface):
        # type: (str, Type[_T_IUnknown]) -> _T_IUnknown
        pass
    @overload
    def CoGetObject(displayname, interface=None, dynamic=False):
        # type: (str, None, bool) -> Any
        pass
def CoGetObject(displayname, interface=None, dynamic=False):
    # type: (str, Optional[Type[comtypes.IUnknown]], bool) -> Any
    return _manage(punk,
                   clsid=None,
                   interface=interface)
        else: # ftype in ('windows_exe', 'console_exe')
SHGetSpecialFolderPath.argtypes = [ctypes.c_ulong, ctypes.c_wchar_p,
                                   ctypes.c_int, ctypes.c_int]
if sys.version_info >= (3, 0):
    base_text_type = str
else:
    base_text_type = basestring

        if isinstance(obj, base_text_type):
    clsid = source.__dict__.get('__clsid')
##    interface = find_single_connection_interface(source)
##    if interface:
##        return interface
    if func.__code__.co_varnames[:2] == ('self', 'this'):
            return comtypes.instancemethod(method,
                                           im_self,
                                           type(im_self))
def CreateEventReceiver(interface, handler):
    if issubclass(interface, comtypes.automation.IDispatch) \
           and not hasattr(sink, ""_dispimpl_""):
##    @ctypes.WINFUNCTYPE(ctypes.c_int, ctypes.c_uint)
        if dwCtrlType == 0: # CTRL+C
            res = ctypes.oledll.ole32.CoWaitForMultipleHandles(0,
                                                               int(timeout * 1000),
                                                               len(handles), handles,
                                                               ctypes.byref(ctypes.c_ulong()))
            if details.winerror != RPC_S_CALLPENDING: # timeout expired
if sys.version_info >= (3, 0):
    base_text_type = str
    import winreg
else:
    base_text_type = basestring
    import _winreg as winreg

from comtypes import GUID, TYPE_CHECKING, typeinfo
if TYPE_CHECKING:
    from typing import Any, Tuple, List, Optional, Dict, Union as _UnionT

def _my_import(fullname):
    # type: (str) -> types.ModuleType
def _resolve_filename(tlib_string, dirpath):
    # type: (str, str) -> Tuple[str, bool]
    assert isinstance(tlib_string, base_text_type)
def GetModule(tlib):
    # type: (_UnionT[Any, typeinfo.ITypeLib]) -> types.ModuleType
    if isinstance(tlib, base_text_type):
        _file_ = frame.f_globals.get(""__file__"", None)  # type: str
        pathname, is_abs = _resolve_filename(tlib_string, _file_ and os.path.dirname(_file_))
        assert not(os.path.isabs(pathname)) or os.path.exists(pathname)
    # create and import the real typelib wrapper module
    mod = _create_wrapper_module(tlib, pathname)
    # try to get the friendly-name, if not, returns the real typelib wrapper module
    modulename = codegenerator.name_friendly_module(tlib)
    if modulename is None:
        return mod
    if sys.version_info < (3, 0):
        modulename = modulename.encode(""mbcs"")
    # create and import the friendly-named module
    return _create_friendly_module(tlib, modulename)


def _load_tlib(obj):
    # type: (Any) -> typeinfo.ITypeLib
    if isinstance(obj, base_text_type):
        with winreg.OpenKey(winreg.HKEY_CLASSES_ROOT, r""CLSID\%s\TypeLib"" % clsid) as key:
        with winreg.OpenKey(winreg.HKEY_CLASSES_ROOT, r""CLSID\%s\Version"" % clsid) as key:
def _create_module_in_file(modulename, code):
    # type: (str, str) -> types.ModuleType
def _create_module_in_memory(modulename, code):
    # type: (str, str) -> types.ModuleType
def _create_friendly_module(tlib, modulename):
    # type: (typeinfo.ITypeLib, str) -> types.ModuleType
    """"""helper which creates and imports the friendly-named module.""""""
    try:
        mod = _my_import(modulename)
    except Exception as details:
        logger.info(""Could not import %s: %s"", modulename, details)
    else:
        return mod
    # the module is always regenerated if the import fails
    logger.info(""# Generating %s"", modulename)
    # determine the Python module name
    modname = codegenerator.name_wrapper_module(tlib).split(""."")[-1]
    code = ""from comtypes.gen import %s\n"" % modname
    code += ""globals().update(%s.__dict__)\n"" % modname
    code += ""__name__ = '%s'"" % modulename
    if comtypes.client.gen_dir is None:
        return _create_module_in_memory(modulename, code)
    return _create_module_in_file(modulename, code)


def _create_wrapper_module(tlib, pathname):
    # type: (typeinfo.ITypeLib, Optional[str]) -> types.ModuleType
    """"""helper which creates and imports the real typelib wrapper module.""""""
    modulename = codegenerator.name_wrapper_module(tlib)
    if modulename in sys.modules:
        return sys.modules[modulename]
    try:
        return _my_import(modulename)
    except Exception as details:
        logger.info(""Could not import %s: %s"", modulename, details)
    # generate the module since it doesn't exist or is out of date
    logger.info(""# Generating %s"", modulename)
    p = tlbparser.TypeLibParser(tlib)
    if pathname is None:
        pathname = tlbparser.get_tlib_filename(tlib)
    items = list(p.parse().values())
    codegen = codegenerator.CodeGenerator(_get_known_symbols())
    code = codegen.generate_code(items, filename=pathname)
    for ext_tlib in codegen.externals:  # generates dependency COM-lib modules
        GetModule(ext_tlib)
    if comtypes.client.gen_dir is None:
        return _create_module_in_memory(modulename, code)
    return _create_module_in_file(modulename, code)


def _get_known_symbols():
    # type: () -> Dict[str, str]
    known_symbols = {}  # type: Dict[str, str]
        ""ctypes""
            names = mod.__known_symbols__  # type: List[str]
import sys
import comtypes.automation
import comtypes.typeinfo
import comtypes.client
import comtypes.client.lazybind
from comtypes import COMError, IUnknown, _is_object
import comtypes.hresult as hres
    # Wrap an object in a Dispatch instance, exposing methods and properties
    # via fully dynamic dispatch
    if isinstance(obj, ctypes.POINTER(comtypes.automation.IDispatch)):
        except (comtypes.COMError, WindowsError):
        return comtypes.client.lazybind.Dispatch(obj, tinfo)
    def __init__(self, _id, _obj):
    def __call__(self, *args):
    def __getitem__(self, *args):
        return self._obj._comobj.Invoke(self._id, *args,
                                        **dict(_invkind=comtypes.automation.DISPATCH_PROPERTYGET))
    def __setitem__(self, *args):
            self._obj._comobj.Invoke(self._id, *args,
                                        **dict(_invkind=comtypes.automation.DISPATCH_PROPERTYPUTREF))
            self._obj._comobj.Invoke(self._id, *args,
                                        **dict(_invkind=comtypes.automation.DISPATCH_PROPERTYPUT))
    # Expose methods and properties via fully dynamic dispatch
    def __init__(self, comobj):
        self.__dict__[""_ids""] = {} # Tiny optimization: trying not to use GetIDsOfNames more than once
    def __enum(self):
        e = self._comobj.Invoke(-4) # DISPID_NEWENUM
        return e.QueryInterface(comtypes.automation.IEnumVARIANT)

    def __cmp__(self, other):
        if not isinstance(other, _Dispatch):
            return 1
        return cmp(self._comobj, other._comobj)
    def __hash__(self):
    def __getitem__(self, index):
    def QueryInterface(self, *args):
        ""QueryInterface is forwarded to the real com object.""
        return self._comobj.QueryInterface(*args)
    def _FlagAsMethod(self, *names):
    def __getattr__(self, name):
##        tc = self._comobj.GetTypeInfo(0).QueryInterface(comtypes.typeinfo.ITypeComp)
##        dispid = tc.Bind(name)[1].memid
        flags = comtypes.automation.DISPATCH_PROPERTYGET
            (hresult, text, details) = err.args
                # The line break is important for 2to3 to work correctly
                raise
        except:
            # The line break is important for 2to3 to work correctly
            raise
    def __setattr__(self, name, value):
    def __iter__(self):
##    def __setitem__(self, index, value):
##        self._comobj.Invoke(-3, index, value,
##                            _invkind=comtypes.automation.DISPATCH_PROPERTYPUT|comtypes.automation.DISPATCH_PROPERTYPUTREF)
    def __init__(self, enum):
    if sys.version_info >= (3, 0):
        def __next__(self):
            item, fetched = self.enum.Next(1)
            if fetched:
                return item
            raise StopIteration
    else:
        def next(self):
            item, fetched = self.enum.Next(1)
            if fetched:
                return item
            raise StopIteration
            return self.disp._comobj._invoke(self.get.memid,
                                             self.get.invkind,
                                             0,
                                             *arg)
            return self.disp._comobj._invoke(self.get.memid,
                                             self.get.invkind,
                                             0)
        return self.disp._comobj._invoke(self.get.memid,
                                         self.get.invkind,
                                         0,
                                         *[arg])
        return self.disp._comobj._invoke(self.get.memid,
                                            self.get.invkind,
                                            0,
                                            *args)
            self.disp._comobj._invoke(descr.memid,
                                      descr.invkind,
                                      0,
                                      *(name + (value,)))
            self.disp._comobj._invoke(descr.memid,
                                      descr.invkind,
                                      0,
                                      value)
            self.disp._comobj._invoke(descr.memid,
                                      descr.invkind,
                                      0,
                                      name,
                                      value)
        """""" Explicitly disallow iteration. """"""
##        self.__dict__[""_iid""] = tinfo.GetTypeAttr().guid
                info = FuncDesc(memid=descr.memid,
                                invkind=descr.invkind,
                                cParams=descr.cParams,
                                funckind=descr.funckind)
        return isinstance(other, Dispatch) and \
               self._comobj == other._comobj
        return self._comobj._invoke(DISPID_VALUE,
                                    DISPATCH_METHOD | DISPATCH_PROPERTYGET,
                                    0,
                                    *args)
            return self._comobj._invoke(DISPID_VALUE,
                                        DISPATCH_METHOD | DISPATCH_PROPERTYGET,
                                        0,
                                        *args)
        return self._comobj._invoke(DISPID_VALUE,
                                    invkind,
                                    0,
                                    *args)
        punk = self._comobj._invoke(DISPID_NEWENUM,
                                    DISPATCH_METHOD | DISPATCH_PROPERTYGET,
                                    0)
        ('pUnk', POINTER(IUnknown)),
        ('dwCookie', c_ulong),
    _iid_ = GUID('{B196B284-BAB4-101A-B69C-00AA00341D07}')
    _iid_ = GUID('{B196B286-BAB4-101A-B69C-00AA00341D07}')
    _iid_ = GUID('{B196B287-BAB4-101A-B69C-00AA00341D07}')
    if sys.version_info >= (3, 0):
        def __next__(self):
            cp, fetched = self.Next(1)
            if fetched == 0:
                raise StopIteration
            return cp
    else:
        def next(self):
            cp, fetched = self.Next(1)
            if fetched == 0:
                raise StopIteration
            return cp
    _iid_ = GUID('{B196B285-BAB4-101A-B69C-00AA00341D07}')
    if sys.version_info >= (3, 0):
        def __next__(self):
            cp, fetched = self.Next(1)
            if fetched == 0:
                raise StopIteration
            return cp
    else:
        def next(self):
            cp, fetched = self.Next(1)
            if fetched == 0:
                raise StopIteration
            return cp
    COMMETHOD([], HRESULT, 'EnumConnectionPoints',
              ( ['out'], POINTER(POINTER(IEnumConnectionPoints)), 'ppEnum' )),
    COMMETHOD([], HRESULT, 'FindConnectionPoint',
              ( ['in'], POINTER(_GUID), 'riid' ),
              ( ['out'], POINTER(POINTER(IConnectionPoint)), 'ppCP' )),
    COMMETHOD([], HRESULT, 'GetConnectionInterface',
              ( ['out'], POINTER(_GUID), 'pIID' )),
    COMMETHOD([], HRESULT, 'GetConnectionPointContainer',
              ( ['out'], POINTER(POINTER(IConnectionPointContainer)), 'ppCPC' )),
    COMMETHOD([], HRESULT, 'Advise',
              ( ['in'], POINTER(IUnknown), 'pUnkSink' ),
              ( ['out'], POINTER(c_ulong), 'pdwCookie' )),
    COMMETHOD([], HRESULT, 'Unadvise',
              ( ['in'], c_ulong, 'dwCookie' )),
    COMMETHOD([], HRESULT, 'EnumConnections',
              ( ['out'], POINTER(POINTER(IEnumConnections)), 'ppEnum' )),
    COMMETHOD([], HRESULT, 'Next',
              ( ['in'], c_ulong, 'cConnections' ),
              ( ['out'], POINTER(tagCONNECTDATA), 'rgcd' ),
              ( ['out'], POINTER(c_ulong), 'pcFetched' )),
    COMMETHOD([], HRESULT, 'Skip',
              ( ['in'], c_ulong, 'cConnections' )),
    COMMETHOD([], HRESULT, 'Reset'),
    COMMETHOD([], HRESULT, 'Clone',
              ( ['out'], POINTER(POINTER(IEnumConnections)), 'ppEnum' )),
    COMMETHOD([], HRESULT, 'Next',
              ( ['in'], c_ulong, 'cConnections' ),
              ( ['out'], POINTER(POINTER(IConnectionPoint)), 'ppCP' ),
              ( ['out'], POINTER(c_ulong), 'pcFetched' )),
    COMMETHOD([], HRESULT, 'Skip',
              ( ['in'], c_ulong, 'cConnections' )),
    COMMETHOD([], HRESULT, 'Reset'),
    COMMETHOD([], HRESULT, 'Clone',
              ( ['out'], POINTER(POINTER(IEnumConnectionPoints)), 'ppEnum' )),
if sys.version_info >= (3, 0):
    base_text_type = str
else:
    base_text_type = basestring
        COMMETHOD([], HRESULT, 'SetGUID',
                  (['in'], POINTER(GUID), ""rguid"")),
        COMMETHOD([], HRESULT, 'SetSource',
                  (['in'], LPCOLESTR, ""szSource"")),
        COMMETHOD([], HRESULT, 'SetDescription',
                  (['in'], LPCOLESTR, ""szDescription"")),
        COMMETHOD([], HRESULT, 'SetHelpFile',
                  (['in'], LPCOLESTR, ""szHelpFile"")),
        COMMETHOD([], HRESULT, 'SetHelpContext',
                  (['in'], DWORD, ""dwHelpContext""))
        ]
        COMMETHOD([], HRESULT, 'GetGUID',
                  (['out'], POINTER(GUID), ""pGUID"")),
        COMMETHOD([], HRESULT, 'GetSource',
                  (['out'], POINTER(BSTR), ""pBstrSource"")),
        COMMETHOD([], HRESULT, 'GetDescription',
                  (['out'], POINTER(BSTR), ""pBstrDescription"")),
        COMMETHOD([], HRESULT, 'GetHelpFile',
                  (['out'], POINTER(BSTR), ""pBstrHelpFile"")),
        COMMETHOD([], HRESULT, 'GetHelpContext',
                  (['out'], POINTER(DWORD), ""pdwHelpContext"")),
        ]
        COMMETHOD([], HRESULT, 'InterfaceSupportsErrorInfo',
                  (['in'], POINTER(GUID), 'riid'))
        ]
def ReportError(text, iid,
                clsid=None, helpfile=None, helpcontext=0, hresult=DISP_E_EXCEPTION):
        if isinstance(clsid, base_text_type):
            ei.SetSource(progid) # progid for the class or application that created the error
def ReportException(hresult, iid, clsid=None, helpfile=None, helpcontext=None,
                    stacklevel=None):
    return ReportError(text, iid,
                       clsid=clsid, helpfile=helpfile, helpcontext=helpcontext,
                       hresult=hresult)
__all__ = [""ICreateErrorInfo"", ""IErrorInfo"", ""ISupportErrorInfo"",
           ""ReportError"", ""ReportException"",
           ""SetErrorInfo"", ""GetErrorInfo"", ""CreateErrorInfo""]
from comtypes import IUnknown, STDMETHOD, COMMETHOD, \
     GUID, HRESULT, CoCreateInstance, CLSCTX_INPROC_SERVER
        STDMETHOD(HRESULT, ""RegisterInterfaceInGlobal"",
                  [POINTER(IUnknown), POINTER(GUID), POINTER(DWORD)]),
        STDMETHOD(HRESULT, ""GetInterfaceFromGlobal"",
                  [DWORD, POINTER(GUID), POINTER(POINTER(IUnknown))]),
        ]
git = CoCreateInstance(CLSID_StdGlobalInterfaceTable,
                       interface=IGlobalInterfaceTable,
                       clsctx=CLSCTX_INPROC_SERVER)
__all__ = [""RegisterInterfaceInGlobal"", ""RevokeInterfaceFromGlobal"", ""GetInterfaceFromGlobal""]
    tlib = CreateTypeLib(""foo.bar"") # we don not save it later
E_UNEXPECTED = -2147418113 #0x8000FFFFL
E_NOTIMPL = -2147467263 #0x80004001L
E_NOINTERFACE = -2147467262 #0x80004002L
E_POINTER = -2147467261 #0x80004003L
E_FAIL = -2147467259 #0x80004005L
E_INVALIDARG = -2147024809 #0x80070057L
E_OUTOFMEMORY = -2147024882 # 0x8007000EL
CLASS_E_NOAGGREGATION = -2147221232 #0x80040110L
CLASS_E_CLASSNOTAVAILABLE = -2147221231 #0x80040111L
CO_E_CLASSSTRING = -2147221005 #0x800401F3L
TYPE_E_ELEMENTNOTFOUND = -2147352077 #0x8002802BL
TYPE_E_REGISTRYACCESS = -2147319780 #0x8002801CL
TYPE_E_CANTLOADLIBRARY = -2147312566 #0x80029C4AL
DISP_E_PARAMNOTOPTIONAL = -2147352561 #0x8002000F
DISP_E_BADPARAMCOUNT = -2147352562 #0x8002000E
DISP_E_ARRAYISLOCKED = -2147352563 #0x8002000D
DISP_E_UNKNOWNLCID = -2147352564 #0x8002000C
DISP_E_BADINDEX = -2147352565 #0x8002000B
DISP_E_OVERFLOW = -2147352566 #0x8002000A
DISP_E_EXCEPTION = -2147352567 #0x80020009
DISP_E_BADVARTYPE = -2147352568 #0x80020008
DISP_E_NONAMEDARGS = -2147352569 #0x80020007
DISP_E_UNKNOWNNAME = -2147352570 #0x80020006
DISP_E_TYPEMISMATCH = -2147352571 #0800020005
DISP_E_PARAMNOTFOUND = -2147352572 #0x80020004
DISP_E_MEMBERNOTFOUND = -2147352573 #0x80020003
DISP_E_UNKNOWNINTERFACE = -2147352575 #0x80020001

RPC_E_CHANGED_MODE = -2147417850 # 0x80010106
RPC_E_SERVERFAULT = -2147417851 # 0x80010105
    def emit(self, record,
             writeA=ctypes.windll.kernel32.OutputDebugStringA,
             writeW=ctypes.windll.kernel32.OutputDebugStringW):
            writeW(text + u""\n"")
    parser.optionxform = str # use case sensitive option names!
    DEFAULTS = {""handler"": ""StreamHandler()"",
                ""format"": ""%(levelname)s:%(name)s:%(message)s"",
                ""level"": ""WARNING""}

                return # got WM_QUIT

            no_replace = getattr(value, '__no_replace', False)
    _iid_ = GUID('{3127CA40-446E-11CE-8135-00AA004BB851}')
        COMMETHOD([], HRESULT, 'AddError',
                  ( ['in'], WSTRING, 'pszPropName' ),
                  ( ['in'], POINTER(tagEXCEPINFO), 'pExcepInfo' )),
        ]
    _iid_ = GUID('{55272A00-42CB-11CE-8135-00AA004BB851}')
        COMMETHOD([], HRESULT, 'Read',
                  ( ['in'], WSTRING, 'pszPropName' ),
                  ( ['in', 'out'], POINTER(VARIANT), 'pVar' ),
                  ( ['in'], POINTER(IErrorLog), 'pErrorLog' )),
##                  ( ['in', 'out'], POINTER(IErrorLog), 'pErrorLog' )),
        COMMETHOD([], HRESULT, 'Write',
                  ( ['in'], WSTRING, 'pszPropName' ),
                  ( ['in'], POINTER(VARIANT), 'pVar' )),
        ]
    _iid_ = GUID('{37D84F60-42CB-11CE-8135-00AA004BB851}')
        COMMETHOD([], HRESULT, 'InitNew'),
        COMMETHOD([], HRESULT, 'Load',
                  ( ['in'], POINTER(IPropertyBag), 'pPropBag' ),
                  ( ['in'], POINTER(IErrorLog), 'pErrorLog' )),
        COMMETHOD([], HRESULT, 'Save',
                  ( ['in'], POINTER(IPropertyBag), 'pPropBag' ),
                  ( ['in'], c_int, 'fClearDirty' ),
                  ( ['in'], c_int, 'fSaveAllProperties' )),
        ]
        ('dwType', c_ulong),
        ('vt', c_ushort),
        ('cfType', CLIPFORMAT),
        ('dwHint', c_ulong),
        ('pstrName', WSTRING),
        ('clsid', GUID),
        ]
    _iid_ = GUID('{22F55882-280B-11D0-A8A9-00A0C90C2004}')
        COMMETHOD([], HRESULT, 'Read',
                  ( ['in'], c_ulong, 'cProperties' ),
                  ( ['in'], POINTER(tagPROPBAG2), 'pPropBag' ),
                  ( ['in'], POINTER(IErrorLog), 'pErrLog' ),
                  ( ['out'], POINTER(VARIANT), 'pvarValue' ),
                  ( ['out'], POINTER(HRESULT), 'phrError' )),
        COMMETHOD([], HRESULT, 'Write',
                  ( ['in'], c_ulong, 'cProperties' ),
                  ( ['in'], POINTER(tagPROPBAG2), 'pPropBag' ),
                  ( ['in'], POINTER(VARIANT), 'pvarValue' )),
        COMMETHOD([], HRESULT, 'CountProperties',
                  ( ['out'], POINTER(c_ulong), 'pcProperties' )),
        COMMETHOD([], HRESULT, 'GetPropertyInfo',
                  ( ['in'], c_ulong, 'iProperty' ),
                  ( ['in'], c_ulong, 'cProperties' ),
                  ( ['out'], POINTER(tagPROPBAG2), 'pPropBag' ),
                  ( ['out'], POINTER(c_ulong), 'pcProperties' )),
        COMMETHOD([], HRESULT, 'LoadObject',
                  ( ['in'], WSTRING, 'pstrName' ),
                  ( ['in'], c_ulong, 'dwHint' ),
                  ( ['in'], POINTER(IUnknown), 'punkObject' ),
                  ( ['in'], POINTER(IErrorLog), 'pErrLog' )),
        ]
    _iid_ = GUID('{22F55881-280B-11D0-A8A9-00A0C90C2004}')
        COMMETHOD([], HRESULT, 'InitNew'),
        COMMETHOD([], HRESULT, 'Load',
                  ( ['in'], POINTER(IPropertyBag2), 'pPropBag' ),
                  ( ['in'], POINTER(IErrorLog), 'pErrLog' )),
        COMMETHOD([], HRESULT, 'Save',
                  ( ['in'], POINTER(IPropertyBag2), 'pPropBag' ),
                  ( ['in'], c_int, 'fClearDirty' ),
                  ( ['in",buggy
"
def binary(obj):
    return bytes(obj)


    _fields_ = [(""Data1"", DWORD), (""Data2"", WORD), (""Data3"", WORD), (""Data4"", BYTE * 8)]
            _CLSIDFromString(str(name), byref(self))
        return 'GUID(""%s"")' % str(self)

        return isinstance(other, GUID) and binary(self) == binary(other)
        return GUID(str(self))
        """"""Get guid from progid, ...""""""
        elif isinstance(progid, str):
            _CLSIDFromProgID(str(progid), byref(inst))
from ctypes import _Pointer, _SimpleCData

try:
    from _ctypes import COMError
except ImportError as e:
    msg = ""\n"".join(
        (
            ""COM technology not available (maybe it's the wrong platform)."",
            ""Note that COM is only supported on Windows."",
            ""For more details, please check: ""
            ""https://learn.microsoft.com/en-us/windows/win32/com"",
        )
    )
    raise ImportError(msg) from e
# fmt: off
from typing import (
    Any, ClassVar, overload, TYPE_CHECKING, TypeVar,
    # instead of `builtins`. see PEP585
    Dict, List, Tuple, Type,
    # instead of `collections.abc`. see PEP585
    Callable, Iterable, Iterator,
    # instead of `A | B` and `None | A`. see PEP604
    Optional, Union as _UnionT,  # avoiding confusion with `ctypes.Union`
)
# fmt: on
    from comtypes import hints as hints  # type: ignore
else:
    _CData = _SimpleCData.__mro__[:-1][-1]
    ComMemberGenerator,
    _ComMemberSpec,
    DispMemberGenerator,
    _DispMemberSpec,
    _encode_idl,
    _resolve_argspec,





pythonapi.PyInstanceMethod_New.argtypes = [py_object]
pythonapi.PyInstanceMethod_New.restype = py_object
PyInstanceMethod_Type = type(pythonapi.PyInstanceMethod_New(id))


def instancemethod(func, inst, cls):
    mth = PyInstanceMethod_Type(func)
    if inst is None:
        return mth
    return mth.__get__(inst)


# class IDLWarning(UserWarning):
#    ""Warn about questionable type information""
tagCLSCTX = c_int  # enum
_ole32_nohresult = windll.ole32  # use this for functions that don't return a HRESULT
COINIT_MULTITHREADED = 0x0
COINIT_DISABLE_OLE1DDE = 0x4



def _shutdown(
    func=_ole32_nohresult.CoUninitialize,
    _debug=logger.debug,
    _exc_clear=getattr(sys, ""exc_clear"", lambda: None),
):
        try:
            func()
        except WindowsError:
            pass






    _case_insensitive_: bool
    _iid_: GUID
    _methods_: List[_ComMemberSpec]
    _disp_methods_: List[_DispMemberSpec]
        p = type(_compointer_base)(
            ""POINTER(%s)"" % new_cls.__name__,
            _ptr_bases,
            {""__com_interface__"": new_cls, ""_needs_com_addref_"": None},
        )

                    if fixed_name != name:  # prevent unbounded recursion
                    object.__setattr__(
                        self, self.__map_case__.get(name.lower(), name), value
                    )

            # assert self.__dict__.get(""_methods_"", None) is None




    def _make_dispmethods(self, methods: List[_DispMemberSpec]) -> None:
    def _make_methods(self, methods: List[_ComMemberSpec]) -> None:
            com_interface_registry[str(iid)] = self



class _compointer_base(c_void_p, metaclass=_compointer_meta):

        return cmp(
            super(_compointer_base, self).value, super(_compointer_base, other).value
        )
        return (
            super(_compointer_base, self).value == super(_compointer_base, other).value
        )




        if self._b_base_ is None or self._needsfree:


class helpstring(str):





def STDMETHOD(restype, name, argtypes=()) -> _ComMemberSpec:

def DISPMETHOD(idlflags, restype, name, *argspec) -> _DispMemberSpec:

def DISPPROPERTY(idlflags, proptype, name) -> _DispMemberSpec:


def COMMETHOD(idlflags, restype, methodname, *argspec) -> _ComMemberSpec:
_T_IUnknown = TypeVar(""_T_IUnknown"", bound=""IUnknown"")

    class _IUnknown_Base(c_void_p, metaclass=_cominterface_meta):

        __com_QueryInterface: Callable[[Any, Any], int]
        __com_AddRef: Callable[[], int]
        __com_Release: Callable[[], int]


class IUnknown(_IUnknown_Base, metaclass=_cominterface_meta):
    _case_insensitive_: ClassVar[bool] = False
    _iid_: ClassVar[GUID] = GUID(""{00000000-0000-0000-C000-000000000046}"")
    _methods_: ClassVar[List[_ComMemberSpec]] = [
        STDMETHOD(HRESULT, ""QueryInterface"", [POINTER(GUID), POINTER(c_void_p)]),
        STDMETHOD(c_ulong, ""Release""),
    ]
    def QueryInterface(
        self, interface: Type[_T_IUnknown], iid: Optional[GUID] = None
    ) -> _T_IUnknown:
        clsid = self.__dict__.get(""__clsid"")
            p.__dict__[""__clsid""] = clsid
    def AddRef(self) -> int:
    def Release(self) -> int:
    _iid_ = GUID(""{0000010C-0000-0000-C000-000000000046}"")
        COMMETHOD([], HRESULT, ""GetClassID"", ([""out""], POINTER(GUID), ""pClassID"")),
    ]
        # Should this be ""normal"" method that calls `self._GetClassID`?
        def GetClassID(self) -> GUID:
            """"""Returns the CLSID that uniquely represents an object class that
            defines the code that can manipulate the object's data.
            """"""
            ...
    _iid_ = GUID(""{6D5140C1-7436-11CE-8034-00AA006009FA}"")
    _QueryService: Callable[[Any, Any, Any], int]
    def QueryService(
        self, serviceIID: GUID, interface: Type[_T_IUnknown]
    ) -> _T_IUnknown:
        COMMETHOD(
            [],
            HRESULT,
            ""QueryService"",
            ([""in""], POINTER(GUID), ""guidService""),
            ([""in""], POINTER(GUID), ""riid""),
            ([""in""], POINTER(c_void_p), ""ppvObject""),
        )
    ]

@overload
def CoGetObject(displayname: str, interface: None) -> IUnknown:
    ...


@overload
def CoGetObject(displayname: str, interface: Type[_T_IUnknown]) -> _T_IUnknown:
    ...


def CoGetObject(displayname: str, interface: Optional[Type[IUnknown]]) -> IUnknown:
    _ole32.CoGetObject(str(displayname), None, byref(interface._iid_), byref(punk))
_pUnkOuter = Type[""_Pointer[IUnknown]""]


@overload
def CoCreateInstance(
    clsid: GUID,
    interface: None = None,
    clsctx: Optional[int] = None,
    punkouter: Optional[_pUnkOuter] = None,
) -> IUnknown:
    ...
@overload
def CoCreateInstance(
    clsid: GUID,
    interface: Type[_T_IUnknown],
    clsctx: Optional[int] = None,
    punkouter: Optional[_pUnkOuter] = None,
) -> _T_IUnknown:
    ...


def CoCreateInstance(
    clsid: GUID,
    interface: Optional[Type[IUnknown]] = None,
    clsctx: Optional[int] = None,
    punkouter: Optional[_pUnkOuter] = None,
) -> IUnknown:




    _CoGetClassObject(clsid, clsctx, pServerInfo, interface._iid_, byref(p))
@overload
def GetActiveObject(clsid: GUID, interface: None = None) -> IUnknown:
    ...


@overload
def GetActiveObject(clsid: GUID, interface: Type[_T_IUnknown]) -> _T_IUnknown:
    ...

def GetActiveObject(
    clsid: GUID, interface: Optional[Type[IUnknown]] = None
) -> IUnknown:
    _fields_ = [(""pIID"", POINTER(GUID)), (""pItf"", POINTER(c_void_p)), (""hr"", HRESULT)]
        pIID: GUID
        pItf: _Pointer[c_void_p]
        hr: HRESULT

        (""User"", POINTER(c_ushort)),
        (""UserLength"", c_ulong),
        (""Domain"", POINTER(c_ushort)),
        (""DomainLength"", c_ulong),
        (""Password"", POINTER(c_ushort)),
        (""PasswordLength"", c_ulong),
        (""Flags"", c_ulong),



        (""dwAuthnSvc"", c_ulong),
        (""dwAuthzSvc"", c_ulong),
        (""pwszServerPrincName"", c_wchar_p),
        (""dwAuthnLevel"", c_ulong),
        (""dwImpersonationLevel"", c_ulong),
        (""pAuthIdentityData"", POINTER(_COAUTHIDENTITY)),
        (""dwCapabilities"", c_ulong),



        (""dwReserved1"", c_ulong),
        (""pwszName"", c_wchar_p),
        (""pAuthInfo"", POINTER(_COAUTHINFO)),
        (""dwReserved2"", c_ulong),
        dwReserved1: int
        pwszName: Optional[str]
        pAuthInfo: _COAUTHINFO
        dwReserved2: int


_CoGetClassObject.argtypes = [
    POINTER(GUID),
    DWORD,
    POINTER(COSERVERINFO),
    POINTER(GUID),
    POINTER(c_void_p),
]

        (""cbStruct"", c_ulong),
        (""grfFlags"", c_ulong),
        (""grfMode"", c_ulong),
        (""dwTickCountDeadline"", c_ulong),



        (""cbStruct"", c_ulong),
        (""grfFlags"", c_ulong),
        (""grfMode"", c_ulong),
        (""dwTickCountDeadline"", c_ulong),
        (""dwTrackFlags"", c_ulong),
        (""dwClassContext"", c_ulong),
        (""locale"", c_ulong),
        (""pServerInfo"", POINTER(_COSERVERINFO)),


# Structures for security setups
        (""User"", POINTER(c_ushort)),
        (""UserLength"", c_ulong),
        (""Domain"", POINTER(c_ushort)),
        (""DomainLength"", c_ulong),
        (""Password"", POINTER(c_ushort)),
        (""PasswordLength"", c_ulong),
        (""Flags"", c_ulong),



        (""dwAuthnSvc"", c_ulong),
        (""dwAuthzSvc"", c_ulong),
        (""pAuthInfo"", POINTER(_SEC_WINNT_AUTH_IDENTITY)),



        (""cAuthInfo"", c_ulong),
        (""pAuthInfo"", POINTER(_SOLE_AUTHENTICATION_INFO)),
SOLE_AUTHENTICATION_LIST = _SOLE_AUTHENTICATION_LIST

@overload
def CoCreateInstanceEx(
    clsid: GUID,
    interface: None = None,
    clsctx: Optional[int] = None,
    machine: Optional[str] = None,
    pServerInfo: Optional[COSERVERINFO] = None,
) -> IUnknown:
    ...


@overload
def CoCreateInstanceEx(
    clsid: GUID,
    interface: Type[_T_IUnknown],
    clsctx: Optional[int] = None,
    machine: Optional[str] = None,
    pServerInfo: Optional[COSERVERINFO] = None,
) -> _T_IUnknown:
    ...


def CoCreateInstanceEx(
    clsid: GUID,
    interface: Optional[Type[IUnknown]] = None,
    clsctx: Optional[int] = None,
    machine: Optional[str] = None,
    pServerInfo: Optional[COSERVERINFO] = None,
) -> IUnknown:
        clsctx = CLSCTX_LOCAL_SERVER | CLSCTX_REMOTE_SERVER
    _ole32.CoCreateInstanceEx(
        byref(clsid), None, clsctx, pServerInfo, 1, byref(multiqi)
    )

class CoClass(COMObject, metaclass=_coclass_meta):


# fmt: off
    ""BIND_OPTS"", ""tagBIND_OPTS"", ""BINDOPTS2"", ""tagBIND_OPTS2"", ""BSTR"",
    ""_check_version"", ""CLSCTX"", ""tagCLSCTX"", ""CLSCTX_ALL"",
    ""CLSCTX_DISABLE_AAA"", ""CLSCTX_ENABLE_AAA"", ""CLSCTX_ENABLE_CODE_DOWNLOAD"",
    ""CLSCTX_FROM_DEFAULT_CONTEXT"", ""CLSCTX_INPROC"", ""CLSCTX_INPROC_HANDLER"",
    ""CLSCTX_INPROC_HANDLER16"", ""CLSCTX_INPROC_SERVER"",
    ""CLSCTX_INPROC_SERVER16"", ""CLSCTX_LOCAL_SERVER"", ""CLSCTX_NO_CODE_DOWNLOAD"",
    ""CLSCTX_NO_CUSTOM_MARSHAL"", ""CLSCTX_NO_FAILURE_LOG"",
    ""CLSCTX_REMOTE_SERVER"", ""CLSCTX_RESERVED1"", ""CLSCTX_RESERVED2"",
    ""CLSCTX_RESERVED3"", ""CLSCTX_RESERVED4"", ""CLSCTX_RESERVED5"",
    ""CLSCTX_SERVER"", ""_COAUTHIDENTITY"", ""COAUTHIDENTITY"", ""_COAUTHINFO"",
    ""COAUTHINFO"", ""CoClass"", ""CoCreateInstance"", ""CoCreateInstanceEx"",
    ""_CoGetClassObject"", ""CoGetClassObject"", ""CoGetObject"",
    ""COINIT_APARTMENTTHREADED"", ""COINIT_DISABLE_OLE1DDE"",
    ""COINIT_MULTITHREADED"", ""COINIT_SPEED_OVER_MEMORY"", ""CoInitialize"",
    ""CoInitializeEx"", ""COMError"", ""COMMETHOD"", ""COMObject"", ""_COSERVERINFO"",
    ""COSERVERINFO"", ""CoUninitialize"", ""dispid"", ""DISPMETHOD"", ""DISPPROPERTY"",
    ""DWORD"", ""EOAC_NONE"", ""GetActiveObject"", ""_GUID"", ""GUID"", ""helpstring"",
    ""IID"", ""IPersist"", ""IServiceProvider"", ""IUnknown"", ""MULTI_QI"",
    ""ReturnHRESULT"", ""RPC_C_AUTHN_LEVEL_CONNECT"", ""RPC_C_AUTHN_WINNT"",
    ""RPC_C_AUTHZ_NONE"", ""RPC_C_IMP_LEVEL_IMPERSONATE"",
    ""_SEC_WINNT_AUTH_IDENTITY"", ""SEC_WINNT_AUTH_IDENTITY"",
    ""SEC_WINNT_AUTH_IDENTITY_UNICODE"", ""_SOLE_AUTHENTICATION_INFO"",
    ""SOLE_AUTHENTICATION_INFO"", ""_SOLE_AUTHENTICATION_LIST"",
    ""SOLE_AUTHENTICATION_LIST"", ""STDMETHOD"", ""wireHWND"",
# fmt: on
    FormatError,
    POINTER,
    Structure,
    WINFUNCTYPE,
    byref,
    c_long,
    c_void_p,
    oledll,
    pointer,
    windll,
import queue
    DISP_E_BADINDEX,
    DISP_E_MEMBERNOTFOUND,
    E_FAIL,
    E_NOINTERFACE,
    E_INVALIDARG,
    E_NOTIMPL,
    RPC_E_CHANGED_MODE,
    S_FALSE,
    S_OK,
        if isinstance(code, int):
    raise TypeError(
        ""Expected comtypes.COMERROR or WindowsError instance, got %s""
        % type(exc).__name__
    )
        _debug(""unimplemented method %s_%s called"", interface_name, method_name)

            return ReportError(text, iid=interface._iid_, clsid=clsid, hresult=hresult)
            _error(
                ""Exception in %s.%s implementation:"",
                interface.__name__,
                mthname,
                exc_info=True,
            )
            _warning(""Unimplemented method %s.%s called"", interface.__name__, mthname)
            _error(
                ""Exception in %s.%s implementation:"",
                interface.__name__,
                mthname,
                exc_info=True,
            )

        has_outargs = bool([x[0] for x in paramflags if x[0] & 2])

        if a & 2:
        if a & 1 or a == 0:
    # if args_in != code.co_argcount - 1:
    #     return catch_errors(inst, mth, interface, mthname)
        # for a in outargs:
        #     if not a:
        #         return E_POINTER
        # make argument list for handler by index array built above
            return ReportError(text, iid=interface._iid_, clsid=clsid, hresult=hresult)
            _error(
                ""Exception in %s.%s implementation:"",
                interface.__name__,
                mthname,
                exc_info=True,
            )
            return ReportError(msg, iid=interface._iid_, clsid=clsid, hresult=hr)
            _error(
                ""Exception in %s.%s implementation:"",
                interface.__name__,
                mthname,
                exc_info=True,
            )
            _warning(""Unimplemented method %s.%s called"", interface.__name__, mthname)
            _error(
                ""Exception in %s.%s implementation:"",
                interface.__name__,
                mthname,
                exc_info=True,
            )

        _debug(""%r: %s.%s not implemented"", self.inst, interface.__name__, mthname)









                if (
                    hasattr(self, ""_outgoing_interfaces_"")
                    and IProvideClassInfo2 not in interfaces
                ):
                    if ""propget"" in idlflags:
                    elif ""propput"" in idlflags:
                    elif ""propputref"" in idlflags:
                            argspec = argspec + (([""out""], restype, """"),)
                    self.__make_dispentry(
                        finder, interface, mthname, idlflags, argspec, invkind
                    )
                        argspec += (([""out""], restype, """"),)
                    self.__make_dispentry(
                        finder,
                        interface,
                        ""_get_"" + mthname,
                        idlflags,
                        argspec,
                        2,  # DISPATCH_PROPERTYGET
                    )
                    if not ""readonly"" in idlflags:
                        self.__make_dispentry(
                            finder, interface, ""_set_"" + mthname, idlflags, argspec, 4
                        )  # DISPATCH_PROPERTYPUT
    def __make_dispentry(self, finder, interface, mthname, idlflags, argspec, invkind):
        paramflags = [((_encode_idl(x[0]), x[1]) + tuple(x[3:])) for x in argspec]
        _debug(""%d active COM objects: Added   %r"", len(COMObject._instances_), obj)
            _debug(""%d active COM objects: Removed %r"", len(COMObject._instances_), obj)

    def IUnknown_AddRef(
        self, this, __InterlockedIncrement=_InterlockedIncrement, _debug=_debug
    ):
    def IUnknown_Release(
        self, this, __InterlockedDecrement=_InterlockedDecrement, _debug=_debug
    ):
            raise COMError(
                E_NOINTERFACE, FormatError(E_NOINTERFACE), (None, None, 0, None, None)
            )
    def IDispatch_GetIDsOfNames(self, this, riid, rgszNames, cNames, lcid, rgDispId):
        return windll.oleaut32.DispGetIDsOfNames(tinfo, rgszNames, cNames, rgDispId)

    def IDispatch_Invoke(
        self,
        this,
        dispIdMember,
        riid,
        lcid,
        wFlags,
        pDispParams,
        pVarResult,
        pExcepInfo,
        puArgErr,
    ):
                ptr,
                tinfo,
                dispIdMember,
                wFlags,
                pDispParams,
                pVarResult,
                pExcepInfo,
                puArgErr,
            args = [
                params.rgvarg[i].value for i in reversed(list(range(params.cNamedArgs)))
            ]
            named_indexes = [
                params.rgdispidNamedArgs[i] for i in range(params.cNamedArgs)
            ]

from typing import (
    Any,
    Callable,
    Dict,
    Iterator,
    List,
    NamedTuple,
    Optional,
    Tuple,
    Type,
    Union as _UnionT,
)

from comtypes import _CData

_PositionalParamFlagType = Tuple[int, Optional[str]]
_OptionalParamFlagType = Tuple[int, Optional[str], Any]
_ParamFlagType = _UnionT[_PositionalParamFlagType, _OptionalParamFlagType]
_PositionalArgSpecElmType = Tuple[List[str], Type[_CData], str]
_OptionalArgSpecElmType = Tuple[List[str], Type[_CData], str, Any]
_ArgSpecElmType = _UnionT[_PositionalArgSpecElmType, _OptionalArgSpecElmType]
}
def _unpack_argspec(
    idl: List[str],
    typ: Type[_CData],
    name: Optional[str] = None,
    defval: Any = _NOTHING,
) -> Tuple[List[str], Type[_CData], Optional[str], Any]:
def _resolve_argspec(
    items: Tuple[_ArgSpecElmType, ...]
) -> Tuple[Tuple[_ParamFlagType, ...], Tuple[Type[_CData], ...]]:
class _ComMemberSpec(NamedTuple):
    restype: Optional[Type[_CData]]
    name: str
    argtypes: Tuple[Type[_CData], ...]
    paramflags: Optional[Tuple[_ParamFlagType, ...]]
    idlflags: Tuple[_UnionT[str, int], ...]
    doc: Optional[str]
    def is_prop(self) -> bool:
        return _is_spec_prop(self)
class _DispMemberSpec(NamedTuple):
    what: str
    name: str
    idlflags: Tuple[_UnionT[str, int], ...]
    restype: Optional[Type[_CData]]
    argspec: Tuple[_ArgSpecElmType, ...]
    def memid(self) -> int:
    def is_prop(self) -> bool:
        return _is_spec_prop(self)


# Specifier of a slot of method or property.
# This should be `typing.Protocol` if supporting Py3.8+ only.
_MemberSpec = _UnionT[_ComMemberSpec, _DispMemberSpec]


def _is_spec_prop(m: _MemberSpec):
    return any(f in (""propget"", ""propput"", ""propputref"") for f in m.idlflags)

_PropFunc = Optional[Callable[..., Any]]
_DocType = Optional[str]

def _fix_inout_args(
    func: Callable[..., Any],
    argtypes: Tuple[Type[_CData], ...],
    paramflags: Tuple[_ParamFlagType, ...],
) -> Callable[..., Any]:

        outargs: Dict[int, _UnionT[_CData, ""ctypes._CArgObject""]] = {}
        param_index = 0
        # Go through all expected arguments and match them to the provided arguments.
        # `param_index` first counts through the positional and then
        # through the keyword arguments.
            dir_in = direction & 1 == 1
            dir_out = direction & 2 == 2
            is_positional = param_index < len(args)
            if not (dir_in or dir_out):
                # The original code here did not check for this special case and
                # effectively treated `(dir_in, dir_out) == (False, False)` and
                # `(dir_in, dir_out) == (True, False)` the same.
                # In order not to break legacy code we do the same.
                # One example of a function that has neither `dir_in` nor `dir_out`
                # set is `IMFAttributes.GetString`.
                dir_in = True
            if dir_in and dir_out:
                atyp: Type[_CData] = getattr(argtypes[i], ""_type_"")

                def prepare_parameter(v):
                    # parameter was passed, call `from_param()` to
                    # convert it to a `ctypes` type.
                        # Array of or pointer to type `atyp` was passed,
                        # pointer to `atyp` expected.
                        # The `from_param` method of simple types
                        # (`c_int`, `c_double`, ...) returns a `byref` object which
                        # we cannot use since later it will be wrapped in a pointer.
                        # Simply call the constructor with the argument in that case.
                    return v

                if is_positional:
                    v = prepare_parameter(args[param_index])
                    args[param_index] = v
                elif name in kw:
                    v = prepare_parameter(kw[name])
                else:
                    # no parameter was passed, make an empty one of the required type
                    # and pass it as a keyword argument
                    v = atyp()
                    if name is not None:
                        kw[name] = v
                    else:
                        raise TypeError(""Unnamed inout parameters cannot be omitted"")
                outargs[outnum] = v
            if dir_out:
            if dir_in:
                param_index += 1


        # Our interpretation of this code
        # (jonschz, junkmd, see https://github.com/enthought/comtypes/pull/473):
        # - `outnum` counts the total number of 'out' and 'inout' arguments.
        # - `outargs` is a dict consisting of the supplied 'inout' arguments.
        # - The call to `func()` returns the 'out' and 'inout' arguments.
        #   Furthermore, it changes the variables in 'outargs' as a ""side effect""
        # - In a perfect world, it should be fine to just return `rescode`.
        #   But we assume there is a reason why the original authors did not do that.
        #   Instead, they replace the 'inout' variables in `rescode` by those in
        #   'outargs', and call `__ctypes_from_outparam__()` on them.

            # In this case, it is little faster than creating list with
            # `rescode = [rescode]` and getting item with index from the list.

        self._data: Dict[Tuple[str, _DocType, int], List[_PropFunc]] = {}
    def add_propget(
        self, name: str, doc: _DocType, nargs: int, func: Callable[..., Any]
    ) -> None:
    def add_propput(
        self, name: str, doc: _DocType, nargs: int, func: Callable[..., Any]
    ) -> None:
    def add_propputref(
        self, name: str, doc: _DocType, nargs: int, func: Callable[..., Any]
    ) -> None:
    def __iter__(self) -> Iterator[Tuple[str, _DocType, int, _PropFunc, _PropFunc]]:


    def __init__(self, cls_name: str) -> None:
    def add(self, m: _MemberSpec, func: Callable[..., Any]) -> None:
    def __iter__(self) -> Iterator[Tuple[str, _UnionT[property, ""named_property""]]]:
    def to_propget_keys(self, m: _MemberSpec) -> Tuple[str, _DocType, int]:
    def to_propput_keys(self, m: _MemberSpec) -> Tuple[str, _DocType, int]:
    def to_propputref_keys(self, m: _MemberSpec) -> Tuple[str, _DocType, int]:
    def to_propget_keys(self, m: _ComMemberSpec) -> Tuple[str, _DocType, int]:
        return m.name[len(""_get_"") :], m.doc, nargs
    def to_propput_keys(self, m: _ComMemberSpec) -> Tuple[str, _DocType, int]:
        return m.name[len(""_set_"") :], m.doc, nargs
    def to_propputref_keys(self, m: _ComMemberSpec) -> Tuple[str, _DocType, int]:
        return m.name[len(""_setref_"") :], m.doc, nargs
    def to_propget_keys(self, m: _DispMemberSpec) -> Tuple[str, _DocType, int]:
    def to_propput_keys(self, m: _DispMemberSpec) -> Tuple[str, _DocType, int]:
    def to_propputref_keys(self, m: _DispMemberSpec) -> Tuple[str, _DocType, int]:
    def __init__(self, cls_name: str, vtbl_offset: int, iid: comtypes.GUID) -> None:
        self._mths: List[Tuple[str, Callable[..., Any], Callable[..., Any], bool]] = []
    def add(self, m: _ComMemberSpec) -> None:
    def _fix_args(
        self, m: _ComMemberSpec, func: Callable[..., Any]
    ) -> Callable[..., Any]:
            dirflags = [(p[0] & 3) for p in m.paramflags]
    def __init__(self, cls_name: str) -> None:
        self._items: List[Tuple[str, _UnionT[Callable[..., Any], property], bool]] = []
    def add(self, m: _DispMemberSpec) -> None:
            assert not m.argspec  # XXX does not yet work for properties with parameters
    def _make_disp_property(self, m: _DispMemberSpec) -> property:

            return obj.Invoke(memid, _invkind=2)  # DISPATCH_PROPERTYGET



    def _make_disp_method(self, m: _DispMemberSpec) -> Callable[..., Any]:

                return obj.Invoke(
                    memid, _invkind=2, *args, **kw
                )  # DISPATCH_PROPERTYGET


                return obj.Invoke(
                    memid, _invkind=4, *args, **kw
                )  # DISPATCH_PROPERTYPUT


                return obj.Invoke(
                    memid, _invkind=8, *args, **kw
                )  # DISPATCH_PROPERTYPUTREF




            return obj.Invoke(memid, _invkind=1, *args, **kw)  # DISPATCH_METHOD


        """"""Explicitly disallow iteration.""""""




        PTR = _coclass_pointer_meta(
            ""POINTER(%s)"" % klass.__name__,
            (klass, c_void_p),
            {
                ""__ctypes_from_outparam__"": _wrap_coclass,
                ""from_param"": classmethod(_coclass_from_param),
            },
        )


    """"""Class encapsulating all the functionality necessary to allow interop of

        """"""Create a dtype for VARIANT. This requires support for Unions, which
        ptr_typecode = ""<u8"" if is_64bits else ""<u4""
            (""pvRecord"", ptr_typecode),
            (""pRecInfo"", ptr_typecode),
                ""VT_BOOL"",
                ""VT_I1"",
                ""VT_I2"",
                ""VT_I4"",
                ""VT_I8"",
                ""VT_INT"",
                ""VT_UI1"",
                ""VT_UI2"",
                ""VT_UI4"",
                ""VT_UI8"",
                ""VT_UINT"",
                ""VT_R4"",
                ""VT_R8"",
                ""VT_CY"",
                ""c_wchar_p"",
                ""c_void_p"",
                ""pparray"",
                ""bstrVal"",
                ""_tagBRECORD"",
                ""<i2"",
                ""<i1"",
                ""<i2"",
                ""<i4"",
                ""<i8"",
                ""<i4"",
                ""<u1"",
                ""<u2"",
                ""<u4"",
                ""<u8"",
                ""<u4"",
                ""<f4"",
                ""<f8"",
                ""<i8"",
                ptr_typecode,
                ptr_typecode,
                ptr_typecode,
                ptr_typecode,
                _tagBRECORD_format,
            offsets=[0] * 19,  # This is what makes it a union
            (""vt"", ""<u2""),
            (""wReserved1"", ""<u2""),
            (""wReserved2"", ""<u2""),
            (""wReserved3"", ""<u2""),

        """"""Check if a value is an ndarray.
        """"""Check if a value is a datetime64.
        """"""The numpy package.""""""

        """"""Enables numpy/comtypes interop.""""""

# if __debug__:
#     from ctypeslib.dynamic_module import include
#     include(""""""\
#     #define UNICODE
#     #define NO_STRICT
#     #include <windows.h>
#     """""",
#             persist=True)

        (""cElements"", DWORD),
        (""lLbound"", LONG),
    ]



        (""cDims"", USHORT),
        (""fFeatures"", USHORT),
        (""cbElements"", DWORD),
        (""cLocks"", DWORD),
        (""pvData"", PVOID),
        (""rgsabound"", SAFEARRAYBOUND * 1),
    ]














from ctypes.wintypes import DWORD, LONG, UINT, VARIANT_BOOL, WCHAR, WORD
from typing import (
    Any,
    Callable,
    ClassVar,
    List,
    Optional,
    TYPE_CHECKING,
    Tuple,
    Union as _UnionT,

from comtypes import BSTR, COMError, COMMETHOD, GUID, IID, IUnknown, STDMETHOD

if TYPE_CHECKING:
    from comtypes import hints  # type: ignore


VARENUM = c_int  # enum


    _fields_ = [
        (""wReserved"", c_ushort),
        (""scale"", c_ubyte),
        (""sign"", c_ubyte),
        (""Hi32"", c_ulong),
        (""Lo64"", c_ulonglong),
    ]
        """"""Convert a tagDEC struct to Decimal.
            ""-"" if self.sign else """",
        vt: int
        _: ""U_VARIANT1.__tagVARIANT.U_VARIANT2""
        null: ClassVar[""VARIANT""]
        empty: ClassVar[""VARIANT""]
        missing: ClassVar[""VARIANT""]
                    _fields_ = [(""pvRecord"", c_void_p), (""pRecInfo"", POINTER(IUnknown))]

                ]

            _fields_ = [
                (""vt"", VARTYPE),
                (""wReserved1"", c_ushort),
                (""wReserved2"", c_ushort),
                (""wReserved3"", c_ushort),
                (""_"", U_VARIANT2),

        _fields_ = [(""__VARIANT_NAME_2"", __tagVARIANT), (""decVal"", DECIMAL)]

        elif (
            hasattr(value, ""__len__"") and len(value) == 0 and not isinstance(value, str)
        ):
        elif isinstance(value, int):
        elif isinstance(value, str):
            com_days = (
                delta.days + (delta.seconds + delta.microseconds * 1e-6) / 86400.0
            )
            com_days /= comtypes.npsupport.numpy.timedelta64(1, ""D"")

                return None  # XXX?
                return None  # XXX?

        if self.vt == VT_BYREF | VT_VARIANT:
    # these are missing:
    # getter[VT_ERROR]
    # getter[VT_ARRAY]
    # getter[VT_BYREF|VT_UI1]
    # getter[VT_BYREF|VT_I2]
    # getter[VT_BYREF|VT_I4]
    # getter[VT_BYREF|VT_R4]
    # getter[VT_BYREF|VT_R8]
    # getter[VT_BYREF|VT_BOOL]
    # getter[VT_BYREF|VT_ERROR]
    # getter[VT_BYREF|VT_CY]
    # getter[VT_BYREF|VT_DATE]
    # getter[VT_BYREF|VT_BSTR]
    # getter[VT_BYREF|VT_UNKNOWN]
    # getter[VT_BYREF|VT_DISPATCH]
    # getter[VT_BYREF|VT_ARRAY]
    # getter[VT_BYREF|VT_VARIANT]
    # getter[VT_BYREF]
    # getter[VT_BYREF|VT_DECIMAL]
    # getter[VT_BYREF|VT_I1]
    # getter[VT_BYREF|VT_UI2]
    # getter[VT_BYREF|VT_UI4]
    # getter[VT_BYREF|VT_INT]
    # getter[VT_BYREF|VT_UINT]
        _VariantChangeType(self, self, 0, typecode)



    _iid_ = GUID(""{00020404-0000-0000-C000-000000000046}"")
    _idlflags_ = [""hidden""]

    def __next__(self):
        item, fetched = self.Next(1)
        if fetched:
            return item
        raise StopIteration
        # if isinstance(index, slice):
        #     self.Skip(index.start or 0)
        #     return self.Next(index.stop or sys.maxint)
        result = [v._get_value(dynamic=self._dynamic) for v in array[: fetched.value]]

    COMMETHOD(
        [],
        HRESULT,
        ""Next"",
        ([""in""], c_ulong, ""celt""),
        ([""out""], POINTER(VARIANT), ""rgvar""),
        ([""out""], POINTER(c_ulong), ""pceltFetched""),
    ),
    COMMETHOD([], HRESULT, ""Skip"", ([""in""], c_ulong, ""celt"")),
    COMMETHOD([], HRESULT, ""Reset""),
    COMMETHOD(
        [], HRESULT, ""Clone"", ([""out""], POINTER(POINTER(IEnumVARIANT)), ""ppenum"")
    ),
        wCode: int
        wReserved: int
        bstrSource: str
        bstrDescription: str
        bstrHelpFile: str
        dwHelpContext: int
        pvReserved: Optional[int]
        pfnDeferredFillIn: Optional[int]
        scode: int
        return ""<EXCEPINFO %s>"" % (
            (
                self.wCode,
                self.bstrSource,
                self.bstrDescription,
                self.bstrHelpFile,
                self.dwHelpContext,
                self.pfnDeferredFillIn,
                self.scode,
            ),
        )


    (""wCode"", WORD),
    (""wReserved"", WORD),
    (""bstrSource"", BSTR),
    (""bstrDescription"", BSTR),
    (""bstrHelpFile"", BSTR),
    (""dwHelpContext"", DWORD),
    (""pvReserved"", c_void_p),
    # ('pfnDeferredFillIn', WINFUNCTYPE(HRESULT, POINTER(tagEXCEPINFO))),
    (""pfnDeferredFillIn"", c_void_p),
    (""scode"", SCODE),

        rgvarg: Array[VARIANT]
        rgdispidNamedArgs: _Pointer[DISPID]
        cArgs: int
        cNamedArgs: int
        (""rgvarg"", POINTER(VARIANTARG)),
        (""rgdispidNamedArgs"", POINTER(DISPID)),
        (""cArgs"", UINT),
        (""cNamedArgs"", UINT),



RawGetIDsOfNamesFunc = Callable[
    [_byref_type, ""Array[c_wchar_p]"", int, int, ""Array[DISPID]""], int
]
# fmt: off
RawInvokeFunc = Callable[
    [
        int, _byref_type, int, int,  # dispIdMember, riid, lcid, wFlags
        _UnionT[_byref_type, DISPPARAMS],  # *pDispParams
        _UnionT[_byref_type, VARIANT],  # pVarResult
        _UnionT[_byref_type, EXCEPINFO, None],  # pExcepInfo
        _UnionT[_byref_type, c_uint],  # puArgErr
    ],
    int,
]
# fmt: on

    _disp_methods_: ClassVar[List[comtypes._DispMemberSpec]]
    _GetTypeInfo: Callable[[int, int], IUnknown]
    __com_GetIDsOfNames: RawGetIDsOfNamesFunc
    __com_Invoke: RawInvokeFunc
        COMMETHOD([], HRESULT, ""GetTypeInfoCount"", ([""out""], POINTER(UINT))),
        COMMETHOD(
            [],
            HRESULT,
            ""GetTypeInfo"",
            ([""in""], UINT, ""index""),
            ([""in""], LCID, ""lcid"", 0),
            # Normally, we would declare this parameter in this way:
            # (['out'], POINTER(POINTER(ITypeInfo)) ) ),
            # but we cannot import comtypes.typeinfo at the top level (recursive imports!).
            ([""out""], POINTER(POINTER(IUnknown))),
        ),
        STDMETHOD(
            HRESULT,
            ""GetIDsOfNames"",
            [POINTER(IID), POINTER(c_wchar_p), UINT, LCID, POINTER(DISPID)],
        ),
        STDMETHOD(
            HRESULT,
            ""Invoke"",
            [
                DISPID,
                POINTER(IID),
                LCID,
                WORD,
                POINTER(DISPPARAMS),
                POINTER(VARIANT),
                POINTER(EXCEPINFO),
                POINTER(UINT),
            ],
        ),
    def GetTypeInfo(self, index: int, lcid: int = 0) -> ""hints.ITypeInfo"":

    def GetIDsOfNames(self, *names: str, **kw: Any) -> List[int]:
    def _invoke(self, memid: int, invkind: int, lcid: int, *args: Any) -> Any:
        self.__com_Invoke(memid, riid_null, lcid, invkind, dp, var, None, argerr)
    def __make_dp(self, _invkind: int, *args: Any) -> DISPPARAMS:
        array = (VARIANT * len(args))()
        for i, a in enumerate(args[::-1]):
            array[i].value = a
        dp = DISPPARAMS()
        dp.cArgs = len(args)
        dp.rgvarg = array
        if _invkind in (DISPATCH_PROPERTYPUT, DISPATCH_PROPERTYPUTREF):  # propput
            dp.cNamedArgs = 1
            dp.rgdispidNamedArgs = pointer(DISPID(DISPID_PROPERTYPUT))
        else:
            dp.cNamedArgs = 0
        return dp

    def Invoke(self, dispid: int, *args: Any, **kw: Any) -> Any:
        _invkind = kw.pop(""_invkind"", 1)  # DISPATCH_METHOD
        dp = self.__make_dp(_invkind, *args)
            self.__com_Invoke(
                dispid,
                riid_null,
                _lcid,
                _invkind,
                byref(dp),
                byref(result),
                byref(excepinfo),
                byref(argerr),
            )
                details = (
                    excepinfo.bstrDescription,
                    excepinfo.bstrSource,
                    excepinfo.bstrHelpFile,
                    excepinfo.dwHelpContext,
                    excepinfo.scode,
                )
                raise COMError(
                    hresult,
                    text,
                    (""TypeError: Parameter %s"" % (argerr.value + 1), args),
                )
}
    POINTER(VARIANT): VT_BYREF | VT_VARIANT,
    POINTER(BSTR): VT_BYREF | VT_BSTR,
    # POINTER(IUnknown): VT_UNKNOWN,
    # POINTER(IDispatch): VT_DISPATCH,
}
# fmt: off
    ""CURRENCY"", ""CY"", ""tagCY"", ""DECIMAL"", ""tagDEC"", ""DISPATCH_METHOD"",
    ""DISPATCH_PROPERTYGET"", ""DISPATCH_PROPERTYPUT"", ""DISPATCH_PROPERTYPUTREF"",
    ""DISPID"", ""DISPID_COLLECT"", ""DISPID_CONSTRUCTOR"", ""DISPID_DESTRUCTOR"",
    ""DISPID_EVALUATE"", ""DISPID_NEWENUM"", ""DISPID_PROPERTYPUT"",
    ""DISPID_UNKNOWN"", ""DISPID_VALUE"", ""DISPPARAMS"", ""tagDISPPARAMS"",
    ""EXCEPINFO"", ""tagEXCEPINFO"", ""IDispatch"", ""IEnumVARIANT"", ""IID_NULL"",
    ""INVOKE_FUNC"", ""INVOKE_PROPERTYGET"", ""INVOKE_PROPERTYPUT"",
    ""INVOKE_PROPERTYPUTREF"", ""INVOKEKIND"", ""tagINVOKEKIND"", ""_midlSAFEARRAY"",
    ""SCODE"", ""_SysAllocStringLen"", ""VARENUM"", ""VARIANT"", ""tagVARIANT"",
    ""VARIANTARG"", ""_VariantChangeType"", ""_VariantClear"", ""_VariantCopy"",
    ""_VariantCopyInd"", ""VARTYPE"", ""VT_ARRAY"", ""VT_BLOB"", ""VT_BLOB_OBJECT"",
    ""VT_BOOL"", ""VT_BSTR"", ""VT_BSTR_BLOB"", ""VT_BYREF"", ""VT_CARRAY"", ""VT_CF"",
    ""VT_CLSID"", ""VT_CY"", ""VT_DATE"", ""VT_DECIMAL"", ""VT_DISPATCH"", ""VT_EMPTY"",
    ""VT_ERROR"", ""VT_FILETIME"", ""VT_HRESULT"", ""VT_I1"", ""VT_I2"", ""VT_I4"",
    ""VT_I8"", ""VT_ILLEGAL"", ""VT_ILLEGALMASKED"", ""VT_INT"", ""VT_INT_PTR"",
    ""VT_LPSTR"", ""VT_LPWSTR"", ""VT_NULL"", ""VT_PTR"", ""VT_R4"", ""VT_R8"",
    ""VT_RECORD"", ""VT_RESERVED"", ""VT_SAFEARRAY"", ""VT_STORAGE"",
    ""VT_STORED_OBJECT"", ""VT_STREAM"", ""VT_STREAMED_OBJECT"", ""VT_TYPEMASK"",
    ""VT_UI1"", ""VT_UI2"", ""VT_UI4"", ""VT_UI8"", ""VT_UINT"", ""VT_UINT_PTR"",
    ""VT_UNKNOWN"", ""VT_USERDEFINED"", ""VT_VARIANT"", ""VT_VECTOR"",
    ""VT_VERSIONED_STREAM"", ""VT_VOID"",
# fmt: on
""""""comtypes.client - High level client level COM support package.""""""
from typing import (
    Any,
    Optional,
    overload,
    Type,
    TYPE_CHECKING,
    TypeVar,
    Union as _UnionT,
)
from comtypes import automation, CoClass, GUID, IUnknown, typeinfo
if TYPE_CHECKING:
    from comtypes import hints  # type: ignore


_T_IUnknown = TypeVar(""_T_IUnknown"", bound=IUnknown)
def wrap_outparam(punk: Any) -> Any:
def GetBestInterface(punk: Any) -> Any:
    if not punk:  # NULL COM pointer
        return punk  # or should we return None?
            logger.debug(
                ""Does NOT implement IProvideClassInfo, trying IProvideClassInfo2""
            )
        tinfo = pci.GetClassInfo()  # TypeInfo for the CoClass
    itf_name = tinfo.GetDocumentation(-1)[0]  # interface name
    tlib = tinfo.GetContainingTypeLib()[0]  # typelib


@overload
def GetActiveObject(progid: _UnionT[str, CoClass, GUID]) -> Any:
    ...


@overload
def GetActiveObject(
    progid: _UnionT[str, CoClass, GUID], interface: Type[_T_IUnknown]
) -> _T_IUnknown:
    ...


def GetActiveObject(
    progid: _UnionT[str, CoClass, GUID],
    interface: Optional[Type[IUnknown]] = None,
    dynamic: bool = False,
) -> Any:
def _manage(
    obj: Any, clsid: Optional[GUID], interface: Optional[Type[IUnknown]]
) -> Any:
    obj.__dict__[""__clsid""] = str(clsid)




def GetClassObject(progid, clsctx=None, pServerInfo=None, interface=None):
@overload
def CreateObject(progid: _UnionT[str, Type[CoClass], GUID]) -> Any:
    ...


@overload
def CreateObject(
    progid: _UnionT[str, Type[CoClass], GUID],
    clsctx: Optional[int] = None,
    machine: Optional[str] = None,
    interface: Optional[Type[_T_IUnknown]] = None,
    dynamic: bool = ...,
    pServerInfo: Optional[comtypes.COSERVERINFO] = None,
) -> _T_IUnknown:
    ...


def CreateObject(
    progid: _UnionT[str, Type[CoClass], GUID],  # which object to create
    clsctx: Optional[int] = None,  # how to create the object
    machine: Optional[str] = None,  # where to create the object
    interface: Optional[Type[IUnknown]] = None,  # the interface we want
    dynamic: bool = False,  # use dynamic dispatch
    pServerInfo: Optional[
        comtypes.COSERVERINFO
    ] = None,  # server info struct for remoting
) -> Any:
        logger.debug(
            ""CoCreateInstance(%s, clsctx=%s, interface=%s)"", clsid, clsctx, interface
        )
        logger.debug(
            ""CoCreateInstanceEx(%s, clsctx=%s, interface=%s, machine=%s,\
            clsid,
            clsctx,
            interface,
            machine,
            pServerInfo,
        )
            msg = ""You cannot set both the machine name and server info.""
        obj = comtypes.CoCreateInstanceEx(
            clsid,
            clsctx=clsctx,
            interface=interface,
            machine=machine,
            pServerInfo=pServerInfo,
        )
@overload
def CoGetObject(displayname: str, interface: Type[_T_IUnknown]) -> _T_IUnknown:
    ...


@overload
def CoGetObject(displayname: str, interface: None = None, dynamic: bool = False) -> Any:
    ...


def CoGetObject(
    displayname: str,
    interface: Optional[Type[comtypes.IUnknown]] = None,
    dynamic: bool = False,
) -> Any:
    return _manage(punk, clsid=None, interface=interface)
# fmt: off
# fmt: on


        else:  # ftype in ('windows_exe', 'console_exe')

SHGetSpecialFolderPath.argtypes = [
    ctypes.c_ulong,
    ctypes.c_wchar_p,
    ctypes.c_int,
    ctypes.c_int,
]







        if isinstance(obj, str):



    clsid = source.__dict__.get(""__clsid"")
    # interface = find_single_connection_interface(source)
    # if interface:
    #     return interface


    if func.__code__.co_varnames[:2] == (""self"", ""this""):








            return comtypes.instancemethod(method, im_self, type(im_self))
def CreateEventReceiver(interface, handler):
    if issubclass(interface, comtypes.automation.IDispatch) and not hasattr(
        sink, ""_dispimpl_""
    ):







    # @ctypes.WINFUNCTYPE(ctypes.c_int, ctypes.c_uint)
        if dwCtrlType == 0:  # CTRL+C

            res = ctypes.oledll.ole32.CoWaitForMultipleHandles(
                0,
                int(timeout * 1000),
                len(handles),
                handles,
                ctypes.byref(ctypes.c_ulong()),
            )
            if details.winerror != RPC_S_CALLPENDING:  # timeout expired
from typing import Any, Tuple, List, Optional, Dict, Union as _UnionT
import winreg

from comtypes import GUID, typeinfo
def _my_import(fullname: str) -> types.ModuleType:

def _resolve_filename(tlib_string: str, dirpath: str) -> Tuple[str, bool]:
    assert isinstance(tlib_string, str)
def GetModule(tlib: _UnionT[Any, typeinfo.ITypeLib]) -> types.ModuleType:
    if isinstance(tlib, str):
        _file_: Optional[str] = frame.f_globals.get(""__file__"", None)
        pathname, is_abs = _resolve_filename(
            tlib_string, _file_ and os.path.dirname(_file_)  # type: ignore
        )
        assert not (os.path.isabs(pathname)) or os.path.exists(pathname)
    return ModuleGenerator().generate(tlib, pathname)


def _load_tlib(obj: Any) -> typeinfo.ITypeLib:
    if isinstance(obj, str):
        with winreg.OpenKey(
            winreg.HKEY_CLASSES_ROOT, r""CLSID\%s\TypeLib"" % clsid
        ) as key:
        with winreg.OpenKey(
            winreg.HKEY_CLASSES_ROOT, r""CLSID\%s\Version"" % clsid
        ) as key:
def _create_module_in_file(modulename: str, code: str) -> types.ModuleType:
def _create_module_in_memory(modulename: str, code: str) -> types.ModuleType:

class ModuleGenerator(object):
    def __init__(self) -> None:
        self.codegen = codegenerator.CodeGenerator(_get_known_symbols())

    def generate(
        self, tlib: typeinfo.ITypeLib, pathname: Optional[str]
    ) -> types.ModuleType:
        # create and import the real typelib wrapper module
        mod = self._create_wrapper_module(tlib, pathname)
        # try to get the friendly-name, if not, returns the real typelib wrapper module
        modulename = codegenerator.name_friendly_module(tlib)
        if modulename is None:
            return mod
        # create and import the friendly-named module
        return self._create_friendly_module(tlib, modulename)

    def _create_friendly_module(
        self, tlib: typeinfo.ITypeLib, modulename: str
    ) -> types.ModuleType:
        """"""helper which creates and imports the friendly-named module.""""""
        try:
            mod = _my_import(modulename)
        except Exception as details:
            logger.info(""Could not import %s: %s"", modulename, details)
        else:
            return mod
        # the module is always regenerated if the import fails
        logger.info(""# Generating %s"", modulename)
        # determine the Python module name
        modname = codegenerator.name_wrapper_module(tlib)
        code = self.codegen.generate_friendly_code(modname)
        if comtypes.client.gen_dir is None:
            return _create_module_in_memory(modulename, code)
        return _create_module_in_file(modulename, code)

    def _create_wrapper_module(
        self, tlib: typeinfo.ITypeLib, pathname: Optional[str]
    ) -> types.ModuleType:
        """"""helper which creates and imports the real typelib wrapper module.""""""
        modulename = codegenerator.name_wrapper_module(tlib)
        if modulename in sys.modules:
            return sys.modules[modulename]
        try:
            return _my_import(modulename)
        except Exception as details:
            logger.info(""Could not import %s: %s"", modulename, details)
        # generate the module since it doesn't exist or is out of date
        logger.info(""# Generating %s"", modulename)
        p = tlbparser.TypeLibParser(tlib)
        if pathname is None:
            pathname = tlbparser.get_tlib_filename(tlib)
        items = list(p.parse().values())
        code = self.codegen.generate_wrapper_code(items, filename=pathname)
        for ext_tlib in self.codegen.externals:  # generates dependency COM-lib modules
            GetModule(ext_tlib)
        if comtypes.client.gen_dir is None:
            return _create_module_in_memory(modulename, code)
        return _create_module_in_file(modulename, code)


def _get_known_symbols() -> Dict[str, str]:
    known_symbols: Dict[str, str] = {}
        ""ctypes"",
            names: List[str] = mod.__known_symbols__

from typing import Any, Dict, Optional, Set, Type, TypeVar
from comtypes import automation
from comtypes.client import lazybind
from comtypes import COMError, GUID, IUnknown, hresult as hres, _is_object

_T_IUnknown = TypeVar(""_T_IUnknown"", bound=IUnknown)

    """"""Wrap an object in a Dispatch instance, exposing methods and properties
    via fully dynamic dispatch.
    """"""
    if isinstance(obj, ctypes.POINTER(automation.IDispatch)):
        except (COMError, WindowsError):
        return lazybind.Dispatch(obj, tinfo)

    def __init__(self, _id: int, _obj: ""_Dispatch"") -> None:
    def __call__(self, *args: Any) -> Any:
    def __getitem__(self, *args: Any) -> Any:
        return self._obj._comobj.Invoke(
            self._id, *args, _invkind=automation.DISPATCH_PROPERTYGET
        )
    def __setitem__(self, *args: Any) -> None:
            self._obj._comobj.Invoke(
                self._id, *args, _invkind=automation.DISPATCH_PROPERTYPUTREF
            )
            self._obj._comobj.Invoke(
                self._id, *args, _invkind=automation.DISPATCH_PROPERTYPUT
            )

    """"""Expose methods and properties via fully dynamic dispatch.""""""

    _comobj: automation.IDispatch
    _ids: Dict[str, int]
    _methods: Set[str]

    def __init__(self, comobj: ""ctypes._Pointer[automation.IDispatch]""):
        # Tiny optimization: trying not to use GetIDsOfNames more than once
        self.__dict__[""_ids""] = {}
    def __enum(self) -> automation.IEnumVARIANT:
        e: IUnknown = self._comobj.Invoke(-4)  # DISPID_NEWENUM
        return e.QueryInterface(automation.IEnumVARIANT)
    def __hash__(self) -> int:
    def __getitem__(self, index: Any) -> Any:
    def QueryInterface(
        self, interface: Type[_T_IUnknown], iid: Optional[GUID] = None
    ) -> _T_IUnknown:
        """"""QueryInterface is forwarded to the real com object.""""""
        return self._comobj.QueryInterface(interface, iid)
    def _FlagAsMethod(self, *names: str) -> None:
    def __getattr__(self, name: str) -> Any:
        # tc = self._comobj.GetTypeInfo(0).QueryInterface(comtypes.typeinfo.ITypeComp)
        # dispid = tc.Bind(name)[1].memid
        flags = automation.DISPATCH_PROPERTYGET
            (hresult, _, _) = err.args
                raise err
    def __setattr__(self, name: str, value: Any) -> None:
    def __iter__(self) -> ""_Collection"":
    # def __setitem__(self, index, value):
    #     self._comobj.Invoke(
    #         -3,
    #         index,
    #         value,
    #         _invkind=automation.DISPATCH_PROPERTYPUT
    #         | automation.DISPATCH_PROPERTYPUTREF,
    #     )

    def __init__(self, enum: automation.IEnumVARIANT):
    def __next__(self) -> Any:
        item, fetched = self.enum.Next(1)
        if fetched:
            return item
        raise StopIteration



            return self.disp._comobj._invoke(self.get.memid, self.get.invkind, 0, *arg)
            return self.disp._comobj._invoke(self.get.memid, self.get.invkind, 0)
        return self.disp._comobj._invoke(self.get.memid, self.get.invkind, 0, *[arg])
        return self.disp._comobj._invoke(self.get.memid, self.get.invkind, 0, *args)
            self.disp._comobj._invoke(descr.memid, descr.invkind, 0, *(name + (value,)))
            self.disp._comobj._invoke(descr.memid, descr.invkind, 0, value)
            self.disp._comobj._invoke(descr.memid, descr.invkind, 0, name, value)
        """"""Explicitly disallow iteration.""""""


        # self.__dict__[""_iid""] = tinfo.GetTypeAttr().guid
                info = FuncDesc(
                    memid=descr.memid,
                    invkind=descr.invkind,
                    cParams=descr.cParams,
                    funckind=descr.funckind,
                )
        return isinstance(other, Dispatch) and self._comobj == other._comobj

        return self._comobj._invoke(
            DISPID_VALUE, DISPATCH_METHOD | DISPATCH_PROPERTYGET, 0, *args
        )
            return self._comobj._invoke(
                DISPID_VALUE, DISPATCH_METHOD | DISPATCH_PROPERTYGET, 0, *args
            )
        return self._comobj._invoke(DISPID_VALUE, invkind, 0, *args)
        punk = self._comobj._invoke(
            DISPID_NEWENUM, DISPATCH_METHOD | DISPATCH_PROPERTYGET, 0
        )


        (""pUnk"", POINTER(IUnknown)),
        (""dwCookie"", c_ulong),



    _iid_ = GUID(""{B196B284-BAB4-101A-B69C-00AA00341D07}"")

    _iid_ = GUID(""{B196B286-BAB4-101A-B69C-00AA00341D07}"")

    _iid_ = GUID(""{B196B287-BAB4-101A-B69C-00AA00341D07}"")
    def __next__(self):
        cp, fetched = self.Next(1)
        if fetched == 0:
            raise StopIteration
        return cp

    _iid_ = GUID(""{B196B285-BAB4-101A-B69C-00AA00341D07}"")
    def __next__(self):
        cp, fetched = self.Next(1)
        if fetched == 0:
            raise StopIteration
        return cp

    COMMETHOD(
        [],
        HRESULT,
        ""EnumConnectionPoints"",
        ([""out""], POINTER(POINTER(IEnumConnectionPoints)), ""ppEnum""),
    ),
    COMMETHOD(
        [],
        HRESULT,
        ""FindConnectionPoint"",
        ([""in""], POINTER(_GUID), ""riid""),
        ([""out""], POINTER(POINTER(IConnectionPoint)), ""ppCP""),
    ),
    COMMETHOD([], HRESULT, ""GetConnectionInterface"", ([""out""], POINTER(_GUID), ""pIID"")),
    COMMETHOD(
        [],
        HRESULT,
        ""GetConnectionPointContainer"",
        ([""out""], POINTER(POINTER(IConnectionPointContainer)), ""ppCPC""),
    ),
    COMMETHOD(
        [],
        HRESULT,
        ""Advise"",
        ([""in""], POINTER(IUnknown), ""pUnkSink""),
        ([""out""], POINTER(c_ulong), ""pdwCookie""),
    ),
    COMMETHOD([], HRESULT, ""Unadvise"", ([""in""], c_ulong, ""dwCookie"")),
    COMMETHOD(
        [],
        HRESULT,
        ""EnumConnections"",
        ([""out""], POINTER(POINTER(IEnumConnections)), ""ppEnum""),
    ),
    COMMETHOD(
        [],
        HRESULT,
        ""Next"",
        ([""in""], c_ulong, ""cConnections""),
        ([""out""], POINTER(tagCONNECTDATA), ""rgcd""),
        ([""out""], POINTER(c_ulong), ""pcFetched""),
    ),
    COMMETHOD([], HRESULT, ""Skip"", ([""in""], c_ulong, ""cConnections"")),
    COMMETHOD([], HRESULT, ""Reset""),
    COMMETHOD(
        [], HRESULT, ""Clone"", ([""out""], POINTER(POINTER(IEnumConnections)), ""ppEnum"")
    ),
    COMMETHOD(
        [],
        HRESULT,
        ""Next"",
        ([""in""], c_ulong, ""cConnections""),
        ([""out""], POINTER(POINTER(IConnectionPoint)), ""ppCP""),
        ([""out""], POINTER(c_ulong), ""pcFetched""),
    ),
    COMMETHOD([], HRESULT, ""Skip"", ([""in""], c_ulong, ""cConnections"")),
    COMMETHOD([], HRESULT, ""Reset""),
    COMMETHOD(
        [],
        HRESULT,
        ""Clone"",
        ([""out""], POINTER(POINTER(IEnumConnectionPoints)), ""ppEnum""),
    ),
        COMMETHOD([], HRESULT, ""SetGUID"", ([""in""], POINTER(GUID), ""rguid"")),
        COMMETHOD([], HRESULT, ""SetSource"", ([""in""], LPCOLESTR, ""szSource"")),
        COMMETHOD([], HRESULT, ""SetDescription"", ([""in""], LPCOLESTR, ""szDescription"")),
        COMMETHOD([], HRESULT, ""SetHelpFile"", ([""in""], LPCOLESTR, ""szHelpFile"")),
        COMMETHOD([], HRESULT, ""SetHelpContext"", ([""in""], DWORD, ""dwHelpContext"")),
    ]

        COMMETHOD([], HRESULT, ""GetGUID"", ([""out""], POINTER(GUID), ""pGUID"")),
        COMMETHOD([], HRESULT, ""GetSource"", ([""out""], POINTER(BSTR), ""pBstrSource"")),
        COMMETHOD(
            [], HRESULT, ""GetDescription"", ([""out""], POINTER(BSTR), ""pBstrDescription"")
        ),
        COMMETHOD(
            [], HRESULT, ""GetHelpFile"", ([""out""], POINTER(BSTR), ""pBstrHelpFile"")
        ),
        COMMETHOD(
            [], HRESULT, ""GetHelpContext"", ([""out""], POINTER(DWORD), ""pdwHelpContext"")
        ),
    ]

        COMMETHOD(
            [], HRESULT, ""InterfaceSupportsErrorInfo"", ([""in""], POINTER(GUID), ""riid"")
        )
    ]





def ReportError(
    text, iid, clsid=None, helpfile=None, helpcontext=0, hresult=DISP_E_EXCEPTION
):
        if isinstance(clsid, str):
            ei.SetSource(
                progid
            )  # progid for the class or application that created the error

def ReportException(
    hresult, iid, clsid=None, helpfile=None, helpcontext=None, stacklevel=None
):
    return ReportError(
        text,
        iid,
        clsid=clsid,
        helpfile=helpfile,
        helpcontext=helpcontext,
        hresult=hresult,
    )

# fmt: off
__all__ = [
    ""ICreateErrorInfo"", ""IErrorInfo"", ""ISupportErrorInfo"", ""ReportError"",
    ""ReportException"", ""SetErrorInfo"", ""GetErrorInfo"", ""CreateErrorInfo"",
]
# fmt: on
from comtypes import (
    IUnknown,
    STDMETHOD,
    COMMETHOD,
    GUID,
    HRESULT,
    CoCreateInstance,
    CLSCTX_INPROC_SERVER,
)

        STDMETHOD(
            HRESULT,
            ""RegisterInterfaceInGlobal"",
            [POINTER(IUnknown), POINTER(GUID), POINTER(DWORD)],
        ),
        STDMETHOD(
            HRESULT,
            ""GetInterfaceFromGlobal"",
            [DWORD, POINTER(GUID), POINTER(POINTER(IUnknown))],
        ),
    ]
git = CoCreateInstance(
    CLSID_StdGlobalInterfaceTable,
    interface=IGlobalInterfaceTable,
    clsctx=CLSCTX_INPROC_SERVER,
)
# fmt: off
__all__ = [
    ""RegisterInterfaceInGlobal"", ""RevokeInterfaceFromGlobal"",
    ""GetInterfaceFromGlobal"",
]
# fmt: on

    tlib = CreateTypeLib(""foo.bar"")  # we don not save it later
E_UNEXPECTED = -2147418113  # 0x8000FFFFL
E_NOTIMPL = -2147467263  # 0x80004001L
E_NOINTERFACE = -2147467262  # 0x80004002L
E_POINTER = -2147467261  # 0x80004003L
E_FAIL = -2147467259  # 0x80004005L
E_INVALIDARG = -2147024809  # 0x80070057L
E_OUTOFMEMORY = -2147024882  # 0x8007000EL
CLASS_E_NOAGGREGATION = -2147221232  # 0x80040110L
CLASS_E_CLASSNOTAVAILABLE = -2147221231  # 0x80040111L
CO_E_CLASSSTRING = -2147221005  # 0x800401F3L
TYPE_E_ELEMENTNOTFOUND = -2147352077  # 0x8002802BL
TYPE_E_REGISTRYACCESS = -2147319780  # 0x8002801CL
TYPE_E_CANTLOADLIBRARY = -2147312566  # 0x80029C4AL
DISP_E_PARAMNOTOPTIONAL = -2147352561  # 0x8002000F
DISP_E_BADPARAMCOUNT = -2147352562  # 0x8002000E
DISP_E_ARRAYISLOCKED = -2147352563  # 0x8002000D
DISP_E_UNKNOWNLCID = -2147352564  # 0x8002000C
DISP_E_BADINDEX = -2147352565  # 0x8002000B
DISP_E_OVERFLOW = -2147352566  # 0x8002000A
DISP_E_EXCEPTION = -2147352567  # 0x80020009
DISP_E_BADVARTYPE = -2147352568  # 0x80020008
DISP_E_NONAMEDARGS = -2147352569  # 0x80020007
DISP_E_UNKNOWNNAME = -2147352570  # 0x80020006
DISP_E_TYPEMISMATCH = -2147352571  # 0800020005
DISP_E_PARAMNOTFOUND = -2147352572  # 0x80020004
DISP_E_MEMBERNOTFOUND = -2147352573  # 0x80020003
DISP_E_UNKNOWNINTERFACE = -2147352575  # 0x80020001

RPC_E_CHANGED_MODE = -2147417850  # 0x80010106
RPC_E_SERVERFAULT = -2147417851  # 0x80010105






    def emit(
        self,
        record,
        writeA=ctypes.windll.kernel32.OutputDebugStringA,
        writeW=ctypes.windll.kernel32.OutputDebugStringW,
    ):
            writeW(text + ""\n"")



    parser.optionxform = str  # use case sensitive option names!
    DEFAULTS = {
        ""handler"": ""StreamHandler()"",
        ""format"": ""%(levelname)s:%(name)s:%(message)s"",
        ""level"": ""WARNING"",
    }

                return  # got WM_QUIT

            no_replace = getattr(value, ""__no_replace"", False)



    _iid_ = GUID(""{3127CA40-446E-11CE-8135-00AA004BB851}"")
        COMMETHOD(
            [],
            HRESULT,
            ""AddError"",
            ([""in""], WSTRING, ""pszPropName""),
            ([""in""], POINTER(tagEXCEPINFO), ""pExcepInfo""),
        ),
    ]

    _iid_ = GUID(""{55272A00-42CB-11CE-8135-00AA004BB851}"")
        COMMETHOD(
            [],
            HRESULT,
            ""Read"",
            ([""in""], WSTRING, ""pszPropName""),
            ([""in"", ""out""], POINTER(VARIANT), ""pVar""),
            ([""in""], POINTER(IErrorLog), ""pErrorLog""),
            # ( ['in', 'out'], POINTER(IErrorLog), 'pErrorLog' ),
        ),
        COMMETHOD(
            [],
            HRESULT,
            ""Write"",
            ([""in""], WSTRING, ""pszPropName""),
            ([""in""], POINTER(VARIANT), ""pVar""),
        ),
    ]

    _iid_ = GUID(""{37D84F60-42CB-11CE-8135-00AA004BB851}"")
        COMMETHOD([], HRESULT, ""InitNew""),
        COMMETHOD(
            [],
            HRESULT,
            ""Load"",
            ([""in""], POINTER(IPropertyBag), ""pPropBag""),
            ([""in""], POINTER(IErrorLog), ""pErrorLog""),
        ),
        COMMETHOD(
            [],
            HRESULT,
            ""Save"",
            ([""in""], POINTER(IPropertyBag), ""pPropBag""),
            ([""in""], c_int, ""fClearDirty""),
            ([""in""], c_int, ""fSaveAllProperties""),
        ),
    ]

        (""dwType"", c_ulong),
        (""vt"", c_ushort),
        (""cfType"", CLIPFORMAT),
        (""dwHint"", c_ulong),
        (""pstrName"", WSTRING),
        (""clsid"", GUID),
    ]

    _iid_ = GUID(""{22F55882-280B-11D0-A8A9-00A0C90C2004}"")
        COMMETHOD(
            [],
            HRESULT,
            ""Read"",
            ([""in""], c_ulong, ""cProperties""),
            ([""in""], POINTER(tagPROPBAG2), ""pPropBag""),
            ([""in""], POINTER(IErrorLog), ""pErrLog""),
            ([""out""], POINTER(VARIANT), ""pvarValue""),
            ([""out""], POINTER(HRESULT), ""phrError""),
        ),
        COMMETHOD(
            [],
            HRESULT,
            ""Write"",
            ([""in""], c_ulong, ""cProperties""),
            ([""in""], POINTER(tagPROPBAG2), ""pPropBag""),
            ([""in""], POINTER(VARIANT), ""pvarValue""),
        ),
        COMMETHOD(
            [], HRESULT, ""CountProperties"", ([""out""], POINTER(c_ulong), ""pcProperties"")
        ),
        COMMETHOD(
            [],
            HRESULT,
            ""GetPropertyInfo"",
            ([""in""], c_ulong, ""iProperty""),
            ([""in""], c_ulong, ""cProperties""),
            ([""out""], POINTER(tagPROPBAG2), ""pPropBag""),
            ([""out""], POINTER(c_ulong), ""pcProperties""),
        ),
        COMMETHOD(
            [],
            HRESULT,
            ""LoadObject"",
            ([""in""], WSTRING, ""pstrName""),
            ([""in""], c_ulong, ""dwHint""),
            ([""in""], POINTER(IUnknown), ""punkObject""),
            ([""in""], POINTER(IErrorLog), ""pErrLog""),
        ),
    ]

    _iid_ = GUID(""{22F55881-280B-11D0-A8A9-00A0C90C2004}"")
        COMMETHOD([], HRESULT, ""InitNew""),
        COMMETHOD(
            [],
            HRESULT,
            ""Load"",
            ([""in""], POINTER(IPropertyBag2), ""pPropBag""),
            ([""in""], POINTER(IErrorLog), ""pErrLog""),
        ),
        COMMETHOD(
            [],
            HRESULT,
            ""Save"",
            ([""in""], POINTER(IPropertyBag2), ""pPropBag""),
            ([""in""], c_int, ""fClearDirty""),
            ([""in""], c_int, ""fSaveAllProperties""),
        ),
        COMMETHOD([], HRESULT, ""IsDirty""),
    ]

    _iid_ = GUID(""{0000010B-0000-0000-C000-000000000046}"")
        COMMETHOD([], HRESULT, ""IsDirty""),
        COMMETHOD(
            [],
            HRESULT,
            ""Load"",
            ([""in""], LPCOLESTR, ""pszFileName""),
            ([""in""], DWORD, ""dwMode""),
        ),
        COMMETHOD(
            [],
            HRESULT,
            ""Save"",
            ([""in""], LPCOLESTR, ""pszFileName""),
            ([""in""], BOOL, ""fRemember""),
        ),
        COMMETHOD([], HRESULT, ""SaveCompleted"", ([""in""], LPCOLESTR, ""pszFileName"")),
        COMMETHOD(
            [], HRESULT, ""GetCurFile"", ([""out""], POINTER(LPOLESTR), ""ppszFileName"")
        ),
    ]



# fmt: off
    ""CLIPFORMAT"", ""DictPropertyBag"", ""IErrorLog"", ""IPersistFile"",
    ""IPersistPropertyBag"", ""IPersistPropertyBag2"", ""IPropertyBag"",
    ""IPropertyBag2"", ""tagPROPBAG2"", ""PROPBAG2_TYPE_DATA"",
    ""PROPBAG2_TYPE_MONIKER"", ""PROPBAG2_TYPE_OBJECT"", ""PROPBAG2_TYPE_STORAGE"",
    ""PROPBAG2_TYPE_STREAM"", ""PROPBAG2_TYPE_UNDEFINED"", ""PROPBAG2_TYPE_URL"",
    ""STGM_CONVERT"", ""STGM_CREATE"", ""STGM_DELETEONRELEASE"", ""STGM_DIRECT"",
    ""STGM_DIRECT_SWMR"", ""STGM_FAILIFTHERE"", ""STGM_NOSCRATCH"",
    ""STGM_NOSNAPSHOT"", ""STGM_PRIORITY"", ""STGM_READ"", ""STGM_READWRITE"",
    ""STGM_SHARE_DENY_NONE"", ""STGM_SHARE_DENY_READ"", ""STGM_SHARE_DENY_WRITE"",
    ""STGM_SHARE_EXCLUSIVE"", ""STGM_SIMPLE"", ""STGM_TRANSACTED"", ""STGM_WRITE"",
# fmt: on
from ctypes import POINTER, Structure, byref, cast, c_long, memmove, pointer, sizeof
    """"""Context manager allowing safe arrays to be extracted as ndarrays.
    """"""

        """"""True if context manager is currently entered on given thread.""""""
        return bool(getattr(self.thread_local, ""count"", 0))
    __nonzero__ = __bool__  # for Py2.7 compatibility
    from comtypes.automation import (
        _ctype_to_vartype,
        VT_RECORD,
        VT_UNKNOWN,
        IDispatch,
        VT_DISPATCH,
    )
    sa_type = meta.__new__(
        meta, ""SAFEARRAY_%s"" % itemtype.__name__, (_safearray.tagSAFEARRAY,), {}
    )

            pa = _safearray.SafeArrayCreateVectorEx(cls._vartype_, 0, len(value), extra)
                    raise TypeError(
                        ""Cannot create SAFEARRAY type VT_RECORD without IRecordInfo.""
                    )

            pa = _safearray.SafeArrayCreateEx(
                cls._vartype_, value.ndim, rgsa, extra  # cDims  # rgsaBound
            )  # pvExtra
                    raise TypeError(
                        ""Cannot create SAFEARRAY type VT_RECORD without IRecordInfo.""
                    )
            # print ""__setitem__"", index, value
                    return (
                        comtypes.npsupport.numpy.asarray(result).reshape((cols, rows)).T
                    )
                lowerbounds = [
                    _safearray.SafeArrayGetLBound(self, d) for d in range(1, dim + 1)
                ]
                upperbounds = [
                    _safearray.SafeArrayGetUBound(self, d) for d in range(1, dim + 1)
                ]

                        if safearray_as_ndarray and self._itemtype_ in list(
                            comtypes.npsupport.typecodes.keys()
                        ):
                            arr = comtypes.npsupport.numpy.ctypeslib.as_array(
                                ptr, (num_elements,)
                            )

            if dim + 1 == len(indices):
                for i in range(indices[dim], upperbounds[dim] + 1):
                for i in range(indices[dim], upperbounds[dim] + 1):
                    result.append(
                        self._get_row(dim + 1, indices, lowerbounds, upperbounds)
                    )
            return tuple(result)  # for compatibility with pywin32.
    """"""Convert an ndarray to VARIANT_dtype array""""""

    varr = numpy.zeros(value.shape, comtypes.npsupport.interop.VARIANT_dtype, order=""F"")
    """"""Convert an ndarray of datetime64 to VARIANT_dtype array""""""

    value = value / numpy.timedelta64(1, ""D"")
    varr = numpy.zeros(value.shape, comtypes.npsupport.interop.VARIANT_dtype, order=""F"")
    varr[""vt""] = VT_DATE
    varr[""_""][""VT_R8""].flat = value.flat
        comtypes.STDMETHOD(
            comtypes.HRESULT,
            ""CreateInstance"",
            [
                ctypes.POINTER(comtypes.IUnknown),
                ctypes.POINTER(comtypes.GUID),
                ctypes.POINTER(ctypes.c_void_p),
            ],
        ),
        comtypes.STDMETHOD(comtypes.HRESULT, ""LockServer"", [ctypes.c_int]),
    ]

# class IExternalConnection(IUnknown):
#     _iid_ = GUID(""{00000019-0000-0000-C000-000000000046}"")
#     _methods_ = [
#         STDMETHOD(HRESULT, ""AddConnection"", [c_ulong, c_ulong]),
#         STDMETHOD(HRESULT, ""ReleaseConnection"", [c_ulong, c_ulong, c_ulong])]
ACTIVEOBJECT_WEAK = 0x1

    oleaut32.RegisterActiveObject(
        punk, ctypes.byref(clsid), flags, ctypes.byref(handle)
    )


        self.items = (
            items  # keep, so that we can restore our iterator (in Reset, and Clone).
        )
        if not rgVar:
            return E_POINTER
        if not pCeltFetched:
            pCeltFetched = [None]
        # except:
        #     # ReportException? return E_FAIL?
        #     import traceback
        #     traceback.print_exc()



        return item.IUnknown_QueryInterface(None, pointer(pitem[0]._iid_), pitem)
        return enum.IUnknown_QueryInterface(None, pointer(IUnknown._iid_), penum)



                        logger.warning(
                            ""_call_sinks(%s, %s, *%s, **%s) failed; removing connection"",
                            self,
                            name,
                            args,
                            kw,
                            exc_info=True,
                        )
                            pass  # connection already gone
                        logger.warning(
                            ""_call_sinks(%s, %s, *%s, **%s)"",
                            self,
             ",bug-free
"from ...sampler import BasePrioritySampler
from ...sampler import BaseSampler  # noqa:F401
        sampler=None,  # type: Optional[BaseSampler]
        self._sampler = sampler
        writer = self.__class__(out=self.out, sampler=self._sampler)
        sampler=None,  # type: Optional[BaseSampler]
        self._sampler = sampler
            )
                    log_args += (binascii.hexlify(payload).decode(),)
                    log_args += (payload,)
        sampler=None,  # type: Optional[BaseSampler]
            sampler=sampler,
            sampler=self._sampler,
        elif response.status < 400 and isinstance(self._sampler, BasePrioritySampler):
            result_traces_json = response.get_json()
            if result_traces_json and ""rate_by_service"" in result_traces_json:
                try:
                    if isinstance(self._sampler, BasePrioritySampler):
                        self._sampler.update_rate_by_service_sample_rates(
                            result_traces_json[""rate_by_service""],
                except ValueError:
                    log.error(""sample_rate is negative, cannot update the rate samplers"")
                sampler=self._sampler,
                sampler=self._sampler,",buggy
"from typing import Any  # noqa:F401
    from typing import Callable  # noqa:F401
        writer = self.__class__(out=self.out)
        # type: (...) -> Response
            )  # type: Tuple[Any, Any, Any]
                    log_args += (binascii.hexlify(payload).decode(),)  # type: ignore
                    log_args += (payload,)  # type: ignore
class AgentResponse(object):
    def __init__(self, rate_by_service):
        # type: (Dict[str, float]) -> None
        self.rate_by_service = rate_by_service


        response_callback=None,  # type: Optional[Callable[[AgentResponse], None]]
        self._response_cb = response_callback
        # type: (...) -> Response
        elif response.status < 400:
            if self._response_cb:
                raw_resp = response.get_json()
                if raw_resp and ""rate_by_service"" in raw_resp:
                    self._response_cb(
                        AgentResponse(
                            rate_by_service=raw_resp[""rate_by_service""],
                    )
from typing import TYPE_CHECKING
from .sampler import BasePrioritySampler
if TYPE_CHECKING:
    from .internal.writer import AgentResponse  # noqa: F401


                response_callback=self._agent_response_callback,
                response_callback=self._agent_response_callback,
    def _agent_response_callback(self, resp):
        # type: (AgentResponse) -> None
        """"""Handle the response from the agent.

        The agent can return updated sample rates for the priority sampler.
        """"""
        try:
            if isinstance(self._sampler, BasePrioritySampler):
                self._sampler.update_rate_by_service_sample_rates(
                    resp.rate_by_service,
                )
        except ValueError:
            log.error(""sample_rate is negative, cannot update the rate samplers"")
",bug-free
"from ...sampler import BasePrioritySampler
from ...sampler import BaseSampler  # noqa:F401
        sampler=None,  # type: Optional[BaseSampler]
        self._sampler = sampler
        writer = self.__class__(out=self.out, sampler=self._sampler)
        sampler=None,  # type: Optional[BaseSampler]
        self._sampler = sampler
            )
                    log_args += (binascii.hexlify(payload).decode(),)
                    log_args += (payload,)
        sampler=None,  # type: Optional[BaseSampler]
            sampler=sampler,
            sampler=self._sampler,
        elif response.status < 400 and isinstance(self._sampler, BasePrioritySampler):
            result_traces_json = response.get_json()
            if result_traces_json and ""rate_by_service"" in result_traces_json:
                try:
                    if isinstance(self._sampler, BasePrioritySampler):
                        self._sampler.update_rate_by_service_sample_rates(
                            result_traces_json[""rate_by_service""],
                except ValueError:
                    log.error(""sample_rate is negative, cannot update the rate samplers"")
                sampler=self._sampler,
                sampler=self._sampler,",buggy
"from typing import Any  # noqa:F401
    from typing import Callable  # noqa:F401
        writer = self.__class__(out=self.out)
        # type: (...) -> Response
            )  # type: Tuple[Any, Any, Any]
                    log_args += (binascii.hexlify(payload).decode(),)  # type: ignore
                    log_args += (payload,)  # type: ignore
class AgentResponse(object):
    def __init__(self, rate_by_service):
        # type: (Dict[str, float]) -> None
        self.rate_by_service = rate_by_service


        response_callback=None,  # type: Optional[Callable[[AgentResponse], None]]
        self._response_cb = response_callback
        # type: (...) -> Response
        elif response.status < 400:
            if self._response_cb:
                raw_resp = response.get_json()
                if raw_resp and ""rate_by_service"" in raw_resp:
                    self._response_cb(
                        AgentResponse(
                            rate_by_service=raw_resp[""rate_by_service""],
                    )
from typing import TYPE_CHECKING
from .sampler import BasePrioritySampler
if TYPE_CHECKING:
    from .internal.writer import AgentResponse  # noqa: F401


                response_callback=self._agent_response_callback,
                response_callback=self._agent_response_callback,
    def _agent_response_callback(self, resp):
        # type: (AgentResponse) -> None
        """"""Handle the response from the agent.

        The agent can return updated sample rates for the priority sampler.
        """"""
        try:
            if isinstance(self._sampler, BasePrioritySampler):
                self._sampler.update_rate_by_service_sample_rates(
                    resp.rate_by_service,
                )
        except ValueError:
            log.error(""sample_rate is negative, cannot update the rate samplers"")
",bug-free
"# All steps below have the signature Step
def improve_existing_code(ai: AI, dbs: DBs):
    Ask the user for a list of paths, ask the AI agent to
    improve, fix or add a new functionality
    A file selection will appear to select the files.
    The terminal will ask for the prompt.
    ask_for_files(dbs.input)  # stores files as full paths.
    files_info = get_code_strings(dbs.input)  # this only has file names not paths
-----------------------------
The following files will be used in the improvement process:
{dbs.input[""file_list.txt""]}
The inserted prompt is the following:
'{dbs.input['prompt']}'
-----------------------------
You can change these files in .gpteng folder ({dbs.input.path}) in your project
before proceeding.
Press enter to proceed with modifications.
""""""
Make sure the output of any files is in the following format where
FILENAME is the file name including the file extension, and the file path.  Do not
forget to include the file path.
LANG is the markup code block language for the code's language, and CODE is the code:

FILENAME
```LANG
CODE
```
""""""
    Config.USE_FEEDBACK: [
        use_feedback,
        gen_entrypoint,
        execute_entrypoint,
        human_review,
    ],
    Config.EXECUTE_ONLY: [
        execute_entrypoint,
    ],
    Config.EVALUATE: [
        execute_entrypoint,
        human_review,
    Config.IMPROVE_CODE: [improve_existing_code],",buggy
"# All steps below have the Step signature
def set_improve_filelist(ai: AI, dbs: DBs):
    """"""Sets the file list for files to work with in existing code mode.""""""
    ask_for_files(dbs.input)  # stores files as full paths.
    return []


def assert_files_ready(ai: AI, dbs: DBs):
    """"""Checks that the required files are present for headless
    improve code execution.""""""
    assert (
        ""file_list.txt"" in dbs.input
    ), ""For auto_mode file_list.txt need to be in your project folder.""
    assert ""prompt"" in dbs.input, ""For auto_mode a prompt file must exist.""
    return []


def get_improve_prompt(ai: AI, dbs: DBs):
    Asks the user what they would like to fix.
    -----------------------------
    The following files will be used in the improvement process:
    {dbs.input[""file_list.txt""]}
    The inserted prompt is the following:
    '{dbs.input['prompt']}'
    -----------------------------
    You can change these files in .gpteng folder ({dbs.input.path}) in your project
    before proceeding.
    Press enter to proceed with modifications.
    """"""
    return []


def improve_existing_code(ai: AI, dbs: DBs):
    """"""
    After the file list and prompt have been aquired, this function is called
    to sent the formatted prompt to the LLM.
    """"""

    files_info = get_code_strings(dbs.input)  # this only has file names not paths

    Make sure the output of any files is in the following format where
    FILENAME is the file name including the file extension, and the file path.  Do not
    forget to include the file path.
    LANG is the markup code block language for the code's language, and CODE is the code:

    FILENAME
    ```LANG
    CODE
    ```
    """"""
    EVAL_IMPROVE_CODE = ""eval_improve_code""
    Config.USE_FEEDBACK: [use_feedback, gen_entrypoint, execute_entrypoint, human_review],
    Config.EXECUTE_ONLY: [execute_entrypoint],
    Config.EVALUATE: [execute_entrypoint, human_review],
    Config.IMPROVE_CODE: [
        set_improve_filelist,
        get_improve_prompt,
        improve_existing_code,
    Config.EVAL_IMPROVE_CODE: [assert_files_ready, improve_existing_code],",bug-free
"# All steps below have the signature Step
def improve_existing_code(ai: AI, dbs: DBs):
    Ask the user for a list of paths, ask the AI agent to
    improve, fix or add a new functionality
    A file selection will appear to select the files.
    The terminal will ask for the prompt.
    ask_for_files(dbs.input)  # stores files as full paths.
    files_info = get_code_strings(dbs.input)  # this only has file names not paths
-----------------------------
The following files will be used in the improvement process:
{dbs.input[""file_list.txt""]}
The inserted prompt is the following:
'{dbs.input['prompt']}'
-----------------------------
You can change these files in .gpteng folder ({dbs.input.path}) in your project
before proceeding.
Press enter to proceed with modifications.
""""""
Make sure the output of any files is in the following format where
FILENAME is the file name including the file extension, and the file path.  Do not
forget to include the file path.
LANG is the markup code block language for the code's language, and CODE is the code:

FILENAME
```LANG
CODE
```
""""""
    Config.USE_FEEDBACK: [
        use_feedback,
        gen_entrypoint,
        execute_entrypoint,
        human_review,
    ],
    Config.EXECUTE_ONLY: [
        execute_entrypoint,
    ],
    Config.EVALUATE: [
        execute_entrypoint,
        human_review,
    Config.IMPROVE_CODE: [improve_existing_code],",buggy
"# All steps below have the Step signature
def set_improve_filelist(ai: AI, dbs: DBs):
    """"""Sets the file list for files to work with in existing code mode.""""""
    ask_for_files(dbs.input)  # stores files as full paths.
    return []


def assert_files_ready(ai: AI, dbs: DBs):
    """"""Checks that the required files are present for headless
    improve code execution.""""""
    assert (
        ""file_list.txt"" in dbs.input
    ), ""For auto_mode file_list.txt need to be in your project folder.""
    assert ""prompt"" in dbs.input, ""For auto_mode a prompt file must exist.""
    return []


def get_improve_prompt(ai: AI, dbs: DBs):
    Asks the user what they would like to fix.
    -----------------------------
    The following files will be used in the improvement process:
    {dbs.input[""file_list.txt""]}
    The inserted prompt is the following:
    '{dbs.input['prompt']}'
    -----------------------------
    You can change these files in .gpteng folder ({dbs.input.path}) in your project
    before proceeding.
    Press enter to proceed with modifications.
    """"""
    return []


def improve_existing_code(ai: AI, dbs: DBs):
    """"""
    After the file list and prompt have been aquired, this function is called
    to sent the formatted prompt to the LLM.
    """"""

    files_info = get_code_strings(dbs.input)  # this only has file names not paths

    Make sure the output of any files is in the following format where
    FILENAME is the file name including the file extension, and the file path.  Do not
    forget to include the file path.
    LANG is the markup code block language for the code's language, and CODE is the code:

    FILENAME
    ```LANG
    CODE
    ```
    """"""
    EVAL_IMPROVE_CODE = ""eval_improve_code""
    Config.USE_FEEDBACK: [use_feedback, gen_entrypoint, execute_entrypoint, human_review],
    Config.EXECUTE_ONLY: [execute_entrypoint],
    Config.EVALUATE: [execute_entrypoint, human_review],
    Config.IMPROVE_CODE: [
        set_improve_filelist,
        get_improve_prompt,
        improve_existing_code,
    Config.EVAL_IMPROVE_CODE: [assert_files_ready, improve_existing_code],",bug-free
"# All steps below have the signature Step
def improve_existing_code(ai: AI, dbs: DBs):
    Ask the user for a list of paths, ask the AI agent to
    improve, fix or add a new functionality
    A file selection will appear to select the files.
    The terminal will ask for the prompt.
    ask_for_files(dbs.input)  # stores files as full paths.
    files_info = get_code_strings(dbs.input)  # this only has file names not paths
-----------------------------
The following files will be used in the improvement process:
{dbs.input[""file_list.txt""]}
The inserted prompt is the following:
'{dbs.input['prompt']}'
-----------------------------
You can change these files in .gpteng folder ({dbs.input.path}) in your project
before proceeding.
Press enter to proceed with modifications.
""""""
Make sure the output of any files is in the following format where
FILENAME is the file name including the file extension, and the file path.  Do not
forget to include the file path.
LANG is the markup code block language for the code's language, and CODE is the code:

FILENAME
```LANG
CODE
```
""""""
    Config.USE_FEEDBACK: [
        use_feedback,
        gen_entrypoint,
        execute_entrypoint,
        human_review,
    ],
    Config.EXECUTE_ONLY: [
        execute_entrypoint,
    ],
    Config.EVALUATE: [
        execute_entrypoint,
        human_review,
    Config.IMPROVE_CODE: [improve_existing_code],",buggy
"# All steps below have the Step signature
def set_improve_filelist(ai: AI, dbs: DBs):
    """"""Sets the file list for files to work with in existing code mode.""""""
    ask_for_files(dbs.input)  # stores files as full paths.
    return []


def assert_files_ready(ai: AI, dbs: DBs):
    """"""Checks that the required files are present for headless
    improve code execution.""""""
    assert (
        ""file_list.txt"" in dbs.input
    ), ""For auto_mode file_list.txt need to be in your project folder.""
    assert ""prompt"" in dbs.input, ""For auto_mode a prompt file must exist.""
    return []


def get_improve_prompt(ai: AI, dbs: DBs):
    Asks the user what they would like to fix.
    -----------------------------
    The following files will be used in the improvement process:
    {dbs.input[""file_list.txt""]}
    The inserted prompt is the following:
    '{dbs.input['prompt']}'
    -----------------------------
    You can change these files in .gpteng folder ({dbs.input.path}) in your project
    before proceeding.
    Press enter to proceed with modifications.
    """"""
    return []


def improve_existing_code(ai: AI, dbs: DBs):
    """"""
    After the file list and prompt have been aquired, this function is called
    to sent the formatted prompt to the LLM.
    """"""

    files_info = get_code_strings(dbs.input)  # this only has file names not paths

    Make sure the output of any files is in the following format where
    FILENAME is the file name including the file extension, and the file path.  Do not
    forget to include the file path.
    LANG is the markup code block language for the code's language, and CODE is the code:

    FILENAME
    ```LANG
    CODE
    ```
    """"""
    EVAL_IMPROVE_CODE = ""eval_improve_code""
    Config.USE_FEEDBACK: [use_feedback, gen_entrypoint, execute_entrypoint, human_review],
    Config.EXECUTE_ONLY: [execute_entrypoint],
    Config.EVALUATE: [execute_entrypoint, human_review],
    Config.IMPROVE_CODE: [
        set_improve_filelist,
        get_improve_prompt,
        improve_existing_code,
    Config.EVAL_IMPROVE_CODE: [assert_files_ready, improve_existing_code],",bug-free
"# All steps below have the signature Step
def improve_existing_code(ai: AI, dbs: DBs):
    Ask the user for a list of paths, ask the AI agent to
    improve, fix or add a new functionality
    A file selection will appear to select the files.
    The terminal will ask for the prompt.
    ask_for_files(dbs.input)  # stores files as full paths.
    files_info = get_code_strings(dbs.input)  # this only has file names not paths
-----------------------------
The following files will be used in the improvement process:
{dbs.input[""file_list.txt""]}
The inserted prompt is the following:
'{dbs.input['prompt']}'
-----------------------------
You can change these files in .gpteng folder ({dbs.input.path}) in your project
before proceeding.
Press enter to proceed with modifications.
""""""
Make sure the output of any files is in the following format where
FILENAME is the file name including the file extension, and the file path.  Do not
forget to include the file path.
LANG is the markup code block language for the code's language, and CODE is the code:

FILENAME
```LANG
CODE
```
""""""
    Config.USE_FEEDBACK: [
        use_feedback,
        gen_entrypoint,
        execute_entrypoint,
        human_review,
    ],
    Config.EXECUTE_ONLY: [
        execute_entrypoint,
    ],
    Config.EVALUATE: [
        execute_entrypoint,
        human_review,
    Config.IMPROVE_CODE: [improve_existing_code],",buggy
"# All steps below have the Step signature
def set_improve_filelist(ai: AI, dbs: DBs):
    """"""Sets the file list for files to work with in existing code mode.""""""
    ask_for_files(dbs.input)  # stores files as full paths.
    return []


def assert_files_ready(ai: AI, dbs: DBs):
    """"""Checks that the required files are present for headless
    improve code execution.""""""
    assert (
        ""file_list.txt"" in dbs.input
    ), ""For auto_mode file_list.txt need to be in your project folder.""
    assert ""prompt"" in dbs.input, ""For auto_mode a prompt file must exist.""
    return []


def get_improve_prompt(ai: AI, dbs: DBs):
    Asks the user what they would like to fix.
    -----------------------------
    The following files will be used in the improvement process:
    {dbs.input[""file_list.txt""]}
    The inserted prompt is the following:
    '{dbs.input['prompt']}'
    -----------------------------
    You can change these files in .gpteng folder ({dbs.input.path}) in your project
    before proceeding.
    Press enter to proceed with modifications.
    """"""
    return []


def improve_existing_code(ai: AI, dbs: DBs):
    """"""
    After the file list and prompt have been aquired, this function is called
    to sent the formatted prompt to the LLM.
    """"""

    files_info = get_code_strings(dbs.input)  # this only has file names not paths

    Make sure the output of any files is in the following format where
    FILENAME is the file name including the file extension, and the file path.  Do not
    forget to include the file path.
    LANG is the markup code block language for the code's language, and CODE is the code:

    FILENAME
    ```LANG
    CODE
    ```
    """"""
    EVAL_IMPROVE_CODE = ""eval_improve_code""
    Config.USE_FEEDBACK: [use_feedback, gen_entrypoint, execute_entrypoint, human_review],
    Config.EXECUTE_ONLY: [execute_entrypoint],
    Config.EVALUATE: [execute_entrypoint, human_review],
    Config.IMPROVE_CODE: [
        set_improve_filelist,
        get_improve_prompt,
        improve_existing_code,
    Config.EVAL_IMPROVE_CODE: [assert_files_ready, improve_existing_code],",bug-free
"# All steps below have the signature Step
def improve_existing_code(ai: AI, dbs: DBs):
    Ask the user for a list of paths, ask the AI agent to
    improve, fix or add a new functionality
    A file selection will appear to select the files.
    The terminal will ask for the prompt.
    ask_for_files(dbs.input)  # stores files as full paths.
    files_info = get_code_strings(dbs.input)  # this only has file names not paths
-----------------------------
The following files will be used in the improvement process:
{dbs.input[""file_list.txt""]}
The inserted prompt is the following:
'{dbs.input['prompt']}'
-----------------------------
You can change these files in .gpteng folder ({dbs.input.path}) in your project
before proceeding.
Press enter to proceed with modifications.
""""""
Make sure the output of any files is in the following format where
FILENAME is the file name including the file extension, and the file path.  Do not
forget to include the file path.
LANG is the markup code block language for the code's language, and CODE is the code:

FILENAME
```LANG
CODE
```
""""""
    Config.USE_FEEDBACK: [
        use_feedback,
        gen_entrypoint,
        execute_entrypoint,
        human_review,
    ],
    Config.EXECUTE_ONLY: [
        execute_entrypoint,
    ],
    Config.EVALUATE: [
        execute_entrypoint,
        human_review,
    Config.IMPROVE_CODE: [improve_existing_code],",buggy
"# All steps below have the Step signature
def set_improve_filelist(ai: AI, dbs: DBs):
    """"""Sets the file list for files to work with in existing code mode.""""""
    ask_for_files(dbs.input)  # stores files as full paths.
    return []


def assert_files_ready(ai: AI, dbs: DBs):
    """"""Checks that the required files are present for headless
    improve code execution.""""""
    assert (
        ""file_list.txt"" in dbs.input
    ), ""For auto_mode file_list.txt need to be in your project folder.""
    assert ""prompt"" in dbs.input, ""For auto_mode a prompt file must exist.""
    return []


def get_improve_prompt(ai: AI, dbs: DBs):
    Asks the user what they would like to fix.
    -----------------------------
    The following files will be used in the improvement process:
    {dbs.input[""file_list.txt""]}
    The inserted prompt is the following:
    '{dbs.input['prompt']}'
    -----------------------------
    You can change these files in .gpteng folder ({dbs.input.path}) in your project
    before proceeding.
    Press enter to proceed with modifications.
    """"""
    return []


def improve_existing_code(ai: AI, dbs: DBs):
    """"""
    After the file list and prompt have been aquired, this function is called
    to sent the formatted prompt to the LLM.
    """"""

    files_info = get_code_strings(dbs.input)  # this only has file names not paths

    Make sure the output of any files is in the following format where
    FILENAME is the file name including the file extension, and the file path.  Do not
    forget to include the file path.
    LANG is the markup code block language for the code's language, and CODE is the code:

    FILENAME
    ```LANG
    CODE
    ```
    """"""
    EVAL_IMPROVE_CODE = ""eval_improve_code""
    Config.USE_FEEDBACK: [use_feedback, gen_entrypoint, execute_entrypoint, human_review],
    Config.EXECUTE_ONLY: [execute_entrypoint],
    Config.EVALUATE: [execute_entrypoint, human_review],
    Config.IMPROVE_CODE: [
        set_improve_filelist,
        get_improve_prompt,
        improve_existing_code,
    Config.EVAL_IMPROVE_CODE: [assert_files_ready, improve_existing_code],",bug-free
"# All steps below have the signature Step
def improve_existing_code(ai: AI, dbs: DBs):
    Ask the user for a list of paths, ask the AI agent to
    improve, fix or add a new functionality
    A file selection will appear to select the files.
    The terminal will ask for the prompt.
    ask_for_files(dbs.input)  # stores files as full paths.
    files_info = get_code_strings(dbs.input)  # this only has file names not paths
-----------------------------
The following files will be used in the improvement process:
{dbs.input[""file_list.txt""]}
The inserted prompt is the following:
'{dbs.input['prompt']}'
-----------------------------
You can change these files in .gpteng folder ({dbs.input.path}) in your project
before proceeding.
Press enter to proceed with modifications.
""""""
Make sure the output of any files is in the following format where
FILENAME is the file name including the file extension, and the file path.  Do not
forget to include the file path.
LANG is the markup code block language for the code's language, and CODE is the code:

FILENAME
```LANG
CODE
```
""""""
    Config.USE_FEEDBACK: [
        use_feedback,
        gen_entrypoint,
        execute_entrypoint,
        human_review,
    ],
    Config.EXECUTE_ONLY: [
        execute_entrypoint,
    ],
    Config.EVALUATE: [
        execute_entrypoint,
        human_review,
    Config.IMPROVE_CODE: [improve_existing_code],",buggy
"# All steps below have the Step signature
def set_improve_filelist(ai: AI, dbs: DBs):
    """"""Sets the file list for files to work with in existing code mode.""""""
    ask_for_files(dbs.input)  # stores files as full paths.
    return []


def assert_files_ready(ai: AI, dbs: DBs):
    """"""Checks that the required files are present for headless
    improve code execution.""""""
    assert (
        ""file_list.txt"" in dbs.input
    ), ""For auto_mode file_list.txt need to be in your project folder.""
    assert ""prompt"" in dbs.input, ""For auto_mode a prompt file must exist.""
    return []


def get_improve_prompt(ai: AI, dbs: DBs):
    Asks the user what they would like to fix.
    -----------------------------
    The following files will be used in the improvement process:
    {dbs.input[""file_list.txt""]}
    The inserted prompt is the following:
    '{dbs.input['prompt']}'
    -----------------------------
    You can change these files in .gpteng folder ({dbs.input.path}) in your project
    before proceeding.
    Press enter to proceed with modifications.
    """"""
    return []


def improve_existing_code(ai: AI, dbs: DBs):
    """"""
    After the file list and prompt have been aquired, this function is called
    to sent the formatted prompt to the LLM.
    """"""

    files_info = get_code_strings(dbs.input)  # this only has file names not paths

    Make sure the output of any files is in the following format where
    FILENAME is the file name including the file extension, and the file path.  Do not
    forget to include the file path.
    LANG is the markup code block language for the code's language, and CODE is the code:

    FILENAME
    ```LANG
    CODE
    ```
    """"""
    EVAL_IMPROVE_CODE = ""eval_improve_code""
    Config.USE_FEEDBACK: [use_feedback, gen_entrypoint, execute_entrypoint, human_review],
    Config.EXECUTE_ONLY: [execute_entrypoint],
    Config.EVALUATE: [execute_entrypoint, human_review],
    Config.IMPROVE_CODE: [
        set_improve_filelist,
        get_improve_prompt,
        improve_existing_code,
    Config.EVAL_IMPROVE_CODE: [assert_files_ready, improve_existing_code],",bug-free
"# All steps below have the signature Step
def improve_existing_code(ai: AI, dbs: DBs):
    Ask the user for a list of paths, ask the AI agent to
    improve, fix or add a new functionality
    A file selection will appear to select the files.
    The terminal will ask for the prompt.
    ask_for_files(dbs.input)  # stores files as full paths.
    files_info = get_code_strings(dbs.input)  # this only has file names not paths
-----------------------------
The following files will be used in the improvement process:
{dbs.input[""file_list.txt""]}
The inserted prompt is the following:
'{dbs.input['prompt']}'
-----------------------------
You can change these files in .gpteng folder ({dbs.input.path}) in your project
before proceeding.
Press enter to proceed with modifications.
""""""
Make sure the output of any files is in the following format where
FILENAME is the file name including the file extension, and the file path.  Do not
forget to include the file path.
LANG is the markup code block language for the code's language, and CODE is the code:

FILENAME
```LANG
CODE
```
""""""
    Config.USE_FEEDBACK: [
        use_feedback,
        gen_entrypoint,
        execute_entrypoint,
        human_review,
    ],
    Config.EXECUTE_ONLY: [
        execute_entrypoint,
    ],
    Config.EVALUATE: [
        execute_entrypoint,
        human_review,
    Config.IMPROVE_CODE: [improve_existing_code],",buggy
"# All steps below have the Step signature
def set_improve_filelist(ai: AI, dbs: DBs):
    """"""Sets the file list for files to work with in existing code mode.""""""
    ask_for_files(dbs.input)  # stores files as full paths.
    return []


def assert_files_ready(ai: AI, dbs: DBs):
    """"""Checks that the required files are present for headless
    improve code execution.""""""
    assert (
        ""file_list.txt"" in dbs.input
    ), ""For auto_mode file_list.txt need to be in your project folder.""
    assert ""prompt"" in dbs.input, ""For auto_mode a prompt file must exist.""
    return []


def get_improve_prompt(ai: AI, dbs: DBs):
    Asks the user what they would like to fix.
    -----------------------------
    The following files will be used in the improvement process:
    {dbs.input[""file_list.txt""]}
    The inserted prompt is the following:
    '{dbs.input['prompt']}'
    -----------------------------
    You can change these files in .gpteng folder ({dbs.input.path}) in your project
    before proceeding.
    Press enter to proceed with modifications.
    """"""
    return []


def improve_existing_code(ai: AI, dbs: DBs):
    """"""
    After the file list and prompt have been aquired, this function is called
    to sent the formatted prompt to the LLM.
    """"""

    files_info = get_code_strings(dbs.input)  # this only has file names not paths

    Make sure the output of any files is in the following format where
    FILENAME is the file name including the file extension, and the file path.  Do not
    forget to include the file path.
    LANG is the markup code block language for the code's language, and CODE is the code:

    FILENAME
    ```LANG
    CODE
    ```
    """"""
    EVAL_IMPROVE_CODE = ""eval_improve_code""
    Config.USE_FEEDBACK: [use_feedback, gen_entrypoint, execute_entrypoint, human_review],
    Config.EXECUTE_ONLY: [execute_entrypoint],
    Config.EVALUATE: [execute_entrypoint, human_review],
    Config.IMPROVE_CODE: [
        set_improve_filelist,
        get_improve_prompt,
        improve_existing_code,
    Config.EVAL_IMPROVE_CODE: [assert_files_ready, improve_existing_code],",bug-free
"# All steps below have the signature Step
def improve_existing_code(ai: AI, dbs: DBs):
    Ask the user for a list of paths, ask the AI agent to
    improve, fix or add a new functionality
    A file selection will appear to select the files.
    The terminal will ask for the prompt.
    ask_for_files(dbs.input)  # stores files as full paths.
    files_info = get_code_strings(dbs.input)  # this only has file names not paths
-----------------------------
The following files will be used in the improvement process:
{dbs.input[""file_list.txt""]}
The inserted prompt is the following:
'{dbs.input['prompt']}'
-----------------------------
You can change these files in .gpteng folder ({dbs.input.path}) in your project
before proceeding.
Press enter to proceed with modifications.
""""""
Make sure the output of any files is in the following format where
FILENAME is the file name including the file extension, and the file path.  Do not
forget to include the file path.
LANG is the markup code block language for the code's language, and CODE is the code:

FILENAME
```LANG
CODE
```
""""""
    Config.USE_FEEDBACK: [
        use_feedback,
        gen_entrypoint,
        execute_entrypoint,
        human_review,
    ],
    Config.EXECUTE_ONLY: [
        execute_entrypoint,
    ],
    Config.EVALUATE: [
        execute_entrypoint,
        human_review,
    Config.IMPROVE_CODE: [improve_existing_code],",buggy
"# All steps below have the Step signature
def set_improve_filelist(ai: AI, dbs: DBs):
    """"""Sets the file list for files to work with in existing code mode.""""""
    ask_for_files(dbs.input)  # stores files as full paths.
    return []


def assert_files_ready(ai: AI, dbs: DBs):
    """"""Checks that the required files are present for headless
    improve code execution.""""""
    assert (
        ""file_list.txt"" in dbs.input
    ), ""For auto_mode file_list.txt need to be in your project folder.""
    assert ""prompt"" in dbs.input, ""For auto_mode a prompt file must exist.""
    return []


def get_improve_prompt(ai: AI, dbs: DBs):
    Asks the user what they would like to fix.
    -----------------------------
    The following files will be used in the improvement process:
    {dbs.input[""file_list.txt""]}
    The inserted prompt is the following:
    '{dbs.input['prompt']}'
    -----------------------------
    You can change these files in .gpteng folder ({dbs.input.path}) in your project
    before proceeding.
    Press enter to proceed with modifications.
    """"""
    return []


def improve_existing_code(ai: AI, dbs: DBs):
    """"""
    After the file list and prompt have been aquired, this function is called
    to sent the formatted prompt to the LLM.
    """"""

    files_info = get_code_strings(dbs.input)  # this only has file names not paths

    Make sure the output of any files is in the following format where
    FILENAME is the file name including the file extension, and the file path.  Do not
    forget to include the file path.
    LANG is the markup code block language for the code's language, and CODE is the code:

    FILENAME
    ```LANG
    CODE
    ```
    """"""
    EVAL_IMPROVE_CODE = ""eval_improve_code""
    Config.USE_FEEDBACK: [use_feedback, gen_entrypoint, execute_entrypoint, human_review],
    Config.EXECUTE_ONLY: [execute_entrypoint],
    Config.EVALUATE: [execute_entrypoint, human_review],
    Config.IMPROVE_CODE: [
        set_improve_filelist,
        get_improve_prompt,
        improve_existing_code,
    Config.EVAL_IMPROVE_CODE: [assert_files_ready, improve_existing_code],",bug-free
"# All steps below have the signature Step
def improve_existing_code(ai: AI, dbs: DBs):
    Ask the user for a list of paths, ask the AI agent to
    improve, fix or add a new functionality
    A file selection will appear to select the files.
    The terminal will ask for the prompt.
    ask_for_files(dbs.input)  # stores files as full paths.
    files_info = get_code_strings(dbs.input)  # this only has file names not paths
-----------------------------
The following files will be used in the improvement process:
{dbs.input[""file_list.txt""]}
The inserted prompt is the following:
'{dbs.input['prompt']}'
-----------------------------
You can change these files in .gpteng folder ({dbs.input.path}) in your project
before proceeding.
Press enter to proceed with modifications.
""""""
Make sure the output of any files is in the following format where
FILENAME is the file name including the file extension, and the file path.  Do not
forget to include the file path.
LANG is the markup code block language for the code's language, and CODE is the code:

FILENAME
```LANG
CODE
```
""""""
    Config.USE_FEEDBACK: [
        use_feedback,
        gen_entrypoint,
        execute_entrypoint,
        human_review,
    ],
    Config.EXECUTE_ONLY: [
        execute_entrypoint,
    ],
    Config.EVALUATE: [
        execute_entrypoint,
        human_review,
    Config.IMPROVE_CODE: [improve_existing_code],",buggy
"# All steps below have the Step signature
def set_improve_filelist(ai: AI, dbs: DBs):
    """"""Sets the file list for files to work with in existing code mode.""""""
    ask_for_files(dbs.input)  # stores files as full paths.
    return []


def assert_files_ready(ai: AI, dbs: DBs):
    """"""Checks that the required files are present for headless
    improve code execution.""""""
    assert (
        ""file_list.txt"" in dbs.input
    ), ""For auto_mode file_list.txt need to be in your project folder.""
    assert ""prompt"" in dbs.input, ""For auto_mode a prompt file must exist.""
    return []


def get_improve_prompt(ai: AI, dbs: DBs):
    Asks the user what they would like to fix.
    -----------------------------
    The following files will be used in the improvement process:
    {dbs.input[""file_list.txt""]}
    The inserted prompt is the following:
    '{dbs.input['prompt']}'
    -----------------------------
    You can change these files in .gpteng folder ({dbs.input.path}) in your project
    before proceeding.
    Press enter to proceed with modifications.
    """"""
    return []


def improve_existing_code(ai: AI, dbs: DBs):
    """"""
    After the file list and prompt have been aquired, this function is called
    to sent the formatted prompt to the LLM.
    """"""

    files_info = get_code_strings(dbs.input)  # this only has file names not paths

    Make sure the output of any files is in the following format where
    FILENAME is the file name including the file extension, and the file path.  Do not
    forget to include the file path.
    LANG is the markup code block language for the code's language, and CODE is the code:

    FILENAME
    ```LANG
    CODE
    ```
    """"""
    EVAL_IMPROVE_CODE = ""eval_improve_code""
    Config.USE_FEEDBACK: [use_feedback, gen_entrypoint, execute_entrypoint, human_review],
    Config.EXECUTE_ONLY: [execute_entrypoint],
    Config.EVALUATE: [execute_entrypoint, human_review],
    Config.IMPROVE_CODE: [
        set_improve_filelist,
        get_improve_prompt,
        improve_existing_code,
    Config.EVAL_IMPROVE_CODE: [assert_files_ready, improve_existing_code],",bug-free
"# All steps below have the signature Step
def improve_existing_code(ai: AI, dbs: DBs):
    Ask the user for a list of paths, ask the AI agent to
    improve, fix or add a new functionality
    A file selection will appear to select the files.
    The terminal will ask for the prompt.
    ask_for_files(dbs.input)  # stores files as full paths.
    files_info = get_code_strings(dbs.input)  # this only has file names not paths
-----------------------------
The following files will be used in the improvement process:
{dbs.input[""file_list.txt""]}
The inserted prompt is the following:
'{dbs.input['prompt']}'
-----------------------------
You can change these files in .gpteng folder ({dbs.input.path}) in your project
before proceeding.
Press enter to proceed with modifications.
""""""
Make sure the output of any files is in the following format where
FILENAME is the file name including the file extension, and the file path.  Do not
forget to include the file path.
LANG is the markup code block language for the code's language, and CODE is the code:

FILENAME
```LANG
CODE
```
""""""
    Config.USE_FEEDBACK: [
        use_feedback,
        gen_entrypoint,
        execute_entrypoint,
        human_review,
    ],
    Config.EXECUTE_ONLY: [
        execute_entrypoint,
    ],
    Config.EVALUATE: [
        execute_entrypoint,
        human_review,
    Config.IMPROVE_CODE: [improve_existing_code],",buggy
"# All steps below have the Step signature
def set_improve_filelist(ai: AI, dbs: DBs):
    """"""Sets the file list for files to work with in existing code mode.""""""
    ask_for_files(dbs.input)  # stores files as full paths.
    return []


def assert_files_ready(ai: AI, dbs: DBs):
    """"""Checks that the required files are present for headless
    improve code execution.""""""
    assert (
        ""file_list.txt"" in dbs.input
    ), ""For auto_mode file_list.txt need to be in your project folder.""
    assert ""prompt"" in dbs.input, ""For auto_mode a prompt file must exist.""
    return []


def get_improve_prompt(ai: AI, dbs: DBs):
    Asks the user what they would like to fix.
    -----------------------------
    The following files will be used in the improvement process:
    {dbs.input[""file_list.txt""]}
    The inserted prompt is the following:
    '{dbs.input['prompt']}'
    -----------------------------
    You can change these files in .gpteng folder ({dbs.input.path}) in your project
    before proceeding.
    Press enter to proceed with modifications.
    """"""
    return []


def improve_existing_code(ai: AI, dbs: DBs):
    """"""
    After the file list and prompt have been aquired, this function is called
    to sent the formatted prompt to the LLM.
    """"""

    files_info = get_code_strings(dbs.input)  # this only has file names not paths

    Make sure the output of any files is in the following format where
    FILENAME is the file name including the file extension, and the file path.  Do not
    forget to include the file path.
    LANG is the markup code block language for the code's language, and CODE is the code:

    FILENAME
    ```LANG
    CODE
    ```
    """"""
    EVAL_IMPROVE_CODE = ""eval_improve_code""
    Config.USE_FEEDBACK: [use_feedback, gen_entrypoint, execute_entrypoint, human_review],
    Config.EXECUTE_ONLY: [execute_entrypoint],
    Config.EVALUATE: [execute_entrypoint, human_review],
    Config.IMPROVE_CODE: [
        set_improve_filelist,
        get_improve_prompt,
        improve_existing_code,
    Config.EVAL_IMPROVE_CODE: [assert_files_ready, improve_existing_code],",bug-free
"# All steps below have the signature Step
def improve_existing_code(ai: AI, dbs: DBs):
    Ask the user for a list of paths, ask the AI agent to
    improve, fix or add a new functionality
    A file selection will appear to select the files.
    The terminal will ask for the prompt.
    ask_for_files(dbs.input)  # stores files as full paths.
    files_info = get_code_strings(dbs.input)  # this only has file names not paths
-----------------------------
The following files will be used in the improvement process:
{dbs.input[""file_list.txt""]}
The inserted prompt is the following:
'{dbs.input['prompt']}'
-----------------------------
You can change these files in .gpteng folder ({dbs.input.path}) in your project
before proceeding.
Press enter to proceed with modifications.
""""""
Make sure the output of any files is in the following format where
FILENAME is the file name including the file extension, and the file path.  Do not
forget to include the file path.
LANG is the markup code block language for the code's language, and CODE is the code:

FILENAME
```LANG
CODE
```
""""""
    Config.USE_FEEDBACK: [
        use_feedback,
        gen_entrypoint,
        execute_entrypoint,
        human_review,
    ],
    Config.EXECUTE_ONLY: [
        execute_entrypoint,
    ],
    Config.EVALUATE: [
        execute_entrypoint,
        human_review,
    Config.IMPROVE_CODE: [improve_existing_code],",buggy
"# All steps below have the Step signature
def set_improve_filelist(ai: AI, dbs: DBs):
    """"""Sets the file list for files to work with in existing code mode.""""""
    ask_for_files(dbs.input)  # stores files as full paths.
    return []


def assert_files_ready(ai: AI, dbs: DBs):
    """"""Checks that the required files are present for headless
    improve code execution.""""""
    assert (
        ""file_list.txt"" in dbs.input
    ), ""For auto_mode file_list.txt need to be in your project folder.""
    assert ""prompt"" in dbs.input, ""For auto_mode a prompt file must exist.""
    return []


def get_improve_prompt(ai: AI, dbs: DBs):
    Asks the user what they would like to fix.
    -----------------------------
    The following files will be used in the improvement process:
    {dbs.input[""file_list.txt""]}
    The inserted prompt is the following:
    '{dbs.input['prompt']}'
    -----------------------------
    You can change these files in .gpteng folder ({dbs.input.path}) in your project
    before proceeding.
    Press enter to proceed with modifications.
    """"""
    return []


def improve_existing_code(ai: AI, dbs: DBs):
    """"""
    After the file list and prompt have been aquired, this function is called
    to sent the formatted prompt to the LLM.
    """"""

    files_info = get_code_strings(dbs.input)  # this only has file names not paths

    Make sure the output of any files is in the following format where
    FILENAME is the file name including the file extension, and the file path.  Do not
    forget to include the file path.
    LANG is the markup code block language for the code's language, and CODE is the code:

    FILENAME
    ```LANG
    CODE
    ```
    """"""
    EVAL_IMPROVE_CODE = ""eval_improve_code""
    Config.USE_FEEDBACK: [use_feedback, gen_entrypoint, execute_entrypoint, human_review],
    Config.EXECUTE_ONLY: [execute_entrypoint],
    Config.EVALUATE: [execute_entrypoint, human_review],
    Config.IMPROVE_CODE: [
        set_improve_filelist,
        get_improve_prompt,
        improve_existing_code,
    Config.EVAL_IMPROVE_CODE: [assert_files_ready, improve_existing_code],",bug-free
"# All steps below have the signature Step
def improve_existing_code(ai: AI, dbs: DBs):
    Ask the user for a list of paths, ask the AI agent to
    improve, fix or add a new functionality
    A file selection will appear to select the files.
    The terminal will ask for the prompt.
    ask_for_files(dbs.input)  # stores files as full paths.
    files_info = get_code_strings(dbs.input)  # this only has file names not paths
-----------------------------
The following files will be used in the improvement process:
{dbs.input[""file_list.txt""]}
The inserted prompt is the following:
'{dbs.input['prompt']}'
-----------------------------
You can change these files in .gpteng folder ({dbs.input.path}) in your project
before proceeding.
Press enter to proceed with modifications.
""""""
Make sure the output of any files is in the following format where
FILENAME is the file name including the file extension, and the file path.  Do not
forget to include the file path.
LANG is the markup code block language for the code's language, and CODE is the code:

FILENAME
```LANG
CODE
```
""""""
    Config.USE_FEEDBACK: [
        use_feedback,
        gen_entrypoint,
        execute_entrypoint,
        human_review,
    ],
    Config.EXECUTE_ONLY: [
        execute_entrypoint,
    ],
    Config.EVALUATE: [
        execute_entrypoint,
        human_review,
    Config.IMPROVE_CODE: [improve_existing_code],",buggy
"# All steps below have the Step signature
def set_improve_filelist(ai: AI, dbs: DBs):
    """"""Sets the file list for files to work with in existing code mode.""""""
    ask_for_files(dbs.input)  # stores files as full paths.
    return []


def assert_files_ready(ai: AI, dbs: DBs):
    """"""Checks that the required files are present for headless
    improve code execution.""""""
    assert (
        ""file_list.txt"" in dbs.input
    ), ""For auto_mode file_list.txt need to be in your project folder.""
    assert ""prompt"" in dbs.input, ""For auto_mode a prompt file must exist.""
    return []


def get_improve_prompt(ai: AI, dbs: DBs):
    Asks the user what they would like to fix.
    -----------------------------
    The following files will be used in the improvement process:
    {dbs.input[""file_list.txt""]}
    The inserted prompt is the following:
    '{dbs.input['prompt']}'
    -----------------------------
    You can change these files in .gpteng folder ({dbs.input.path}) in your project
    before proceeding.
    Press enter to proceed with modifications.
    """"""
    return []


def improve_existing_code(ai: AI, dbs: DBs):
    """"""
    After the file list and prompt have been aquired, this function is called
    to sent the formatted prompt to the LLM.
    """"""

    files_info = get_code_strings(dbs.input)  # this only has file names not paths

    Make sure the output of any files is in the following format where
    FILENAME is the file name including the file extension, and the file path.  Do not
    forget to include the file path.
    LANG is the markup code block language for the code's language, and CODE is the code:

    FILENAME
    ```LANG
    CODE
    ```
    """"""
    EVAL_IMPROVE_CODE = ""eval_improve_code""
    Config.USE_FEEDBACK: [use_feedback, gen_entrypoint, execute_entrypoint, human_review],
    Config.EXECUTE_ONLY: [execute_entrypoint],
    Config.EVALUATE: [execute_entrypoint, human_review],
    Config.IMPROVE_CODE: [
        set_improve_filelist,
        get_improve_prompt,
        improve_existing_code,
    Config.EVAL_IMPROVE_CODE: [assert_files_ready, improve_existing_code],",bug-free
"# All steps below have the signature Step
def improve_existing_code(ai: AI, dbs: DBs):
    Ask the user for a list of paths, ask the AI agent to
    improve, fix or add a new functionality
    A file selection will appear to select the files.
    The terminal will ask for the prompt.
    ask_for_files(dbs.input)  # stores files as full paths.
    files_info = get_code_strings(dbs.input)  # this only has file names not paths
-----------------------------
The following files will be used in the improvement process:
{dbs.input[""file_list.txt""]}
The inserted prompt is the following:
'{dbs.input['prompt']}'
-----------------------------
You can change these files in .gpteng folder ({dbs.input.path}) in your project
before proceeding.
Press enter to proceed with modifications.
""""""
Make sure the output of any files is in the following format where
FILENAME is the file name including the file extension, and the file path.  Do not
forget to include the file path.
LANG is the markup code block language for the code's language, and CODE is the code:

FILENAME
```LANG
CODE
```
""""""
    Config.USE_FEEDBACK: [
        use_feedback,
        gen_entrypoint,
        execute_entrypoint,
        human_review,
    ],
    Config.EXECUTE_ONLY: [
        execute_entrypoint,
    ],
    Config.EVALUATE: [
        execute_entrypoint,
        human_review,
    Config.IMPROVE_CODE: [improve_existing_code],",buggy
"# All steps below have the Step signature
def set_improve_filelist(ai: AI, dbs: DBs):
    """"""Sets the file list for files to work with in existing code mode.""""""
    ask_for_files(dbs.input)  # stores files as full paths.
    return []


def assert_files_ready(ai: AI, dbs: DBs):
    """"""Checks that the required files are present for headless
    improve code execution.""""""
    assert (
        ""file_list.txt"" in dbs.input
    ), ""For auto_mode file_list.txt need to be in your project folder.""
    assert ""prompt"" in dbs.input, ""For auto_mode a prompt file must exist.""
    return []


def get_improve_prompt(ai: AI, dbs: DBs):
    Asks the user what they would like to fix.
    -----------------------------
    The following files will be used in the improvement process:
    {dbs.input[""file_list.txt""]}
    The inserted prompt is the following:
    '{dbs.input['prompt']}'
    -----------------------------
    You can change these files in .gpteng folder ({dbs.input.path}) in your project
    before proceeding.
    Press enter to proceed with modifications.
    """"""
    return []


def improve_existing_code(ai: AI, dbs: DBs):
    """"""
    After the file list and prompt have been aquired, this function is called
    to sent the formatted prompt to the LLM.
    """"""

    files_info = get_code_strings(dbs.input)  # this only has file names not paths

    Make sure the output of any files is in the following format where
    FILENAME is the file name including the file extension, and the file path.  Do not
    forget to include the file path.
    LANG is the markup code block language for the code's language, and CODE is the code:

    FILENAME
    ```LANG
    CODE
    ```
    """"""
    EVAL_IMPROVE_CODE = ""eval_improve_code""
    Config.USE_FEEDBACK: [use_feedback, gen_entrypoint, execute_entrypoint, human_review],
    Config.EXECUTE_ONLY: [execute_entrypoint],
    Config.EVALUATE: [execute_entrypoint, human_review],
    Config.IMPROVE_CODE: [
        set_improve_filelist,
        get_improve_prompt,
        improve_existing_code,
    Config.EVAL_IMPROVE_CODE: [assert_files_ready, improve_existing_code],",bug-free
"# All steps below have the signature Step
def improve_existing_code(ai: AI, dbs: DBs):
    Ask the user for a list of paths, ask the AI agent to
    improve, fix or add a new functionality
    A file selection will appear to select the files.
    The terminal will ask for the prompt.
    ask_for_files(dbs.input)  # stores files as full paths.
    files_info = get_code_strings(dbs.input)  # this only has file names not paths
-----------------------------
The following files will be used in the improvement process:
{dbs.input[""file_list.txt""]}
The inserted prompt is the following:
'{dbs.input['prompt']}'
-----------------------------
You can change these files in .gpteng folder ({dbs.input.path}) in your project
before proceeding.
Press enter to proceed with modifications.
""""""
Make sure the output of any files is in the following format where
FILENAME is the file name including the file extension, and the file path.  Do not
forget to include the file path.
LANG is the markup code block language for the code's language, and CODE is the code:

FILENAME
```LANG
CODE
```
""""""
    Config.USE_FEEDBACK: [
        use_feedback,
        gen_entrypoint,
        execute_entrypoint,
        human_review,
    ],
    Config.EXECUTE_ONLY: [
        execute_entrypoint,
    ],
    Config.EVALUATE: [
        execute_entrypoint,
        human_review,
    Config.IMPROVE_CODE: [improve_existing_code],",buggy
"# All steps below have the Step signature
def set_improve_filelist(ai: AI, dbs: DBs):
    """"""Sets the file list for files to work with in existing code mode.""""""
    ask_for_files(dbs.input)  # stores files as full paths.
    return []


def assert_files_ready(ai: AI, dbs: DBs):
    """"""Checks that the required files are present for headless
    improve code execution.""""""
    assert (
        ""file_list.txt"" in dbs.input
    ), ""For auto_mode file_list.txt need to be in your project folder.""
    assert ""prompt"" in dbs.input, ""For auto_mode a prompt file must exist.""
    return []


def get_improve_prompt(ai: AI, dbs: DBs):
    Asks the user what they would like to fix.
    -----------------------------
    The following files will be used in the improvement process:
    {dbs.input[""file_list.txt""]}
    The inserted prompt is the following:
    '{dbs.input['prompt']}'
    -----------------------------
    You can change these files in .gpteng folder ({dbs.input.path}) in your project
    before proceeding.
    Press enter to proceed with modifications.
    """"""
    return []


def improve_existing_code(ai: AI, dbs: DBs):
    """"""
    After the file list and prompt have been aquired, this function is called
    to sent the formatted prompt to the LLM.
    """"""

    files_info = get_code_strings(dbs.input)  # this only has file names not paths

    Make sure the output of any files is in the following format where
    FILENAME is the file name including the file extension, and the file path.  Do not
    forget to include the file path.
    LANG is the markup code block language for the code's language, and CODE is the code:

    FILENAME
    ```LANG
    CODE
    ```
    """"""
    EVAL_IMPROVE_CODE = ""eval_improve_code""
    Config.USE_FEEDBACK: [use_feedback, gen_entrypoint, execute_entrypoint, human_review],
    Config.EXECUTE_ONLY: [execute_entrypoint],
    Config.EVALUATE: [execute_entrypoint, human_review],
    Config.IMPROVE_CODE: [
        set_improve_filelist,
        get_improve_prompt,
        improve_existing_code,
    Config.EVAL_IMPROVE_CODE: [assert_files_ready, improve_existing_code],",bug-free
"# All steps below have the signature Step
def improve_existing_code(ai: AI, dbs: DBs):
    Ask the user for a list of paths, ask the AI agent to
    improve, fix or add a new functionality
    A file selection will appear to select the files.
    The terminal will ask for the prompt.
    ask_for_files(dbs.input)  # stores files as full paths.
    files_info = get_code_strings(dbs.input)  # this only has file names not paths
-----------------------------
The following files will be used in the improvement process:
{dbs.input[""file_list.txt""]}
The inserted prompt is the following:
'{dbs.input['prompt']}'
-----------------------------
You can change these files in .gpteng folder ({dbs.input.path}) in your project
before proceeding.
Press enter to proceed with modifications.
""""""
Make sure the output of any files is in the following format where
FILENAME is the file name including the file extension, and the file path.  Do not
forget to include the file path.
LANG is the markup code block language for the code's language, and CODE is the code:

FILENAME
```LANG
CODE
```
""""""
    Config.USE_FEEDBACK: [
        use_feedback,
        gen_entrypoint,
        execute_entrypoint,
        human_review,
    ],
    Config.EXECUTE_ONLY: [
        execute_entrypoint,
    ],
    Config.EVALUATE: [
        execute_entrypoint,
        human_review,
    Config.IMPROVE_CODE: [improve_existing_code],",buggy
"# All steps below have the Step signature
def set_improve_filelist(ai: AI, dbs: DBs):
    """"""Sets the file list for files to work with in existing code mode.""""""
    ask_for_files(dbs.input)  # stores files as full paths.
    return []


def assert_files_ready(ai: AI, dbs: DBs):
    """"""Checks that the required files are present for headless
    improve code execution.""""""
    assert (
        ""file_list.txt"" in dbs.input
    ), ""For auto_mode file_list.txt need to be in your project folder.""
    assert ""prompt"" in dbs.input, ""For auto_mode a prompt file must exist.""
    return []


def get_improve_prompt(ai: AI, dbs: DBs):
    Asks the user what they would like to fix.
    -----------------------------
    The following files will be used in the improvement process:
    {dbs.input[""file_list.txt""]}
    The inserted prompt is the following:
    '{dbs.input['prompt']}'
    -----------------------------
    You can change these files in .gpteng folder ({dbs.input.path}) in your project
    before proceeding.
    Press enter to proceed with modifications.
    """"""
    return []


def improve_existing_code(ai: AI, dbs: DBs):
    """"""
    After the file list and prompt have been aquired, this function is called
    to sent the formatted prompt to the LLM.
    """"""

    files_info = get_code_strings(dbs.input)  # this only has file names not paths

    Make sure the output of any files is in the following format where
    FILENAME is the file name including the file extension, and the file path.  Do not
    forget to include the file path.
    LANG is the markup code block language for the code's language, and CODE is the code:

    FILENAME
    ```LANG
    CODE
    ```
    """"""
    EVAL_IMPROVE_CODE = ""eval_improve_code""
    Config.USE_FEEDBACK: [use_feedback, gen_entrypoint, execute_entrypoint, human_review],
    Config.EXECUTE_ONLY: [execute_entrypoint],
    Config.EVALUATE: [execute_entrypoint, human_review],
    Config.IMPROVE_CODE: [
        set_improve_filelist,
        get_improve_prompt,
        improve_existing_code,
    Config.EVAL_IMPROVE_CODE: [assert_files_ready, improve_existing_code],",bug-free
"# All steps below have the signature Step
def improve_existing_code(ai: AI, dbs: DBs):
    Ask the user for a list of paths, ask the AI agent to
    improve, fix or add a new functionality
    A file selection will appear to select the files.
    The terminal will ask for the prompt.
    ask_for_files(dbs.input)  # stores files as full paths.
    files_info = get_code_strings(dbs.input)  # this only has file names not paths
-----------------------------
The following files will be used in the improvement process:
{dbs.input[""file_list.txt""]}
The inserted prompt is the following:
'{dbs.input['prompt']}'
-----------------------------
You can change these files in .gpteng folder ({dbs.input.path}) in your project
before proceeding.
Press enter to proceed with modifications.
""""""
Make sure the output of any files is in the following format where
FILENAME is the file name including the file extension, and the file path.  Do not
forget to include the file path.
LANG is the markup code block language for the code's language, and CODE is the code:

FILENAME
```LANG
CODE
```
""""""
    Config.USE_FEEDBACK: [
        use_feedback,
        gen_entrypoint,
        execute_entrypoint,
        human_review,
    ],
    Config.EXECUTE_ONLY: [
        execute_entrypoint,
    ],
    Config.EVALUATE: [
        execute_entrypoint,
        human_review,
    Config.IMPROVE_CODE: [improve_existing_code],",buggy
"# All steps below have the Step signature
def set_improve_filelist(ai: AI, dbs: DBs):
    """"""Sets the file list for files to work with in existing code mode.""""""
    ask_for_files(dbs.input)  # stores files as full paths.
    return []


def assert_files_ready(ai: AI, dbs: DBs):
    """"""Checks that the required files are present for headless
    improve code execution.""""""
    assert (
        ""file_list.txt"" in dbs.input
    ), ""For auto_mode file_list.txt need to be in your project folder.""
    assert ""prompt"" in dbs.input, ""For auto_mode a prompt file must exist.""
    return []


def get_improve_prompt(ai: AI, dbs: DBs):
    Asks the user what they would like to fix.
    -----------------------------
    The following files will be used in the improvement process:
    {dbs.input[""file_list.txt""]}
    The inserted prompt is the following:
    '{dbs.input['prompt']}'
    -----------------------------
    You can change these files in .gpteng folder ({dbs.input.path}) in your project
    before proceeding.
    Press enter to proceed with modifications.
    """"""
    return []


def improve_existing_code(ai: AI, dbs: DBs):
    """"""
    After the file list and prompt have been aquired, this function is called
    to sent the formatted prompt to the LLM.
    """"""

    files_info = get_code_strings(dbs.input)  # this only has file names not paths

    Make sure the output of any files is in the following format where
    FILENAME is the file name including the file extension, and the file path.  Do not
    forget to include the file path.
    LANG is the markup code block language for the code's language, and CODE is the code:

    FILENAME
    ```LANG
    CODE
    ```
    """"""
    EVAL_IMPROVE_CODE = ""eval_improve_code""
    Config.USE_FEEDBACK: [use_feedback, gen_entrypoint, execute_entrypoint, human_review],
    Config.EXECUTE_ONLY: [execute_entrypoint],
    Config.EVALUATE: [execute_entrypoint, human_review],
    Config.IMPROVE_CODE: [
        set_improve_filelist,
        get_improve_prompt,
        improve_existing_code,
    Config.EVAL_IMPROVE_CODE: [assert_files_ready, improve_existing_code],",bug-free
"# All steps below have the signature Step
def improve_existing_code(ai: AI, dbs: DBs):
    Ask the user for a list of paths, ask the AI agent to
    improve, fix or add a new functionality
    A file selection will appear to select the files.
    The terminal will ask for the prompt.
    ask_for_files(dbs.input)  # stores files as full paths.
    files_info = get_code_strings(dbs.input)  # this only has file names not paths
-----------------------------
The following files will be used in the improvement process:
{dbs.input[""file_list.txt""]}
The inserted prompt is the following:
'{dbs.input['prompt']}'
-----------------------------
You can change these files in .gpteng folder ({dbs.input.path}) in your project
before proceeding.
Press enter to proceed with modifications.
""""""
Make sure the output of any files is in the following format where
FILENAME is the file name including the file extension, and the file path.  Do not
forget to include the file path.
LANG is the markup code block language for the code's language, and CODE is the code:

FILENAME
```LANG
CODE
```
""""""
    Config.USE_FEEDBACK: [
        use_feedback,
        gen_entrypoint,
        execute_entrypoint,
        human_review,
    ],
    Config.EXECUTE_ONLY: [
        execute_entrypoint,
    ],
    Config.EVALUATE: [
        execute_entrypoint,
        human_review,
    Config.IMPROVE_CODE: [improve_existing_code],",buggy
"# All steps below have the Step signature
def set_improve_filelist(ai: AI, dbs: DBs):
    """"""Sets the file list for files to work with in existing code mode.""""""
    ask_for_files(dbs.input)  # stores files as full paths.
    return []


def assert_files_ready(ai: AI, dbs: DBs):
    """"""Checks that the required files are present for headless
    improve code execution.""""""
    assert (
        ""file_list.txt"" in dbs.input
    ), ""For auto_mode file_list.txt need to be in your project folder.""
    assert ""prompt"" in dbs.input, ""For auto_mode a prompt file must exist.""
    return []


def get_improve_prompt(ai: AI, dbs: DBs):
    Asks the user what they would like to fix.
    -----------------------------
    The following files will be used in the improvement process:
    {dbs.input[""file_list.txt""]}
    The inserted prompt is the following:
    '{dbs.input['prompt']}'
    -----------------------------
    You can change these files in .gpteng folder ({dbs.input.path}) in your project
    before proceeding.
    Press enter to proceed with modifications.
    """"""
    return []


def improve_existing_code(ai: AI, dbs: DBs):
    """"""
    After the file list and prompt have been aquired, this function is called
    to sent the formatted prompt to the LLM.
    """"""

    files_info = get_code_strings(dbs.input)  # this only has file names not paths

    Make sure the output of any files is in the following format where
    FILENAME is the file name including the file extension, and the file path.  Do not
    forget to include the file path.
    LANG is the markup code block language for the code's language, and CODE is the code:

    FILENAME
    ```LANG
    CODE
    ```
    """"""
    EVAL_IMPROVE_CODE = ""eval_improve_code""
    Config.USE_FEEDBACK: [use_feedback, gen_entrypoint, execute_entrypoint, human_review],
    Config.EXECUTE_ONLY: [execute_entrypoint],
    Config.EVALUATE: [execute_entrypoint, human_review],
    Config.IMPROVE_CODE: [
        set_improve_filelist,
        get_improve_prompt,
        improve_existing_code,
    Config.EVAL_IMPROVE_CODE: [assert_files_ready, improve_existing_code],",bug-free
"# All steps below have the signature Step
def improve_existing_code(ai: AI, dbs: DBs):
    Ask the user for a list of paths, ask the AI agent to
    improve, fix or add a new functionality
    A file selection will appear to select the files.
    The terminal will ask for the prompt.
    ask_for_files(dbs.input)  # stores files as full paths.
    files_info = get_code_strings(dbs.input)  # this only has file names not paths
-----------------------------
The following files will be used in the improvement process:
{dbs.input[""file_list.txt""]}
The inserted prompt is the following:
'{dbs.input['prompt']}'
-----------------------------
You can change these files in .gpteng folder ({dbs.input.path}) in your project
before proceeding.
Press enter to proceed with modifications.
""""""
Make sure the output of any files is in the following format where
FILENAME is the file name including the file extension, and the file path.  Do not
forget to include the file path.
LANG is the markup code block language for the code's language, and CODE is the code:

FILENAME
```LANG
CODE
```
""""""
    Config.USE_FEEDBACK: [
        use_feedback,
        gen_entrypoint,
        execute_entrypoint,
        human_review,
    ],
    Config.EXECUTE_ONLY: [
        execute_entrypoint,
    ],
    Config.EVALUATE: [
        execute_entrypoint,
        human_review,
    Config.IMPROVE_CODE: [improve_existing_code],",buggy
"# All steps below have the Step signature
def set_improve_filelist(ai: AI, dbs: DBs):
    """"""Sets the file list for files to work with in existing code mode.""""""
    ask_for_files(dbs.input)  # stores files as full paths.
    return []


def assert_files_ready(ai: AI, dbs: DBs):
    """"""Checks that the required files are present for headless
    improve code execution.""""""
    assert (
        ""file_list.txt"" in dbs.input
    ), ""For auto_mode file_list.txt need to be in your project folder.""
    assert ""prompt"" in dbs.input, ""For auto_mode a prompt file must exist.""
    return []


def get_improve_prompt(ai: AI, dbs: DBs):
    Asks the user what they would like to fix.
    -----------------------------
    The following files will be used in the improvement process:
    {dbs.input[""file_list.txt""]}
    The inserted prompt is the following:
    '{dbs.input['prompt']}'
    -----------------------------
    You can change these files in .gpteng folder ({dbs.input.path}) in your project
    before proceeding.
    Press enter to proceed with modifications.
    """"""
    return []


def improve_existing_code(ai: AI, dbs: DBs):
    """"""
    After the file list and prompt have been aquired, this function is called
    to sent the formatted prompt to the LLM.
    """"""

    files_info = get_code_strings(dbs.input)  # this only has file names not paths

    Make sure the output of any files is in the following format where
    FILENAME is the file name including the file extension, and the file path.  Do not
    forget to include the file path.
    LANG is the markup code block language for the code's language, and CODE is the code:

    FILENAME
    ```LANG
    CODE
    ```
    """"""
    EVAL_IMPROVE_CODE = ""eval_improve_code""
    Config.USE_FEEDBACK: [use_feedback, gen_entrypoint, execute_entrypoint, human_review],
    Config.EXECUTE_ONLY: [execute_entrypoint],
    Config.EVALUATE: [execute_entrypoint, human_review],
    Config.IMPROVE_CODE: [
        set_improve_filelist,
        get_improve_prompt,
        improve_existing_code,
    Config.EVAL_IMPROVE_CODE: [assert_files_ready, improve_existing_code],",bug-free
"# All steps below have the signature Step
def improve_existing_code(ai: AI, dbs: DBs):
    Ask the user for a list of paths, ask the AI agent to
    improve, fix or add a new functionality
    A file selection will appear to select the files.
    The terminal will ask for the prompt.
    ask_for_files(dbs.input)  # stores files as full paths.
    files_info = get_code_strings(dbs.input)  # this only has file names not paths
-----------------------------
The following files will be used in the improvement process:
{dbs.input[""file_list.txt""]}
The inserted prompt is the following:
'{dbs.input['prompt']}'
-----------------------------
You can change these files in .gpteng folder ({dbs.input.path}) in your project
before proceeding.
Press enter to proceed with modifications.
""""""
Make sure the output of any files is in the following format where
FILENAME is the file name including the file extension, and the file path.  Do not
forget to include the file path.
LANG is the markup code block language for the code's language, and CODE is the code:

FILENAME
```LANG
CODE
```
""""""
    Config.USE_FEEDBACK: [
        use_feedback,
        gen_entrypoint,
        execute_entrypoint,
        human_review,
    ],
    Config.EXECUTE_ONLY: [
        execute_entrypoint,
    ],
    Config.EVALUATE: [
        execute_entrypoint,
        human_review,
    Config.IMPROVE_CODE: [improve_existing_code],",buggy
"# All steps below have the Step signature
def set_improve_filelist(ai: AI, dbs: DBs):
    """"""Sets the file list for files to work with in existing code mode.""""""
    ask_for_files(dbs.input)  # stores files as full paths.
    return []


def assert_files_ready(ai: AI, dbs: DBs):
    """"""Checks that the required files are present for headless
    improve code execution.""""""
    assert (
        ""file_list.txt"" in dbs.input
    ), ""For auto_mode file_list.txt need to be in your project folder.""
    assert ""prompt"" in dbs.input, ""For auto_mode a prompt file must exist.""
    return []


def get_improve_prompt(ai: AI, dbs: DBs):
    Asks the user what they would like to fix.
    -----------------------------
    The following files will be used in the improvement process:
    {dbs.input[""file_list.txt""]}
    The inserted prompt is the following:
    '{dbs.input['prompt']}'
    -----------------------------
    You can change these files in .gpteng folder ({dbs.input.path}) in your project
    before proceeding.
    Press enter to proceed with modifications.
    """"""
    return []


def improve_existing_code(ai: AI, dbs: DBs):
    """"""
    After the file list and prompt have been aquired, this function is called
    to sent the formatted prompt to the LLM.
    """"""

    files_info = get_code_strings(dbs.input)  # this only has file names not paths

    Make sure the output of any files is in the following format where
    FILENAME is the file name including the file extension, and the file path.  Do not
    forget to include the file path.
    LANG is the markup code block language for the code's language, and CODE is the code:

    FILENAME
    ```LANG
    CODE
    ```
    """"""
    EVAL_IMPROVE_CODE = ""eval_improve_code""
    Config.USE_FEEDBACK: [use_feedback, gen_entrypoint, execute_entrypoint, human_review],
    Config.EXECUTE_ONLY: [execute_entrypoint],
    Config.EVALUATE: [execute_entrypoint, human_review],
    Config.IMPROVE_CODE: [
        set_improve_filelist,
        get_improve_prompt,
        improve_existing_code,
    Config.EVAL_IMPROVE_CODE: [assert_files_ready, improve_existing_code],",bug-free
"# All steps below have the signature Step
def improve_existing_code(ai: AI, dbs: DBs):
    Ask the user for a list of paths, ask the AI agent to
    improve, fix or add a new functionality
    A file selection will appear to select the files.
    The terminal will ask for the prompt.
    ask_for_files(dbs.input)  # stores files as full paths.
    files_info = get_code_strings(dbs.input)  # this only has file names not paths
-----------------------------
The following files will be used in the improvement process:
{dbs.input[""file_list.txt""]}
The inserted prompt is the following:
'{dbs.input['prompt']}'
-----------------------------
You can change these files in .gpteng folder ({dbs.input.path}) in your project
before proceeding.
Press enter to proceed with modifications.
""""""
Make sure the output of any files is in the following format where
FILENAME is the file name including the file extension, and the file path.  Do not
forget to include the file path.
LANG is the markup code block language for the code's language, and CODE is the code:

FILENAME
```LANG
CODE
```
""""""
    Config.USE_FEEDBACK: [
        use_feedback,
        gen_entrypoint,
        execute_entrypoint,
        human_review,
    ],
    Config.EXECUTE_ONLY: [
        execute_entrypoint,
    ],
    Config.EVALUATE: [
        execute_entrypoint,
        human_review,
    Config.IMPROVE_CODE: [improve_existing_code],",buggy
"# All steps below have the Step signature
def set_improve_filelist(ai: AI, dbs: DBs):
    """"""Sets the file list for files to work with in existing code mode.""""""
    ask_for_files(dbs.input)  # stores files as full paths.
    return []


def assert_files_ready(ai: AI, dbs: DBs):
    """"""Checks that the required files are present for headless
    improve code execution.""""""
    assert (
        ""file_list.txt"" in dbs.input
    ), ""For auto_mode file_list.txt need to be in your project folder.""
    assert ""prompt"" in dbs.input, ""For auto_mode a prompt file must exist.""
    return []


def get_improve_prompt(ai: AI, dbs: DBs):
    Asks the user what they would like to fix.
    -----------------------------
    The following files will be used in the improvement process:
    {dbs.input[""file_list.txt""]}
    The inserted prompt is the following:
    '{dbs.input['prompt']}'
    -----------------------------
    You can change these files in .gpteng folder ({dbs.input.path}) in your project
    before proceeding.
    Press enter to proceed with modifications.
    """"""
    return []


def improve_existing_code(ai: AI, dbs: DBs):
    """"""
    After the file list and prompt have been aquired, this function is called
    to sent the formatted prompt to the LLM.
    """"""

    files_info = get_code_strings(dbs.input)  # this only has file names not paths

    Make sure the output of any files is in the following format where
    FILENAME is the file name including the file extension, and the file path.  Do not
    forget to include the file path.
    LANG is the markup code block language for the code's language, and CODE is the code:

    FILENAME
    ```LANG
    CODE
    ```
    """"""
    EVAL_IMPROVE_CODE = ""eval_improve_code""
    Config.USE_FEEDBACK: [use_feedback, gen_entrypoint, execute_entrypoint, human_review],
    Config.EXECUTE_ONLY: [execute_entrypoint],
    Config.EVALUATE: [execute_entrypoint, human_review],
    Config.IMPROVE_CODE: [
        set_improve_filelist,
        get_improve_prompt,
        improve_existing_code,
    Config.EVAL_IMPROVE_CODE: [assert_files_ready, improve_existing_code],",bug-free
"		frappe.db.set_value(""Global Defaults"", None, ""current_fiscal_year"", self.name)
			frappe.db.set_value(
				""Accounts Settings"", ""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
			frappe.db.set_value(""Selling Settings"", None, ""validate_selling_price"", 0)
			frappe.db.set_value(""Selling Settings"", ""Selling Settings"", ""validate_selling_price"", 1)
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1
		)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_value(""Accounts Settings"", None, ""post_change_gl_entries"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""post_change_gl_entries"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", old_negative_stock)
		frappe.db.set_value(""Accounts Settings"", None, ""enable_common_party_accounting"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""enable_common_party_accounting"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", add_days(getdate(), 1))
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", None)
		frappe.db.set_value(""Accounts Settings"", None, ""over_billing_allowance"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""over_billing_allowance"", over_billing_allowance)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", getdate(""2019-01-31""))
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", None)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1
		)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_value(""Shopping Cart Settings"", None, ""enabled"", 0)
	frappe.db.set_value(""Accounts Settings"", None, ""book_asset_depreciation_entry_automatically"", 1)
	frappe.db.set_value(""Accounts Settings"", None, ""book_asset_depreciation_entry_automatically"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""over_billing_allowance"", 0)
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(""Selling Settings"", None, ""maintain_same_sales_rate"", 1)
		frappe.db.set_value(""Buying Settings"", None, ""maintain_same_rate"", 1)
		frappe.db.set_value(""Buying Settings"", None, ""supp_master_name"", ""Naming Series"")
		frappe.db.set_value(""Buying Settings"", None, ""supp_master_name"", ""Supplier Name"")
	frappe.db.set_value(
		""Buying Settings"", None, ""backflush_raw_materials_of_subcontract_based_on"", based_on
		frappe.db.set_value(
			""CRM Settings"", ""CRM Settings"", ""carry_forward_communication_and_comments"", 1
		)
		frappe.db.set_value(""E Commerce Settings"", None, ""save_quotations_as_draft"", 0)
		frappe.db.set_value(""Plaid Settings"", None, ""enabled"", 0)
		frappe.db.set_value(
			""Manufacturing Settings"",
			None,
			{""disable_capacity_planning"": 0, ""capacity_planning_for_days"": 1},
			frappe.db.set_value(""Manufacturing Settings"", None, {""capacity_planning_for_days"": 30})
		frappe.db.set_value(""Manufacturing Settings"", None, ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_value(""Manufacturing Settings"", None, ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_value(""Manufacturing Settings"", None, ""make_serial_no_batch_from_work_order"", 1)
		frappe.db.set_value(""Manufacturing Settings"", None, ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_value(""Manufacturing Settings"", None, ""material_consumption"", 1)
		frappe.db.set_value(""Manufacturing Settings"", None, ""material_consumption"", 0)
		frappe.db.set_value(""Manufacturing Settings"", None, ""material_consumption"", 0)
		frappe.db.set_value(
			None,
		frappe.db.set_value(""Manufacturing Settings"", None, ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_value(
			None,
		frappe.db.set_value(""Manufacturing Settings"", None, ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_value(
			None,
		frappe.db.set_value(
			None,
		frappe.db.set_value(
			None,
		frappe.db.set_value(
			None,
	frappe.db.set_value(
		""Buying Settings"", None, ""backflush_raw_materials_of_subcontract_based_on"", ""BOM""
	frappe.db.set_value(""Accounts Settings"", None, ""over_delivery_receipt_allowance"", qty_allowance)
	frappe.db.set_value(
		""Accounts Settings"", None, ""automatically_process_deferred_accounting_entry"", 1
	frappe.db.set_value(""Homepage"", ""Homepage"", ""hero_section_based_on"", ""Default"")
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", None)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", acc_frozen_upto)
			frappe.db.set_value(doctype, doctype, ""enable_discount_accounting"", 1, update_modified=False)
		frappe.db.set_value(
			""CRM Settings"",
		frappe.db.set_value(""Selling Settings"", None, ""cust_master_name"", ""Naming Series"")
		frappe.db.set_value(""Selling Settings"", None, ""cust_master_name"", ""Customer Name"")
		frappe.db.set_value(
			""Accounts Settings"",
			""Accounts Settings"",
			""unlink_advance_payment_on_cancelation_of_order"",
			cls.unlink_setting,
		frappe.db.set_value(""Stock Settings"", None, ""default_warehouse"", ""_Test Warehouse - _TC"")
		frappe.db.set_value(""Stock Settings"", None, ""default_warehouse"", old_stock_settings_value)
		frappe.db.set_value(""Stock Settings"", None, ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""auto_insert_price_list_rate_if_missing"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
	frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""stale_days"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""stale_days"", 1)
	frappe.db.set_value(""System Settings"", None, ""app_name"", ""ERPNext"")
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(
			""Stock Settings"", None, ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""mr_qty_allowance"", 20)
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
	frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_value(""Stock Settings"", None, ""action_if_quality_inspection_is_rejected"", ""Warn"")
		frappe.db.set_value(""Stock Settings"", None, ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""auto_indent"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""auto_indent"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""stock_auth_role"", """")
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto"", add_days(nowdate(), 5))
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto"", """")
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto_days"", -1)
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto_days"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(
			""Stock Settings"", None, ""role_allowed_to_create_edit_back_dated_transactions"", ""Stock Manager""
			frappe.db.set_value(
				""Stock Settings"", None, ""role_allowed_to_create_edit_back_dated_transactions"", None
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""clean_description_html"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(
			""Stock Settings"", None, ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Exotel Settings"", ""Exotel Settings"", ""enabled"", 1)",buggy
"		frappe.db.set_single_value(""Global Defaults"", ""current_fiscal_year"", self.name)
			frappe.db.set_single_value(
				""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
			frappe.db.set_single_value(""Selling Settings"", ""validate_selling_price"", 0)
			frappe.db.set_single_value(""Selling Settings"", ""validate_selling_price"", 1)
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1)
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_single_value(""Accounts Settings"", ""post_change_gl_entries"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""post_change_gl_entries"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", old_negative_stock)
		frappe.db.set_single_value(""Accounts Settings"", ""enable_common_party_accounting"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""enable_common_party_accounting"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", add_days(getdate(), 1))
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", None)
		frappe.db.set_single_value(""Accounts Settings"", ""over_billing_allowance"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""over_billing_allowance"", over_billing_allowance)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", getdate(""2019-01-31""))
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", None)
		frappe.db.set_single_value(""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1)
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_single_value(""Shopping Cart Settings"", ""enabled"", 0)
	frappe.db.set_single_value(""Accounts Settings"", ""book_asset_depreciation_entry_automatically"", 1)
	frappe.db.set_single_value(""Accounts Settings"", ""book_asset_depreciation_entry_automatically"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""over_billing_allowance"", 0)
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Selling Settings"", ""maintain_same_sales_rate"", 1)
		frappe.db.set_single_value(""Buying Settings"", ""maintain_same_rate"", 1)
		frappe.db.set_single_value(""Buying Settings"", ""supp_master_name"", ""Naming Series"")
		frappe.db.set_single_value(""Buying Settings"", ""supp_master_name"", ""Supplier Name"")
	frappe.db.set_single_value(
		""Buying Settings"", ""backflush_raw_materials_of_subcontract_based_on"", based_on
		frappe.db.set_single_value(""CRM Settings"", ""carry_forward_communication_and_comments"", 1)
		frappe.db.set_single_value(""E Commerce Settings"", ""save_quotations_as_draft"", 0)
		frappe.db.set_single_value(""Plaid Settings"", ""enabled"", 0)
		frappe.db.set_single_value(
			""Manufacturing Settings"", {""disable_capacity_planning"": 0, ""capacity_planning_for_days"": 1}
			frappe.db.set_single_value(""Manufacturing Settings"", {""capacity_planning_for_days"": 30})
		frappe.db.set_single_value(""Manufacturing Settings"", ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_single_value(""Manufacturing Settings"", ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_single_value(""Manufacturing Settings"", ""make_serial_no_batch_from_work_order"", 1)
		frappe.db.set_single_value(""Manufacturing Settings"", ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_single_value(""Manufacturing Settings"", ""material_consumption"", 1)
		frappe.db.set_single_value(""Manufacturing Settings"", ""material_consumption"", 0)
		frappe.db.set_single_value(""Manufacturing Settings"", ""material_consumption"", 0)
		frappe.db.set_single_value(
		frappe.db.set_single_value(""Manufacturing Settings"", ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_single_value(
		frappe.db.set_single_value(""Manufacturing Settings"", ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_single_value(
		frappe.db.set_single_value(
		frappe.db.set_single_value(
		frappe.db.set_single_value(
	frappe.db.set_single_value(
		""Buying Settings"", ""backflush_raw_materials_of_subcontract_based_on"", ""BOM""
	frappe.db.set_single_value(""Accounts Settings"", ""over_delivery_receipt_allowance"", qty_allowance)
	frappe.db.set_single_value(
		""Accounts Settings"", ""automatically_process_deferred_accounting_entry"", 1
	frappe.db.set_single_value(""Homepage"", ""hero_section_based_on"", ""Default"")
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", None)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", acc_frozen_upto)
			frappe.db.set_single_value(doctype, ""enable_discount_accounting"", 1, update_modified=False)
		frappe.db.set_single_value(
		frappe.db.set_single_value(""Selling Settings"", ""cust_master_name"", ""Naming Series"")
		frappe.db.set_single_value(""Selling Settings"", ""cust_master_name"", ""Customer Name"")
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", cls.unlink_setting
		frappe.db.set_single_value(""Stock Settings"", ""default_warehouse"", ""_Test Warehouse - _TC"")
		frappe.db.set_single_value(""Stock Settings"", ""default_warehouse"", old_stock_settings_value)
		frappe.db.set_single_value(""Stock Settings"", ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""auto_insert_price_list_rate_if_missing"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
	frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""stale_days"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""stale_days"", 1)
	frappe.db.set_single_value(""System Settings"", ""app_name"", ""ERPNext"")
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(
			""Stock Settings"", ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""mr_qty_allowance"", 20)
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
	frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_single_value(""Stock Settings"", ""action_if_quality_inspection_is_rejected"", ""Warn"")
		frappe.db.set_single_value(""Stock Settings"", ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""auto_indent"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""auto_indent"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""stock_auth_role"", """")
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto"", add_days(nowdate(), 5))
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto"", """")
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto_days"", -1)
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto_days"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(
			""Stock Settings"", ""role_allowed_to_create_edit_back_dated_transactions"", ""Stock Manager""
			frappe.db.set_single_value(
				""Stock Settings"", ""role_allowed_to_create_edit_back_dated_transactions"", None
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""clean_description_html"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(
			""Stock Settings"", ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Exotel Settings"", ""enabled"", 1)",bug-free
"		frappe.db.set_value(""Global Defaults"", None, ""current_fiscal_year"", self.name)
			frappe.db.set_value(
				""Accounts Settings"", ""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
			frappe.db.set_value(""Selling Settings"", None, ""validate_selling_price"", 0)
			frappe.db.set_value(""Selling Settings"", ""Selling Settings"", ""validate_selling_price"", 1)
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1
		)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_value(""Accounts Settings"", None, ""post_change_gl_entries"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""post_change_gl_entries"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", old_negative_stock)
		frappe.db.set_value(""Accounts Settings"", None, ""enable_common_party_accounting"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""enable_common_party_accounting"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", add_days(getdate(), 1))
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", None)
		frappe.db.set_value(""Accounts Settings"", None, ""over_billing_allowance"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""over_billing_allowance"", over_billing_allowance)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", getdate(""2019-01-31""))
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", None)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1
		)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_value(""Shopping Cart Settings"", None, ""enabled"", 0)
	frappe.db.set_value(""Accounts Settings"", None, ""book_asset_depreciation_entry_automatically"", 1)
	frappe.db.set_value(""Accounts Settings"", None, ""book_asset_depreciation_entry_automatically"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""over_billing_allowance"", 0)
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(""Selling Settings"", None, ""maintain_same_sales_rate"", 1)
		frappe.db.set_value(""Buying Settings"", None, ""maintain_same_rate"", 1)
		frappe.db.set_value(""Buying Settings"", None, ""supp_master_name"", ""Naming Series"")
		frappe.db.set_value(""Buying Settings"", None, ""supp_master_name"", ""Supplier Name"")
	frappe.db.set_value(
		""Buying Settings"", None, ""backflush_raw_materials_of_subcontract_based_on"", based_on
		frappe.db.set_value(
			""CRM Settings"", ""CRM Settings"", ""carry_forward_communication_and_comments"", 1
		)
		frappe.db.set_value(""E Commerce Settings"", None, ""save_quotations_as_draft"", 0)
		frappe.db.set_value(""Plaid Settings"", None, ""enabled"", 0)
		frappe.db.set_value(
			""Manufacturing Settings"",
			None,
			{""disable_capacity_planning"": 0, ""capacity_planning_for_days"": 1},
			frappe.db.set_value(""Manufacturing Settings"", None, {""capacity_planning_for_days"": 30})
		frappe.db.set_value(""Manufacturing Settings"", None, ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_value(""Manufacturing Settings"", None, ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_value(""Manufacturing Settings"", None, ""make_serial_no_batch_from_work_order"", 1)
		frappe.db.set_value(""Manufacturing Settings"", None, ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_value(""Manufacturing Settings"", None, ""material_consumption"", 1)
		frappe.db.set_value(""Manufacturing Settings"", None, ""material_consumption"", 0)
		frappe.db.set_value(""Manufacturing Settings"", None, ""material_consumption"", 0)
		frappe.db.set_value(
			None,
		frappe.db.set_value(""Manufacturing Settings"", None, ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_value(
			None,
		frappe.db.set_value(""Manufacturing Settings"", None, ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_value(
			None,
		frappe.db.set_value(
			None,
		frappe.db.set_value(
			None,
		frappe.db.set_value(
			None,
	frappe.db.set_value(
		""Buying Settings"", None, ""backflush_raw_materials_of_subcontract_based_on"", ""BOM""
	frappe.db.set_value(""Accounts Settings"", None, ""over_delivery_receipt_allowance"", qty_allowance)
	frappe.db.set_value(
		""Accounts Settings"", None, ""automatically_process_deferred_accounting_entry"", 1
	frappe.db.set_value(""Homepage"", ""Homepage"", ""hero_section_based_on"", ""Default"")
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", None)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", acc_frozen_upto)
			frappe.db.set_value(doctype, doctype, ""enable_discount_accounting"", 1, update_modified=False)
		frappe.db.set_value(
			""CRM Settings"",
		frappe.db.set_value(""Selling Settings"", None, ""cust_master_name"", ""Naming Series"")
		frappe.db.set_value(""Selling Settings"", None, ""cust_master_name"", ""Customer Name"")
		frappe.db.set_value(
			""Accounts Settings"",
			""Accounts Settings"",
			""unlink_advance_payment_on_cancelation_of_order"",
			cls.unlink_setting,
		frappe.db.set_value(""Stock Settings"", None, ""default_warehouse"", ""_Test Warehouse - _TC"")
		frappe.db.set_value(""Stock Settings"", None, ""default_warehouse"", old_stock_settings_value)
		frappe.db.set_value(""Stock Settings"", None, ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""auto_insert_price_list_rate_if_missing"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
	frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""stale_days"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""stale_days"", 1)
	frappe.db.set_value(""System Settings"", None, ""app_name"", ""ERPNext"")
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(
			""Stock Settings"", None, ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""mr_qty_allowance"", 20)
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
	frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_value(""Stock Settings"", None, ""action_if_quality_inspection_is_rejected"", ""Warn"")
		frappe.db.set_value(""Stock Settings"", None, ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""auto_indent"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""auto_indent"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""stock_auth_role"", """")
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto"", add_days(nowdate(), 5))
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto"", """")
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto_days"", -1)
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto_days"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(
			""Stock Settings"", None, ""role_allowed_to_create_edit_back_dated_transactions"", ""Stock Manager""
			frappe.db.set_value(
				""Stock Settings"", None, ""role_allowed_to_create_edit_back_dated_transactions"", None
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""clean_description_html"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(
			""Stock Settings"", None, ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Exotel Settings"", ""Exotel Settings"", ""enabled"", 1)",buggy
"		frappe.db.set_single_value(""Global Defaults"", ""current_fiscal_year"", self.name)
			frappe.db.set_single_value(
				""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
			frappe.db.set_single_value(""Selling Settings"", ""validate_selling_price"", 0)
			frappe.db.set_single_value(""Selling Settings"", ""validate_selling_price"", 1)
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1)
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_single_value(""Accounts Settings"", ""post_change_gl_entries"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""post_change_gl_entries"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", old_negative_stock)
		frappe.db.set_single_value(""Accounts Settings"", ""enable_common_party_accounting"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""enable_common_party_accounting"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", add_days(getdate(), 1))
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", None)
		frappe.db.set_single_value(""Accounts Settings"", ""over_billing_allowance"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""over_billing_allowance"", over_billing_allowance)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", getdate(""2019-01-31""))
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", None)
		frappe.db.set_single_value(""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1)
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_single_value(""Shopping Cart Settings"", ""enabled"", 0)
	frappe.db.set_single_value(""Accounts Settings"", ""book_asset_depreciation_entry_automatically"", 1)
	frappe.db.set_single_value(""Accounts Settings"", ""book_asset_depreciation_entry_automatically"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""over_billing_allowance"", 0)
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Selling Settings"", ""maintain_same_sales_rate"", 1)
		frappe.db.set_single_value(""Buying Settings"", ""maintain_same_rate"", 1)
		frappe.db.set_single_value(""Buying Settings"", ""supp_master_name"", ""Naming Series"")
		frappe.db.set_single_value(""Buying Settings"", ""supp_master_name"", ""Supplier Name"")
	frappe.db.set_single_value(
		""Buying Settings"", ""backflush_raw_materials_of_subcontract_based_on"", based_on
		frappe.db.set_single_value(""CRM Settings"", ""carry_forward_communication_and_comments"", 1)
		frappe.db.set_single_value(""E Commerce Settings"", ""save_quotations_as_draft"", 0)
		frappe.db.set_single_value(""Plaid Settings"", ""enabled"", 0)
		frappe.db.set_single_value(
			""Manufacturing Settings"", {""disable_capacity_planning"": 0, ""capacity_planning_for_days"": 1}
			frappe.db.set_single_value(""Manufacturing Settings"", {""capacity_planning_for_days"": 30})
		frappe.db.set_single_value(""Manufacturing Settings"", ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_single_value(""Manufacturing Settings"", ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_single_value(""Manufacturing Settings"", ""make_serial_no_batch_from_work_order"", 1)
		frappe.db.set_single_value(""Manufacturing Settings"", ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_single_value(""Manufacturing Settings"", ""material_consumption"", 1)
		frappe.db.set_single_value(""Manufacturing Settings"", ""material_consumption"", 0)
		frappe.db.set_single_value(""Manufacturing Settings"", ""material_consumption"", 0)
		frappe.db.set_single_value(
		frappe.db.set_single_value(""Manufacturing Settings"", ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_single_value(
		frappe.db.set_single_value(""Manufacturing Settings"", ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_single_value(
		frappe.db.set_single_value(
		frappe.db.set_single_value(
		frappe.db.set_single_value(
	frappe.db.set_single_value(
		""Buying Settings"", ""backflush_raw_materials_of_subcontract_based_on"", ""BOM""
	frappe.db.set_single_value(""Accounts Settings"", ""over_delivery_receipt_allowance"", qty_allowance)
	frappe.db.set_single_value(
		""Accounts Settings"", ""automatically_process_deferred_accounting_entry"", 1
	frappe.db.set_single_value(""Homepage"", ""hero_section_based_on"", ""Default"")
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", None)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", acc_frozen_upto)
			frappe.db.set_single_value(doctype, ""enable_discount_accounting"", 1, update_modified=False)
		frappe.db.set_single_value(
		frappe.db.set_single_value(""Selling Settings"", ""cust_master_name"", ""Naming Series"")
		frappe.db.set_single_value(""Selling Settings"", ""cust_master_name"", ""Customer Name"")
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", cls.unlink_setting
		frappe.db.set_single_value(""Stock Settings"", ""default_warehouse"", ""_Test Warehouse - _TC"")
		frappe.db.set_single_value(""Stock Settings"", ""default_warehouse"", old_stock_settings_value)
		frappe.db.set_single_value(""Stock Settings"", ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""auto_insert_price_list_rate_if_missing"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
	frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""stale_days"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""stale_days"", 1)
	frappe.db.set_single_value(""System Settings"", ""app_name"", ""ERPNext"")
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(
			""Stock Settings"", ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""mr_qty_allowance"", 20)
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
	frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_single_value(""Stock Settings"", ""action_if_quality_inspection_is_rejected"", ""Warn"")
		frappe.db.set_single_value(""Stock Settings"", ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""auto_indent"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""auto_indent"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""stock_auth_role"", """")
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto"", add_days(nowdate(), 5))
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto"", """")
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto_days"", -1)
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto_days"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(
			""Stock Settings"", ""role_allowed_to_create_edit_back_dated_transactions"", ""Stock Manager""
			frappe.db.set_single_value(
				""Stock Settings"", ""role_allowed_to_create_edit_back_dated_transactions"", None
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""clean_description_html"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(
			""Stock Settings"", ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Exotel Settings"", ""enabled"", 1)",bug-free
"		frappe.db.set_value(""Global Defaults"", None, ""current_fiscal_year"", self.name)
			frappe.db.set_value(
				""Accounts Settings"", ""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
			frappe.db.set_value(""Selling Settings"", None, ""validate_selling_price"", 0)
			frappe.db.set_value(""Selling Settings"", ""Selling Settings"", ""validate_selling_price"", 1)
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1
		)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_value(""Accounts Settings"", None, ""post_change_gl_entries"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""post_change_gl_entries"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", old_negative_stock)
		frappe.db.set_value(""Accounts Settings"", None, ""enable_common_party_accounting"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""enable_common_party_accounting"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", add_days(getdate(), 1))
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", None)
		frappe.db.set_value(""Accounts Settings"", None, ""over_billing_allowance"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""over_billing_allowance"", over_billing_allowance)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", getdate(""2019-01-31""))
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", None)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1
		)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_value(""Shopping Cart Settings"", None, ""enabled"", 0)
	frappe.db.set_value(""Accounts Settings"", None, ""book_asset_depreciation_entry_automatically"", 1)
	frappe.db.set_value(""Accounts Settings"", None, ""book_asset_depreciation_entry_automatically"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""over_billing_allowance"", 0)
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(""Selling Settings"", None, ""maintain_same_sales_rate"", 1)
		frappe.db.set_value(""Buying Settings"", None, ""maintain_same_rate"", 1)
		frappe.db.set_value(""Buying Settings"", None, ""supp_master_name"", ""Naming Series"")
		frappe.db.set_value(""Buying Settings"", None, ""supp_master_name"", ""Supplier Name"")
	frappe.db.set_value(
		""Buying Settings"", None, ""backflush_raw_materials_of_subcontract_based_on"", based_on
		frappe.db.set_value(
			""CRM Settings"", ""CRM Settings"", ""carry_forward_communication_and_comments"", 1
		)
		frappe.db.set_value(""E Commerce Settings"", None, ""save_quotations_as_draft"", 0)
		frappe.db.set_value(""Plaid Settings"", None, ""enabled"", 0)
		frappe.db.set_value(
			""Manufacturing Settings"",
			None,
			{""disable_capacity_planning"": 0, ""capacity_planning_for_days"": 1},
			frappe.db.set_value(""Manufacturing Settings"", None, {""capacity_planning_for_days"": 30})
		frappe.db.set_value(""Manufacturing Settings"", None, ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_value(""Manufacturing Settings"", None, ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_value(""Manufacturing Settings"", None, ""make_serial_no_batch_from_work_order"", 1)
		frappe.db.set_value(""Manufacturing Settings"", None, ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_value(""Manufacturing Settings"", None, ""material_consumption"", 1)
		frappe.db.set_value(""Manufacturing Settings"", None, ""material_consumption"", 0)
		frappe.db.set_value(""Manufacturing Settings"", None, ""material_consumption"", 0)
		frappe.db.set_value(
			None,
		frappe.db.set_value(""Manufacturing Settings"", None, ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_value(
			None,
		frappe.db.set_value(""Manufacturing Settings"", None, ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_value(
			None,
		frappe.db.set_value(
			None,
		frappe.db.set_value(
			None,
		frappe.db.set_value(
			None,
	frappe.db.set_value(
		""Buying Settings"", None, ""backflush_raw_materials_of_subcontract_based_on"", ""BOM""
	frappe.db.set_value(""Accounts Settings"", None, ""over_delivery_receipt_allowance"", qty_allowance)
	frappe.db.set_value(
		""Accounts Settings"", None, ""automatically_process_deferred_accounting_entry"", 1
	frappe.db.set_value(""Homepage"", ""Homepage"", ""hero_section_based_on"", ""Default"")
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", None)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", acc_frozen_upto)
			frappe.db.set_value(doctype, doctype, ""enable_discount_accounting"", 1, update_modified=False)
		frappe.db.set_value(
			""CRM Settings"",
		frappe.db.set_value(""Selling Settings"", None, ""cust_master_name"", ""Naming Series"")
		frappe.db.set_value(""Selling Settings"", None, ""cust_master_name"", ""Customer Name"")
		frappe.db.set_value(
			""Accounts Settings"",
			""Accounts Settings"",
			""unlink_advance_payment_on_cancelation_of_order"",
			cls.unlink_setting,
		frappe.db.set_value(""Stock Settings"", None, ""default_warehouse"", ""_Test Warehouse - _TC"")
		frappe.db.set_value(""Stock Settings"", None, ""default_warehouse"", old_stock_settings_value)
		frappe.db.set_value(""Stock Settings"", None, ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""auto_insert_price_list_rate_if_missing"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
	frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""stale_days"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""stale_days"", 1)
	frappe.db.set_value(""System Settings"", None, ""app_name"", ""ERPNext"")
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(
			""Stock Settings"", None, ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""mr_qty_allowance"", 20)
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
	frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_value(""Stock Settings"", None, ""action_if_quality_inspection_is_rejected"", ""Warn"")
		frappe.db.set_value(""Stock Settings"", None, ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""auto_indent"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""auto_indent"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""stock_auth_role"", """")
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto"", add_days(nowdate(), 5))
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto"", """")
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto_days"", -1)
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto_days"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(
			""Stock Settings"", None, ""role_allowed_to_create_edit_back_dated_transactions"", ""Stock Manager""
			frappe.db.set_value(
				""Stock Settings"", None, ""role_allowed_to_create_edit_back_dated_transactions"", None
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""clean_description_html"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(
			""Stock Settings"", None, ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Exotel Settings"", ""Exotel Settings"", ""enabled"", 1)",buggy
"		frappe.db.set_single_value(""Global Defaults"", ""current_fiscal_year"", self.name)
			frappe.db.set_single_value(
				""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
			frappe.db.set_single_value(""Selling Settings"", ""validate_selling_price"", 0)
			frappe.db.set_single_value(""Selling Settings"", ""validate_selling_price"", 1)
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1)
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_single_value(""Accounts Settings"", ""post_change_gl_entries"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""post_change_gl_entries"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", old_negative_stock)
		frappe.db.set_single_value(""Accounts Settings"", ""enable_common_party_accounting"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""enable_common_party_accounting"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", add_days(getdate(), 1))
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", None)
		frappe.db.set_single_value(""Accounts Settings"", ""over_billing_allowance"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""over_billing_allowance"", over_billing_allowance)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", getdate(""2019-01-31""))
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", None)
		frappe.db.set_single_value(""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1)
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_single_value(""Shopping Cart Settings"", ""enabled"", 0)
	frappe.db.set_single_value(""Accounts Settings"", ""book_asset_depreciation_entry_automatically"", 1)
	frappe.db.set_single_value(""Accounts Settings"", ""book_asset_depreciation_entry_automatically"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""over_billing_allowance"", 0)
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Selling Settings"", ""maintain_same_sales_rate"", 1)
		frappe.db.set_single_value(""Buying Settings"", ""maintain_same_rate"", 1)
		frappe.db.set_single_value(""Buying Settings"", ""supp_master_name"", ""Naming Series"")
		frappe.db.set_single_value(""Buying Settings"", ""supp_master_name"", ""Supplier Name"")
	frappe.db.set_single_value(
		""Buying Settings"", ""backflush_raw_materials_of_subcontract_based_on"", based_on
		frappe.db.set_single_value(""CRM Settings"", ""carry_forward_communication_and_comments"", 1)
		frappe.db.set_single_value(""E Commerce Settings"", ""save_quotations_as_draft"", 0)
		frappe.db.set_single_value(""Plaid Settings"", ""enabled"", 0)
		frappe.db.set_single_value(
			""Manufacturing Settings"", {""disable_capacity_planning"": 0, ""capacity_planning_for_days"": 1}
			frappe.db.set_single_value(""Manufacturing Settings"", {""capacity_planning_for_days"": 30})
		frappe.db.set_single_value(""Manufacturing Settings"", ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_single_value(""Manufacturing Settings"", ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_single_value(""Manufacturing Settings"", ""make_serial_no_batch_from_work_order"", 1)
		frappe.db.set_single_value(""Manufacturing Settings"", ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_single_value(""Manufacturing Settings"", ""material_consumption"", 1)
		frappe.db.set_single_value(""Manufacturing Settings"", ""material_consumption"", 0)
		frappe.db.set_single_value(""Manufacturing Settings"", ""material_consumption"", 0)
		frappe.db.set_single_value(
		frappe.db.set_single_value(""Manufacturing Settings"", ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_single_value(
		frappe.db.set_single_value(""Manufacturing Settings"", ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_single_value(
		frappe.db.set_single_value(
		frappe.db.set_single_value(
		frappe.db.set_single_value(
	frappe.db.set_single_value(
		""Buying Settings"", ""backflush_raw_materials_of_subcontract_based_on"", ""BOM""
	frappe.db.set_single_value(""Accounts Settings"", ""over_delivery_receipt_allowance"", qty_allowance)
	frappe.db.set_single_value(
		""Accounts Settings"", ""automatically_process_deferred_accounting_entry"", 1
	frappe.db.set_single_value(""Homepage"", ""hero_section_based_on"", ""Default"")
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", None)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", acc_frozen_upto)
			frappe.db.set_single_value(doctype, ""enable_discount_accounting"", 1, update_modified=False)
		frappe.db.set_single_value(
		frappe.db.set_single_value(""Selling Settings"", ""cust_master_name"", ""Naming Series"")
		frappe.db.set_single_value(""Selling Settings"", ""cust_master_name"", ""Customer Name"")
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", cls.unlink_setting
		frappe.db.set_single_value(""Stock Settings"", ""default_warehouse"", ""_Test Warehouse - _TC"")
		frappe.db.set_single_value(""Stock Settings"", ""default_warehouse"", old_stock_settings_value)
		frappe.db.set_single_value(""Stock Settings"", ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""auto_insert_price_list_rate_if_missing"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
	frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""stale_days"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""stale_days"", 1)
	frappe.db.set_single_value(""System Settings"", ""app_name"", ""ERPNext"")
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(
			""Stock Settings"", ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""mr_qty_allowance"", 20)
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
	frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_single_value(""Stock Settings"", ""action_if_quality_inspection_is_rejected"", ""Warn"")
		frappe.db.set_single_value(""Stock Settings"", ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""auto_indent"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""auto_indent"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""stock_auth_role"", """")
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto"", add_days(nowdate(), 5))
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto"", """")
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto_days"", -1)
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto_days"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(
			""Stock Settings"", ""role_allowed_to_create_edit_back_dated_transactions"", ""Stock Manager""
			frappe.db.set_single_value(
				""Stock Settings"", ""role_allowed_to_create_edit_back_dated_transactions"", None
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""clean_description_html"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(
			""Stock Settings"", ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Exotel Settings"", ""enabled"", 1)",bug-free
"		frappe.db.set_value(""Global Defaults"", None, ""current_fiscal_year"", self.name)
			frappe.db.set_value(
				""Accounts Settings"", ""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
			frappe.db.set_value(""Selling Settings"", None, ""validate_selling_price"", 0)
			frappe.db.set_value(""Selling Settings"", ""Selling Settings"", ""validate_selling_price"", 1)
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1
		)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_value(""Accounts Settings"", None, ""post_change_gl_entries"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""post_change_gl_entries"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", old_negative_stock)
		frappe.db.set_value(""Accounts Settings"", None, ""enable_common_party_accounting"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""enable_common_party_accounting"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", add_days(getdate(), 1))
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", None)
		frappe.db.set_value(""Accounts Settings"", None, ""over_billing_allowance"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""over_billing_allowance"", over_billing_allowance)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", getdate(""2019-01-31""))
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", None)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1
		)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_value(""Shopping Cart Settings"", None, ""enabled"", 0)
	frappe.db.set_value(""Accounts Settings"", None, ""book_asset_depreciation_entry_automatically"", 1)
	frappe.db.set_value(""Accounts Settings"", None, ""book_asset_depreciation_entry_automatically"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""over_billing_allowance"", 0)
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(""Selling Settings"", None, ""maintain_same_sales_rate"", 1)
		frappe.db.set_value(""Buying Settings"", None, ""maintain_same_rate"", 1)
		frappe.db.set_value(""Buying Settings"", None, ""supp_master_name"", ""Naming Series"")
		frappe.db.set_value(""Buying Settings"", None, ""supp_master_name"", ""Supplier Name"")
	frappe.db.set_value(
		""Buying Settings"", None, ""backflush_raw_materials_of_subcontract_based_on"", based_on
		frappe.db.set_value(
			""CRM Settings"", ""CRM Settings"", ""carry_forward_communication_and_comments"", 1
		)
		frappe.db.set_value(""E Commerce Settings"", None, ""save_quotations_as_draft"", 0)
		frappe.db.set_value(""Plaid Settings"", None, ""enabled"", 0)
		frappe.db.set_value(
			""Manufacturing Settings"",
			None,
			{""disable_capacity_planning"": 0, ""capacity_planning_for_days"": 1},
			frappe.db.set_value(""Manufacturing Settings"", None, {""capacity_planning_for_days"": 30})
		frappe.db.set_value(""Manufacturing Settings"", None, ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_value(""Manufacturing Settings"", None, ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_value(""Manufacturing Settings"", None, ""make_serial_no_batch_from_work_order"", 1)
		frappe.db.set_value(""Manufacturing Settings"", None, ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_value(""Manufacturing Settings"", None, ""material_consumption"", 1)
		frappe.db.set_value(""Manufacturing Settings"", None, ""material_consumption"", 0)
		frappe.db.set_value(""Manufacturing Settings"", None, ""material_consumption"", 0)
		frappe.db.set_value(
			None,
		frappe.db.set_value(""Manufacturing Settings"", None, ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_value(
			None,
		frappe.db.set_value(""Manufacturing Settings"", None, ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_value(
			None,
		frappe.db.set_value(
			None,
		frappe.db.set_value(
			None,
		frappe.db.set_value(
			None,
	frappe.db.set_value(
		""Buying Settings"", None, ""backflush_raw_materials_of_subcontract_based_on"", ""BOM""
	frappe.db.set_value(""Accounts Settings"", None, ""over_delivery_receipt_allowance"", qty_allowance)
	frappe.db.set_value(
		""Accounts Settings"", None, ""automatically_process_deferred_accounting_entry"", 1
	frappe.db.set_value(""Homepage"", ""Homepage"", ""hero_section_based_on"", ""Default"")
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", None)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", acc_frozen_upto)
			frappe.db.set_value(doctype, doctype, ""enable_discount_accounting"", 1, update_modified=False)
		frappe.db.set_value(
			""CRM Settings"",
		frappe.db.set_value(""Selling Settings"", None, ""cust_master_name"", ""Naming Series"")
		frappe.db.set_value(""Selling Settings"", None, ""cust_master_name"", ""Customer Name"")
		frappe.db.set_value(
			""Accounts Settings"",
			""Accounts Settings"",
			""unlink_advance_payment_on_cancelation_of_order"",
			cls.unlink_setting,
		frappe.db.set_value(""Stock Settings"", None, ""default_warehouse"", ""_Test Warehouse - _TC"")
		frappe.db.set_value(""Stock Settings"", None, ""default_warehouse"", old_stock_settings_value)
		frappe.db.set_value(""Stock Settings"", None, ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""auto_insert_price_list_rate_if_missing"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
	frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""stale_days"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""stale_days"", 1)
	frappe.db.set_value(""System Settings"", None, ""app_name"", ""ERPNext"")
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(
			""Stock Settings"", None, ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""mr_qty_allowance"", 20)
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
	frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_value(""Stock Settings"", None, ""action_if_quality_inspection_is_rejected"", ""Warn"")
		frappe.db.set_value(""Stock Settings"", None, ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""auto_indent"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""auto_indent"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""stock_auth_role"", """")
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto"", add_days(nowdate(), 5))
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto"", """")
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto_days"", -1)
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto_days"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(
			""Stock Settings"", None, ""role_allowed_to_create_edit_back_dated_transactions"", ""Stock Manager""
			frappe.db.set_value(
				""Stock Settings"", None, ""role_allowed_to_create_edit_back_dated_transactions"", None
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""clean_description_html"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(
			""Stock Settings"", None, ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Exotel Settings"", ""Exotel Settings"", ""enabled"", 1)",buggy
"		frappe.db.set_single_value(""Global Defaults"", ""current_fiscal_year"", self.name)
			frappe.db.set_single_value(
				""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
			frappe.db.set_single_value(""Selling Settings"", ""validate_selling_price"", 0)
			frappe.db.set_single_value(""Selling Settings"", ""validate_selling_price"", 1)
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1)
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_single_value(""Accounts Settings"", ""post_change_gl_entries"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""post_change_gl_entries"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", old_negative_stock)
		frappe.db.set_single_value(""Accounts Settings"", ""enable_common_party_accounting"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""enable_common_party_accounting"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", add_days(getdate(), 1))
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", None)
		frappe.db.set_single_value(""Accounts Settings"", ""over_billing_allowance"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""over_billing_allowance"", over_billing_allowance)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", getdate(""2019-01-31""))
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", None)
		frappe.db.set_single_value(""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1)
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_single_value(""Shopping Cart Settings"", ""enabled"", 0)
	frappe.db.set_single_value(""Accounts Settings"", ""book_asset_depreciation_entry_automatically"", 1)
	frappe.db.set_single_value(""Accounts Settings"", ""book_asset_depreciation_entry_automatically"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""over_billing_allowance"", 0)
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Selling Settings"", ""maintain_same_sales_rate"", 1)
		frappe.db.set_single_value(""Buying Settings"", ""maintain_same_rate"", 1)
		frappe.db.set_single_value(""Buying Settings"", ""supp_master_name"", ""Naming Series"")
		frappe.db.set_single_value(""Buying Settings"", ""supp_master_name"", ""Supplier Name"")
	frappe.db.set_single_value(
		""Buying Settings"", ""backflush_raw_materials_of_subcontract_based_on"", based_on
		frappe.db.set_single_value(""CRM Settings"", ""carry_forward_communication_and_comments"", 1)
		frappe.db.set_single_value(""E Commerce Settings"", ""save_quotations_as_draft"", 0)
		frappe.db.set_single_value(""Plaid Settings"", ""enabled"", 0)
		frappe.db.set_single_value(
			""Manufacturing Settings"", {""disable_capacity_planning"": 0, ""capacity_planning_for_days"": 1}
			frappe.db.set_single_value(""Manufacturing Settings"", {""capacity_planning_for_days"": 30})
		frappe.db.set_single_value(""Manufacturing Settings"", ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_single_value(""Manufacturing Settings"", ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_single_value(""Manufacturing Settings"", ""make_serial_no_batch_from_work_order"", 1)
		frappe.db.set_single_value(""Manufacturing Settings"", ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_single_value(""Manufacturing Settings"", ""material_consumption"", 1)
		frappe.db.set_single_value(""Manufacturing Settings"", ""material_consumption"", 0)
		frappe.db.set_single_value(""Manufacturing Settings"", ""material_consumption"", 0)
		frappe.db.set_single_value(
		frappe.db.set_single_value(""Manufacturing Settings"", ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_single_value(
		frappe.db.set_single_value(""Manufacturing Settings"", ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_single_value(
		frappe.db.set_single_value(
		frappe.db.set_single_value(
		frappe.db.set_single_value(
	frappe.db.set_single_value(
		""Buying Settings"", ""backflush_raw_materials_of_subcontract_based_on"", ""BOM""
	frappe.db.set_single_value(""Accounts Settings"", ""over_delivery_receipt_allowance"", qty_allowance)
	frappe.db.set_single_value(
		""Accounts Settings"", ""automatically_process_deferred_accounting_entry"", 1
	frappe.db.set_single_value(""Homepage"", ""hero_section_based_on"", ""Default"")
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", None)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", acc_frozen_upto)
			frappe.db.set_single_value(doctype, ""enable_discount_accounting"", 1, update_modified=False)
		frappe.db.set_single_value(
		frappe.db.set_single_value(""Selling Settings"", ""cust_master_name"", ""Naming Series"")
		frappe.db.set_single_value(""Selling Settings"", ""cust_master_name"", ""Customer Name"")
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", cls.unlink_setting
		frappe.db.set_single_value(""Stock Settings"", ""default_warehouse"", ""_Test Warehouse - _TC"")
		frappe.db.set_single_value(""Stock Settings"", ""default_warehouse"", old_stock_settings_value)
		frappe.db.set_single_value(""Stock Settings"", ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""auto_insert_price_list_rate_if_missing"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
	frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""stale_days"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""stale_days"", 1)
	frappe.db.set_single_value(""System Settings"", ""app_name"", ""ERPNext"")
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(
			""Stock Settings"", ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""mr_qty_allowance"", 20)
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
	frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_single_value(""Stock Settings"", ""action_if_quality_inspection_is_rejected"", ""Warn"")
		frappe.db.set_single_value(""Stock Settings"", ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""auto_indent"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""auto_indent"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""stock_auth_role"", """")
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto"", add_days(nowdate(), 5))
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto"", """")
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto_days"", -1)
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto_days"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(
			""Stock Settings"", ""role_allowed_to_create_edit_back_dated_transactions"", ""Stock Manager""
			frappe.db.set_single_value(
				""Stock Settings"", ""role_allowed_to_create_edit_back_dated_transactions"", None
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""clean_description_html"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(
			""Stock Settings"", ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Exotel Settings"", ""enabled"", 1)",bug-free
"		frappe.db.set_value(""Global Defaults"", None, ""current_fiscal_year"", self.name)
			frappe.db.set_value(
				""Accounts Settings"", ""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
			frappe.db.set_value(""Selling Settings"", None, ""validate_selling_price"", 0)
			frappe.db.set_value(""Selling Settings"", ""Selling Settings"", ""validate_selling_price"", 1)
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1
		)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_value(""Accounts Settings"", None, ""post_change_gl_entries"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""post_change_gl_entries"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", old_negative_stock)
		frappe.db.set_value(""Accounts Settings"", None, ""enable_common_party_accounting"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""enable_common_party_accounting"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", add_days(getdate(), 1))
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", None)
		frappe.db.set_value(""Accounts Settings"", None, ""over_billing_allowance"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""over_billing_allowance"", over_billing_allowance)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", getdate(""2019-01-31""))
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", None)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1
		)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_value(""Shopping Cart Settings"", None, ""enabled"", 0)
	frappe.db.set_value(""Accounts Settings"", None, ""book_asset_depreciation_entry_automatically"", 1)
	frappe.db.set_value(""Accounts Settings"", None, ""book_asset_depreciation_entry_automatically"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""over_billing_allowance"", 0)
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(""Selling Settings"", None, ""maintain_same_sales_rate"", 1)
		frappe.db.set_value(""Buying Settings"", None, ""maintain_same_rate"", 1)
		frappe.db.set_value(""Buying Settings"", None, ""supp_master_name"", ""Naming Series"")
		frappe.db.set_value(""Buying Settings"", None, ""supp_master_name"", ""Supplier Name"")
	frappe.db.set_value(
		""Buying Settings"", None, ""backflush_raw_materials_of_subcontract_based_on"", based_on
		frappe.db.set_value(
			""CRM Settings"", ""CRM Settings"", ""carry_forward_communication_and_comments"", 1
		)
		frappe.db.set_value(""E Commerce Settings"", None, ""save_quotations_as_draft"", 0)
		frappe.db.set_value(""Plaid Settings"", None, ""enabled"", 0)
		frappe.db.set_value(
			""Manufacturing Settings"",
			None,
			{""disable_capacity_planning"": 0, ""capacity_planning_for_days"": 1},
			frappe.db.set_value(""Manufacturing Settings"", None, {""capacity_planning_for_days"": 30})
		frappe.db.set_value(""Manufacturing Settings"", None, ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_value(""Manufacturing Settings"", None, ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_value(""Manufacturing Settings"", None, ""make_serial_no_batch_from_work_order"", 1)
		frappe.db.set_value(""Manufacturing Settings"", None, ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_value(""Manufacturing Settings"", None, ""material_consumption"", 1)
		frappe.db.set_value(""Manufacturing Settings"", None, ""material_consumption"", 0)
		frappe.db.set_value(""Manufacturing Settings"", None, ""material_consumption"", 0)
		frappe.db.set_value(
			None,
		frappe.db.set_value(""Manufacturing Settings"", None, ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_value(
			None,
		frappe.db.set_value(""Manufacturing Settings"", None, ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_value(
			None,
		frappe.db.set_value(
			None,
		frappe.db.set_value(
			None,
		frappe.db.set_value(
			None,
	frappe.db.set_value(
		""Buying Settings"", None, ""backflush_raw_materials_of_subcontract_based_on"", ""BOM""
	frappe.db.set_value(""Accounts Settings"", None, ""over_delivery_receipt_allowance"", qty_allowance)
	frappe.db.set_value(
		""Accounts Settings"", None, ""automatically_process_deferred_accounting_entry"", 1
	frappe.db.set_value(""Homepage"", ""Homepage"", ""hero_section_based_on"", ""Default"")
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", None)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", acc_frozen_upto)
			frappe.db.set_value(doctype, doctype, ""enable_discount_accounting"", 1, update_modified=False)
		frappe.db.set_value(
			""CRM Settings"",
		frappe.db.set_value(""Selling Settings"", None, ""cust_master_name"", ""Naming Series"")
		frappe.db.set_value(""Selling Settings"", None, ""cust_master_name"", ""Customer Name"")
		frappe.db.set_value(
			""Accounts Settings"",
			""Accounts Settings"",
			""unlink_advance_payment_on_cancelation_of_order"",
			cls.unlink_setting,
		frappe.db.set_value(""Stock Settings"", None, ""default_warehouse"", ""_Test Warehouse - _TC"")
		frappe.db.set_value(""Stock Settings"", None, ""default_warehouse"", old_stock_settings_value)
		frappe.db.set_value(""Stock Settings"", None, ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""auto_insert_price_list_rate_if_missing"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
	frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""stale_days"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""stale_days"", 1)
	frappe.db.set_value(""System Settings"", None, ""app_name"", ""ERPNext"")
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(
			""Stock Settings"", None, ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""mr_qty_allowance"", 20)
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
	frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_value(""Stock Settings"", None, ""action_if_quality_inspection_is_rejected"", ""Warn"")
		frappe.db.set_value(""Stock Settings"", None, ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""auto_indent"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""auto_indent"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""stock_auth_role"", """")
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto"", add_days(nowdate(), 5))
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto"", """")
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto_days"", -1)
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto_days"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(
			""Stock Settings"", None, ""role_allowed_to_create_edit_back_dated_transactions"", ""Stock Manager""
			frappe.db.set_value(
				""Stock Settings"", None, ""role_allowed_to_create_edit_back_dated_transactions"", None
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""clean_description_html"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(
			""Stock Settings"", None, ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Exotel Settings"", ""Exotel Settings"", ""enabled"", 1)",buggy
"		frappe.db.set_single_value(""Global Defaults"", ""current_fiscal_year"", self.name)
			frappe.db.set_single_value(
				""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
			frappe.db.set_single_value(""Selling Settings"", ""validate_selling_price"", 0)
			frappe.db.set_single_value(""Selling Settings"", ""validate_selling_price"", 1)
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1)
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_single_value(""Accounts Settings"", ""post_change_gl_entries"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""post_change_gl_entries"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", old_negative_stock)
		frappe.db.set_single_value(""Accounts Settings"", ""enable_common_party_accounting"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""enable_common_party_accounting"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", add_days(getdate(), 1))
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", None)
		frappe.db.set_single_value(""Accounts Settings"", ""over_billing_allowance"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""over_billing_allowance"", over_billing_allowance)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", getdate(""2019-01-31""))
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", None)
		frappe.db.set_single_value(""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1)
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_single_value(""Shopping Cart Settings"", ""enabled"", 0)
	frappe.db.set_single_value(""Accounts Settings"", ""book_asset_depreciation_entry_automatically"", 1)
	frappe.db.set_single_value(""Accounts Settings"", ""book_asset_depreciation_entry_automatically"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""over_billing_allowance"", 0)
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Selling Settings"", ""maintain_same_sales_rate"", 1)
		frappe.db.set_single_value(""Buying Settings"", ""maintain_same_rate"", 1)
		frappe.db.set_single_value(""Buying Settings"", ""supp_master_name"", ""Naming Series"")
		frappe.db.set_single_value(""Buying Settings"", ""supp_master_name"", ""Supplier Name"")
	frappe.db.set_single_value(
		""Buying Settings"", ""backflush_raw_materials_of_subcontract_based_on"", based_on
		frappe.db.set_single_value(""CRM Settings"", ""carry_forward_communication_and_comments"", 1)
		frappe.db.set_single_value(""E Commerce Settings"", ""save_quotations_as_draft"", 0)
		frappe.db.set_single_value(""Plaid Settings"", ""enabled"", 0)
		frappe.db.set_single_value(
			""Manufacturing Settings"", {""disable_capacity_planning"": 0, ""capacity_planning_for_days"": 1}
			frappe.db.set_single_value(""Manufacturing Settings"", {""capacity_planning_for_days"": 30})
		frappe.db.set_single_value(""Manufacturing Settings"", ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_single_value(""Manufacturing Settings"", ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_single_value(""Manufacturing Settings"", ""make_serial_no_batch_from_work_order"", 1)
		frappe.db.set_single_value(""Manufacturing Settings"", ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_single_value(""Manufacturing Settings"", ""material_consumption"", 1)
		frappe.db.set_single_value(""Manufacturing Settings"", ""material_consumption"", 0)
		frappe.db.set_single_value(""Manufacturing Settings"", ""material_consumption"", 0)
		frappe.db.set_single_value(
		frappe.db.set_single_value(""Manufacturing Settings"", ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_single_value(
		frappe.db.set_single_value(""Manufacturing Settings"", ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_single_value(
		frappe.db.set_single_value(
		frappe.db.set_single_value(
		frappe.db.set_single_value(
	frappe.db.set_single_value(
		""Buying Settings"", ""backflush_raw_materials_of_subcontract_based_on"", ""BOM""
	frappe.db.set_single_value(""Accounts Settings"", ""over_delivery_receipt_allowance"", qty_allowance)
	frappe.db.set_single_value(
		""Accounts Settings"", ""automatically_process_deferred_accounting_entry"", 1
	frappe.db.set_single_value(""Homepage"", ""hero_section_based_on"", ""Default"")
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", None)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", acc_frozen_upto)
			frappe.db.set_single_value(doctype, ""enable_discount_accounting"", 1, update_modified=False)
		frappe.db.set_single_value(
		frappe.db.set_single_value(""Selling Settings"", ""cust_master_name"", ""Naming Series"")
		frappe.db.set_single_value(""Selling Settings"", ""cust_master_name"", ""Customer Name"")
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", cls.unlink_setting
		frappe.db.set_single_value(""Stock Settings"", ""default_warehouse"", ""_Test Warehouse - _TC"")
		frappe.db.set_single_value(""Stock Settings"", ""default_warehouse"", old_stock_settings_value)
		frappe.db.set_single_value(""Stock Settings"", ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""auto_insert_price_list_rate_if_missing"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
	frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""stale_days"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""stale_days"", 1)
	frappe.db.set_single_value(""System Settings"", ""app_name"", ""ERPNext"")
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(
			""Stock Settings"", ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""mr_qty_allowance"", 20)
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
	frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_single_value(""Stock Settings"", ""action_if_quality_inspection_is_rejected"", ""Warn"")
		frappe.db.set_single_value(""Stock Settings"", ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""auto_indent"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""auto_indent"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""stock_auth_role"", """")
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto"", add_days(nowdate(), 5))
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto"", """")
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto_days"", -1)
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto_days"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(
			""Stock Settings"", ""role_allowed_to_create_edit_back_dated_transactions"", ""Stock Manager""
			frappe.db.set_single_value(
				""Stock Settings"", ""role_allowed_to_create_edit_back_dated_transactions"", None
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""clean_description_html"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(
			""Stock Settings"", ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Exotel Settings"", ""enabled"", 1)",bug-free
"		frappe.db.set_value(""Global Defaults"", None, ""current_fiscal_year"", self.name)
			frappe.db.set_value(
				""Accounts Settings"", ""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
			frappe.db.set_value(""Selling Settings"", None, ""validate_selling_price"", 0)
			frappe.db.set_value(""Selling Settings"", ""Selling Settings"", ""validate_selling_price"", 1)
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1
		)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_value(""Accounts Settings"", None, ""post_change_gl_entries"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""post_change_gl_entries"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", old_negative_stock)
		frappe.db.set_value(""Accounts Settings"", None, ""enable_common_party_accounting"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""enable_common_party_accounting"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", add_days(getdate(), 1))
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", None)
		frappe.db.set_value(""Accounts Settings"", None, ""over_billing_allowance"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""over_billing_allowance"", over_billing_allowance)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", getdate(""2019-01-31""))
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", None)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1
		)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_value(""Shopping Cart Settings"", None, ""enabled"", 0)
	frappe.db.set_value(""Accounts Settings"", None, ""book_asset_depreciation_entry_automatically"", 1)
	frappe.db.set_value(""Accounts Settings"", None, ""book_asset_depreciation_entry_automatically"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""over_billing_allowance"", 0)
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(""Selling Settings"", None, ""maintain_same_sales_rate"", 1)
		frappe.db.set_value(""Buying Settings"", None, ""maintain_same_rate"", 1)
		frappe.db.set_value(""Buying Settings"", None, ""supp_master_name"", ""Naming Series"")
		frappe.db.set_value(""Buying Settings"", None, ""supp_master_name"", ""Supplier Name"")
	frappe.db.set_value(
		""Buying Settings"", None, ""backflush_raw_materials_of_subcontract_based_on"", based_on
		frappe.db.set_value(
			""CRM Settings"", ""CRM Settings"", ""carry_forward_communication_and_comments"", 1
		)
		frappe.db.set_value(""E Commerce Settings"", None, ""save_quotations_as_draft"", 0)
		frappe.db.set_value(""Plaid Settings"", None, ""enabled"", 0)
		frappe.db.set_value(
			""Manufacturing Settings"",
			None,
			{""disable_capacity_planning"": 0, ""capacity_planning_for_days"": 1},
			frappe.db.set_value(""Manufacturing Settings"", None, {""capacity_planning_for_days"": 30})
		frappe.db.set_value(""Manufacturing Settings"", None, ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_value(""Manufacturing Settings"", None, ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_value(""Manufacturing Settings"", None, ""make_serial_no_batch_from_work_order"", 1)
		frappe.db.set_value(""Manufacturing Settings"", None, ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_value(""Manufacturing Settings"", None, ""material_consumption"", 1)
		frappe.db.set_value(""Manufacturing Settings"", None, ""material_consumption"", 0)
		frappe.db.set_value(""Manufacturing Settings"", None, ""material_consumption"", 0)
		frappe.db.set_value(
			None,
		frappe.db.set_value(""Manufacturing Settings"", None, ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_value(
			None,
		frappe.db.set_value(""Manufacturing Settings"", None, ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_value(
			None,
		frappe.db.set_value(
			None,
		frappe.db.set_value(
			None,
		frappe.db.set_value(
			None,
	frappe.db.set_value(
		""Buying Settings"", None, ""backflush_raw_materials_of_subcontract_based_on"", ""BOM""
	frappe.db.set_value(""Accounts Settings"", None, ""over_delivery_receipt_allowance"", qty_allowance)
	frappe.db.set_value(
		""Accounts Settings"", None, ""automatically_process_deferred_accounting_entry"", 1
	frappe.db.set_value(""Homepage"", ""Homepage"", ""hero_section_based_on"", ""Default"")
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", None)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", acc_frozen_upto)
			frappe.db.set_value(doctype, doctype, ""enable_discount_accounting"", 1, update_modified=False)
		frappe.db.set_value(
			""CRM Settings"",
		frappe.db.set_value(""Selling Settings"", None, ""cust_master_name"", ""Naming Series"")
		frappe.db.set_value(""Selling Settings"", None, ""cust_master_name"", ""Customer Name"")
		frappe.db.set_value(
			""Accounts Settings"",
			""Accounts Settings"",
			""unlink_advance_payment_on_cancelation_of_order"",
			cls.unlink_setting,
		frappe.db.set_value(""Stock Settings"", None, ""default_warehouse"", ""_Test Warehouse - _TC"")
		frappe.db.set_value(""Stock Settings"", None, ""default_warehouse"", old_stock_settings_value)
		frappe.db.set_value(""Stock Settings"", None, ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""auto_insert_price_list_rate_if_missing"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
	frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""stale_days"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""stale_days"", 1)
	frappe.db.set_value(""System Settings"", None, ""app_name"", ""ERPNext"")
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(
			""Stock Settings"", None, ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""mr_qty_allowance"", 20)
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
	frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_value(""Stock Settings"", None, ""action_if_quality_inspection_is_rejected"", ""Warn"")
		frappe.db.set_value(""Stock Settings"", None, ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""auto_indent"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""auto_indent"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""stock_auth_role"", """")
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto"", add_days(nowdate(), 5))
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto"", """")
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto_days"", -1)
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto_days"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(
			""Stock Settings"", None, ""role_allowed_to_create_edit_back_dated_transactions"", ""Stock Manager""
			frappe.db.set_value(
				""Stock Settings"", None, ""role_allowed_to_create_edit_back_dated_transactions"", None
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""clean_description_html"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(
			""Stock Settings"", None, ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Exotel Settings"", ""Exotel Settings"", ""enabled"", 1)",buggy
"		frappe.db.set_single_value(""Global Defaults"", ""current_fiscal_year"", self.name)
			frappe.db.set_single_value(
				""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
			frappe.db.set_single_value(""Selling Settings"", ""validate_selling_price"", 0)
			frappe.db.set_single_value(""Selling Settings"", ""validate_selling_price"", 1)
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1)
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_single_value(""Accounts Settings"", ""post_change_gl_entries"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""post_change_gl_entries"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", old_negative_stock)
		frappe.db.set_single_value(""Accounts Settings"", ""enable_common_party_accounting"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""enable_common_party_accounting"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", add_days(getdate(), 1))
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", None)
		frappe.db.set_single_value(""Accounts Settings"", ""over_billing_allowance"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""over_billing_allowance"", over_billing_allowance)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", getdate(""2019-01-31""))
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", None)
		frappe.db.set_single_value(""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1)
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_single_value(""Shopping Cart Settings"", ""enabled"", 0)
	frappe.db.set_single_value(""Accounts Settings"", ""book_asset_depreciation_entry_automatically"", 1)
	frappe.db.set_single_value(""Accounts Settings"", ""book_asset_depreciation_entry_automatically"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""over_billing_allowance"", 0)
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Selling Settings"", ""maintain_same_sales_rate"", 1)
		frappe.db.set_single_value(""Buying Settings"", ""maintain_same_rate"", 1)
		frappe.db.set_single_value(""Buying Settings"", ""supp_master_name"", ""Naming Series"")
		frappe.db.set_single_value(""Buying Settings"", ""supp_master_name"", ""Supplier Name"")
	frappe.db.set_single_value(
		""Buying Settings"", ""backflush_raw_materials_of_subcontract_based_on"", based_on
		frappe.db.set_single_value(""CRM Settings"", ""carry_forward_communication_and_comments"", 1)
		frappe.db.set_single_value(""E Commerce Settings"", ""save_quotations_as_draft"", 0)
		frappe.db.set_single_value(""Plaid Settings"", ""enabled"", 0)
		frappe.db.set_single_value(
			""Manufacturing Settings"", {""disable_capacity_planning"": 0, ""capacity_planning_for_days"": 1}
			frappe.db.set_single_value(""Manufacturing Settings"", {""capacity_planning_for_days"": 30})
		frappe.db.set_single_value(""Manufacturing Settings"", ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_single_value(""Manufacturing Settings"", ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_single_value(""Manufacturing Settings"", ""make_serial_no_batch_from_work_order"", 1)
		frappe.db.set_single_value(""Manufacturing Settings"", ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_single_value(""Manufacturing Settings"", ""material_consumption"", 1)
		frappe.db.set_single_value(""Manufacturing Settings"", ""material_consumption"", 0)
		frappe.db.set_single_value(""Manufacturing Settings"", ""material_consumption"", 0)
		frappe.db.set_single_value(
		frappe.db.set_single_value(""Manufacturing Settings"", ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_single_value(
		frappe.db.set_single_value(""Manufacturing Settings"", ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_single_value(
		frappe.db.set_single_value(
		frappe.db.set_single_value(
		frappe.db.set_single_value(
	frappe.db.set_single_value(
		""Buying Settings"", ""backflush_raw_materials_of_subcontract_based_on"", ""BOM""
	frappe.db.set_single_value(""Accounts Settings"", ""over_delivery_receipt_allowance"", qty_allowance)
	frappe.db.set_single_value(
		""Accounts Settings"", ""automatically_process_deferred_accounting_entry"", 1
	frappe.db.set_single_value(""Homepage"", ""hero_section_based_on"", ""Default"")
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", None)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", acc_frozen_upto)
			frappe.db.set_single_value(doctype, ""enable_discount_accounting"", 1, update_modified=False)
		frappe.db.set_single_value(
		frappe.db.set_single_value(""Selling Settings"", ""cust_master_name"", ""Naming Series"")
		frappe.db.set_single_value(""Selling Settings"", ""cust_master_name"", ""Customer Name"")
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", cls.unlink_setting
		frappe.db.set_single_value(""Stock Settings"", ""default_warehouse"", ""_Test Warehouse - _TC"")
		frappe.db.set_single_value(""Stock Settings"", ""default_warehouse"", old_stock_settings_value)
		frappe.db.set_single_value(""Stock Settings"", ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""auto_insert_price_list_rate_if_missing"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
	frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""stale_days"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""stale_days"", 1)
	frappe.db.set_single_value(""System Settings"", ""app_name"", ""ERPNext"")
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(
			""Stock Settings"", ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""mr_qty_allowance"", 20)
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
	frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_single_value(""Stock Settings"", ""action_if_quality_inspection_is_rejected"", ""Warn"")
		frappe.db.set_single_value(""Stock Settings"", ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""auto_indent"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""auto_indent"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""stock_auth_role"", """")
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto"", add_days(nowdate(), 5))
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto"", """")
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto_days"", -1)
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto_days"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(
			""Stock Settings"", ""role_allowed_to_create_edit_back_dated_transactions"", ""Stock Manager""
			frappe.db.set_single_value(
				""Stock Settings"", ""role_allowed_to_create_edit_back_dated_transactions"", None
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""clean_description_html"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(
			""Stock Settings"", ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Exotel Settings"", ""enabled"", 1)",bug-free
"		frappe.db.set_value(""Global Defaults"", None, ""current_fiscal_year"", self.name)
			frappe.db.set_value(
				""Accounts Settings"", ""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
			frappe.db.set_value(""Selling Settings"", None, ""validate_selling_price"", 0)
			frappe.db.set_value(""Selling Settings"", ""Selling Settings"", ""validate_selling_price"", 1)
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1
		)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_value(""Accounts Settings"", None, ""post_change_gl_entries"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""post_change_gl_entries"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", old_negative_stock)
		frappe.db.set_value(""Accounts Settings"", None, ""enable_common_party_accounting"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""enable_common_party_accounting"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", add_days(getdate(), 1))
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", None)
		frappe.db.set_value(""Accounts Settings"", None, ""over_billing_allowance"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""over_billing_allowance"", over_billing_allowance)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", getdate(""2019-01-31""))
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", None)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1
		)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_value(""Shopping Cart Settings"", None, ""enabled"", 0)
	frappe.db.set_value(""Accounts Settings"", None, ""book_asset_depreciation_entry_automatically"", 1)
	frappe.db.set_value(""Accounts Settings"", None, ""book_asset_depreciation_entry_automatically"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""over_billing_allowance"", 0)
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(""Selling Settings"", None, ""maintain_same_sales_rate"", 1)
		frappe.db.set_value(""Buying Settings"", None, ""maintain_same_rate"", 1)
		frappe.db.set_value(""Buying Settings"", None, ""supp_master_name"", ""Naming Series"")
		frappe.db.set_value(""Buying Settings"", None, ""supp_master_name"", ""Supplier Name"")
	frappe.db.set_value(
		""Buying Settings"", None, ""backflush_raw_materials_of_subcontract_based_on"", based_on
		frappe.db.set_value(
			""CRM Settings"", ""CRM Settings"", ""carry_forward_communication_and_comments"", 1
		)
		frappe.db.set_value(""E Commerce Settings"", None, ""save_quotations_as_draft"", 0)
		frappe.db.set_value(""Plaid Settings"", None, ""enabled"", 0)
		frappe.db.set_value(
			""Manufacturing Settings"",
			None,
			{""disable_capacity_planning"": 0, ""capacity_planning_for_days"": 1},
			frappe.db.set_value(""Manufacturing Settings"", None, {""capacity_planning_for_days"": 30})
		frappe.db.set_value(""Manufacturing Settings"", None, ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_value(""Manufacturing Settings"", None, ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_value(""Manufacturing Settings"", None, ""make_serial_no_batch_from_work_order"", 1)
		frappe.db.set_value(""Manufacturing Settings"", None, ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_value(""Manufacturing Settings"", None, ""material_consumption"", 1)
		frappe.db.set_value(""Manufacturing Settings"", None, ""material_consumption"", 0)
		frappe.db.set_value(""Manufacturing Settings"", None, ""material_consumption"", 0)
		frappe.db.set_value(
			None,
		frappe.db.set_value(""Manufacturing Settings"", None, ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_value(
			None,
		frappe.db.set_value(""Manufacturing Settings"", None, ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_value(
			None,
		frappe.db.set_value(
			None,
		frappe.db.set_value(
			None,
		frappe.db.set_value(
			None,
	frappe.db.set_value(
		""Buying Settings"", None, ""backflush_raw_materials_of_subcontract_based_on"", ""BOM""
	frappe.db.set_value(""Accounts Settings"", None, ""over_delivery_receipt_allowance"", qty_allowance)
	frappe.db.set_value(
		""Accounts Settings"", None, ""automatically_process_deferred_accounting_entry"", 1
	frappe.db.set_value(""Homepage"", ""Homepage"", ""hero_section_based_on"", ""Default"")
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", None)
		frappe.db.set_value(""Accounts Settings"", None, ""acc_frozen_upto"", acc_frozen_upto)
			frappe.db.set_value(doctype, doctype, ""enable_discount_accounting"", 1, update_modified=False)
		frappe.db.set_value(
			""CRM Settings"",
		frappe.db.set_value(""Selling Settings"", None, ""cust_master_name"", ""Naming Series"")
		frappe.db.set_value(""Selling Settings"", None, ""cust_master_name"", ""Customer Name"")
		frappe.db.set_value(
			""Accounts Settings"",
			""Accounts Settings"",
			""unlink_advance_payment_on_cancelation_of_order"",
			cls.unlink_setting,
		frappe.db.set_value(""Stock Settings"", None, ""default_warehouse"", ""_Test Warehouse - _TC"")
		frappe.db.set_value(""Stock Settings"", None, ""default_warehouse"", old_stock_settings_value)
		frappe.db.set_value(""Stock Settings"", None, ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""auto_insert_price_list_rate_if_missing"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
		frappe.db.set_value(
			""Accounts Settings"", ""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
	frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""stale_days"", 1)
		frappe.db.set_value(""Accounts Settings"", None, ""allow_stale"", 0)
		frappe.db.set_value(""Accounts Settings"", None, ""stale_days"", 1)
	frappe.db.set_value(""System Settings"", None, ""app_name"", ""ERPNext"")
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(
			""Stock Settings"", None, ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""mr_qty_allowance"", 20)
		frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
	frappe.db.set_value(""Buying Settings"", None, ""allow_multiple_items"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_value(""Stock Settings"", None, ""action_if_quality_inspection_is_rejected"", ""Warn"")
		frappe.db.set_value(""Stock Settings"", None, ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""auto_indent"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""auto_indent"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""stock_auth_role"", """")
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto"", add_days(nowdate(), 5))
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto"", """")
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto_days"", -1)
		frappe.db.set_value(""Stock Settings"", None, ""stock_frozen_upto_days"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(
			""Stock Settings"", None, ""role_allowed_to_create_edit_back_dated_transactions"", ""Stock Manager""
			frappe.db.set_value(
				""Stock Settings"", None, ""role_allowed_to_create_edit_back_dated_transactions"", None
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(""Stock Settings"", None, ""clean_description_html"", 0)
		frappe.db.set_value(""Stock Settings"", None, ""allow_negative_stock"", 1)
		frappe.db.set_value(
			""Stock Settings"", None, ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Support Settings"", None, ""track_service_level_agreement"", 1)
		frappe.db.set_value(""Exotel Settings"", ""Exotel Settings"", ""enabled"", 1)",buggy
"		frappe.db.set_single_value(""Global Defaults"", ""current_fiscal_year"", self.name)
			frappe.db.set_single_value(
				""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
			frappe.db.set_single_value(""Selling Settings"", ""validate_selling_price"", 0)
			frappe.db.set_single_value(""Selling Settings"", ""validate_selling_price"", 1)
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1)
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_single_value(""Accounts Settings"", ""post_change_gl_entries"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""post_change_gl_entries"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", old_negative_stock)
		frappe.db.set_single_value(""Accounts Settings"", ""enable_common_party_accounting"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""enable_common_party_accounting"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", add_days(getdate(), 1))
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", None)
		frappe.db.set_single_value(""Accounts Settings"", ""over_billing_allowance"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""over_billing_allowance"", over_billing_allowance)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", getdate(""2019-01-31""))
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", None)
		frappe.db.set_single_value(""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", 1)
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_payment_on_cancel_of_invoice"", unlink_enabled
		frappe.db.set_single_value(""Shopping Cart Settings"", ""enabled"", 0)
	frappe.db.set_single_value(""Accounts Settings"", ""book_asset_depreciation_entry_automatically"", 1)
	frappe.db.set_single_value(""Accounts Settings"", ""book_asset_depreciation_entry_automatically"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""over_billing_allowance"", 0)
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Selling Settings"", ""maintain_same_sales_rate"", 1)
		frappe.db.set_single_value(""Buying Settings"", ""maintain_same_rate"", 1)
		frappe.db.set_single_value(""Buying Settings"", ""supp_master_name"", ""Naming Series"")
		frappe.db.set_single_value(""Buying Settings"", ""supp_master_name"", ""Supplier Name"")
	frappe.db.set_single_value(
		""Buying Settings"", ""backflush_raw_materials_of_subcontract_based_on"", based_on
		frappe.db.set_single_value(""CRM Settings"", ""carry_forward_communication_and_comments"", 1)
		frappe.db.set_single_value(""E Commerce Settings"", ""save_quotations_as_draft"", 0)
		frappe.db.set_single_value(""Plaid Settings"", ""enabled"", 0)
		frappe.db.set_single_value(
			""Manufacturing Settings"", {""disable_capacity_planning"": 0, ""capacity_planning_for_days"": 1}
			frappe.db.set_single_value(""Manufacturing Settings"", {""capacity_planning_for_days"": 30})
		frappe.db.set_single_value(""Manufacturing Settings"", ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_single_value(""Manufacturing Settings"", ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_single_value(""Manufacturing Settings"", ""make_serial_no_batch_from_work_order"", 1)
		frappe.db.set_single_value(""Manufacturing Settings"", ""make_serial_no_batch_from_work_order"", 0)
		frappe.db.set_single_value(""Manufacturing Settings"", ""material_consumption"", 1)
		frappe.db.set_single_value(""Manufacturing Settings"", ""material_consumption"", 0)
		frappe.db.set_single_value(""Manufacturing Settings"", ""material_consumption"", 0)
		frappe.db.set_single_value(
		frappe.db.set_single_value(""Manufacturing Settings"", ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_single_value(
		frappe.db.set_single_value(""Manufacturing Settings"", ""backflush_raw_materials_based_on"", ""BOM"")
		frappe.db.set_single_value(
		frappe.db.set_single_value(
		frappe.db.set_single_value(
		frappe.db.set_single_value(
	frappe.db.set_single_value(
		""Buying Settings"", ""backflush_raw_materials_of_subcontract_based_on"", ""BOM""
	frappe.db.set_single_value(""Accounts Settings"", ""over_delivery_receipt_allowance"", qty_allowance)
	frappe.db.set_single_value(
		""Accounts Settings"", ""automatically_process_deferred_accounting_entry"", 1
	frappe.db.set_single_value(""Homepage"", ""hero_section_based_on"", ""Default"")
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", None)
		frappe.db.set_single_value(""Accounts Settings"", ""acc_frozen_upto"", acc_frozen_upto)
			frappe.db.set_single_value(doctype, ""enable_discount_accounting"", 1, update_modified=False)
		frappe.db.set_single_value(
		frappe.db.set_single_value(""Selling Settings"", ""cust_master_name"", ""Naming Series"")
		frappe.db.set_single_value(""Selling Settings"", ""cust_master_name"", ""Customer Name"")
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", cls.unlink_setting
		frappe.db.set_single_value(""Stock Settings"", ""default_warehouse"", ""_Test Warehouse - _TC"")
		frappe.db.set_single_value(""Stock Settings"", ""default_warehouse"", old_stock_settings_value)
		frappe.db.set_single_value(""Stock Settings"", ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""auto_insert_price_list_rate_if_missing"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""auto_insert_price_list_rate_if_missing"", 1)
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
		frappe.db.set_single_value(
			""Accounts Settings"", ""unlink_advance_payment_on_cancelation_of_order"", 0
	frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""stale_days"", 1)
		frappe.db.set_single_value(""Accounts Settings"", ""allow_stale"", 0)
		frappe.db.set_single_value(""Accounts Settings"", ""stale_days"", 1)
	frappe.db.set_single_value(""System Settings"", ""app_name"", ""ERPNext"")
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(
			""Stock Settings"", ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""mr_qty_allowance"", 20)
		frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
	frappe.db.set_single_value(""Buying Settings"", ""allow_multiple_items"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_single_value(""Stock Settings"", ""action_if_quality_inspection_is_rejected"", ""Warn"")
		frappe.db.set_single_value(""Stock Settings"", ""action_if_quality_inspection_is_rejected"", ""Stop"")
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""auto_indent"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""auto_indent"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""stock_auth_role"", """")
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto"", add_days(nowdate(), 5))
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto"", """")
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto_days"", -1)
		frappe.db.set_single_value(""Stock Settings"", ""stock_frozen_upto_days"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(
			""Stock Settings"", ""role_allowed_to_create_edit_back_dated_transactions"", ""Stock Manager""
			frappe.db.set_single_value(
				""Stock Settings"", ""role_allowed_to_create_edit_back_dated_transactions"", None
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(""Stock Settings"", ""clean_description_html"", 0)
		frappe.db.set_single_value(""Stock Settings"", ""allow_negative_stock"", 1)
		frappe.db.set_single_value(
			""Stock Settings"", ""allow_negative_stock"", existing_allow_negative_stock
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Support Settings"", ""track_service_level_agreement"", 1)
		frappe.db.set_single_value(""Exotel Settings"", ""enabled"", 1)",bug-free
